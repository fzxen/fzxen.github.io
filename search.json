[{"title":"架构整洁之道","url":"/posts/a8730dfb.html","content":"\n# Part1. INTRODUCTION 概述\n\nIt doesn’t take a huge amount of knowledge and skill to get a program working. Kids in high school do it all the time. Young men and women in college start billion-dollar businesses based on scrabbling together a few lines of PHP or Ruby. Hoards of junior programmers in cube farms around the world slog through massive requirements documents held in huge issue tracking systems to get their systems to “work” by the sheer brute force of will. The code they produce may not be pretty; but it works. It works because getting something to work—once—just isn’t that hard.\n\n> 编写并调试一段代码直到成功运行并不需要特别高深的知识和技能，现在的一名普通高中生都可以做到。有的大学生甚至通过拼凑一些 PHP 或 Ruby 代码就可以 创办一个市值 10 亿美元的公司。想象一下，世界上有成群的初级程序员挤在大公司的隔板间里，日复一日地用蛮力将记录在大型问题跟踪系统里的巨型需求文档一点点转化为能实际运行的代码。他们写出的代码可能不够优美，但是确实能够正常工作。因为创造一个能正常运行的系统——哪怕只成功运行一次——还真不是一件特别困难的事。\n\nGetting it right is another matter entirely. Getting software right is hard. It takes knowledge and skills that most young programmers haven’t yet acquired. It requires thought and insight that most programmers don’t take the time to develop. It requires a level of discipline and dedication that most programmers never dreamed they’d need. Mostly, it takes a passion for the craft and the desire to be a professional.\n\n> 但是将软件架构设计做好就完全另当别论了。软件架构设计是一件非常困难的情，这通常需要大多数程序员所不具备的经验和技能。同时，也不是所有人都愿意花时间来学习和钻研这个方向。做一个好的软件架构师所需要的自律和专注程度可能会让大部分程序员始料未及，更别提软件架构师这个职业本身的社会认同感与人们投身其中的热情了。\n\nAnd when you get software right, something magical happens: You don’t need hordes of programmers to keep it working. You don’t need massive requirements documents and huge issue tracking systems. You don’t need global cube farms and 24/7 programming.\n\n> 但是，一旦将软件架构做好了，你就会立即体会到其中的奥妙：维持系统正常运转再也不需要成群的程序员了；每个变更的实施也不再需要巨大的需求文档和复杂的任务追踪系统了；程序员们再也不用缩在全球各地的隔板间里，24 x 7（即每天 24 小时，每星期 7 天）地疯狂加班了。\n\nWhen software is done right, it requires a fraction of the human resources to create and maintain. Changes are simple and rapid. Defects are few and far between. Effort is minimized, and functionality and flexibility are maximized.\n\n> 采用好的软件架构可以大大节省软件项目构建与维护的人力成本。让每次变更都短小简单，易于实施，并且避免缺陷，用最小的成本，最大程度地满足功能性和灵活性的要求。\n\nYes, this vision sounds a bit utopian. But I’ve been there; I’ve seen it happen. I’ve worked in projects where the design and architecture of the system made it easy to write and easy to maintain. I’ve experienced projects that required a fraction of the anticipated human resources. I’ve worked on systems that had extremely low defect rates. I’ve seen the extraordinary effect that good software architecture can have on a system, a project, and a team. I’ve been to the promised land.\n\n> 是的，这可能有点像童话故事一样不可信，但是这些又确实是我的亲身经历。我曾经见过因为采用了好的软件架构设计，使得整个系统构建更简单、维护更容易的情况。我也见过因为采用了好的软件架构设计，整个项目最终比预计所使用的人力资源更少，而且更快地完成了。我真真切切地体会过，好的软件架构设计为整个系统所带来的翻天覆地的变化，绝不忽悠。\n\nBut don’t take my word for it. Look at your own experience. Have you experienced the opposite? Have you worked on systems that are so interconnected and intricately coupled that every change, regardless of how trivial, takes weeks and involves huge risks? Have you experienced the impedance of bad code and rotten design? Has the design of the systems you’ve worked on had a huge negative effect on the morale of the team, the trust of the customers, and the patience of the managers? Have you seen teams, departments, and even companies that have been brought down by the rotten structure of their software? Have you been to programming hell?\n\n> 请读者回头想想自己的亲身经历，你肯定经历过这样的情境：某个系统因为其组件错综复杂，相互耦合紧密，而导致不管多么小的改动都需要数周的恶战才能完成。又或是某个系统中到处充满了腐朽的设计和连篇累牍的恶心代码，处处都是障碍。再或者，你有没有见过哪个系统的设计如此之差，让整个团队的士气低落，客户天天痛苦，项目经理们手足无措？你有没有见过某个软件系统因其架构腐朽不堪.而导致团队流失，部门解散，甚至公司倒闭？作为一名程序员，你在编程时体会过那种生不如死的感觉吗?\n\nI have—and to some extent, most of the rest of us have, too. It is far more common to fight your way through terrible software designs than it is to enjoy the pleasure of working with a good one.\n\n> 以上这些我也都切身体会过。我相信绝大部分读者也或多或少会有共鸣。好的软件架构太难得了，我们职业生涯的大部分时间可能都在和差的架构做斗争，而没有机会一睹优美的架构究竟是什么样子。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap1. WHAT IS DESIGN AND ARCHITECTURE? 设计与架构到底是什么\n\n![](../../images/books/架构整洁之道/CH-UN01.jpg)\n\nThere has been a lot of confusion about design and architecture over the years. What is design? What is architecture? What are the differences between the two?\n\n> 一直以来，设计（Design）与架构（Architecture）这两个概念让大多数人十分迷惑——什么是设计？什么是架构？二者究竟有什么区别？\n\nOne of the goals of this book is to cut through all that confusion and to define, once and for all, what design and architecture are. For starters, I’ll assert that there is no difference between them. None at all.\n\n> 本书的一个重要的目标就是要清晰、明确地对二者进行定义。首先我要明确地说，二者没有任何区别。一丁点区别都没有！\n\nThe word “architecture” is often used in the context of something at a high level that is divorced from the lower-level details, whereas “design” more often seems to imply structures and decisions at a lower level. But this usage is nonsensical when you look at what a real architect does.\n\n> “架构”这个词往往使用于“高层级”的讨论中。这类讨论一般都把“底层”的实现细节排除在外。而“设计”一词，往往用来指代具体的系统底层组织结构和实现的细节。但是，从一个真正的系统架构师的日常工作来看，这样的区分是根本不成立的。\n\nConsider the architect who designed my new home. Does this home have an architecture? Of course it does. And what is that architecture? Well, it is the shape of the home, the outward appearance, the elevations, and the layout of the spaces and rooms. But as I look through the diagrams that my architect produced, I see an immense number of low-level details. I see where every outlet, light switch, and light will be placed. I see which switches control which lights. I see where the furnace is placed, and the size and placement of the water heater and the sump pump. I see detailed depictions of how the walls, roofs, and foundations will be constructed.\n\n> 以给我设计新房子的建筑设计师要做的事情为例。新房子当然是存在着既定架构的，但这个架构具体包含哪些内容呢？首先，它应该包括房屋的形状、外观设计、垂直高度、房间的布局，等等。但是，如果查看建筑设计师使用的图纸，会发现其中也充斥着大量的设计细节。譬如，我们可以看到每个插座、开关以及每个电灯具体的安装位置，同时也可以看到某个开关与所控制的电灯的具体连接信息；我们也能看到壁炉的具体安装位置，热水器的大小和位置信息，甚至是污水泵的位置；同时也可以看到关于墙体、屋顶和地基都有非常详细的建造说明。\n\nIn short, I see all the little details that support all the high-level decisions. I also see that those low-level details and high-level decisions are part of the whole design of the house.\n\n> 总的来说，架构图里实际上包含了所有的底层设计细节，这些细节信息共同支撑了顶层的架构设计，底层设计信息和顶层架构设计共同组成了整个房屋的架构文档。\n\nAnd so it is with software design. The low-level details and the high-level structure are all part of the same whole. They form a continuous fabric that defines the shape of the system. You can’t have one without the other; indeed, no clear dividing line separates them. There is simply a continuum of decisions from the highest to the lowest levels.\n\n> 软件设计也是如此。底层设计细节和高层架构信息是不可分割的。它们组合在一起，共同定义了整个软件系统，缺一不可。所谓的底层和高层本身就是一系列决策组成的连续体，并没有清晰的分界线。\n\n## THE GOAL? 目标是什么\n\nAnd the goal of those decisions? The goal of good software design? That goal is nothing less than my utopian description:\n\n> 所有这些决策的终极目标是什么呢？ 一个好的软件设计的终极目标是什么呢？就像我之前描述过的：\n\nThe goal of software architecture is to minimize the human resources required to build and maintain the required system.\n\n> 软件架构的终极目标是，用最小的人力成本来满足构建和维护该系统的需求。\n\nThe measure of design quality is simply the measure of the effort required to meet the needs of the customer. If that effort is low, and stays low throughout the lifetime of the system, the design is good. If that effort grows with each new release, the design is bad. It’s as simple as that.\n\n> 一个软件架构的优劣，可以用它满足用户需求所需要的成本来衡量。如果该成本很低，并且在系统的整个生命周期内一直都能维持这样的低成本，那么这个系统的设计就是优良的。如果该系统的每次发布都会提升下一次变更的成本，那么这个设计就是不好的。就这么简单。\n\n## CASE STUDY 案例分析\n\nAs an example, consider the following case study. It includes real data from a real company that wishes to remain anonymous.\n\n> 下面来看一个真实案例，该案例中的数据均来源于一个要求匿名的真实公司。\n\nFirst, let’s look at the growth of the engineering staff. I’m sure you’ll agree that this trend is very encouraging. Growth like that shown in Figure 1.1 must be an indication of significant success!\n\n> 首先，我们来看一下工程师团队规模的增长。你肯定认为这个增长趋势是特别可喜的，像图 1.1 中的这种增长线条一定是公司业务取得巨大成功的直观体现。\n\n<Figures figure=\"1-1\">Growth of the engineering staff</Figures>\n\nReproduced with permission from a slide presentation by Jason Gorman\n\nNow let’s look at the company’s productivity over the same time period, as measured by simple lines of code (Figure 1.2).\n\n> 现在再让我们来看一下整个公司同期的生产效率（productivity），这里用简单的代码行数作为指标（参见图 1.2）。\n\n<Figures figure=\"1-2\">Productivity over the same period of time</Figures>\n\nClearly something is going wrong here. Even though every release is supported by an ever-increasing number of developers, the growth of the code looks like it is approaching an asymptote.\n\n> 这明显是有问题的。伴随着产品的每次发布，公司的工程师团队在持续不断地扩展壮大，但是仅从代码行数的增长来看，该产品却正在逐渐陷入困境。\n\nNow here’s the really scary graph: Figure 1.3 shows how the cost per line of code has changed over time.\n\n> 还有更可怕的：图 1.3 展示的是同期内每行代码的变更成本。\n\nThese trends aren’t sustainable. It doesn’t matter how profitable the company might be at the moment: Those curves will catastrophically drain the profit from the business model and drive the company into a stall, if not into a downright collapse.\n\n> 显然，图中展示的趋势是不可持续的。不管公司现在的利润率有多高，图中线条表明，按这个趋势下去，公司的利润会被一点点榨干，整个公司会因此陷入困境，甚至直接关门倒闭。\n\nWhat caused this remarkable change in productivity? Why was the code 40 times more expensive to produce in release 8 as opposed to release 1?\n\n> 究竟是什么因素造成生产力的大幅变化呢？为什么第 8 代产品的构建成本要 比第 1 代产品高 40 倍？\n\n<Figures figure=\"1-3\">Cost per line of code over time</Figures>\n\n### THE SIGNATURE OF A MESS 乱麻系统的特点\n\nWhat you are looking at is the signature of a mess. When systems are thrown together in a hurry, when the sheer number of programmers is the sole driver of output, and when little or no thought is given to the cleanliness of the code or the structure of the design, then you can bank on riding this curve to its ugly end.\n\n> 我们在这里看到的是一个典型的乱麻系统。这种系统一般都是没有经过设计，匆匆忙忙被构建起来的。然后为了加快发布的速度，拼命地往团队里加入新人，同时加上决策层对代码质量提升和设计结构优化存在着持续的、长久的忽视，这种状态能持续下去就怪了。\n\nFigure 1.4 shows what this curve looks like to the developers. They started out at nearly 100% productivity, but with each release their productivity declined. By the fourth release, it was clear that their productivity was going to bottom out in an asymptotic approach to zero.\n\n> 图 1.4 展示了系统开发者的切身体会。他们一开始的效率都接近 100%，然而伴随着每次产品的发布，他们的生产力直线下降。到了产品的第 4 版本时，很明显大家的生产力已经不可避免地趋近为零了。\n\n<Figures figure=\"1-4\">Productivity by release</Figures>\n\nFrom the developers’ point of view, this is tremendously frustrating, because everyone is working hard. Nobody has decreased their effort.\n\n> 对系统的开发者来说，这会带来很大的挫败感，因为团队中并没有人偷懒，每个人还都是和之前一样在拼命工作。\n\nAnd yet, despite all their heroics, overtime, and dedication, they simply aren’t getting much of anything done anymore. All their effort has been diverted away from features and is now consumed with managing the mess. Their job, such as it is, has changed into moving the mess from one place to the next, and the next, and the next, so that they can add one more meager little feature.\n\n> 然而，不管他们投入了多少个人时间，救了多少次火，加了多少次班，他们的产出始终上不去。工程师的大部分时间都消耗在对现有系统的修修补补上，而不是真正完成实际的新功能。这些工程师真正的任务是：拆了东墙补西墙，周而往复，偶尔有精力能顺便实现一点小功能。\n\n### THE EXECUTIVE VIEW 管理层视角\n\nIf you think that’s bad, imagine what this picture looks like to the executives! Consider Figure 1.5, which depicts monthly development payroll for the same period.\n\n> 如果你觉得开发者们这样就已经够苦了，那么就再想想公司髙管们的感受吧! 请看图 1.5，该部门月工资同期图。\n\n<Figures figure=\"1-5\">Monthly development payroll by release</Figures>\n\nRelease 1 was delivered with a monthly payroll of a few hundred thousand dollars. The second release cost a few hundred thousand more. By the eighth release monthly payroll was `$20` million, and climbing.\n\n> 如你所见，产品的第 1 版是在月总工资 10 万美元左右的时候上线的。第 2 版又花掉了几十万美元。当发布第 8 版的时候，部门月工资已经达到了 2 千万美元，而且还在持续上升。\n\nJust this chart alone is scary. Clearly something startling is happening. One hopes that revenues are outpacing costs and therefore justifying the expense. But no matter how you look at this curve, it’s cause for concern.\n\n> 也许我们可以指望该公司的营收增长远远超出成本增长，这样公司就还能维持正常运转。但是这么惊人的曲线还是值得我们深入挖掘其中存在的巨大问题的。\n\nBut now compare the curve in Figure 1.5 with the lines of code written per release in Figure 1.2. That initial few hundred thousand dollars per month bought a lot of functionality—but the final `$20` million bought almost nothing! Any CFO would look at these two graphs and know that immediate action is necessary to stave off disaster.\n\n> 现在，只要将图 1.5 的月工资曲线和图 1.2 的每次发布代码行数曲线对比一下，任何一个理性的 CEO 都会一眼看出其中的问题：最开始的十几万美元工资给公司带来了很多新功能、新收益，而最后的 2 千万美元几乎全打了水漂。应立刻采取行动解决这个问题，刻不容缓。\n\nBut which action can be taken? What has gone wrong? What has caused this incredible decline in productivity? What can executives do, other than to stamp their feet and rage at the developers?\n\n> 但是具体采取什么样的行动才能解决问题呢？究竟问题出在哪里？是什么造成了工程师生产力的直线下降？高管们除了跺脚、发飙，还能做什么呢？\n\n### WHAT WENT WRONG? 问题到底在哪里\n\nNearly 2600 years ago, Aesop told the story of the Tortoise and the Hare. The moral of that story has been stated many times in many different ways:\n\n> 大约 2600 年前，《伊索寓言》里写到了龟兔赛跑的故事。这个故事的主题思想可以归纳为以下几种：\n\n- “Slow and steady wins the race.”\n- “The race is not to the swift, nor the battle to the strong.”\n- “The more haste, the less speed.”\n\n---\n\n> 1. 慢但是稳，是成功的秘诀。\n> 2. 该比赛并不是拼谁开始跑得快，也不是拼谁更有力气的。\n> 3. 心态越急，反而跑得越慢。\n\nThe story itself illustrates the foolishness of overconfidence. The Hare, so confident in its intrinsic speed, does not take the race seriously, and so naps while the Tortoise crosses the finish line.\n\n> 这个故事本身揭露的是过度自信的愚蠢行为。兔子由于对自己速度的过度自信，没有把乌龟当回事，结果乌龟爬过终点线取得胜利的时候，它还在睡觉。\n\nModern developers are in a similar race, and exhibit a similar overconfidence. Oh, they don’t sleep—far from it. Most modern developers work their butts off. But a part of their brain does sleep—the part that knows that good, clean, well-designed code matters.\n\n> 这和现代软件研发工作有点类似，现在的软件研发工程师都有点过于自信。哦，当然，他们确实不会偷懒，一点也不。但是他们真正偷懒的地方在于——持续低估那些好的、良好设计的、整洁的代码的重要性。\n\nThese developers buy into a familiar lie: “We can clean it up later; we just have to get to market first!” Of course, things never do get cleaned up later, because market pressures never abate. Getting to market first simply means that you’ve now got a horde of competitors on your tail, and you have to stay ahead of them by running as fast as you can.\n\n> 这些工程师们普遍用一句话来欺骗自己：“我们可以未来再重构代码，产品上线最重要！”但是结果大家都知道，产品上线以后重构工作就再没人提起了。市场的压力永远也不会消退，作为首先上市的产品，后面有无数的竞争对手追赶，必须要比他们跑得更快才能保持领先。\n\nAnd so the developers never switch modes. They can’t go back and clean things up because they’ve got to get the next feature done, and the next, and the next, and the next. And so the mess builds, and productivity continues its asymptotic approach toward zero.\n\n> 所以，重构的时机永远不会再有了。工程师们忙于完成新功能，新功能做不完，哪有时间重构老的代码？循环往复，系统成了一团乱麻，主产效率持续直线下降，直至为零。\n\nJust as the Hare was overconfident in its speed, so the developers are overconfident in their ability to remain productive. But the creeping mess of code that saps their productivity never sleeps and never relents. If given its way, it will reduce productivity to zero in a matter of months.\n\n> 结果就像龟兔赛跑中过于自信的兔子一样，软件研发工程师们对自己保持高产出的能力过于自信了。但是乱成一团的系统代码可没有休息时间，也不会放松。如果不严加提防，在几个月之内，整个研发团队就会陷入困境。\n\nThe bigger lie that developers buy into is the notion that writing messy code makes them go fast in the short term, and just slows them down in the long term. Developers who accept this lie exhibit the hare’s overconfidence in their ability to switch modes from making messes to cleaning up messes sometime in the future, but they also make a simple error of fact. The fact is that making messes is always slower than staying clean, no matter which time scale you are using.\n\n> 工程师们经常相信的另外一个错误观点是： “在工程中容忍糟糕的代码存在可以在短期内加快该工程上线的速度，未来这些代码会造成一些额外的工作量，但是并没有什么大不了。”相信这些鬼话的工程师对自己清理乱麻代码的能力过于自信了。但是更重要的是，他们还忽视了一个自然规律：无论是从短期还是长期来看，胡乱编写代码的工作速度其实比循规蹈矩更慢。\n\nConsider the results of a remarkable experiment performed by Jason Gorman depicted in Figure 1.6. Jason conducted this test over a period of six days. Each day he completed a simple program to convert integers into Roman numerals. He knew his work was complete when his predefined set of acceptance tests passed. Each day the task took a little less than 30 minutes. Jason used a well-known cleanliness discipline named test-driven development (TDD) on the first, third, and fifth days. On the other three days, he wrote the code without that discipline.\n\n> 图 1.6 展示的是 Jason Gorman 进行的一次为期 6 天的实验。在该实验中，Jaosn 每天都编写一段代码，功能是将一个整数转化为相应罗马数字的字符串。当事先定义好的一个测试集完全通过时，即认为当天工作完成。每天实验的时长不超过 30 分钟。第一天、第三天和第五天，Jason 在编写代码的过程中采用了业界知名的优质代码方法论：测试驱动开发（TDD），而其他三天他则直接从头开始编写代码。\n\n<Figures figure=\"1-6\">Time to completion by iterations and use/non-use of TDD</Figures>\n\nFirst, notice the learning curve apparent in Figure 1.6. Work on the latter days is completed more quickly than the former days. Notice also that work on the TDD days proceeded approximately 10% faster than work on the non-TDD days, and that even the slowest TDD day was faster than the fastest non-TDD day.\n\n> 首先，我们要关注的是图 1.6 中那些柱状图。很显然，日子越往后，完成工作所需的时间就越少。同时，我们也可以看到当人们采用了 TDD 方法编程后，一般就会比未采用 TDD 方法编程少用 10%的时间，并且采用 TDD 方法编程时最差的一天也比未采用 TDD 方法编程时最好的一天用时要短。\n\nSome folks might look at that result and think it’s a remarkable outcome. But to those who haven’t been deluded by the Hare’s overconfidence, the result is expected, because they know this simple truth of software development:\n\n> 对于这个结果，有些人可能会觉得挺意外的。但是对常年关注软件开发本质的人来说，它其实揭示了软件开发的一个核心特点：\n\nThe only way to go fast, is to go well.\n\n> 要想跑得快，先要跑得稳。\n\nAnd that’s the answer to the executive’s dilemma. The only way to reverse the decline in productivity and the increase in cost is to get the developers to stop thinking like the overconfident Hare and start taking responsibility for the mess that they’ve made.\n\n> 综上所述，管理层扭转局面的唯一选择就是扭转开发者的观念，让他们从过度自信的兔子模式转变回来，为自己构建的乱麻系统负起责任来。\n\nThe developers may think that the answer is to start over from scratch and redesign the whole system—but that’s just the Hare talking again. The same overconfidence that led to the mess is now telling them that they can build it better if only they can start the race over. The reality is less rosy:\n\n> 当然，某些软件研发工程师可能会认为挽救一个系统的唯一办法是抛弃现有系统，设计一个全新的系统来替代。但是这里仍然没有逃离过度自信。试问：如果是工程师的过度自信导致了目前的一团乱麻，开始，结果就会更好呢？\n\nTheir overconfidence will drive the redesign into the same mess as the original project.\n\n> 那么，我们有什么理由认为让他们从头第 1 章设计与架构究竟是什么过度自信只会使得重构设计陷入和原项目一样的困局中。\n\n## CONCLUSION 本章小结\n\nIn every case, the best option is for the development organization to recognize and avoid its own overconfidence and to start taking the quality of its software architecture seriously.\n\n> 不管怎么看，研发团队最好的选择是清晰地认识并避开工程师们过度自信的特点，开始认真地对待自己的代码架构，对其质量负责。\n\nTo take software architecture seriously, you need to know what good software architecture is. To build a system with a design and an architecture that minimize effort and maximize productivity, you need to know which attributes of system architecture lead to that end.\n\n> 要想提高自己软件架构的质量，就需要先知道什么是优秀的软件架构。而为了在系统构建过程中采用好的设计和架构以便减少构建成本，提高生产力，又需要先了解系统架构的各种属性与成本和生产力的关系。\n\nThat’s what this book is about. It describes what good clean architectures and designs look like, so that software developers can build systems that will have long profitable lifetimes.\n\n> 这就是这本书的主题。本书为读者描述了什么是优秀的、整洁的软件架构与设计，读者可以参考这些设计来构建一个长期稳定的、持久优秀的系统。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap2. A TALE OF TWO VALUES 两个价值维度\n\n![](../../images/books/架构整洁之道/CH-UN02.jpg)\n\nEvery software system provides two different values to the stakeholders: behavior and structure. Software developers are responsible for ensuring that both those values remain high. Unfortunately, they often focus on one to the exclusion of the other. Even more unfortunately, they often focus on the lesser of the two values, leaving the software system eventually valueless.\n\n> 对于每个软件系统，我们都对以通过行为和架构两个维度来休现它的实际价值。软件研发人员应该确保自己的系统在这两个维度上的实际价值都能长时间维持在很高的状态。不幸的是，他们往往只关注一个维度，而忽视了另外一个维度。更不幸的是，他们常常关注的还是错误的维度，这导致了系统的价值最终趋降为零。\n\n## BEHAVIOR 行为价值\n\nThe first value of software is its behavior. Programmers are hired to make machines behave in a way that makes or saves money for the stakeholders. We do this by helping the stakeholders develop a functional specification, or requirements document. Then we write the code that causes the stakeholder’s machines to satisfy those requirements.\n\n> 软件系统的行为是其最直观的价值维度。程序员的工作就是让机器按照某种指定方式运转，给系统的使用者创造或者提高利润。程序员们为了达到这个目的，往往需要帮助系统使用者编写一个对系统功能的定义，也就是需求文档。然后，程序员们再把需求文档转化为实际的代码。\n\nWhen the machine violates those requirements, programmers get their debuggers out and fix the problem.\n\n> 当机器出现异常行为时，程序员要负责调试，解决这些问题。\n\nMany programmers believe that is the entirety of their job. They believe their job is to make the machine implement the requirements and to fix any bugs. They are sadly mistaken.\n\n> 大部分程序员认为这就是他们的全部工作。他们的工作是且仅是：按照需求文档编写代码，并且修复任何 Bug。这真是大错特错。\n\n## ARCHITECTURE 架构价值\n\nThe second value of software has to do with the word “software”—a compound word composed of “soft” and “ware.” The word “ware” means “product”; the word “soft”… Well, that’s where the second value lies.\n\n> 软件系统的第二个价值维度，就体现在软件这个英文单词上：software。“ware” 的意思是“产品”，而 “soft” 的意思，不言而喻，是指软件的灵活性。\n\nSoftware was invented to be “soft.” It was intended to be a way to easily change the behavior of machines. If we’d wanted the behavior of machines to be hard to change, we would have called it hardware.\n\n> 软件系统必须保持灵活。软件发明的目的，就是让我们可以以一种灵活的方式来改变机器的工作行为。对机器上那些很难改变的工作行为，我们通常称之为硬件（hardware）。\n\nTo fulfill its purpose, software must be soft—that is, it must be easy to change. When the stakeholders change their minds about a feature, that change should be simple and easy to make. The difficulty in making such a change should be proportional only to the scope of the change, and not to the shape of the change.\n\n> 为了达到软件的本来目的，软件系统必须够“软” 也就是说，软件应该容易被修改。当需求方改变需求的时候，随之所需的软件变更必须可以简单而方便地实现。变更实施的难度应该和变更的范畴（scope）成等比关系，而与变更的具体形状（shape）无关。\n\nIt is this difference between scope and shape that often drives the growth in software development costs. It is the reason that costs grow out of proportion to the size of the requested changes. It is the reason that the first year of development is much cheaper than the second, and the second year is much cheaper than the third.\n\n> 需求变更的范畴与形状，是决定对应软件变更实施成本高低的关键。这就是为什么有的代码变更的成本与其实现的功能改变不成比例。这也是为什么第二年的研发成本比第一年的高很多，第三年又比第二年更高。\n\nFrom the stakeholders’ point of view, they are simply providing a stream of changes of roughly similar scope. From the developers’ point of view, the stakeholders are giving them a stream of jigsaw puzzle pieces that they must fit into a puzzle of ever-increasing complexity. Each new request is harder to fit than the last, because the shape of the system does not match the shape of the request.\n\n> 从系统相关方（Stakeholder）的角度来看，他们所提出的一系列的变更需求的范畴都是类似的，因此成本也应该是固定的。但是从研发者角度来看，系统用户持续不断的变更需求就像是要求他们不停地用一堆不同形状的拼图块，拼成一个新的形状。整个拼图的过程越来越困难，因为现有系统的形状永远和需求的形状不一致.\n\nI’m using the word “shape” here in a unconventional way, but I think the metaphor is apt. Software developers often feel as if they are forced to jam square pegs into round holes.\n\n> 我们在这里使用了“形状”这个词，这可能不是该词的标准用法，但是其寓意应该很明确。毕竟，软件工程师们经常会觉得自己的工作就是把方螺丝拧到圆螺丝孔里面。\n\nThe problem, of course, is the architecture of the system. The more this architecture prefers one shape over another, the more likely new features will be harder and harder to fit into that structure. Therefore architectures should be as shape agnostic are practical.\n\n> 问题的实际根源当然就是系统的架构设计。如果系统的架构设计偏向某种特定的“形状”，那么新的变更就会越来越难以实施。所以，好的系统架构设计应该尽可能做到与“形状”无关。\n\n## THE GREATER VALUE 哪个价值维度更重要\n\nFunction or architecture? Which of these two provides the greater value? Is it more important for the software system to work, or is it more important for the software system to be easy to change?\n\n> 那么，究竟是系统行为更重要，还是系统架构的灵活性更重要？哪个价值更大?系统正常工作更重要，还是系统易于修改更重要？\n\nIf you ask the business managers, they’ll often say that it’s more important for the software system to work. Developers, in turn, often go along with this attitude. But it’s the wrong attitude. I can prove that it is wrong with the simple logical tool of examining the extremes.\n\n> 如果这个问题由业务部门来回答，他们通常认为系统正常工作很重要。系统开发人员常常也就跟随采取了这种态度。但是这种态度是错误的。下面我就用简单的逻辑推导来证明这个态度的错误性。\n\n- If you give me a program that works perfectly but is impossible to change, then it won’t work when the requirements change, and I won’t be able to make it work. Therefore the program will become useless.\n- If you give me a program that does not work but is easy to change, then I can make it work, and keep it working as requirements change. Therefore the program will remain continually useful.\n\n---\n\n> - 如果某程序可以正常工作，但是无法修改，那么当需求变更的时候它就不再能够正常工作了，我们也无法通过修改让它能继续正常工作。因此，这个程序的价值将成为 0。\n> - 如果某程序目前无法正常工作，但是我们可以很容易地修改它，那么将它改好，并且随着需求变化不停地修改它，都应该是很容易的事。因此，这个程序会持续产生价值。\n\nYou may not find this argument convincing. After all, there’s no such thing as a program that is impossible to change. However, there are systems that are practically impossible to change, because the cost of change exceeds the benefit of change. Many systems reach that point in some of their features or configurations.\n\n> 当然，上面的逻辑论断可能不足以说服大家，修改的。但是，现实中有一些系统确实无法更改，因为其变更实施的成本会远远超过变更带来的价值。你在实际工作中一定遇到过很多这样的例了。\n\nIf you ask the business managers if they want to be able to make changes, they’ll say that of course they do, but may then qualify their answer by noting that the current functionality is more important than any later flexibility. In contrast, if the business managers ask you for a change, and your estimated costs for that change are unaffordably high, the business managers will likely be furious that you allowed the system to get to the point where the change was impractical.\n\n> 如果你问业务部门，是否想要能够变更需求，他们的回答一般是肯定的，而且他们会增加一句：完成现在的功能比实现未来的灵活度更重要。但讽刺的是，如果事后业务部门提出了一项需求，而你的预估工作量大大超出他们的预期，这帮家伙通常会对你放任系统混乱到无法变更的状态而勃然大怒。\n\n## EISENHOWER’S MATRIX 艾森豪威尔矩阵\n\nConsider President Dwight D. Eisenhower’s matrix of importance versus urgency (Figure 2.1). Of this matrix, Eisenhower said:\n\n> 我们来看美国前总统艾森豪威尔的紧急/重要矩阵（参见图 2.1），面对这个矩阵，艾森豪威尔曾说道：\n\nI have two kinds of problems, the urgent and the important. The urgent are not important, and the important are never urgent.1\n\n> 我有两种难题：紧急的和重要的，而紧急的难题永远是不重要的，重要的难题永远是不紧急的。\n\n<Figures figure=\"2-1\">Eisenhower matrix</Figures>\n\nThere is a great deal of truth to this old adage. Those things that are urgent are rarely of great importance, and those things that are important are seldom of great urgency.\n\n> 虽然老调重弹，但其中的道理依然成立。确实，紧急的事情常常没那么重要，而重要的事情则似乎永远也排不上优先级。\n\nThe first value of software—behavior—is urgent but not always particularly important.\n\n> 软件系统的第一个价值维度：系统行为，是紧急的，但是并不总是特别重要。\n\nThe second value of software—architecture—is important but never particularly urgent.\n\n> 软件系统的第二个价值维度：系统架构，是重要的，但是并不总是特别紧急。\n\nOf course, some things are both urgent and important. Other things are not urgent and not important. Ultimately, we can arrange these four couplets into priorities:\n\n> 当然，我们会有些重要且紧急的事情，也会有一些事情不重要也不紧急。最终我们应将这四类事情进行如下排序：\n\n1. Urgent and important\n2. Not urgent and important\n3. Urgent and not important\n4. Not urgent and not important\n\n---\n\n> 1. 重要且紧急\n> 2. 重要不紧急\n> 3. 不重要但紧急\n> 4. 不重要且不紧急\n\nNote that the architecture of the code—the important stuff—is in the top two positions of this list, whereas the behavior of the code occupies the first and third positions.\n\n> 在这里你可以看到，软件的系统架构——那些重要的事情——占据了该列表的前两位，而系统行为——那些紧急的事情——只占据了第一和第三位。\n\nThe mistake that business managers and developers often make is to elevate items in position 3 to position 1. In other words, they fail to separate those features that are urgent but not important from those features that truly are urgent and important. This failure then leads to ignoring the important architecture of the system in favor of the unimportant features of the system.\n\n> 业务部门与研发人员经常犯的共同错误就是将第三优先级的事情提到第一优先级去做。换句话说，他们没有把真正紧急并且重要的功能和紧急但是不重要的功能分开。这个错误导致了重要的事被忽略了，重要的系统架构问题让位给了不重要的系统行为功能。\n\nThe dilemma for software developers is that business managers are not equipped to evaluate the importance of architecture. That’s what software developers were hired to do. Therefore it is the responsibility of the software development team to assert the importance of architecture over the urgency of features.\n\n> 但研发人员还忘了一点，那就是业务部门原本就是没有能力评估系统架构的重要程度的，这本来就应该是研发人员自己的工作职责！所以，平衡系统架构的重要性与功能的紧急程度这件事，是软件研发人员自己的职责。\n\n## FIGHT FOR THE ARCHITECTURE 为好的软件架构而持续斗争\n\nFulfilling this responsibility means wading into a fight—or perhaps a better word is “struggle.” Frankly, that’s always the way these things are done. The development team has to struggle for what they believe to be best for the company, and so do the management team, and the marketing team, and the sales team, and the operations team. It’s always a struggle.\n\n> 为了做好上述职责，软件团队必须做好斗争的准备——或者说“长期抗争”的准备。现状就是这样。研发团队必须从公司长远利益出发与其他部门抗争，这和管理团队的工作一样，甚至市场团队、销售团队、运营团队都是这样。公司内部的抗争本来就是无止境的。\n\nEffective software development teams tackle that struggle head on. They unabashedly squabble with all the other stakeholders as equals. Remember, as a software developer, you are a stakeholder. You have a stake in the software that you need to safeguard. That’s part of your role, and part of your duty. And it’s a big part of why you were hired.\n\n> 有成效的软件研发团队会迎难而上，毫不掩饰地与所有其他的系统相关方进行平等的争吵。请记住，作为—名软件开发人员，你也是相关者之一。软件系统的可维护性需要由你来保护，这是你角色的一部分，也是你职责中不可缺少的一部分。公司雇你的很大一部分原因就是需要有人来做这件事。\n\nThis challenge is doubly important if you are a software architect. Software architects are, by virtue of their job description, more focused on the structure of the system than on its features and functions. Architects create an architecture that allows those features and functions to be easily developed, easily modified, and easily extended.\n\n> 如果你是软件架构师，那么这项工作就加倍重要了。软件架构师这一职责本身就应更关注系统的整体结构，而不是具体的功能和系统行为的实现，软件架构师必须创建出一个可以让功能实现起来更容易、修改起来更简单、扩展起来更轻松的软件架构。\n\nJust remember: If architecture comes last, then the system will become ever more costly to develop, and eventually change will become practically impossible for part or all of the system. If that is allowed to happen, it means the software development team did not fight hard enough for what they knew was necessary.\n\n> 请记住：如果忽视软件架构的价值，系统将会变得越来越难以维护，终会有一天，系统将会变得再也无法修改。如果系统变成了这个样子，那么说明软件开发团队没有和需求方做足够的抗争，没有完成自己应尽的职责。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Part2. STARTING WITH THE BRICKS: PROGRAMMING PARADIGMS 从基础构件开始：编程范式\n\nSoftware architecture begins with the code—and so we will begin our discussion of architecture by looking at what we’ve learned about code since code was first written.\n\n> 任何软件架构的实现都离不开具体的代码，所以我们对软件架构的讨论应该从第一行被写下的代码开始。\n\nIn 1938, Alan Turing laid the foundations of what was to become computer programming. He was not the first to conceive of a programmable machine, but he was the first to understand that programs were simply data. By 1945, Turing was writing real programs on real computers in code that we would recognize (if we squinted enough). Those programs used loops, branches, assignment, subroutines, stacks, and other familiar structures. Turing’s language was binary.\n\n> 1938 年，阿兰·图灵为现代计算机编程打下了地基。尽管他并不是第一个发明可编程机器的人，但却是第一个提出“程序即数据”的人。到 1945 年时，图灵已经在真实计算机上编写真实的、我们现在也能看懂的计算机程序了。这些程序中用到了循环、分支、赋值、子调用、栈等如今我们都很熟悉的结构。而图灵用的编程语言就是简单的二进制数序列。\n\nSince those days, a number of revolutions in programming have occurred. One revolution with which we are all very familiar is the revolution of languages. First, in the late 1940s, came assemblers. These “languages” relieved the programmers of the drudgery of translating their programs into binary. In 1951, Grace Hopper invented A0, the first compiler. In fact, she coined the term compiler. Fortran was invented in 1953 (the year after I was born). What followed was an unceasing flood of new programming languages—COBOL, PL/1, SNOBOL, C, Pascal, C++, Java, ad infinitum.\n\n> 从那时到现在，编程领域历经了数次变革，其中我们都很熟悉的就是编程语言的变革。首先是在 20 世纪 40 年代末期出现了汇编器（assembler），它能自动将一段程序转化为相应的二进制数序列，大幅解放了程序员。然后是 1951 年，Grace Hopper 发明了 A0，这是世界上第一个编译器（compiler）。事实上，编译器这个名字就是他定义和推广使用的。再接着就到了 1953 年，那一年 FORTRAN 面世了（就在我出生的第二年）。接下来就是层出不穷的新编程语言了——COBOL、PL/1、SNOBOL、C、Pascal、C++、Java 等等，不胜枚举。\n\nAnother, probably more significant, revolution was in programming paradigms. Paradigms are ways of programming, relatively unrelated to languages. A paradigm tells you which programming structures to use, and when to use them. To date, there have been three such paradigms. For reasons we shall discuss later, there are unlikely to be any others.\n\n> 除此之外，计算机编程领域还经历了另外一个更巨大、更重要的变革，那就果编程范式（paradigm）的变迁。编程范式指的是程序的编写模式，与具体的编程语言关系相对较小。这些范式会告诉你应该在什么时候采用什么样的代码结构。直到今天，我们也一共只有三个编程范式，而且未来几乎不可能再出现新的，接下来我们就看一下为什么。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap3. PARADIGM OVERVIEW 编程范式总览\n\n![](../../images/books/架构整洁之道/CH-UN03.jpg)\n\nThe three paradigms included in this overview chapter are structured programming, object-orient programming, and functional programming.\n\n> 本章将讲述三个编程范式，它们分别是结构化编程（structured programming）、 面向对象编程（object-oriented programming）以及函数式编程（functional programming）。\n\n## STRUCTURED PROGRAMMING 结构化编程\n\nThe first paradigm to be adopted (but not the first to be invented) was structured programming, which was discovered by Edsger Wybe Dijkstra in 1968. Dijkstra showed that the use of unrestrained jumps (goto statements) is harmful to program structure. As we’ll see in the chapters that follow, he replaced those jumps with the more familiar if/then/else and do/while/until constructs.\n\n> 结构化编程是第一个普遍被采用的编程范式（但是却不是第一个被提出的），由 Edsger Wybe Dijkstra 于 1968 年最先提出。与此同时，Dijkstra 还论证了使用 goto 这样的无限制跳转语句将会损害程序的整体结构。接下来的章节我们还会说到，二是这位 Dijkstra 最先主张用我们现在熟知的 if/then/else 语句和 do/while/until 语句来代替跳转语句的。\n\nWe can summarize the structured programming paradigm as follows:\n\n> 我们可以将结构化编程范式归结为一句话：\n\nStructured programming imposes discipline on direct transfer of control.\n\n> 结构化编程对程序控制权的直接转移进行了限制和规范。\n\n## OBJECT-ORIENTED PROGRAMMING 面向对象编程\n\nThe second paradigm to be adopted was actually discovered two years earlier, in 1966, by Ole Johan Dahl and Kristen Nygaard. These two programmers noticed that the function call stack frame in the ALGOL language could be moved to a heap, thereby allowing local variables declared by a function to exist long after the function returned. The function became a constructor for a class, the local variables became instance variables, and the nested functions became methods. This led inevitably to the discovery of polymorphism through the disciplined use of function pointers.\n\n> 说到编程领域中第二个被广泛采用的编程范式，当然就是面向对象编程了：事实上，这个编程范式的提出比结构化编程还早了两年，是在 1966 年由 Ole Johan Dahl 和 Kriste Nygaard 在论文中总结归纳出来的。这两个程序员注意到在 ALGOL 语言中. 函数调用堆栈（call stack frame）可以被挪到堆内存区域里，这样函数定义的本地变量就可以在函数返回之后继续存在。这个函数就成为了一个类（class）的构造函数，而它所定义的本地变量就是类的成员变量，构造函数定义的嵌套函数就成为了成员方法（method）。这样一来，我们就可以利用多态（polymorphism）来限制用户对函数指针的使用。\n\nWe can summarize the object-oriented programming paradigm as follows:\n\n> 在这里，我们也可以用一句话来总结面向对象编程：\n\nObject-oriented programming imposes discipline on indirect transfer of control.\n\n> 面向对象编程对程序控制权的间接转移进行了限制和规范。\n\n## FUNCTIONAL PROGRAMMING 函数式编程\n\nThe third paradigm, which has only recently begun to be adopted, was the first to be invented. Indeed, its invention predates computer programming itself. Functional programming is the direct result of the work of Alonzo Church, who in 1936 invented l-calculus while pursuing the same mathematical problem that was motivating Alan Turing at the same time. His l-calculus is the foundation of the LISP language, invented in 1958 by John McCarthy. A foundational notion of l-calculus is immutability—that is, the notion that the values of symbols do not change. This effectively means that a functional language has no assignment statement. Most functional languages do, in fact, have some means to alter the value of a variable, but only under very strict discipline.\n\n> 尽管第三个编程范式是近些年才刚刚开始被采用的，但它其实是三个范式中最先被发明的。事实上，函数式编程概念是基于与阿兰·图灵同时代的数学家 Alonzo Church 在 1936 年发明的入演算的直接衍生物。1958 年 John Mccarthy 利用其作为基础发明了 LISP 语言。众所周知，λ 演算法的一个核心思想是不可变性——某个符号所对应的值是永远不变的，所以从理论上来说，函数式编程语言中应该是没有赋值语句的。大部分函数式编程语言只允许在非常严格的限制条件下，才可以更改某个变量的值。\n\nWe can summarize the functional programming paradigm as follows:\n\n> 因此，我们在这里可以将函数式编程范式总结为下面这句话：\n\nFunctional programming imposes discipline upon assignment.\n\n> 函数式编程对程序中的赋值进行了限制和规范。\n\n## FOOD FOR THOUGHT 仅供思考\n\nNotice the pattern that I’ve quite deliberately set up in introducing these three programming paradigms: Each of the paradigms removes capabilities from the programmer. None of them adds new capabilities. Each imposes some kind of extra discipline that is negative in its intent. The paradigms tell us what not to do, more than they tell us what to do.\n\n> 如你所见，我在介绍三个编程范式的时候，有意采用了上面这种格式，目的是凸显每个编程范式的实际含义——它们都从某一方面限制和规范了程序员的能力。没有一个范式是增加新能力的。也就是说，每个编程范式的目的都是设置限制。这些范式主要是为了告诉我们不能做什么，而不是可以做什么。\n\nAnother way to look at this issue is to recognize that each paradigm takes something away from us. The three paradigms together remove goto statements, function pointers, and assignment. Is there anything left to take away?\n\n> 另外，我们应该认识到，这三个编程范式分别限制了 goto 语句、函数指针和赋值语句的使用。那么除此之外，还有什么可以去除的吗？\n\nProbably not. Thus these three paradigms are likely to be the only three we will see—at least the only three that are negative. Further evidence that there are no more such paradigms is that they were all discovered within the ten years between 1958 and 1968. In the many decades that have followed, no new paradigms have been added.\n\n> 可能没有了。因此这三个编程范式可能是仅有的三个了——如果单论去除能力的编程范式的话。支撑这一结论的另外一个证据是，三个编程范式都是在 1958 年到 1968 年这 10 年间被提出来的，后续再也没有新的编程范式出现过。\n\n## CONCLUSION 本章小结\n\nWhat does this history lesson on paradigms have to do with architecture? Everything. We use polymorphism as the mechanism to cross architectural boundaries; we use functional programming to impose discipline on the location of and access to data; and we use structured programming as the algorithmic foundation of our modules.\n\n> 大家可能会问，这些编程范式的历史知识与软件架构有关系吗？当然有，而目关系相当密切。譬如说，多态是我们跨越架构边界的手段，函数式编程是我们规范和限制数据存放位置与访问权限的手段，结构化编程则是各模块的算法实现基础。\n\nNotice how well those three align with the three big concerns of architecture: function, separation of components, and data management.\n\n> 这和软件架构的三大关注重点不谋而合：功能性、组件独立性以及数据管理。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap4. STRUCTURED PROGRAMMING 结构化编程\n\n![](../../images/books/架构整洁之道/CH-UN04.jpg)\n\nEdsger Wybe Dijkstra was born in Rotterdam in 1930. He survived the bombing of Rotterdam during World War II, along with the German occupation of the Netherlands, and in 1948 graduated from high school with the highest possible marks in math, physics, chemistry, and biology. In March 1952, at the age of 21 (and just 9 months before I was born), Dijkstra took a job with the Mathematical Center of Amsterdam as the Netherlands’ very first programmer.\n\n> Edsger Wybe Dijkstra 于 1930 年出生在荷兰鹿特丹。生于乱世，他亲身经历了第二次世界大战中的鹿特丹大轰炸、德国占领荷兰等事件。1948 年，他以数学、物理、化学以及生物全满分的成绩高中毕业。1952 年 3 月，年仅 21 岁的 Dijkstra （此时距离我出生还有 9 个月时间）入职荷兰阿姆斯特丹数学中心，成为了荷兰的第一个程序员。\n\nIn 1955, having been a programmer for three years, and while still a student, Dijkstra concluded that the intellectual challenge of programming was greater than the intellectual challenge of theoretical physics. As a result, he chose programming as his long-term career.\n\n> 1955 年，在从事编程工作 3 年之后，当时还是一个学生的 Dijkstra 就认为编程相比理论物理更有挑战性，因此他选择将编程作为终身职业。\n\nIn 1957, Dijkstra married Maria Debets. At the time, you had to state your profession as part of the marriage rites in the Netherlands. The Dutch authorities were unwilling to accept “programmer” as Dijkstra’s profession; they had never heard of such a profession. To satisfy them, Dijkstra settled for “theoretical physicist” as his job title.\n\n> 1957 年，Dijkstra 与 Maria Debets 结婚了。在当时的荷兰，新郎新娘必须在结婚仪式上公布自己的职业。而当时的荷兰官方政府拒绝承认“程序员”这一职业，因为他们从来没有听说过。最终 Dijkstra 不得不继续使用\"理论物理学家这一职位名称。\n\nAs part of deciding to make programming his career, Dijkstra conferred with his boss, Adriaan van Wijngaarden. Dijkstra was concerned that no one had identified a discipline, or science, of programming, and that he would therefore not be taken seriously. His boss replied that Dijkstra might very well be one of the people who would discover such disciplines, thereby evolving software into a science.\n\n> Dijkstra 和他的老板 Adriaan van Wijingaarden 曾经讨论过将“程序员”当作终身职业这件事，Dijkstra 最担心的是由于没有人认真地对待过编程这件事或者将它当作是一门学术学科对待，他的科研成果可能将不会得到认真对待。而 Adriaan 则建议 Dijkstra：为什么不亲自去开创这门学科呢?\n\nDijkstra started his career in the era of vacuum tubes, when computers were huge, fragile, slow, unreliable, and (by today’s standards) extremely limited. In those early years, programs were written in binary, or in very crude assembly language. Input took the physical form of paper tape or punched cards. The edit/compile/test loop was hours—if not days—long.\n\n> 当时还是真空管阶段。计算机体积巨大，运行缓慢，还非常容易出故障，功能（与今天对比）十分有限。人们还是直接使用二进制数，或者使用非常原始的汇编语言编程。计算机的输入方式则还是用纸卷带或者是打孔卡片。要想执行完整的编辑、编译、测试流程是非常耗时的，通常需要数小时或者数天才能完成。\n\nIt was in this primitive environment that Dijkstra made his great discoveries.\n\n> Dijkstra 就是在这样原始的条件下做出其非凡的成就的。\n\n## PROOF 可推导性\n\nThe problem that Dijkstra recognized, early on, was that programming is hard, and that programmers don’t do it very well. A program of any complexity contains too many details for a human brain to manage without help. Overlooking just one small detail results in programs that may seem to work, but fail in surprising ways.\n\n> Dijkstra 很早就得出的结论是：编程是一项难度很大的活动。一段程序无论复杂与否，都包含了很多的细节信息。如果没有工具的帮助，这些细节的信息是远远超过一个程序员的认知能力范围的。而在一段程序中，哪怕仅仅是一个小细节的错误，也会造成整个程序出错。\n\nDijkstra’s solution was to apply the mathematical discipline of proof. His vision was the construction of a Euclidian hierarchy of postulates, theorems, corollaries, and lemmas. Dijkstra thought that programmers could use that hierarchy the way mathematicians do. In other words, programmers would use proven structures, and tie them together with code that they would then prove correct themselves.\n\n> Dijkstra 提出的解决方案是采用数学推导方法。他的想法是借鉴数学中的公理（Postulate）、定理（Theorem）、推论（Corollary）和引理（Lemma），形成一种欧几里得结构。Dijkstra 认为程序员可以像数学家一样对自己的程序进行推理证明。换句话说，程序员可以用代码将一些已证明可用的结构串联起来，只要自行证明这些额外代码是正确的，就可以推导出整个程序的正确性。\n\nOf course, to get this going, Dijkstra realized that he would have to demonstrate the technique for writing basic proofs of simple algorithms. This he found to be quite challenging.\n\n> 当然，在这之前，必须先展示如何推导证明简单算法的正确性，这本身就是一件极具挑战性的工作。\n\nDuring his investigation, Dijkstra discovered that certain uses of goto statements prevent modules from being decomposed recursively into smaller and smaller units, thereby preventing use of the divide-and-conquer approach necessary for reasonable proofs.\n\n> Dijkstra 在研究过程中发现了一个问题：goto 语句的某些用法会导致某个模块 无法被递归拆分成更小的、可证明的单元，这会导致无法采用分解法来将大型问题进一步拆分成更小的、可证明的部分。\n\nOther uses of goto, however, did not have this problem. Dijkstra realized that these “good” uses of goto corresponded to simple selection and iteration control structures such as if/then/else and do/while. Modules that used only those kinds of control structures could be recursively subdivided into provable units.\n\n> goto 语句的其他用法虽然不会导致这种问题，但是 Dijkstra 意识到它们的实际效果其实和更简单的分支结构 if-then-else 以及循环结构 do-while 是一致的。如果代码中只采用了这两类控制结构，则一定可以将程序分解成更小的、可证明的单元。\n\nDijkstra knew that those control structures, when combined with sequential execution, were special. They had been identified two years before by Böhm and Jacopini, who proved that all programs can be constructed from just three structures: sequence, selection, and iteration.\n\n> 事实上，Dijkstra 很早就知道将这些控制结构与顺序结构的程序组合起来很有用。因为在两年前，Bohm 和 Jocopini 刚刚证明了人们可以用顺序结构、分支结构、循环结构这三种结构构造出任何程序。\n\nThis discovery was remarkable: The very control structures that made a module provable were the same minimum set of control structures from which all programs can be built. Thus structured programming was born.\n\n> 这个发现非常重要：因为它证明了我们构建可推导模块所需要的控制结构集与构建所有程序所需的控制结构集的最小集是等同的。这样—来，结构化编程就诞生了。\n\nDijkstra showed that sequential statements could be proved correct through simple enumeration. The technique mathematically traced the inputs of the sequence to the outputs of the sequence. This approach was no different from any normal mathematical proof.\n\n> Dijkstra 展示了顺序结构的正确性可以通过枚举法证明，其过程与其他一般的数学推导过程是一样的：针对序列中的每个输入，跟踪其对应的输出值的变化就可以了。\n\nDijkstra tackled selection through reapplication of enumeration. Each path through the selection was enumerated. If both paths eventually produced appropriate mathematical results, then the proof was solid.\n\n> 同样的，Dijkstra 利用枚举法又证明了分支结构的可推导性。因为我们只要能用枚举法证明分支结构中每条路径的正确性，自然就可以推导出分支结构本身的正确性。\n\nIteration was a bit different. To prove an iteration correct, Dijkstra had to use induction. He proved the case for 1 by enumeration. Then he proved the case that if N was assumed correct, N + 1 was correct, again by enumeration. He also proved the starting and ending criteria of the iteration by enumeration.\n\n> 循环结构的证明过程则有所不同，为了证明一段循环程序的正确性，Dijkstra 需要采用数学归纳法。具体来说就是，首先要用枚举法证明循环 1 次的正确性。接下来再证明如果循环 N 次是正确的，那么循环 N+1 次也同样也是正确的。最后还要用枚举法证明循环结构的起始与结束条件的正确性。\n\nSuch proofs were laborious and complex—but they were proofs. With their development, the idea that a Euclidean hierarchy of theorems could be constructed seemed reachable.\n\n> 尽管这些证明过程本身非常复杂和烦琐，但确实是完备的。有了这样的证明过程，用欧几里得层级构造定理的方式来验证程序正确性的目标，貌似近在咫尺了。\n\n## A HARMFUL PROCLAMATION goto 是有害的\n\nIn 1968, Dijkstra wrote a letter to the editor of CACM, which was published in the March issue. The title of this letter was “Go To Statement Considered Harmful.” The article outlined his position on the three control structures.\n\n> 1968 年，Dijkstra 曾经给 CACM 的编辑写过一封信。这封信后来发表于 CACM 3 月刊，标题是 Go To Statement Considered Harmful，Dijkstra 在信中具体描绘了他对三种控制结构的看法。\n\nAnd the programming world caught fire. Back then we didn’t have an Internet, so people couldn’t post nasty memes of Dijkstra, and they couldn’t flame him online. But they could, and they did, write letters to the editors of many published journals.\n\n> 这可捅了个大篓子。由于当时还没有互联网，大家还不能直接上网发帖来对 Dijkstra 进行冷嘲热讽，他们唯一能做的，也是大部分人的选择，就是不停地给各种公开发表的报刊的编辑们写信。\n\nThose letters weren’t necessarily all polite. Some were intensely negative; others voiced strong support for his position. And so the battle was joined, ultimately to last about a decade.\n\n> 可想而知，有的信件的措辞并不那么友善，甚至是非常负面的。但是，也不乏强烈支持者。总之，这场火热的争论持续了超过 10 年。\n\nEventually the argument petered out. The reason was simple: Dijkstra had won. As computer languages evolved, the goto statement moved ever rearward, until it all but disappeared. Most modern languages do not have a goto statement—and, of course, LISP never did.\n\n> 当然，这场辩论最终还是逐渐停止了。原因很简单：Dijkstra 是对的。随着编程语言的演进，goto 语句的重要性越来越小，最终甚至消失了。如今大部分的现代编程语言中都已经没有了 goto 语句。哦，对了，LISP 里从来就没有过！\n\nNowadays we are all structured programmers, though not necessarily by choice. It’s just that our languages don’t give us the option to use undisciplined direct transfer of control.\n\n> 现如今，无论是否自愿，我们都是结构化编程范式的践行者了，因为我们用的编程语言基本上都已经禁止了不受限制的直接控制转移语句。\n\nSome may point to named breaks in Java or exceptions as goto analogs. In fact, these structures are not the utterly unrestricted transfers of control that older languages like Fortran or COBOL once had. Indeed, even languages that still support the goto keyword often restrict the target to within the scope of the current function.\n\n> 或许有些人会指出，Java 中的带命名的 break 语句或者 Exception 都和 goto 很类似。这些语法结构与老的编程语言（类似 FORTRAN 和 COBOL）中的完全无限制的 goto 语句根本不一样。就算那些还支持 goto 关键词的编程语言也通常限制了 goto 的目标不能超出当前函数范围。\n\n## FUNCTIONAL DECOMPOSITION 功能性降解拆分\n\nStructured programming allows modules to be recursively decomposed into provable units, which in turn means that modules can be functionally decomposed. That is, you can take a large-scale problem statement and decompose it into high-level functions. Each of those functions can then be decomposed into lower-level functions, ad infinitum. Moreover, each of those decomposed functions can be represented using the restricted control structures of structured programming.\n\n> 既然结构化编程范式可将模块递归降解拆分为可推导的单元，这就意味着模块了可以按功能进行降解拆分。这样一来，我们就可以将一个大型问题拆分为一系列高级函数的组合，而这些高级函数各自又可以继续被拆分为一系列低级函数，如此无限递归。更重要的是，每个被拆分出来的函数也都可以用结构化编程范式来书写。\n\nBuilding on this foundation, disciplines such as structured analysis and structured design became popular in the late 1970s and throughout the 1980s. Men like Ed Yourdon, Larry Constantine, Tom DeMarco, and Meilir Page-Jones promoted and popularized these techniques throughout that period. By following these disciplines, programmers could break down large proposed systems into modules and components that could be further broken down into tiny provable functions.\n\n> 以此为理论基础，在 20 世纪 70 年代晚期到 10 年代中期出现的结构化分析与结构化设计工作才能广为人知。Ed Yourdon、Larry Constantine、Tom DeMarco 以及 Meilir Page Jones 在这期间为此做了很多推广工作。通过采用这些技巧，程序员可以将大型系统设计拆分成模块和组件，而这些模块和组件最终可以拆分为更小的、可证明的函数。\n\n## NO FORMAL PROOFS 形式化证明没有发生\n\nBut the proofs never came. The Euclidean hierarchy of theorems was never built. And programmers at large never saw the benefits of working through the laborious process of formally proving each and every little function correct. In the end, Dijkstra’s dream faded and died. Few of today’s programmers believe that formal proofs are an appropriate way to produce high-quality software.\n\n> 但是，人人都用完整的形式化证明的一天没有到来。大部分人不会真的按照欧几里得结构为每个小函数书写冗长复杂的正确性证明过程。Dijkstra 的梦想最终并没有实现。没有几个程序员会认为形式化验证是产出高质量软件的必备条件。\n\nOf course, formal, Euclidian style, mathematical proofs are not the only strategy for proving something correct. Another highly successful strategy is the scientific method.\n\n> 当然，形式化的、欧几里得式的数学推导证明并不是证明结构化编程正确性的唯一手段。下面我们来看另外一个十分成功的策略：科学证明法。\n\n## SCIENCE TO THE RESCUE 科学来救场\n\nScience is fundamentally different from mathematics, in that scientific theories and laws cannot be proven correct. I cannot prove to you that Newton’s second law of motion, F = ma, or law of gravity, F = Gm1m2/r2, are correct. I can demonstrate these laws to you, and I can make measurements that show them correct to many decimal places, but I cannot prove them in the sense of a mathematical proof. No matter how many experiments I conduct or how much empirical evidence I gather, there is always the chance that some experiment will show that those laws of motion and gravity are incorrect.\n\n> 科学和数学在证明方法上有着根本性的不同，科学理论和科学定律通常是无法被证明的，譬如我们并没有办法证明牛顿第二运动定律 F=ma 或者万有引力定律 F=Gm1m2/r^2 是正确的，但我们可以用实际案例来演示这些定律的正确性，并通过高精度测量来证明当相关精度达到小数点后多少位时，被测量对象仍然一直满足这个定律。但我们始终没有办法像用数学方法一样推导出这个定律。而且，不管我们进行多少次正确的实验，也无法排除今后会存在某一次实验可以推翻牛顿第二运动定律与万有引力定律的可能性。\n\nThat is the nature of scientific theories and laws: They are falsifiable but not provable.\n\n> 这就是科学理论和科学定律的特点：它们可以被证伪，但是没有办法被证明。\n\nAnd yet we bet our lives on these laws every day. Every time you get into a car, you bet your life that F = ma is a reliable description of the way the world works. Every time you take a step, you bet your health and safety that F = Gm1m2/r2 is correct.\n\n> 但是我们仍然每天都在依赖这些定律生活。开车的时候，我们就等于是在用性命担保 F=ma 是对世界运转方式的一个可靠的描述。每当我们迈出一步的时候，和等于在亲身证明 F=Gm1m2/r^2 是正确的。\n\nScience does not work by proving statements true, but rather by proving statements false. Those statements that we cannot prove false, after much effort, we deem to be true enough for our purposes.\n\n> 科学方法论不需要证明某条结论是正确的，只需要想办法证明它是错误的。如果某个结论经过一定的努力无法证伪，我们则认为它在当下是足够正确的。\n\nOf course, not all statements are provable. The statement “This is a lie” is neither true nor false. It is one of the simplest examples of a statement that is not provable.\n\n> 当然，不是所有的结论都可以被证明或者证伪的。举一个最简单的不可证明的例子：“这句话是假的”，非真也非伪。\n\nUltimately, we can say that mathematics is the discipline of proving provable statements true. Science, in contrast, is the discipline of proving provable statements false.\n\n> 最终，我们可以说数学是要将可证明的结论证明，而与之相反，科学研究则是要将可证明的结论证伪。\n\n## TESTS 测试\n\nDijkstra once said, “Testing shows the presence, not the absence, of bugs.” In other words, a program can be proven incorrect by a test, but it cannot be proven correct. All that tests can do, after sufficient testing effort, is allow us to deem a program to be correct enough for our purposes.\n\n> Dijkstra 曾经说过“测试只能展示 Bug 的存在，并不能证明不存在 Bug”，换句话说，一段程序可以由一个测试来证明其错误性，但是却不能被证明是正确的。测试的作用是让我们得出某段程序已经足够实现当前目标这一结论。\n\nThe implications of this fact are stunning. Software development is not a mathematical endeavor, even though it seems to manipulate mathematical constructs. Rather, software is like a science. We show correctness by failing to prove incorrectness, despite our best efforts.\n\n> 这一事实所带来的影响是惊人的。软件开发虽然看起来是在操作很多数学结构，其实不是一个数学研究过程。恰恰相反，软件开发更像是一门科学研究学科，我们通过无法证伪来证明软件的正确性。\n\nSuch proofs of incorrectness can be applied only to provable programs. A program that is not provable—due to unrestrained use of goto, for example—cannot be deemed correct no matter how many tests are applied to it.\n\n> 注意，这种证伪过程只能应用于可证明的程序上。某段程序如果是不可证明的，例如，其中采用了不加限制的 goto 语句，那么无论我们为它写多少测试，也不能够证明其正确性。\n\nStructured programming forces us to recursively decompose a program into a set of small provable functions. We can then use tests to try to prove those small provable functions incorrect. If such tests fail to prove incorrectness, then we deem the functions to be correct enough for our purposes.\n\n> 结构化编程范式促使我们先将一段程序递归降解为一系列可证明的小函数，然后再编写相关的测试来试图证明这些函数是错误的。如果这些测试无法证伪这些函数，那么我们就可以认为这些函数是足够正确的，进而推导整个程序是正确的。\n\n## CONCLUSION 本章小结\n\nIt is this ability to create falsifiable units of programming that makes structured programming valuable today. This is the reason that modern languages do not typically support unrestrained goto statements. Moreover, at the architectural level, this is why we still consider functional decomposition to be one of our best practices.\n\n> 结构化编程范式中最有价值的地方就是，它赋予了我们创造可证伪程序单元的能力。这就是为什么现代编程语言一般不支持无限制的 goto 语句。更重要的是，这也是为什么在架构设计领域，功能性降解拆分仍然是最佳实践之一。\n\nAt every level, from the smallest function to the largest component, software is like a science and, therefore, is driven by falsifiability. Software architects strive to define modules, components, and services that are easily falsifiable (testable). To do so, they employ restrictive disciplines similar to structured programming, albeit at a much higher level.\n\n> 无论在哪一个层面上，从最小的函数到最大组件，软件开发的过程都和科学研究非常类似，它们都是由证伪驱动的。软件架构师需要定义可以方便地进行证伪（测试）的模块、组件以及服务。为了达到这个目的，他们需要将类似结构化编程的限制方法应用在更高的层面上。\n\nIt is those restrictive disciplines that we will study in some detail in the chapters to come.\n\n> 我们在接下来的章节中将会深入研究这些限制性的方法。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap5. OBJECT-ORIENTED PROGRAMMING 面向对象编程\n\n![](../../images/books/架构整洁之道/CH-UN05.jpg)\n\nAs we will see, the basis of a good architecture is the understanding and application of the principles of object-oriented design (OO). But just what is OO?\n\n> 稍后我们会讲到，设计一个优秀的软件架构要基于对面向对象设计（Object-Oriented Design）的深入理解及应用。但我们首先得弄明白一个问题：究竟什么是面向对象？\n\nOne answer to this question is “The combination of data and function.” Although often cited, this is a very unsatisfying answer because it implies that o.f() is somehow different from f(o). This is absurd. Programmers were passing data structures into functions long before 1966, when Dahl and Nygaard moved the function call stack frame to the heap and invented OO.\n\n> 对于这个问题，一种常见的回答是“数据与函数的组合”。这种说法虽然被广为引用，但总显得并不是那么贴切，因为它似乎暗示了 `o.f()` 与 `f(o)` 之间是有区别的，这显然不是事实。面向对象理论是在 1966 年提出的，当时 Dahl 和 Nygaard 主要是将函数调用栈迁移到了堆区域中。数据结构被用作函数的调用参数这件事情远比这发生的时间更早。\n\nAnother common answer to this question is “A way to model the real world.” This is an evasive answer at best. What does “modeling the real world” actually mean, and why is it something we would want to do? Perhaps this statement is intended to imply that OO makes software easier to understand because it has a closer relationship to the real world—but even that statement is evasive and too loosely defined. It does not tell us what OO is.\n\n> 另一种常见的回答是“面向对象编程是一种对真实世界进行建模的方式”，这种回答只能算作避重就轻。“对真实世界的建模”到底要如何进行？我们为什么要这么做，有什么好处？也许这句话意味着是“由于采用面向对象方式构建的软件与真实世界的关系更紧密，所以面向对象编程可以使得软件开发更容易”——即使这样说，也仍然逃避了关键问题——面向对象编程究竟是什么?\n\nSome folks fall back on three magic words to explain the nature of OO: encapsulation, inheritance, and polymorphism. The implication is that OO is the proper admixture of these three things, or at least that an OO language must support these three things.\n\n> 还有些人在回答这个问题的时候，往往会搬出一些神秘的词语，譬如封装（encapsulation）、继承（inheritance）、多态（polymorphism）。其隐含意思就是说面向对象编程是这三项的有机组合，或者任何一种支持面向对象的编程语言必须支持这三个特性。\n\nLet’s examine each of these concepts in turn.\n\n> 那么，我们接下来可以逐个来分析一下这三个概念。\n\n## ENCAPSULATION? 封装\n\nThe reason encapsulation is cited as part of the definition of OO is that OO languages provide easy and effective encapsulation of data and function. As a result, a line can be drawn around a cohesive set of data and functions. Outside of that line, the data is hidden and only some of the functions are known. We see this concept in action as the private data members and the public member functions of a class.\n\n> 导致封装这个概念经常被引用为面向对象编程定义的一部分。通过釆用封装特性，我们可以把一组相关联的数据和函数圈起来，便圈外血的代码只能看见部分函数，数据则完全不可见。譬如在实际应用中，类（class）中的公共函数和私有成员变量就是这样。\n\nThis idea is certainly not unique to OO. Indeed, we had perfect encapsulation in C. Consider this simple C program:\n\n> 然而，这个特性其实并不是面向对象编程所独有的。其实，c 语言也支持完整的封装，下面来看一个简单的 c 程序：\n\npoint.h\n\n```c\nstruct Point;\nstruct Point* makePoint(double x, double y);\ndouble distance (struct Point *p1, struct Point *p2);\n```\n\npoint.c\n\n```c\n#include \"point.h\"\n#include <stdlib.h>\n#include <math.h>\n\nstruct Point {\n  double x,y;\n};\n\nstruct Point* makepoint(double x, double y) {\n  struct Point* p = malloc(sizeof(struct Point));\n  p->x = x;\n  p->y = y;\n  return p;\n}\n\ndouble distance(struct Point* p1, struct Point* p2) {\n  double dx = p1->x - p2->x;\n  double dy = p1->y - p2->y;\n  return sqrt(dx*dx+dy*dy);\n}\n```\n\nThe users of point.h have no access whatsoever to the members of struct Point. They can call the makePoint() function, and the distance() function, but they have absolutely no knowledge of the implementation of either the Point data structure or the functions.\n\n> 显然，使用 point.h 的程序是没有 Point 结构体成员的访问权限的。它们只能调用 `makePoint()` 函数和 `distance()` 函数，但对它们来说，Point 这个数据结构体的内部细节，以及函数的具体实现方式都是不可见的。\n\nThis is perfect encapsulation—in a non-OO language. C programmers used to do this kind of thing all the time. We would forward declare data structures and functions in header files, and then implement them in implementation files. Our users never had access to the elements in those implementation files.\n\n> 这正是完美封装 虽然 C 语言是非面向对象的编程语言。上述 C 程序是很常见的。在头文件中进行数据结构以及函数定义的前置声明（forward declare），然后 在程序文件中具体实现。程序文件中的具体实现细节对使用者来说是不可见的。\n\nBut then came OO in the form of C++—and the perfect encapsulation of C was broken.\n\n> 而 C++作为一种面向对象编程语言，反而破坏了 c 的完美封装性。\n\nThe C++ compiler, for technical reasons,1 needed the member variables of a class to be declared in the header file of that class. So our Point program changed to look like this:\n\n> 由于一些技术原，C++编译器要求类的成员变量必须在该类的头文件中声明。这样一来，我们的 point.h 程序随之就改成了这样：\n\npoint.h\n\n```cpp\nclass Point {\npublic:\n  Point(double x, double y);\n  double distance(const Point& p) const;\n\nprivate:\n  double x;\n  double y;\n};\n```\n\npoint.cc\n\n```cpp\n#include \"point.h\"\n#include <math.h>\n\nPoint::Point(double x, double y)\n: x(x), y(y)\n{}\n\ndouble Point::distance(const Point& p) const {\n  double dx = x-p.x;\n  double dy = y-p.y;\n  return sqrt(dx*dx + dy*dy);\n}\n```\n\nClients of the header file point.h know about the member variables x and y! The compiler will prevent access to them, but the client still knows they exist. For example, if those member names are changed, the point.cc file must be recompiled! Encapsulation has been broken.\n\n> 好了，point.h 文件的使用者现在知道了成员变量 x 和 y 的存在！虽然编译器会禁止对这两个变量的直接访问，但是使用者仍然知道了它们的存在。而且，如果 x 和 y 变量名称被改变了，point.cc 也必须重新编译才行！这样的封装性显然是不完美的。\n\nIndeed, the way encapsulation is partially repaired is by introducing the public, private, and protected keywords into the language. This, however, was a hack necessitated by the technical need for the compiler to see those variables in the header file.\n\n> 当然，C++通过在编程语言层面引入 public、private、protected 这些关键词，部分维护了封装性。但所有这些都是为了解决编译器自身的技术实现问题而引入的 hack——编译器由于技术实现原因必须在头文件中看到成员变量的定义。\n\nJava and C# simply abolished the header/implementation split altogether, thereby weakening encapsulation even more. In these languages, it is impossible to separate the declaration and definition of a class.\n\n> 而 Java 和 C# 则彻底抛弃了头文件与实现文件分离的编程方式，这其实进一步削弱了封装性。因为在这些语言中，我们是无法区分一个类的声明和定义的。\n\nFor these reasons, it is difficult to accept that OO depends on strong encapsulation. Indeed, many OO languages2 have little or no enforced encapsulation.\n\n> 由于上述原因，我们很难说强封装是面向对象编程的必要条件。而事实上，有很多面向对象编程语言|对封装性并没有强制性的要求。\n\nOO certainly does depend on the idea that programmers are well-behaved enough to not circumvent encapsulated data. Even so, the languages that claim to provide OO have only weakened the once perfect encapsulation we enjoyed with C.\n\n> 面向对象编程在应用上确实会要求程序员尽量避免破坏数据的封装性。但实际情况是，那些声称自己提供面向对象编程支持的编程语言，相对于 C 这种完美封装的语言而言，其封装性都被削弱了，而不是加强了。\n\n## INHERITANCE? 继承\n\nIf OO languages did not give us better encapsulation, then they certainly gave us inheritance.\n\n> 既然面向对象编程语言并没有提供更好的封装性，那么在继承性方面又如何呢？\n\nWell—sort of. Inheritance is simply the redeclaration of a group of variables and functions within an enclosing scope. This is something C programmers3 were able to do manually long before there was an OO language.\n\n> 嗯，其实也就一般般吧。简而言之，继承的主要作用是让我们可以在某个作用域内对外部定义的某一组变量与函数进行覆盖。这事实上也是 c 程序员早在面向对象编程语言发明之前就一直在做的事了。\n\nConsider this addition to our original point.h C program:\n\n> 下面，看一下刚才的 C 程序 point.h 的扩展版：\n\nnamedPoint.h\n\n```c\nstruct NamedPoint;\n\nstruct NamedPoint* makeNamedPoint(double x, double y, char* name);\nvoid setName(struct NamedPoint* np, char* name);\nchar* getName(struct NamedPoint* np);\n```\n\nnamedPoint.c\n\n```c\n#include \"namedPoint.h\"\n#include <stdlib.h>\n\nstruct NamedPoint {\n  double x,y;\n  char* name;\n};\n\nstruct NamedPoint* makeNamedPoint(double x, double y, char* name) {\n  struct NamedPoint* p = malloc(sizeof(struct NamedPoint));\n  p->x = x;\n  p->y = y;\n  p->name = name;\n  return p;\n}\n\nvoid setName(struct NamedPoint* np, char* name) {\n  np->name = name;\n}\n\nchar* getName(struct NamedPoint* np) {\n  return np->name;\n}\n```\n\nmain.c\n\n```c\n#include \"point.h\"\n#include \"namedPoint.h\"\n#include <stdio.h>\n\nint main(int ac, char** av) {\n  struct NamedPoint* origin = makeNamedPoint(0.0, 0.0, \"origin\");\n  struct NamedPoint* upperRight = makeNamedPoint  (1.0, 1.0, \"upperRight\");\n  printf(\"distance=%f\\n\",\n    distance(\n             (struct Point*) origin,\n             (struct Point*) upperRight));\n}\n```\n\nIf you look carefully at the main program, you’ll see that the NamedPoint data structure acts as though it is a derivative of the Point data structure. This is because the order of the first two fields in NamedPoint is the same as Point. In short, NamedPoint can masquerade as Point because NamedPoint is a pure superset of Point and maintains the ordering of the members that correspond to Point.\n\n> 请仔细观察 main 函数，这里 NamedPoint 数据结构是被当作 Point 数据结构的一个衍生体來使用的。之所以可以这样做，是因为 NamedPoint 结构体的前两个成员的顺用与 Point 结构休的完全一致。简单来说，NamedPoint 之所以可以被伪装成 Point 来使用，是因为 NamedPoint 是 Point 结构体的一个超集，同两者共同成员的顺序也是一样的。\n\nThis kind of trickery was a common practice4 of programmers prior to the advent of OO. In fact, such trickery is how C++ implements single inheritance.\n\n> 面这种编程方式虽然看上去有些投机取巧，但是在面向对象理论被提出之前，这已经很常见了。其实，C++内部就是这样实现单继承的。\n\nThus we might say that we had a kind of inheritance long before OO languages were invented. That statement wouldn’t quite be true, though. We had a trick, but it’s not nearly as convenient as true inheritance. Moreover, multiple inheritance is a considerably more difficult to achieve by such trickery.\n\n> 因此，我们可以说，早在面向对象编程语言被发明之前，对继承性的支持就已经存在很久了。当然了，这种支持用了一些投机取巧的手段，并不像如今的继昼：样便利易用，而且，多重继承（multiple inheritance）如果还想用这种方法来实现，就更难了。\n\nNote also that in main.c, I was forced to cast the NamedPoint arguments to Point. In a real OO language, such upcasting would be implicit.\n\n> 同时应该注意的是，在 main.c 中，程序员必须强制将 NamedPoint 的参数类型转换为 Point，而在真正的面向对象编程语言中，这种类型的向上转换通常应该是隐性的。\n\nIt’s fair to say that while OO languages did not give us something completely brand new, it did make the masquerading of data structures significantly more convenient.\n\n> 综上所述，我们可以认为，虽然面向对象编程在继承性方面并没有开创出新，但是的确在数据结构的伪装性上提供了相当程度的便利性。\n\nTo recap: We can award no point to OO for encapsulation, and perhaps a half-point for inheritance. So far, that’s not such a great score.\n\n> 回顾一下到目前为止的分析，面向对象编程在封装性上得 0 分，在继承性上勉强可以得 0.5 分（满分为 1)。\n\nBut there’s one more attribute to consider.\n\n> 下面，我们还有最后一个特性要讨论。\n\n## POLYMORPHISM? 多态\n\nDid we have polymorphic behavior before OO languages? Of course we did. Consider this simple C copy program.\n\n> 在面向编程对象语言被发明之前，我们所使用的编程语言能支持多态吗? 答案是肯定的，请注意看下面这段用 C 语言编写的 copy 程序：\n\n```c\n#include <stdio.h>\n\nvoid copy() {\n  int c;\n  while ((c=getchar()) != EOF)\n    putchar(c);\n}\n```\n\nThe function getchar() reads from STDIN. But which device is STDIN? The putchar() function writes to STDOUT. But which device is that? These functions are polymorphic—their behavior depends on the type of STDIN and STDOUT.\n\n> 在上述程序中，函数 `getchar()` 主要负责从 STDTN 中读取数据。但是 STDLLN 究竟指代的是哪个设备呢？同样的道理，`putchar()` 主要负责将数据写入 STDOUT，而 STDOUT 又指代的是哪个设备呢？很显然，这类函数其实就具有多态性，因为它们的行为依赖于 STDIN 和 STDOUT 的具体类型。\n\nIt’s as though STDIN and STDOUT are Java-style interfaces that have implementations for each device. Of course, there are no interfaces in the example C program—so how does the call to getchar() actually get delivered to the device driver that reads the character?\n\n> 这里的 STDIN 和 STDOUT 与 Java 中的接口类似，各种设备都有各自的实现。当然，这个 C 程序中是没有接口这个概念的，那么 `getchar()` 这个调用的动作是 如何真正传递到设备驱动程序中，从而读取到具体内容的呢？\n\nThe answer to that question is pretty straightforward. The UNIX operating system requires that every IO device driver provide five standard functions:5 open, close, read, write, and seek. The signatures of those functions must be identical for every IO driver.\n\n> 其实很简单，UNIX 操作系统强制要求每个 IO 设备都要提供 open、close、read、write 和 seek 这 5 个标准函数。也就是说，每个 IO 设备驱动程序对这 5 种函数的实现在函数调用上必须保持一致。\n\nThe FILE data structure contains five pointers to functions. In our example, it might look like this:\n\n> 首先，FILE 数据结构体中包含了相对应的 5 个函数指针，分别用于指向这些函数：\n\n```c\nstruct FILE {  void (*open)(char* name, int mode);  void (*close)();  int (*read)();  void (*write)(char);  void (*seek)(long index, int mode);};\n```\n\nThe IO driver for the console will define those functions and load up a FILE data structure with their addresses—something like this:\n\n> 然后，譬如控制台设备的 IO 驱动程序就会提供这 5 个函数的实际定义，将 FILE 结构体的函数指针指向这些对应的实现函数：\n\n```c\n#include \"file.h\"void open(char* name, int mode) {/*...*/}void close() {/*...*/};int read() {int c;/*...*/ return c;}void write(char c) {/*...*/}void seek(long index, int mode) {/*...*/}struct FILE console = {open, close, read, write, seek};\n```\n\nNow if STDIN is defined as a `FILE*`, and if it points to the console data structure, then getchar() might be implemented this way:\n\n> 现在，如果 STDIN 的定义是 `FILE*`，并同时指向了 console 这个数据结构，那么 `getchar()` 的实现方式就是这样的：\n\n```c\nextern struct FILE* STDIN;int getchar() {  return STDIN->read();}\n```\n\nIn other words, getchar() simply calls the function pointed to by the read pointer of the FILE data structure pointed to by STDIN.\n\n> 换句话说，`getchar()` 只是调用了 STDIN 所指向的 FIL E 数据结构体中的 read 函数指针指向的函数。\n\nThis simple trick is the basis for all polymorphism in OO. In C++, for example, every virtual function within a class has a pointer in a table called a vtable, and all calls to virtual functions go through that table. Constructors of derivatives simply load their versions of those functions into the vtable of the object being created.\n\n> 这个简单的编程技巧正是面向对象编程中多态的基础。例如在 C++中，类中的每个虚函数（virtual function）的地址都被记录在一个名叫 vtable 的数据结构里。我们对虚函数的每次调用都要先查询这个表，其衍生类的构造函数负责将该衍生类的虚函数地址加载到整个对象的 vtable 中。\n\nThe bottom line is that polymorphism is an application of pointers to functions. Programmers have been using pointers to functions to achieve polymorphic behavior since Von Neumann architectures were first implemented in the late 1940s. In other words, OO has provided nothing new.\n\n> 归根结底，多态其实不过就是函数指针的一种应用。自从 20 世纪 40 年代末期冯·诺依曼架构诞生那天起，程序员们就一直在使用函数指针模拟多态了。也就是说，面向对象编程在多态方面没有提出任何新概念。\n\nAh, but that’s not quite correct. OO languages may not have given us polymorphism, but they have made it much safer and much more convenient.\n\n> 当然了，面向对象编程语言虽然在多态上并没有理论创新，但它们也确实让多态变得更安全、更便于使用了。\n\nThe problem with explicitly using pointers to functions to create polymorphic behavior is that pointers to functions are dangerous. Such use is driven by a set of manual conventions. You have to remember to follow the convention to initialize those pointers. You have to remember to follow the convention to call all your functions through those pointers. If any programmer fails to remember these conventions, the resulting bug can be devilishly hard to track down and eliminate.\n\n> 用函数指针显式实现多态的问题就在于函数指针的危险性。毕竟，函数指针的调用依赖于一系列需要人为遵守的约定。程序员必须严格按照固定约定来初始化函数指针，并同样严格地按照约定来调用这些指针。只要有一个程序员没有遵守这些约定，整个程序就会产生极其难以跟踪和消除的 Bug。\n\nOO languages eliminate these conventions and, therefore, these dangers. Using an OO language makes polymorphism trivial. That fact provides an enormous power that old C programmers could only dream of. On this basis, we can conclude that OO imposes discipline on indirect transfer of control.\n\n> 面向对象编程语言为我们消除人工遵守这些约定的必要，也就等于消除了这方面的危险性。采用面向对象编程语言让多态实现变得非常简单，让一个传统 C 程序员可以去做以前不敢想的事情。综上所述，我们认为面向对象编程其实是对程序间接控制权的转移进行了约束。\n\n### THE POWER OF POLYMORPHISM 多态的强大性\n\nWhat’s so great about polymorphism? To better appreciate its charms, let’s reconsider the example copy program. What happens to that program if a new IO device is created? Suppose we want to use the copy program to copy data from a handwriting recognition device to a speech synthesizer device: How do we need to change the copy program to get it to work with those new devices?\n\n> 那么多态的优势在哪里呢？为了让读者更好地理解多态的好处，我们需要再来看一下刚才的 copy 程序。如果要支持新的 IO 设备，该程序需要做什么改动呢？譬如，假设我们想要用该 copy 程序从一个手写识别设备将数据复制到另一个语音合成设备中，我们需要针对 copy 程序做什么改动，才能实现这个目标呢？\n\nWe don’t need any changes at all! Indeed, we don’t even need to recompile the copy program. Why? Because the source code of the copy program does not depend on the source code of the IO drivers. As long as those IO drivers implement the five standard functions defined by FILE, the copy program will be happy to use them.\n\n> 答案是完全不需要做任何改动！确实，我们甚至不需要重新编译该 copy 程序。为什么？因为 copy 程序的源代码并不依赖于 IO 设备驱动程序的代码。只要 IO 设备驱动程序实现了 FILE 结构体中定义的 5 个标准函数，该 copy 程序就可以正常使用它们。\n\nIn short, the IO devices have become plugins to the copy program.\n\n> 简单来说，IO 设备变成了 copy 程序的插件。\n\nWhy did the UNIX operating system make IO devices plugins? Because we learned, in the late 1950s, that our programs should be device independent. Why? Because we wrote lots of programs that were device dependent, only to discover that we really wanted those programs to do the same job but use a different device.\n\n> 为什么 UNIX 操作系统会将 IO 设备设计成插件形式呢？因为自 20 世纪 50 年代末期以来，我们学到了一个重要经验：程序应该与设备无关。这个经验从何而来呢？因为一度所有程序都是设备相关的，但是后来我们发现自己其实真正需要的是在不同的设备上实现同样的功能。\n\nFor example, we often wrote programs that read input data from decks of cards,6 and then punched new decks of cards as output. Later, our customers stopped giving us decks of cards and started giving us reels of magnetic tape. This was very inconvenient, because it meant rewriting large portions of the original program. It would be very convenient if the same program worked interchangeably with cards or tape.\n\n> 例如，我们曾经写过一些程序，需要从卡片盒中的打孔卡片读取数据，同时要通过在新的卡片上打孔来输出数据。后来，客户不再使用打孔卡片，而开始使用磁带卷了。这就给我们带来了很多麻烦，很多程序都需要重写。于是我们就会想，如果这段程序可以同时操作打孔卡片和磁带那该多好。\n\nThe plugin architecture was invented to support this kind of IO device independence, and has been implemented in almost every operating system since its introduction. Even so, most programmers did not extend the idea to their own programs, because using pointers to functions was dangerous.\n\n> 插件式架构就是为了支持这种 IO 不相关性而发明的，它几乎在随后的所有系统中都有应用。但即使多态有如此多优点，大部分程序员还是没有将插件特性引入他们自己的程序中，因为函数指针实在是太危险了。\n\nOO allows the plugin architecture to be used anywhere, for anything.\n\n> 而面向对象编程的出现使得这种插件式架构可以在任何地方被安全地使用。\n\n### DEPENDENCY INVERSION 依赖反转\n\nImagine what software was like before a safe and convenient mechanism for polymorphism was available. In the typical calling tree, main functions called high-level functions, which called mid-level functions, which called low-level functions. In that calling tree, however, source code dependencies inexorably followed the flow of control (Figure 5.1).\n\n> 我们可以想象一下在安全和便利的多态支持出现之前，软件是什么样子的。下面有一个典型的调用树的例子，main 函数调用了一些高层函数，这些高层函数又调用了一些中层函数，这些中层函数又继续调用了一些底层函数。在这里，源代码面的依赖不可避免地要跟随程序的控制流（详见图 5.1）。\n\n<Figures figure=\"5-1\">Source code dependencies versus flow of control</Figures>\n\nFor mainq1w2e3r4 to call one of the high-level functions, it had to mention the name of the module that contained that function In C, this was a #include. In Java, it was an import statement. In C#, it was a using statement. Indeed, every caller was forced to mention the name of the module that contained the callee.\n\n> 如你所见，main 函数为了调用高层函数，它就必须能够看到这个函数所在模块。在 C 中，我们会通过 #include 来实现，在 Java 中则通过 import 来实现，而在 C# 中则用的是 using 语句。总之，每个函数的调用方都必须要引用被调用方所在的模块。\n\nThis requirement presented the software architect with few, if any, options. The flow of control was dictated by the behavior of the system, and the source code dependencies were dictated by that flow of control.\n\n> 显然，这样做就导致了我们在软件架构上别无选择。在这里，系统行为决定了控制流，而控制流则决定了源代码依赖关系。\n\nWhen polymorphism is brought into play, however, something very different can happen (Figure 5.2).\n\n> 但一旦我们使用了多态，情况就不一样了（详见图 5.2）。\n\n<Figures figure=\"5-2\">Dependency inversion</Figures>\n\nIn Figure 5.2, module HL1 calls the F() function in module ML1. The fact that it calls this function through an interface is a source code contrivance. At runtime, the interface doesn’t exist. HL1 simply calls F() within ML1.7\n\n> 在图 5.2 中，模块 HL1 调用了 ML1 模块中的 F() 函数，这里的调用是通过源代码级别的接口来实现的。当然在程序实际运行时，接口这个概念是不存在的，HL1 会调用 ML1 中的 F() 函数。\n\nNote, however, that the source code dependency (the inheritance relationship) between ML1 and the interface I points in the opposite direction compared to the flow of control. This is called dependency inversion, and its implications for the software architect are profound.\n\n> 请注意模块 ML1 和接口 I 在源代码上的依赖关系（或者叫继承关系），该关系的方向和控制流正好是相反的，我们称之为依赖反转。这种反转对软件架构设计的影响是非常大的。\n\nThe fact that OO languages provide safe and convenient polymorphism means that any source code dependency, no matter where it is, can be inverted.\n\n> 事实上，通过利用面向编程语言所提供的这种安全便利的多态实现，无论我们面对怎样的源代码级别的依赖关系，都可以将其反转。\n\nNow look back at that calling tree in Figure 5.1, and its many source code dependencies. Any of those source code dependencies can be turned around by inserting an interface between them.\n\n> 现在，我们可以再回头来看图 5.1 中的调用树，就会发现其中的众多源代码依赖关系都可以通过引入接口的方式来进行反转。\n\nWith this approach, software architects working in systems written in OO languages have absolute control over the direction of all source code dependencies in the system. They are not constrained to align those dependencies with the flow of control. No matter which module does the calling and which module is called, the software architect can point the source code dependency in either direction.\n\n> 通过这种方法，软件架构师可以完全控制采用了面向对象这种编程方式的系统中所有的源代码依赖关系，而不再受到系统控制流的限制。不管哪个模块调用或者被调用，软件架构师都可以随意更改源代码依赖关系。\n\nThat is power! That is the power that OO provides. That’s what OO is really all about—at least from the architect’s point of view.\n\n> 这就是面向对象编程的好处，同时也是面向对象编程这种范式的核心本质至少对一个软件架构师来说是这样的。\n\nWhat can you do with that power? As an example, you can rearrange the source code dependencies of your system so that the database and the user interface (UI) depend on the business rules (Figure 5.3), rather than the other way around.\n\n> 这种能力有什么用呢？在下面的例子中，我们可以用它来让数据库模块和用户界面模块都依赖于业务逻辑模块（见图 5.3），而非相反。\n\n<Figures figure=\"5-3\">The database and the user interface depend on the business rules</Figures>\n\nThis means that the UI and the database can be plugins to the business rules. It means that the source code of the business rules never mentions the UI or the database.\n\n> 这意味着我们让用户界面和数据库都成为业务逻辑的插件。也就是说，业务逻辑模块的源代码不需要引入用户界面和数据库这两个模块。\n\nAs a consequence, the business rules, the UI, and the database can be compiled into three separate components or deployment units (e.g., jar files, DLLs, or Gem files) that have the same dependencies as the source code. The component containing the business rules will not depend on the components containing the UI and database.\n\n> 这样一来，业务逻辑、用户界面以及数据库就可以被编译成三个独立的组件或者部署单元（例如 jar 文件、DLL 文件、Gem 文件等）了，这些组件或者部署单元的依赖关系与源代码的依赖关系是一致的，业务逻辑组件也不会依赖于用户界面和数据库这两个组件。\n\nIn turn, the business rules can be deployed independently of the UI and the database. Changes to the UI or the database need not have any effect on the business rules. Those components can be deployed separately and independently.\n\n> 于是，业务逻辑组件就可以独立于用户界面和数据库来进行部署了，我们对用户界面或者数据库的修改将不会对业务逻辑产生任何影响，这些组件都可以被分另独立地部署。\n\nIn short, when the source code in a component changes, only that component needs to be redeployed. This is independent deployability.\n\n> 简单来说，当某个组件的源代码需要修改时，仅仅需要重新部署该组件，不需要更改其他组件，这就是独立部署能力。\n\nIf the modules in your system can be deployed independently, then they can be developed independently by different teams. That’s independent developability.\n\n> 如果系统中的所有组件都可以独立部署，那它们就可以由不同的团队并行开发，这就是所谓的独立开发能力。\n\n## CONCLUSION 本章小结\n\nWhat is OO? There are many opinions and many answers to this question. To the software architect, however, the answer is clear: OO is the ability, through the use of polymorphism, to gain absolute control over every source code dependency in the system. It allows the architect to create a plugin architecture, in which modules that contain high-level policies are independent of modules that contain low-level details. The low-level details are relegated to plugin modules that can be deployed and developed independently from the modules that contain high-level policies.\n\n> 面向对象编程到底是什么？业界在这个问题上存在着很多不同的说法和意见。然而对一个软件架构师来说，其含义应该是非常明确的：面向对象编程就是以对象为手段来对源代码中的依赖关系进行控制的能力，这种能力让软件架构师可以构建出某种插件式架构，让高层策略性组件与底层实现性组件相分离，底层组件可必编译成插件，实现独立于高层组件的开发和部署。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap6. FUNCTIONAL PROGRAMMING 函数式编程\n\n![](../../images/books/架构整洁之道/CH-UN06.jpg)\n\nIn many ways, the concepts of functional programming predate programming itself. This paradigm is strongly based on the l-calculus invented by Alonzo Church in the 1930s.\n\n> 函数式编程所依赖的原理，在很多方而其实是早于编程本身出现的。因为函数式编程这种范式强烈依赖于 Alonzo Church 在 20 世纪 30 年代发明的 λ 演算。\n\n## SQUARES OF INTEGERS 整数平方\n\nTo explain what functional programming is, it’s best to examine some examples. Let’s investigate a simple problem: printing the squares of the first 25 integers.\n\n> 我们最好还是用一个例子来解释什么是函数式编程。请看下面的这个例子：这段代码想要输出前 25 个整数的平方值。\n\nIn a language like Java, we might write the following:\n\n> 如果使用 Java 语言，代码如下：\n\n```java\npublic class Squint {\n  public static void main(String args[]) {\n    for (int i=0; i<25; i++)\n      System.out.println(i*i);\n  }\n}\n```\n\nIn a language like Clojure, which is a derivative of Lisp, and is functional, we might implement this same program as follows:\n\n> 下面我们改用 Clojure 语言来写这个程序，Clojure 是 LISP 语言的一种衍生体，属于函数式编程语言。其代码如下：\n\n```lisp\n(println (take 25 (map (fn [x] (* x x)) (range))))\n```\n\nIf you don’t know Lisp, then this might look a little strange. So let me reformat it a bit and add some comments.\n\n> 如果读者对 LISP 不熟悉，这段代码可能看起来很奇怪。没关系，让我们换一种格式，用注释来说明一下吧：\n\n```lisp\n(println ;___________________ Print\n  (take 25 ;_________________ the first 25\n    (map (fn [x] (* x x)) ;__ squares\n      (range)))) ;___________ of Integers\n```\n\nIt should be clear that println, take, map, and range are all functions. In Lisp, you call a function by putting it in parentheses. For example, (range) calls the range function.\n\n> 很明显，这里的 println、take、map 和 range 都是函数。在 LISP 中，函数是通过括号来调用的，例如（range）表达式就是在调用 range 函数。\n\nThe expression `(fn [x] (* x x))` is an anonymous function that calls the multiply function, passing its input argument in twice. In other words, it computes the square of its input.\n\n> 而表达式 `(fn [x] (* xx))` 则是一个匿名函数，该函数用同样的值作为参数调用了乘法函数。换句话说，该函数计算的是平方值。\n\nLooking at the whole thing again, it’s best to start with the innermost function call.\n\n> 现在让我们回过头再看一下这整句代码，从最内侧的函数调用开始：\n\n- The range function returns a never-ending list of integers starting with 0.\n- This list is passed into the map function, which calls the anonymous squaring function on each element, producing a new never-ending list of all the squares.\n- The list of squares is passed into the take function, which returns a new list with only the first 25 elements.\n- The println function prints its input, which is a list of the first 25 squares of integers.\n\n---\n\n> - range 函数会返回一个从 0 开始的整数无穷列表。\n> - 然后该列表会被传入 map 函数，并针对列表中的每个元素，调用求平方值的匿名函数，产生了一个无穷多的、包含平方值的列表。\n> - 接着再将这个列表传入 take 函数，后者会返回一个仅包含前 25 个元素的 新列表。\n> - println 函数将它的参数输出，该参数就是上面这个包含了 25 个平方值的 列表。\n\nIf you find yourself terrified by the concept of never-ending lists, don’t worry. Only the first 25 elements of those never-ending lists are actually created. That’s because no element of a never-ending list is evaluated until it is accessed.\n\n> 读者不用担心上面提到的无穷列表。因为这些列表中的元素只有在被访问时才会被创建，所以实际上只有前 25 个元素是真正被创建了的。\n\nIf you found all of that confusing, then you can look forward to a glorious time learning all about Clojure and functional programming. It is not my goal to teach you about these topics here.\n\n> 如果上述内容还是让读者觉得云里雾里的话，可以自行学习一下 Clojure 和函数式编程，本书的目标并不是要教你学会这门语言，因此不再展开。\n\nInstead, my goal here is to point out something very dramatic about the difference between the Clojure and Java programs. The Java program uses a mutable variable—a variable that changes state during the execution of the program. That variable is i—the loop control variable. No such mutable variable exists in the Clojure program. In the Clojure program, variables like x are initialized, but they are never modified.\n\n> 相反，我们讨论它的主要目标是要突显出 Clojure 和 Java 这两种语言之间的巨大区别。在 Java 程序中，我们使用的是可变量，即变量 i，该变量的值会随着程序执行的过程而改变，故被称为循环控制变量。而 Clojure 程序中是不存在这种变量的，变量 x 一旦被初始化之后，就不会再被更改了。\n\nThis leads us to a surprising statement: Variables in functional languages do not vary.\n\n> 这句话有点出人意料：函数式编程语言中的变量（Variable）是不可变（Vary）的。\n\n## IMMUTABILITY AND ARCHITECTURE 不可变性与软件架构\n\nWhy is this point important as an architectural consideration? Why would an architect be concerned with the mutability of variables? The answer is absurdly simple: All race conditions, deadlock conditions, and concurrent update problems are due to mutable variables. You cannot have a race condition or a concurrent update problem if no variable is ever updated. You cannot have deadlocks without mutable locks.\n\n> 为什么不可变性是软件架构设计需要考虑的重点呢？为什么软件架构帅要操心变量的可变性呢？答案显而易见：所有的竞争问题、死锁问题、并发更新问题都是由可变变量导致的。如果变量永远不会被更改，那就不可能产生竞争或者并发更新问题。如果锁状态是不可变的，那就永远不会产生死锁问题。\n\nIn other words, all the problems that we face in concurrent applications—all the problems we face in applications that require multiple threads, and multiple processors—cannot happen if there are no mutable variables.\n\n> 换句话说，一切并发应用遇到的问题，一切由于使用多线程、多处理器而引起的问题，如果没有可变变量的话都不对能发工。\n\nAs an architect, you should be very interested in issues of concurrency. You want to make sure that the systems you design will be robust in the presence of multiple threads and processors. The question you must be asking yourself, then, is whether immutability is practicable.\n\n> 作为一个软件架构师，当然应该要对并发问题保持高度关注。我们需要确保自己设计的系统在多线程、多处理器环境中能稳定工作。所以在这里，我们实际应该要问的问题是：不可变性是否实际可行？\n\nThe answer to that question is affirmative, if you have infinite storage and infinite processor speed. Lacking those infinite resources, the answer is a bit more nuanced. Yes, immutability can be practicable, if certain compromises are made.\n\n> 如果我们能忽略存储器与处理器在速度上的限制，那么答案是肯定的。否则的话，不可变性只有在一定情况下是可行的。\n\nLet’s look at some of those compromises.\n\n> 下面让我们来看一下它具体该如何做到可行。\n\n## SEGREGATION OF MUTABILITY 可变性的隔离\n\nOne of the most common compromises in regard to immutability is to segregate the application, or the services within the application, into mutable and immutable components. The immutable components perform their tasks in a purely functional way, without using any mutable variables. The immutable components communicate with one or more other components that are not purely functional, and allow for the state of variables to be mutated (Figure 6.1).\n\n> 一种常见方式是将应用程序，或者是应用程序的内部服务进行切分，划分为可变的和不可变的两种组件。不可变组件用纯函数的方式来执行任务，期间不更改任何状态。这些不可变的组件将通过与一个或多个非函数式组件通信的方式来修改变量状态（参见图 6.1）。\n\n<Figures figure=\"6-1\">Mutating state and transactional memory</Figures>\n\nSince mutating state exposes those components to all the problems of concurrency, it is common practice to use some kind of transactional memory to protect the mutable variables from concurrent updates and race conditions.\n\n> 由于状态的修改会导致一系列并发问题的产生，所以我们通常会采用某种事务型内存来保护可变变量，避免同步更新和竞争状态的发生。\n\nTransactional memory simply treats variables in memory the same way a database treats records on disk.1 It protects those variables with a transaction- or retry-based scheme.\n\n> 事务型内存基本上与数据库保护磁盘数据的方式 1 类似，通常釆用的是事务或者重试机制。\n\nA simple example of this approach is Clojure’s atom facility:\n\n> 下面我们可以用 Clojure 中的 atom 机制来写一个简单的例子：\n\n```clojure\n(def counter (atom 0)) ; initialize counter to 0\n(swap! counter inc)    ; safely increment counter.\n```\n\nIn this code, the counter variable is defined as an atom. In Clojure, an atom is a special kind of variable whose value is allowed to mutate under very disciplined conditions that are enforced by the swap! function.\n\n> 在这段代码中，counter 变量被定义为 atom 类型。在 Clojure 中，atom 是一类特殊的变量，它被允许在 swap!函数定义的严格条件下进行更改。\n\nThe swap! function, shown in the preceding code, takes two arguments: the atom to be mutated, and a function that computes the new value to be stored in the atom. In our example code, the counter atom will be changed to the value computed by the inc function, which simply increments its argument.\n\n> 至于 swap! 函数，如同上面代码所写，它需要两个参数：一个是被用来修改的 atom 类型实例，另一个是用来计算新值的函数。在上面的代码中，inc 函数会将参数加 1 并存入 counter 这个 atom 实例。\n\nThe strategy used by swap! is a traditional compare and swap algorithm. The value of counter is read and passed to inc. When inc returns, the value of counter is locked and compared to the value that was passed to inc. If the value is the same, then the value returned by inc is stored in counter and the lock is released. Otherwise, the lock is released, and the strategy is retried from the beginning.\n\n> 在这里，swap!所采用的策略是传统的比较+替换算法。即先读取 counter 变量的值，再将其传入 inc 函数。然后当 inc 函数返回时，将原先用锁保护起来的 counter 值与传入 inc 时的值进行比较。如果两边的值一致，则将 inc 函数返回的值存入 counter，释放锁。否则，先释放锁，再从头进行重试。\n\nThe atom facility is adequate for simple applications. Unfortunately, it cannot completely safeguard against concurrent updates and deadlocks when multiple dependent variables come into play. In those instances, more elaborate facilities can be used.\n\n> 当然，atom 这个机制只适用于上面这种简单的应用程序，它并不适用于解决由多个相关变量同时需要更改所引发的并发更新问题和死锁问题，要想解决这些问题，我们就需要用到更复杂的机制。\n\nThe point is that well-structured applications will be segregated into those components that do not mutate variables and those that do. This kind of segregation is supported by the use of appropriate disciplines to protect those mutated variables.\n\n> 这里的要点是：一个架构设计良好的应用程序应该将状态修改的部分和不需要修改状态的部分隔离成单独的组件，然后用合适的机制来保护可变量。\n\nArchitects would be wise to push as much processing as possible into the immutable components, and to drive as much code as possible out of those components that must allow mutation.\n\n> 软件架构师应该着力于将大部分处理逻辑都归于不可变组件中，可变状态组件的逻辑应该越少越好。\n\n## EVENT SOURCING 事件溯源\n\nThe limits of storage and processing power have been rapidly receding from view. Nowadays it is common for processors to execute billions of instructions per second and to have billions of bytes of RAM. The more memory we have, and the faster our machines are, the less we need mutable state.\n\n> 随着存储和处理能力的大幅进步，现在拥有每秒可以执行数十亿条指令的处理器，以及数十亿字节内存的计算机已经很常见了。而内存越大，处理速度越快，我们对可变状态的依赖就会越少。\n\nAs a simple example, imagine a banking application that maintains the account balances of its customers. It mutates those balances when deposit and withdrawal transactions are executed.\n\n> 举个简单的例子，假设某个银行应用程序需要维护客户账户余额信息，当它放行存取款事务时，就要同时负责修改余额记录。\n\nNow imagine that instead of storing the account balances, we store only the transactions. Whenever anyone wants to know the balance of an account, we simply add up all the transactions for that account, from the beginning of time. This scheme requires no mutable variables.\n\n> 如果我们不保存具体账户余额，仅仅保存事务日志，那么当有人想查询账户余额时。我们就将全部交易记录取出，并且每次都得从最开始到当下进行累计。当然，这样的设计就不需要维护任何可变变量了。\n\nObviously, this approach sounds absurd. Over time, the number of transactions would grow without bound, and the processing power required to compute the totals would become intolerable. To make this scheme work forever, we would need infinite storage and infinite processing power.\n\n> 但显而易见，这种实现是有些不合理的。因为随着时间的推移，事务的数目会无限制增长，每次处理总额所需要的处理能力很快就会变得不能接受。如果想使这种设计永远可行的话，我们将需要无限容量的存储，以及无限的处理能力。\n\nBut perhaps we don’t have to make the scheme work forever. And perhaps we have enough storage and enough processing power to make the scheme work for the reasonable lifetime of the application.\n\n> 但是可能我们并不需要这个设计永远可行，而且可能在整个程序的生命周期内，我们有足够的存储和处理能力来满足它。\n\nThis is the idea behind event sourcing.2 Event sourcing is a strategy wherein we store the transactions, but not the state. When state is required, we simply apply all the transactions from the beginning of time.\n\n> 这就是事件溯源，在这种体系下，我们只存储事务记录，不存储具体状态。当需要具体状态时，我们只要从头开始计算所有的事务即可。\n\nOf course, we can take shortcuts. For example, we can compute and save the state every midnight. Then, when the state information is required, we need compute only the transactions since midnight.\n\nNow consider the data storage required for this scheme: We would need a lot of it. Realistically, offline data storage has been growing so fast that we now consider trillions of bytes to be small—so we have a lot of it.\n\n> 在存储方面，这种架构的确需要很大的存储容量。如今离线数据存储器的增长是非常快的，现在 1 TB 对我们来说也已经不算什么了。\n\nMore importantly, nothing ever gets deleted or updated from such a data store. As a consequence, our applications are not CRUD; they are just CR. Also, because neither updates nor deletions occur in the data store, there cannot be any concurrent update issues.\n\n> 更重要的是，这种数据存储模式中不存在删除和更新的情况，我们的应用程序不是 CRUD，而是 CR。因为更新和删除这两种操作都不存在了，自然也就不存在并发问题。\n\nIf we have enough storage and enough processor power, we can make our applications entirely immutable—and, therefore, entirely functional.\n\n> 如果我们有足够大的存储量和处理能力，应用程序就可以用完全不可变的、纯函数式的方式来编程。\n\nIf this still sounds absurd, it might help if you remembered that this is precisely the way your source code control system works.\n\n> 如果读者还是觉得这听起来不太靠谱，可以想想我们现在用的源代码管理程序，它们正是用这种方式工作的！\n\n## CONCLUSION 本章小结\n\nTo summarize:\n\n> 下面我们来总结一下：\n\n- Structured programming is discipline imposed upon direct transfer of control.\n- Object-oriented programming is discipline imposed upon indirect transfer of control.\n- Functional programming is discipline imposed upon variable assignment.\n\n---\n\n> - 结构化编程是多对程序控制权的直接转移的限制。\n> - 面向对象编程是对程序控制权的间接转移的限制。\n> - 函数式编程是对程序中赋值操作的限制。\n\nEach of these three paradigms has taken something away from us. Each restricts some aspect of the way we write code. None of them has added to our power or our capabilities.\n\n> 这三个编程范式都对程序员提出了新的限制。每个范式都约束了某种编写代码的方式，没有一个编程范式是在增加新能力。\n\nWhat we have learned over the last half-century is what not to do.\n\n> 也就是说，我们过去 50 年学到的东西主要是——什么不应该做。\n\nWith that realization, we have to face an unwelcome fact: Software is not a rapidly advancing technology. The rules of software are the same today as they were in 1946, when Alan Turing wrote the very first code that would execute in an electronic computer. The tools have changed, and the hardware has changed, but the essence of software remains the same.\n\n> 我们必须面对这种不友好的现实：软件构建并不是一个迅速前进的技术。今天构建软件的规则和 1946 年阿兰·图灵写下电子计算机的第一行代码时是一样的。尽管工具变化了，硬件变化了，但是软件编程的核心没有变。\n\nSoftware—the stuff of computer programs—is composed of sequence, selection, iteration, and indirection. Nothing more. Nothing less.\n\n> 总而言之，软件，或者说计算机程序无一例外是由顺序结构、分支结构、循环结构和间接转移这几种行为组合而成的，无可增加，也缺一不可。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Part3. DESIGN PRINCIPLES 设计原则\n\n![](../../images/books/架构整洁之道/PA-UN03.jpg)\n\nGood software systems begin with clean code. On the one hand, if the bricks aren’t well made, the architecture of the building doesn’t matter much. On the other hand, you can make a substantial mess with well-made bricks. This is where the SOLID principles come in.\n\n> 通常来说，要想构建一个好的软件系统，应该从写整洁的代码开始做起。毕竟，如果建筑所使用的砖头质量不佳，那么架构所能起到的作用也会很有限。反之亦然，如果建筑的架构设计不佳，那么其所用的砖头质量再好也没有用。这就是 SOLID 设计原则所要解决的问题。\n\nThe SOLID principles tell us how to arrange our functions and data structures into classes, and how those classes should be interconnected. The use of the word “class” does not imply that these principles are applicable only to object-oriented software. A class is simply a coupled grouping of functions and data. Every software system has such groupings, whether they are called classes or not. The SOLID principles apply to those groupings.\n\n> SOLID 原则的主要作用就是告诉我们如何将数据和函数组织成为类，以及如将这些类链接起来成为程序。请注意，这里虽然用到了 “类”这个词，但是并不意味着我们将要讨论的这些设计原则仅仅适用于面向对象编程。这里的类仅仅代表一种数据和函数的分组，每个软件系统都会有自己的分类系统，不管它们各自是不是将其称为“类”，事实上都是 SOLID 原则的适用领域。\n\nThe goal of the principles is the creation of mid-level software structures that:\n\n> 一般情况下，我们为软件构建中层结构的主要目标如下：\n\n- Tolerate change,\n- Are easy to understand, and\n- Are the basis of components that can be used in many software systems.\n\n---\n\n> - 使软件可容忍被改动。\n> - 使软件更容易被理解。\n> - 构建可在多个软件系统中复用的组件。\n\nThe term “mid-level” refers to the fact that these principles are applied by programmers working at the module level. They are applied just above the level of the code and help to define the kinds of software structures used within modules and components.\n\n> 我们在这里之所以会使用“中层”这个词，是因为这些设计原则主要适用于那些进行模块级编程的程序员。SOLID 原则应该直接紧贴于具体的代码逻辑之上，这些原则是用来帮助我们定义软件架构中的组件和模块的。\n\nJust as it is possible to create a substantial mess with well-made bricks, so it is also possible to create a system-wide mess with well-designed mid-level components. For this reason, once we have covered the SOLID principles, we will move on to their counterparts in the component world, and then to the principles of high-level architecture.\n\n> 当然了，正如用好砖也会盖歪楼一样，采用设计良好的中层组件并不能保证系统的整体架构运作良好。正因为如此，我们在讲完 SOLID 原则之后，还会再继续针对组件的设计原则进行更进一步的讨论，将其推进到高级软件架构部分。\n\nThe history of the SOLID principles is long. I began to assemble them in the late 1980s while debating software design principles with others on USENET (an early kind of Facebook). Over the years, the principles have shifted and changed. Some were deleted. Others were merged. Still others were added. The final grouping stabilized in the early 2000s, although I presented them in a different order.\n\n> SOLID 原则的历史已经很悠久了，早在 20 世纪 80 年代末期，我在 USENET 新闻组 （该新闻组在当时就相当于今天的 Facebook）上和其他人辩论软件设计理念的时候，该设计原则就已经开始逐渐成型了。随着时间的推移，其中有一些原则得到了修改，有一些则被抛弃了，还有一些被合并了，另外也增加了一些。它们的最终形态是在 2000 年左右形成的，只不过当时采用的是另外一个展现顺序。\n\nIn 2004 or thereabouts, Michael Feathers sent me an email saying that if I rearranged the principles, their first words would spell the word SOLID—and thus the SOLID principles were born.\n\n> 2004 年前后，Michael Feathers 的一封电子邮件提醒我：如果重新排列这些设计原则，那么它们的首字母可以排列成 SOLID——这就是 SOLID 原则诞生的故事。\n\nThe chapters that follow describe each principle more thoroughly. Here is the executive summary:\n\n> 在这一部分中，我们会逐章地详细讨论每个设计原则，下面先来做一个简单摘要。\n\n- SRP: The Single Responsibility Principle\n  An active corollary to Conway’s law: The best structure for a software system is heavily influenced by the social structure of the organization that uses it so that each software module has one, and only one, reason to change.\n- OCP: The Open-Closed Principle\n  Bertrand Meyer made this principle famous in the 1980s. The gist is that for software systems to be easy to change, they must be designed to allow the behavior of those systems to be changed by adding new code, rather than changing existing code.\n- LSP: The Liskov Substitution Principle\n  Barbara Liskov’s famous definition of subtypes, from 1988. In short, this principle says that to build software systems from interchangeable parts, those parts must adhere to a contract that allows those parts to be substituted one for another.\n- ISP: The Interface Segregation Principle\n  This principle advises software designers to avoid depending on things that they don’t use.\n- DIP: The Dependency Inversion Principle\n  The code that implements high-level policy should not depend on the code that implements low-level details. Rather, details should depend on policies.\n\n---\n\n> - SRP：单一职责原则。\n>   该设计原则是某于康威圧律（Conway's Law）的一个推论——一个软件系统的最佳结构高度依赖于开发这个系统的组织的内部结构。这样，每个软件模块都有且只有一个需要被改变的理由。\n> - OCP：开闭原则。\n>   该设计原则是由 Bertrand Meyer 在 20 世纪 80 年代大力推广的，其核心要素是：如果软件系统想要更容易被改变，那么其设计就必须允许新增代码来修改系统行为，而非只能靠修改原来的代码。\n> - LSP：里氏替换原则。\n>   该设计原则是 Barbara Liskov 在 1988 年提出的一个著名的子类型定义。简单来说，这项原则的意思是如果想用可替换的组件来构建软件系统，那么这些组件就必须遵守同一个约定，以便让这些组件可以相互替换。\n> - ISP：接口隔离原则。\n>   这项设计原则主要告诫软件设计师应该在设计中避免不必要的依赖。\n> - DIP：依赖反转原则。\n>   该设计原则指出高层策略性的代码不应该依赖实现底层细节的代码，恰恰相反，那些实现底层细节的代码应该依赖高层策略性的代码。\n\nThese principles have been described in detail in many different publications1 over the years. The chapters that follow will focus on the architectural implications of these principles instead of repeating those detailed discussions. If you are not already familiar with these principles, what follows is insufficient to understand them in detail and you would be well advised to study them in the footnoted documents.\n\n> 这些年来，这些设计原则在很多不同的出版物中都有过详细描述。在接下来的章节中，我们将会主要关注这些原则在软件架构上的意义，而不再重复其细节信息。如果你对这些原则并不是特别了解，那么我建议你先通过脚注中的文档熟悉一下它们，否则接下来的章节可能有点难以理解。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap7. SRP: THE SINGLE RESPONSIBILITY PRINCIPLE SRP：单一职责原则\n\n![](../../images/books/架构整洁之道/CH-UN07.jpg)\n\nOf all the SOLID principles, the Single Responsibility Principle (SRP) might be the least well understood. That’s likely because it has a particularly inappropriate name. It is too easy for programmers to hear the name and then assume that it means that every module should do just one thing.\n\n> SRP 是 SOLID 五大设计原则中最容易被误解的一个。也许是名字的原因，很多程序员根据 SRP 这个名字想当然地认为这个原则就是指：每个模块都应该只做一件事。\n\nMake no mistake, there is a principle like that. A function should do one, and only one, thing. We use that principle when we are refactoring large functions into smaller functions; we use it at the lowest levels. But it is not one of the SOLID principles—it is not the SRP.\n\n> 没错，后者的确也是一个设订原则，即确保一个函数只完成一个功能。我们在将大型函数亜构成小函数时经常会用到这个原则，但这只是一个面向底层实现细节的设计原则，并不是 SRP 的全部。\n\nHistorically, the SRP has been described this way:\n\n> 在历史上，我们曾经这样描述 SRP 这一设计原则：\n\nA module should have one, and only one, reason to change.\n\n> 任何一个软件模块都应该有且仅有一个被修改的原因。\n\nSoftware systems are changed to satisfy users and stakeholders; those users and stakeholders are the “reason to change” that the principle is talking about. Indeed, we can rephrase the principle to say this:\n\n> 在现实环境中，软件系统为了满足用户和所有者的要求，必然要经常做出这样那样的修改。而该系统的用户或者所有者就是该设计原则中所指的“被修改的原因”。所以，我们也可以这样描述 SRP：\n\nA module should be responsible to one, and only one, user or stakeholder.\n\n> 任何一个软件模块都应该只对一个用户（User）或系统利益相关者（Stakeholder）负责。\n\nUnfortunately, the words “user” and “stakeholder” aren’t really the right words to use here. There will likely be more than one user or stakeholder who wants the system changed in the same way. Instead, we’re really referring to a group—one or more people who require that change. We’ll refer to that group as an actor.\n\n> 不过，这里的“用户”和 “系统利益相关者”在用词上也并不完全准确，它们很有可能指的是一个或多个用户和利益相关者，只要这些人希望对系统进行的变更是相似的，就可以归为一类——一个或多个有共同需求的人。在这里，我们将其称为行为者（actor）。\n\nThus the final version of the SRP is:\n\n> 所以，对于 SRP 的最终描述就变成了：\n\nA module should be responsible to one, and only one, actor.\n\n> 任何一个软件模块都应该只对某一类行为者负责。\n\nNow, what do we mean by the word “module”? The simplest definition is just a source file. Most of the time that definition works fine. Some languages and development environments, though, don’t use source files to contain their code. In those cases a module is just a cohesive set of functions and data structures.\n\n> 那么，上文中提到的“软件模块”究竟又是在指什么呢？大部分情况下，其最简单的定义就是指一个源代码文件。然而，有些编程语言和编程环境并不是用源代码文件来存储程序的。在这些情况下，“软件模块”指的就是一组紧密相关的函数和数据结构。\n\nThat word “cohesive” implies the SRP. Cohesion is the force that binds together the code responsible to a single actor.\n\n> 在这里，“相关”这个词实际上就隐含了 SRP 这一原则。代码与数据就是靠着与某一类行为者的相关性被组合在一起的。\n\nPerhaps the best way to understand this principle is by looking at the symptoms of violating it.\n\n> 或许，理解这个设计原则最好的办法就是计大家来看一些反面案例。\n\n## SYMPTOM 1: ACCIDENTAL DUPLICATION 反面案例 1：重复的假象\n\nMy favorite example is the Employee class from a payroll application. It has three methods: calculatePay(), reportHours(), and save() (Figure 7.1).\n\n> 这是我最喜欢举的一个例子：某个工资管理程序中的 Employee 类有三个函数 calculatePay()、reportHours() 和 save()（见图 7.1）。\n\n<Figures figure=\"7-1\">The Employee class</Figures>\n\nThis class violates the SRP because those three methods are responsible to three very different actors.\n\n> 如你所见，这个类的三个函数分别对应的是三类非常不同的行为者，违反了 SRP 设计原则。\n\n- The calculatePay() method is specified by the accounting department, which reports to the CFO.\n- The reportHours() method is specified and used by the human resources department, which reports to the COO.\n- The save() method is specified by the database administrators (DBAs), who report to the CTO.\n\n---\n\n> - calculatePay() 函数是由财务部门制定的，他们负责向 CFO 汇报。\n> - reportHours() 函数是由人力资源部门制定并使用的，他们负责向 COO 汇报。\n> - save() 函数是由 DBA 制定的，他们负责向 CTO 汇报。\n\nBy putting the source code for these three methods into a single Employee class, the developers have coupled each of these actors to the others. This coupling can cause the actions of the CFO’s team to affect something that the COO’s team depends on.\n\n> 这三个函数被放在同一个源代码文件，即同一个 Employee 类中，程序员这样 做实际上就等于使三类行为者的行为耦合在了一起，这有可能会导致 CFO 团队的命令影响到 C 00 团队所依赖的功能。\n\nFor example, suppose that the calculatePay() function and the reportHours() function share a common algorithm for calculating non-overtime hours. Suppose also that the developers, who are careful not to duplicate code, put that algorithm into a function named regularHours() (Figure 7.2).\n\n> 例如，calculatePay() 函数和 reportHours() 函数使用同样的逻辑来计算正常工作时数。程序员为了避免重复编码，通常会将该算法单独实现为一个名为 regularHours() 的函数（见图 7.2）。\n\n<Figures figure=\"7-2\">Shared algorithm</Figures>\n\nNow suppose that the CFO’s team decides that the way non-overtime hours are calculated needs to be tweaked. In contrast, the COO’s team in HR does not want that particular tweak because they use non-overtime hours for a different purpose.\n\n> 接下来，假设 CFO 团队需要修改正常工作时数的计算方法，而 COO 带领的 HR 团队不需要这个修改，因为他们对数据的用法是不同的。\n\nA developer is tasked to make the change, and sees the convenient regularHours() function called by the calculatePay() method. Unfortunately, that developer does not notice that the function is also called by the reportHours() function.\n\n> 这时候，负责这项修改的程序员会注意到 calculatePay() 函数调用了 regularHours() 函数，但可能不会注意到该函数会同时被 reportHours() 调用。\n\nThe developer makes the required change and carefully tests it. The CFO’s team validates that the new function works as desired, and the system is deployed.\n\n> 于是，该程序员就这样按照要求进行了修改，同时 CFO 团队的成员验证了新算法工作正常。这项修改最终被成功部署上线了。\n\nOf course, the COO’s team doesn’t know that this is happening. The HR personnel continue to use the reports generated by the reportHours() function—but now they contain incorrect numbers. Eventually the problem is discovered, and the COO is livid because the bad data has cost his budget millions of dollars.\n\n> 但是，COO 团队显然完全不知道这些事情的发生，HR 仍然在使用 reportHours() 产生的报表，随后就会发现他们的数据出错了！最终这个问题让 COO 十分愤怒，因为这些错误的数据给公司造成了几百万美元的损失。\n\nWe’ve all seen things like this happen. These problems occur because we put code that different actors depend on into close proximity. The SRP says to separate the code that different actors depend on.\n\n> 与此类似的事情我们肯定多多少少都经历过。这类问题发生的根源就是因为我们将不同行为者所依赖的代码强凑到了一起。对此，SRP 强调这类代码一定要被分开。\n\n## SYMPTOM 2: MERGES 反面案例 2：代码合井\n\nIt’s not hard to imagine that merges will be common in source files that contain many different methods. This situation is especially likely if those methods are responsible to different actors.\n\n> 一个拥有很多函数的源代码文件必然会经历很多次代码合并，该文件中的这些函数分别服务不同行为者的情况就更常见了。\n\nFor example, suppose that the CTO’s team of DBAs decides that there should be a simple schema change to the Employee table of the database. Suppose also that the COO’s team of HR clerks decides that they need a change in the format of the hours report.\n\n> 例如，CTO 团队的 DBA 决定要对 Employee 数据库表结构进行简单修改。与此同时，COO 团队的 HR 需要修改工作时数报表的格式。\n\nTwo different developers, possibly from two different teams, check out the Employee class and begin to make changes. Unfortunately their changes collide. The result is a merge.\n\n> 这样一来，就很可能出现两个来自不同团队的程序员分别对 Employee 类进行 修改的情况。不出意外的话，他们各自的修改一定会互相冲突，这就必须要进行代码合并。\n\nI probably don’t need to tell you that merges are risky affairs. Our tools are pretty good nowadays, but no tool can deal with every merge case. In the end, there is always risk.\n\nIn our example, the merge puts both the CTO and the COO at risk. It’s not inconceivable that the CFO could be affected as well.\n\n> 在这个例子中，这次代码合并不仅有可能让 CTO 和 COO 要求的功能出错，甚至连 CFO 原本正常的功能也可能收到影响。\n\nThere are many other symptoms that we could investigate, but they all involve multiple people changing the same source file for different reasons.\n\n> 事实上，这样的案例还有很多，我们就不一一列举了。它们的一个共同点是，多人为了不同的目的修改了同一份源代码，这很容易造成问题的产生。\n\nOnce again, the way to avoid this problem is to separate code that supports different actors.\n\n> 而避免这种问题产生的方法就是将服务不同行为者的代码进行切分。\n\n## SOLUTIONS 解决方案\n\nThere are many different solutions to this problem. Each moves the functions into different classes.\n\n> 我们有很多不同的方法可以用来解决上面的问题，每一种方法都需要将相关的函数划分成不同的类。\n\nPerhaps the most obvious way to solve the problem is to separate the data from the functions. The three classes share access to EmployeeData, which is a simple data structure with no methods (Figure 7.3). Each class holds only the source code necessary for its particular function. The three classes are not allowed to know about each other. Thus any accidental duplication is avoided.\n\n> 其中，最简单直接的办法是将数据与函数分离，设计三个类共同使用一个不包括函数的、十分简单的 EmployeeData 类（见图 7.3），每个类只包含与之相关的函数代码，互相不可见，这样就不存在互相依赖的情况了。\n\n<Figures figure=\"7-3\">The three classes do not know about each other</Figures>\n\nThe downside of this solution is that the developers now have three classes that they have to instantiate and track. A common solution to this dilemma is to use the Facade pattern (Figure 7.4).\n\n> 这种解决方案的坏处在于：程序员现在需要在程序里处理三个类。另一种解决办法是使用 Facade 设计模式（见图 7.4）。\n\n<Figures figure=\"7-4\">The Facade pattern</Figures>\n\nThe EmployeeFacade contains very little code. It is responsible for instantiating and delegating to the classes with the functions.\n\n> 这样一来，EmployeeFacade 类所需要的代码量就很少了，它仅仅包含了初始化和调用三个具体实现类的函数。\n\nSome developers prefer to keep the most important business rules closer to the data. This can be done by keeping the most important method in the original Employee class and then using that class as a Facade for the lesser functions (Figure 7.5).\n\n> 当然，也有些程序员更倾向于把最重要的业务逻辑与数据放在一起，那么我们也可以选择将最重要的函数保留在 Employee 类中，同时用这个类来调用其他没那么重要的函数（见图 7.5）。\n\n<Figures figure=\"7-5\">The most important method is kept in the original Employee class and used as a Facade for the lesser functions</Figures>\n\nYou might object to these solutions on the basis that every class would contain just one function. This is hardly the case. The number of functions required to calculate pay, generate a report, or save the data is likely to be large in each case. Each of those classes would have many private methods in them.\n\n> 读者也许会反对上面这些解决方案，因为看上去这里的每个类中都只有一个函数。事实上并非如此，因为无论是计算工资、生成报表还是保存数据都是一个很复杂的过程，每个类都可能包含了许多私有函数。\n\nEach of the classes that contain such a family of methods is a scope. Outside of that scope, no one knows that the private members of the family exist.\n\n> 总而言之，上面的每一个类都分别容纳了一组作用于相同作用域的函数，而在该作用域之外，它们各自的私有函数是互相不可见的。\n\n## CONCLUSION 本章小结\n\nThe Single Responsibility Principle is about functions and classes—but it reappears in a different form at two more levels. At the level of components, it becomes the Common Closure Principle. At the architectural level, it becomes the Axis of Change responsible for the creation of Architectural Boundaries. We’ll be studying all of these ideas in the chapters to come.\n\n> 单一职责原则主要讨论的是函数和类之间的关系——但是它在两个讨论层面上会以不同的形式出现。在组件层面，我们可以将其称为共同闭包原则（Common Closure Principle)，在软件架构层面，它则是用于奠定架构边界的变更轴心（Axis of Change）。我们在接下来的章节中会深入学习这些原则。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap8. OCP: THE OPEN-CLOSED PRINCIPLE OCP：开闭原则\n\n![](../../images/books/架构整洁之道/CH-UN08.jpg)\n\nThe Open-Closed Principle (OCP) was coined in 1988 by Bertrand Meyer.1 It says:\n\n> 开闭原则（OCP）是 Bertrand Meyer 在 1988 年提出的，该设计原则认为：\n\nA software artifact should be open for extension but closed for modification.\n\n> 设计良好的计算机软件应该易于扩展，同时抗拒修改。\n\nIn other words, the behavior of a software artifact ought to be extendible, without having to modify that artifact.\n\n> 换句话说，一个设计良好的计算机系统应该在不需要修改的前提下就可以轻易被扩展。\n\nThis, of course, is the most fundamental reason that we study software architecture. Clearly, if simple extensions to the requirements force massive changes to the software, then the architects of that software system have engaged in a spectacular failure.\n\n> 其实这也是我们研究软件架构的根本目的。如果对原始需求的小小延伸就需要对原有的软件系统进行大幅修改，那么这个系统的架构设计显然是失败的。\n\nMost students of software design recognize the OCP as a principle that guides them in the design of classes and modules. But the principle takes on even greater significance when we consider the level of architectural components.\n\n> 尽管大部分软件设计师都已经认可了 OCP 是设计类与模块时的重要原则，但是在软件架构层面，这项原则的意义则更为重大。\n\nA thought experiment will make this clear.\n\n> 下面，让我们用一个思想实验来做一些说明。\n\n## A THOUGHT EXPERIMENT 思想实验\n\nImagine, for a moment, that we have a system that displays a financial summary on a web page. The data on the page is scrollable, and negative numbers are rendered in red.\n\n> 假设我们现在要设计一个在 Web 页面上展示财务数据的系统，页面上的数据要可以滚动显示，其中负值应显示为红色。\n\nNow imagine that the stakeholders ask that this same information be turned into a report to be printed on a black-and-white printer. The report should be properly paginated, with appropriate page headers, page footers, and column labels. Negative numbers should be surrounded by parentheses.\n\n> 接下来，该系统的所有者又要求同样的数据需要形成一个报表，该报表要能用黑白打印机打印，并且其报表格式要得到合理分页，每页都要包含页头、页尾及栏目名。同时，负值应该以括号表示。\n\nClearly, some new code must be written. But how much old code will have to change?\n\n> 显然，我们需要增加一些代码来完成这个要求。但在这里我们更关注的问题是，满足新的要求需要更改多少旧代码。\n\nA good software architecture would reduce the amount of changed code to the barest minimum. Ideally, zero.\n\n> 一个好的软件架构设计师会努力将旧代码的修改需求量降至最小，甚至为 0。\n\nHow? By properly separating the things that change for different reasons (the Single Responsibility Principle), and then organizing the dependencies between those things properly (the Dependency Inversion Principle).\n\n> 但该如何实现这一点呢？我们可以先将满足不同需求的代码分组（即 SRP），然后再来调整这些分组之间的依赖关系（即 DIP）。\n\nBy applying the SRP, we might come up with the data-flow view shown in Figure 8.1. Some analysis procedure inspects the financial data and produces reportable data, which is then formatted appropriately by the two reporter processes.\n\n> 利用 SRP，我们可以按图 8.1 中所展示的方式来处理数据流。即先用一段分析程序处理原始的财务数据，以形成报表的数据结构，最后再用两个不同的报表生成器来产生报表。\n\n<Figures figure=\"8-1\">Applying the SRP</Figures>\n\nThe essential insight here is that generating the report involves two separate responsibilities: the calculation of the reported data, and the presentation of that data into a web- and printer-friendly form.\n\n> 这里的核心就是将应用生成报表的过程拆成两个不同的操作。即先计算出报表数据，再生成具体的展示报表（分别以网页及纸质的形式展示）。\n\nHaving made this separation, we need to organize the source code dependencies to ensure that changes to one of those responsibilities do not cause changes in the other. Also, the new organization should ensure that the behavior can be extended without undo modification.\n\n> 接下来，我们就该修改其源代码之间的依赖关系了。这样做的目的是保证其中一个操作被修改之后不会影响到另外一个操作。同时，我们所构建的新的组织形式应该保证该程序后续在行为上的扩展都无须修改现有代码。\n\nWe accomplish this by partitioning the processes into classes, and separating those classes into components, as shown by the double lines in the diagram in Figure 8.2. In this figure, the component at the upper left is the Controller. At the upper right, we have the Interactor. At the lower right, there is the Database. Finally, at the lower left, there are four components that represent the Presenters and the Views.\n\n> 在具体实现上，我们会将整个程序进程划分成一系列的类，然后再将这些类分割成不同的组件。下面，我们用图 8.2 中的那些双线框来具体描述一下整个实现。在这个图中，左上角的组件是 Controller，右上角是 Interactor，右下角是 Database，左下角则有四个组件分别用于代表不同的 Presenter 和 View。\n\n<Figures figure=\"8-2\">Partitioning the processes into classes and separating the classes into components</Figures>\n\nClasses marked with `<I>` are interfaces; those marked with `<DS>` are data structures. Open arrowheads are using relationships. Closed arrowheads are implements or inheritance relationships.\n\n> 在图 8.2 中，用 `<I>` 标记的类代表接口，用 `<DS>` 标记的则代表数据结构；开放箭头指代的是使用关系，闭合箭头则指代了实现与继承关系。\n\nThe first thing to notice is that all the dependencies are source code dependencies. An arrow pointing from class A to class B means that the source code of class A mentions the name of class B, but class B mentions nothing about class A. Thus, in Figure 8.2, FinancialDataMapper knows about FinancialDataGateway through an implements relationship, but FinancialDataGateway knows nothing at all about FinancialDataMapper.\n\n> 首先，我们在图 8.2 中看到的所有依赖关系都是其源代码中存在的依赖关系。这里，从类 A 指向类 B 的箭头意味着 A 的源代码中涉及了 B，但 是 B 的源代码中并不涉及 A。因此在图 8.2 中，FinancialDataMapper 在实现接口时需要知道 FinancialDataGateway 的实现，而 FinancialDataGateway 则完全知道 FinancialDataMapper 的实现。\n\nThe next thing to notice is that each double line is crossed in one direction only. This means that all component relationships are unidirectional, as shown in the component graph in Figure 8.3. These arrows point toward the components that we want to protect from change.\n\n> 其次，这里很重要的一点是这些双线框的边界都是单向跨越的。也就是说，上图中所有组件之间的关系都是单向依赖的，如图 8.3 所示，图中的箭头都指向那些我们不想经常更改的组件。\n\n<Figures figure=\"8-3\">The component relationships are unidirectional</Figures>\n\nLet me say that again: If component A should be protected from changes in component B, then component B should depend on component A.\n\n> 让我们再来复述一下这里的设计原则：如果 A 组件不想被 B 组件上发生的修改所影响，那么就应该让 B 组件依赖于 A 组件。\n\nWe want to protect the Controller from changes in the Presenters. We want to protect the Presenters from changes in the Views. We want to protect the Interactor from changes in—well, anything.\n\n> 所以现在的情况是，我们不想让发生在 Presenter 上的修改影响到 Controller，也不想让发生在 View 上的修改影响到 Presenter。而最关键的是，我们不想让任何修改影响到 Interactor。\n\nThe Interactor is in the position that best conforms to the OCP. Changes to the Database, or the Controller, or the Presenters, or the Views, will have no impact on the Interactor.\n\n> 其中，Interactor 组件是整个系统中最符合 OCP 的。发生在 Database、Controller、Presenter 甚至 View 上的修改都不会影响到 Interactor。\n\nWhy should the Interactor hold such a privileged position? Because it contains the business rules. The Interactor contains the highest-level policies of the application. All the other components are dealing with peripheral concerns. The Interactor deals with the central concern.\n\n> 为什么 Interactor 会被放在这么重要的位置上呢？因为它是该程序的业务逻辑所在之处，Interactor 中包含了其最高层次的应用策略。其他组件都只是负责处理周边的辅助逻辑，只有 Interactor 才是核心组件。\n\nEven though the Controller is peripheral to the Interactor, it is nevertheless central to the Presenters and Views. And while the Presenters might be peripheral to the Controller, they are central to the Views.\n\n> 虽然 Controller 组件只是 Interactor 的附属品，但它却是 Presenter 和 View 所服务的核心。同样的，虽然 Presenter 组件是 Controller 的附属品，但它却是 View 所服务的核心。\n\nNotice how this creates a hierarchy of protection based on the notion of “level.” Interactors are the highest-level concept, so they are the most protected. Views are among the lowest-level concepts, so they are the least protected. Presenters are higher level than Views, but lower level than the Controller or the Interactor.\n\n> 另外需要注意的是，这里利用“层级”这个概念创造了一系列不同的保护层级。譬如，Interactor 是最高层的抽象，所以它被保护得最严密，而 Presenter 比 View 时层级高，但比 Controller 和 Interactor 的层级低。\n\nThis is how the OCP works at the architectural level. Architects separate functionality based on how, why, and when it changes, and then organize that separated functionality into a hierarchy of components. Higher-level components in that hierarchy are protected from the changes made to lower-level components.\n\n> 以上就是我们在软件架构层次上对 OCP 这一设计原则的应用。软件架构师可以根据相关函数被修改的原因、修改的方式及修改的时间来对其进行分组隔离，并将这些互相隔离的函数分组整理成组件结构，使得高阶组件不会因低阶组件被修改而受到影响。\n\n## DIRECTIONAL CONTROL 依赖方向的控制\n\nIf you recoiled in horror from the class design shown earlier, look again. Much of the complexity in that diagram was intended to make sure that the dependencies between the components pointed in the correct direction.\n\n> 如果刚刚的类设计把你吓着了，别害怕！你刚刚在图表中所看到的复杂度是我们想要对组件之间的依赖方向进行控制而产生的。\n\nFor example, the FinancialDataGateway interface between the FinancialReportGenerator and the FinancialDataMapper exists to invert the dependency that would otherwise have pointed from the Interactor component to the Database component. The same is true of the FinancialReportPresenter interface, and the two View interfaces.\n\n> 例如，FinanciaIReportGenerator 和 FinancialDataMapper 之间的 Financial Da taGateway 接口是为了反转 Interactor 与 Database 之间的依赖关系而产生的。同样的，FinancialReportPresenter 接口与两个 View 接口之间也类似于这种情况。\n\n## INFORMATION HIDING 信息隐藏\n\nThe FinancialReportRequester interface serves a different purpose. It is there to protect the FinancialReportController from knowing too much about the internals of the Interactor. If that interface were not there, then the Controller would have transitive dependencies on the FinancialEntities.\n\n> 当然，FinancialReportRequester 接口的作用则完全不同，它的作用是保护 FinancialReportController 不过度依赖于 Interactor 的内部细节。如果没有这个接口，则 Controller 将会传递性地依赖于 FinancialEntities。\n\nTransitive dependencies are a violation of the general principle that software entities should not depend on things they don’t directly use. We’ll encounter that principle again when we talk about the Interface Segregation Principle and the Common Reuse Principle.\n\n> 这种传递性依赖违反了“软件系统不应该依赖其不直接使用的组件”这一基本原则。之后，我们会在讨论接口隔离原则和共同复用原则的时候再次提到这一点。\n\nSo, even though our first priority is to protect the Interactor from changes to the Controller, we also want to protect the Controller from changes to the Interactor by hiding the internals of the Interactor.\n\n> 所以，虽然我们的首要目的是为了让 Interactor 屏蔽掉发生在 Controller 上的修改，但也需要通过隐藏 Interactor 内部细节的方法来让其屏蔽掉来自 Controller 的依赖。\n\n## CONCLUSION 本章小结\n\nThe OCP is one of the driving forces behind the architecture of systems. The goal is to make the system easy to extend without incurring a high impact of change. This goal is accomplished by partitioning the system into components, and arranging those components into a dependency hierarchy that protects higher-level components from changes in lower-level components.\n\n> OCP 是我们进行系统架构设计的主导原则，其主要目标是让系统易于扩展，同时限制其每次被修改所影响的范围。实现方式是通过将系统划分为一系列组件，并且将这些组件间的依赖关系按层次结构进行组织，使得高阶组件不会因低阶组件被修改而受到影响。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap9. LSP: THE LISKOV SUBSTITUTION PRINCIPLE LSP：里氏替换原则\n\n![](../../images/books/架构整洁之道/CH-UN09.jpg)\n\nIn 1988, Barbara Liskov wrote the following as a way of defining subtypes.\n\n> 1988 年，Barbara Liskov 在描述如何定义子类型时写下了这样一段话：\n\nWhat is wanted here is something like the following substitution property: If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.1\n\n> 这里需要的是一种可替换性：如果对于每个类型是 S 的对象 o1 都存在一个类型为 T 的对象 o2，能使操作 T 类型的程序 P 在用 o2 替换 o1 时行为保持不变，我们就可以将 S 称为 T 的子类型。\n\nTo understand this idea, which is known as the Liskov Substitution Principle (LSP), let’s look at some examples.\n\n> 为了让读者理解这段话中所体现的设计理念，也就是里氏替换原则（LSP），我们可以来看几个例子。\n\n## GUIDING THE USE OF INHERITANCE 继承的使用指导\n\nImagine that we have a class named License, as shown in Figure 9.1. This class has a method named calcFee(), which is called by the Billing application. There are two “subtypes” of License: PersonalLicense and BusinessLicense. They use different algorithms to calculate the license fee.\n\n> 假设我们有一个 License 类，其结构如图 9.1 所示。该类中有一个名为 calcFee() 的方法，该方法将由 Billing 应用程序来调用。而 License 类有两个“子类型”：PersonalLicense 与 BusinessLicense，这两个类会用不同的算法来计算授权费用。\n\n<Figures figure=\"9-1\">License, and its derivatives, conform to LSP</Figures>\n\nThis design conforms to the LSP because the behavior of the Billing application does not depend, in any way, on which of the two subtypes it uses. Both of the subtypes are substitutable for the License type.\n\n> 上述设计是符合 LSP 原则的，因为 Billing 应用程序的行为并不依赖于其使用的任何一个衍生类。也就是说，这两个衍生类的对象都是可以用来替换 License 类对象的。\n\n## THE SQUARE/RECTANGLE PROBLEM 正方形/长方形问题\n\nThe canonical example of a violation of the LSP is the famed (or infamous, depending on your perspective) square/rectangle problem (Figure 9.2).\n\n> 正方形/长方形问题是个著名（或者说臭名远扬）的违反 LSP 的设计案例（这个问题的结构如图 9.2 所示）。\n\n<Figures figure=\"9-2\">The infamous square/rectangle problem</Figures>\n\nIn this example, Square is not a proper subtype of Rectangle because the height and width of the Rectangle are independently mutable; in contrast, the height and width of the Square must change together. Since the User believes it is communicating with a Rectangle, it could easily get confused. The following code shows why:\n\n> 在这个案例中，Square 类并不是 Rectangle 类的子类型，因为 Rectangle 类的高和宽可以分别修改，而 Square 类的高和宽则必须一同修改。由于 User 类 始终认为自己在操作 Rectangle 类，因此会带来一些混淆。例如在下面的代码中：\n\n```java\nRectangle r = …\nr.setW(5);\nr.setH(2);\nassert(r.area() == 10);\n```\n\nIf the … code produced a Square, then the assertion would fail.\n\n> 很显然，如果上述代码在…处返回的是 Square 类，则最后的这个 assert 是不会成立的。\n\nThe only way to defend against this kind of LSP violation is to add mechanisms to the User (such as an if statement) that detects whether the Rectangle is, in fact, a Square. Since the behavior of the User depends on the types it uses, those types are not substitutable.\n\n> 如果想要防范这种违反 LSP 的行为，唯一的办法就是在 user 类中增加用于区分 Rectangle 和 Square 的检测逻辑（例如增加 if 语句）。但这样一来，user 为的行为又将依赖于它所使用的类，这两个类就不能互相替换了。\n\n## LSP AND ARCHITECTURE LSP 与软件架构\n\nIn the early years of the object-oriented revolution, we thought of the LSP as a way to guide the use of inheritance, as shown in the previous sections. However, over the years the LSP has morphed into a broader principle of software design that pertains to interfaces and implementations.\n\n> 在面向对象这场编程革命兴起的早期，我们的普遍认知正如上文所说，认为 LSP 只不过是指导如何使用继承关系的一种方法，然而随着时间的推移，LSP 逐渐演变成了一种更广泛的、指导接口与其实现方式的设计原则。\n\nThe interfaces in question can be of many forms. We might have a Java-style interface, implemented by several classes. Or we might have several Ruby classes that share the same method signatures. Or we might have a set of services that all respond to the same REST interface.\n\n> 这里提到的接口可以有多种形式——可以是 Java 风格的接口，具有多个实现类；也可以像 Ruby 一样，几个类共用一样的方法签名，甚至可以是几个服务响应同一个 REST 接口。\n\nIn all of these situations, and more, the LSP is applicable because there are users who depend on well-defined interfaces, and on the substitutability of the implementations of those interfaces.\n\n> LSP 适用于上述所有的应用场景，因为这些场景中的用户都依赖于一种接口，并且都期待实现该接口的类之间能具有可替换性。\n\nThe best way to understand the LSP from an architectural viewpoint is to look at what happens to the architecture of a system when the principle is violated.\n\n> 想要从软件架构的角度来理解 LSP 的意义，最好的办法还是来看几个反面案例。\n\n## EXAMPLE LSP VIOLATION 违反 LSP 的案例\n\nAssume that we are building an aggregator for many taxi dispatch services. Customers use our website to find the most appropriate taxi to use, regardless of taxi company. Once the customer makes a decision, our system dispatches the chosen taxi by using a restful service.\n\n> 假设我们现在正在构建一个提供出租车调度服务的系统。在该系统中，用户可以通过访问我们的网站，从多个出租车公司内寻找最适合自己的出租车。当用户选定车子时，该系统会通过调用 restful 服务接口来调度这辆车。\n\nNow assume that the URI for the restful dispatch service is part of the information contained in the driver database. Once our system has chosen a driver appropriate for the customer, it gets that URI from the driver record and then uses it to dispatch the driver.\n\n> 接下来，我们再假设该 restful 调度服务接口的 URI 被存储在司机数据库中。一旦该系统选中了最合适的出租车司机，它就会从司机数据库的记录中读取相应的 URI 信息，并通过调用这个 URI 来调度汽车。\n\nSuppose Driver Bob has a dispatch URI that looks like this:\n\n> 也就是说，如果司机 Bob 的记录中包含如下调度 URI：\n\n```\npurplecab.com/driver/Bob\n```\n\nOur system will append the dispatch information onto this URI and send it with a PUT, as follows:\n\n> 那么，我们的系统就会将调度信息附加在这个 URI 上，并发送这样一个 PUT 请求：\n\n```\npurplecab.com/driver/Bob\n       /pickupAddress/24 Maple St.\n       /pickupTime/153\n       /destination/ORD\n```\n\nClearly, this means that all the dispatch services, for all the different companies, must conform to the same REST interface. They must treat the pickupAddress, pickupTime, and destination fields identically.\n\n> 很显然，这意味着所存参与该调度服务的公司都必须遵守同样的 REST 接口，它们必须用同样的方式处理 pickupAddress、pickupTime 和 destination 字段。\n\nNow suppose the Acme taxi company hired some programmers who didn’t read the spec very carefully. They abbreviated the destination field to just dest. Acme is the largest taxi company in our area, and Acme’s CEO’s ex-wife is our CEO’s new wife, and … Well, you get the picture. What would happen to the architecture of our system?\n\n> 接下来，我们再假设 Acme 出租车公司现在招聘的程序员由于没有仔细阅读上述接口定义，结果将 destination 字段缩写成了 dest。而 Acme 又是本地最大的出租车公司，另外，Acme CEO 的前妻不巧还是我们 CEO 的新欢……你懂的！这这会对系统的架构造成什么影响呢？\n\nObviously, we would need to add a special case. The dispatch request for any Acme driver would have to be constructed using a different set of rules from all the other drivers.\n\n> 显然，我们需要为系统增加一类特殊用例，以应对 Acme 司机的调度请求。这必须要用另外一套规则来构建。\n\nThe simplest way to accomplish this goal would be to add an if statement to the module that constructed the dispatch command:\n\n> 最简单的做法当然是增加一条 if 语句：\n\n```java\nif (driver.getDispatchUri().startsWith(\"acme.com\"))…\n```\n\nBut, of course, no architect worth his or her salt would allow such a construction to exist in the system. Putting the word “acme” into the code itself creates an opportunity for all kinds of horrible and mysterious errors, not to mention security breaches.\n\n> 然而很明显，任何一个称职的软件架构师都不会允许这样一条语句出现在自己的系统中。因为直接将“acme”这样的字串写入代码会留下各种各样神奇又可怕的错误隐患，甚至会导致安全问题。\n\nFor example, what if Acme became even more successful and bought the Purple Taxi company. What if the merged company maintained the separate brands and the separate websites, but unified all of the original companies’ systems? Would we have to add another if statement for “purple”?\n\n> 例如，Acme 也许会变得更加成功，最终收购了 Purple 出租车公司。然后，它们在保留了各自名字的同时却统一了彼此的计算机系统。在这种情况下，系统中难道还要再增加一条“purple”的特例吗？\n\nOur architect would have to insulate the system from bugs like this by creating some kind of dispatch command creation module that was driven by a configuration database keyed by the dispatch URI. The configuration data might look something like this:\n\n> 软件架构师应该创建一个调度请求创建组件，并让该组件使用一个配置数据库来保存 URI 组装格式，这样的方式可以保护系统不受外界因素变化的影响。例如其配置信息可以如下：\n\n| URI      | Dispatch Format                                |\n| -------- | ---------------------------------------------- |\n| Acme.com | /pickupAddress/%s/pickupTime/%s/dest/%s        |\n| `*.*`    | /pickupAddress/%s/pickupTime/%s/destination/%s |\n\nAnd so our architect has had to add a significant and complex mechanism to deal with the fact that the interfaces of the restful services are not all substitutable.\n\n> 但这样一来，软件架构师就需要通过增加一个复杂的组件来应对并不完全能实现互相替换的 restful 服务接口。\n\n## CONCLUSION 本章小结\n\nThe LSP can, and should, be extended to the level of architecture. A simple violation of substitutability, can cause a system’s architecture to be polluted with a significant amount of extra mechanisms.\n\n> LSP 可以且应该被应用于软件架构层面，因为一旦违背了可替换也该系统架构就不得不为此增添大量复杂的应对机制。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap10. ISP: THE INTERFACE SEGREGATION PRINCIPLE ISP：接口隔离原则\n\n![](../../images/books/架构整洁之道/CH-UN10.jpg)\n\nThe Interface Segregation Principle (ISP) derives its name from the diagram shown in Figure 10.1.\n\n> “接口隔离原则（ISP）”这个名字来自图 10.1 所示的这种软件结构。\n\n<Figures figure=\"10-1\">The Interface Segregation Principle</Figures>\n\nIn the situation illustrated in Figure 10.1, there are several users who use the operations of the OPS class. Let’s assume that User1 uses only op1, User2 uses only op2, and User3 uses only op3.\n\n> 在图 10.1 所描绘的应用中，有多个用户需要操作 OPS 类。现在，我们假设这里的 User1 只需要使用 op1，User2 只需要使用 op2，User3 只需要使用 op3。\n\nNow imagine that OPS is a class written in a language like Java. Clearly, in that case, the source code of User1 will inadvertently depend on op2 and op3, even though it doesn’t call them. This dependence means that a change to the source code of op2 in OPS will force User1 to be recompiled and redeployed, even though nothing that it cared about has actually changed.\n\n> 在这种情况下，如果 OPS 类是用 Java 编程语言编写的，那么很明显，User1 虽然不需要调用 op2、op3，但在源代码层次上也与它们形成依赖关系。这种依赖意味着我们对 OPS 代码中 op2 所做的任何修改，即使不会影响到 User1 的功能，也会导致它需要被重新编译和部署。\n\nThis problem can be resolved by segregating the operations into interfaces as shown in Figure 10.2.\n\nAgain, if we imagine that this is implemented in a statically typed language like Java, then the source code of User1 will depend on U1Ops, and op1, but will not depend on OPS. Thus a change to OPS that User1 does not care about will not cause User1 to be recompiled and redeployed.\n\n> 这个问题可以通过将不同的操作隔离成接口来解决，具体如图 10.2 所示。同样，我们也假设这个例子是用 Java 这种静态类型语言来实现的，那么现在 User1 的源代码会依赖于 U1Ops 和 op1，但不会依赖于 OPS。这样一来，我们之后对 OPS 做的修改只要不影响到 User1 的功能，就不需要重新编译和部署 User1 了。\n\n<Figures figure=\"10-2\">Segregated operations</Figures>\n\n## ISP AND LANGUAGE ISP 与编程语言\n\nClearly, the previously given description depends critically on language type. Statically typed languages like Java force programmers to create declarations that users must import, or use, or otherwise include. It is these included declarations in source code that create the source code dependencies that force recompilation and redeployment.\n\n> 很明显，上述例子很大程度上也依赖于我们所釆用的编程语言：对于 Java 这样的静态类型语言来说，它们需要程序员显式地 import、use 或者 include 其实现功能所需要的源代码。而正是这些语句带来了源代码之间的依赖关系，这也就导致了某些模块需要被重新编译和重新部署。\n\nIn dynamically typed languages like Ruby and Python, such declarations don’t exist in source code. Instead, they are inferred at runtime. Thus there are no source code dependencies to force recompilation and redeployment. This is the primary reason that dynamically typed languages create systems that are more flexible and less tightly coupled than statically typed languages.\n\n> 而对于 Ruby 和 Python 这样的动态类型语言来说，源代码中就不存在这样的声明，它们所用对象的类型会在运行时被推演出来，所以也就不存在强制重新编译重新部署的必要性。这就是动态类型语言要比静态类型语言更灵活、耦合度更松的原因。\n\nThis fact could lead you to conclude that the ISP is a language issue, rather than an architecture issue.\n\n> 当然，如果仅仅就这样说的话，读者可能会误以为 ISP 只是一个与编程语言的选择紧密相关的设计原则，而非软件架构问题，这就错了。\n\n## ISP AND ARCHITECTURE ISP 与软件架构\n\nIf you take a step back and look at the root motivations of the ISP, you can see a deeper concern lurking there. In general, it is harmful to depend on modules that contain more than you need. This is obviously true for source code dependencies that can force unnecessary recompilation and redeployment—but it is also true at a much higher, architectural level.\n\n> 回顾一下 ISP 最初的成因：在一般情况下，任何层次的软件设计如果依赖于不需要的东西，都会是有害的。从源代码层次来说，这样的依赖关系会导致不必要的重新编译和重新部署，对更高层次的软件架构设计来说，问题也是类似的。\n\nConsider, for example, an architect working on a system, S. He wants to include a certain framework, F, into the system. Now suppose that the authors of F have bound it to a particular database, D. So S depends on F. which depends on D (Figure 10.3).\n\n> 例如，我们假设某位软件架构师在设计系统 S 时，想要在该系统中引入某个框架 F。这时候，假设框架 F 的作者又将其捆绑在一个特定的数据库 D 上，那么就形成了 S 依赖于 F，F 又依赖于 D 的关系（参见图 10.3）。\n\n<Figures figure=\"10-3\">A problematic architecture</Figures>\n\nNow suppose that D contains features that F does not use and, therefore, that S does not care about. Changes to those features within D may well force the redeployment of F and, therefore, the redeployment of S. Even worse, a failure of one of the features within D may cause failures in F and S.\n\n> 在这种情况下，如果 D 中包含了 F 不需要的功能，那么这些功能同样也会是 S 不需要的。而我们对 D 中的这些功能的修改将会导致 F 需要被重新部署，后者又会导致 S 的重新部署。更糟糕的是，D 中一个无关功能的错误也可能会导致 F 和 S 运行出错。\n\n## CONCLUSION 本章小结\n\nThe lesson here is that depending on something that carries baggage that you don’t need can cause you troubles that you didn’t expect.\n\n> 本章所讨论的设计原则告诉我们：任何层次的软件设计如果依赖了它并不需要的东西，就会带来意料之外的麻烦。\n\nWe’ll explore this idea in more detail when we discuss the Common Reuse Principle in Chapter 13, “Component Cohesion.”\n\n> 我们将会在第 13 章“组件聚合”中讨论共同复用原则的时候再来深入探讨更多相关的细节。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap11. DIP: THE DEPENDENCY INVERSION PRINCIPLE DIP：依赖反转原则\n\n![](../../images/books/架构整洁之道/CH-UN11.jpg)\n\nThe Dependency Inversion Principle (DIP) tells us that the most flexible systems are those in which source code dependencies refer only to abstractions, not to concretions.\n\n> 依赖反转原则（DIP）主要想告诉我们的是，如果想要设计一个灵活的系统，在源代码层次的依赖关系中就应该多引用抽象类型，而用具体实现。\n\nIn a statically typed language, like Java, this means that the use, import, and include statements should refer only to source modules containing interfaces, abstract classes, or some other kind of abstract declaration. Nothing concrete should be depended on.\n\n> 也就是说，在 Java 这类静态类型的编程语言中，在使用 use、import、include 这些语句时应该只引用那些包含接口、抽象类或者其他抽象类型声明的源文件，不应该引用任何具体实现。\n\nThe same rule applies for dynamically typed languages, like Ruby and Python. Source code dependencies should not refer to concrete modules. However, in these languages it is a bit harder to define what a concrete module is. In particular, it is any module in which the functions being called are implemented.\n\n> 同样的，在 Ruby、Python 这类动态类型的编程语言中，我们也不应该在源代码 层次上引用包含具体实现的模块。当然，在这类语言中，事实上很难清晰界定某个模块是否属于“具体实现”。\n\nClearly, treating this idea as a rule is unrealistic, because software systems must depend on many concrete facilities. For example, the String class in Java is concrete, and it would be unrealistic to try to force it to be abstract. The source code dependency on the concrete java.lang.string cannot, and should not, be avoided.\n\n> 显而易见，把这条设计原则当成金科玉律来加以严格执行是不现实的，因为软件系统在实际构造中不可避免地需要依赖到一些具体实现。例如，Java 中的 String 类就是这样一个具体实现，我们将其强迫转化为抽象类是不现实的，而在源代码层次上也无法避免对 java.lang.String 的依赖，并且也不应该尝试去避免。\n\nBy comparison, the String class is very stable. Changes to that class are very rare and tightly controlled. Programmers and architects do not have to worry about frequent and capricious changes to String.\n\n> 但 String 类本身是非常稳定的，因为这个类被修改的情况是非常罕见的，而且可修改的内容也受到严格的控制，所以程序员和软件架构师完全不必担心 String 类上会发生经常性的或意料之外的修改。\n\nFor these reasons, we tend to ignore the stable background of operating system and platform facilities when it comes to DIP. We tolerate those concrete dependencies because we know we can rely on them not to change.\n\n> 同理，在应用 DIP 时，我们也不必考虑稳定的操作系统或者平台设施，因为这些系统接口很少会有变动。\n\nIt is the volatile concrete elements of our system that we want to avoid depending on. Those are the modules that we are actively developing, and that are undergoing frequent change.\n\n> 我们主要应该关注的是软件系统内部那些会经常变动的（volatile）具体实现模块，这些模块是不停开发的，也就会经常出现变更。\n\n## STABLE ABSTRACTIONS 稳定的抽象层\n\nEvery change to an abstract interface corresponds to a change to its concrete implementations. Conversely, changes to concrete implementations do not always, or even usually, require changes to the interfaces that they implement. Therefore interfaces are less volatile than implementations.\n\n> 我们每次修改抽象接口的时候，一定也会去修改对应的具体实现。但反过来，当我们修改具体实现时，却很少需要去修改相应的抽象接口。所以我们可以认为接口比实现更稳定。\n\nIndeed, good software designers and architects work hard to reduce the volatility of interfaces. They try to find ways to add functionality to implementations without making changes to the interfaces. This is Software Design 101.\n\n> 的确，优秀的软件设计师和架构师会花费很大精力来设计接口，以减少未来对其进行改动。毕竟争取在不修改接口的情况下为软件增加新的功能是软件设计的基础常识。\n\nThe implication, then, is that stable software architectures are those that avoid depending on volatile concretions, and that favor the use of stable abstract interfaces. This implication boils down to a set of very specific coding practices:\n\n> 也就是说，如果想要在软件架构设计上追求稳定，就必须多使用稳定的抽象接口，少依赖多变的具体实现。下面，我们将该设计原则归结为以下几条具体的编码守则：\n\n- Don’t refer to volatile concrete classes. Refer to abstract interfaces instead. This rule applies in all languages, whether statically or dynamically typed. It also puts severe constraints on the creation of objects and generally enforces the use of Abstract Factories.\n- Don’t derive from volatile concrete classes. This is a corollary to the previous rule, but it bears special mention. In statically typed languages, inheritance is the strongest, and most rigid, of all the source code relationships; consequently, it should be used with great care. In dynamically typed languages, inheritance is less of a problem, but it is still a dependency—and caution is always the wisest choice.\n- Don’t override concrete functions. Concrete functions often require source code dependencies. When you override those functions, you do not eliminate those dependencies—indeed, you inherit them. To manage those dependencies, you should make the function abstract and create multiple implementations.\n- Never mention the name of anything concrete and volatile. This is really just a restatement of the principle itself.\n\n---\n\n> - 应在代码中多使用抽象接口，尽量避免使用那些多变的具体实现类。这条守则适用于所有编程语言，无论静态类型语言还是动态类型语言。同时，对象的创建过程也应该受到严格限制，对此，我们通常会选择用抽象工厂（abstract factory）这个设计模式。\n> - 不要在具体实现类上创建衍生类。上一条守则虽然也隐含了这层意思，但它还是值得被单独拿出来做一次详细声明。在静态类型的编程语言中，继承关系是所有一切源代码依赖关系中最强的、最难被修改的，所以我们对继承的使用应该格外小心。即使是在稍微便于修改的动态类型语言中，这条守则也应该被认真考虑。\n> - 不要覆盖（override）包含具体实现的函数。调用包含具体实现的函数通常 就意味着引入了源代码级别的依赖。即使覆盖了这些函数，我们也无法消除这其中的依赖——这些函数继承了那些依赖关系。在这里，控制依赖关系的唯一办法，就是创建一个抽象函数，然后再为该函数提供多种具体实现。\n> - 应避免在代码中写入与任何具体实现相关的名字，或者是其他容易变动的事物的名字。这基本上是 DIP 原则的另外一个表达方式。\n\n## FACTORIES 工厂模式\n\nTo comply with these rules, the creation of volatile concrete objects requires special handling. This caution is warranted because, in virtually all languages, the creation of an object requires a source code dependency on the concrete definition of that object.\n\n> 如果想要遵守上述编码守则，我们就必须要对那些易变对象的创建过程做一些特殊处理，这样的谨慎是很有必要的，因为基本在所有的编程语言中，创建对象的操作都免不了需要在源代码层次上依赖对象的具体实现。\n\nIn most object-oriented languages, such as Java, we would use an Abstract Factory to manage this undesirable dependency.\n\n> 在大部分面向对象编程语言中，人们都会选择用抽象工厂模式来解决这个源代码依赖的问题。\n\nThe diagram in Figure 11.1 shows the structure. The Application uses the ConcreteImpl through the Service interface. However, the Application must somehow create instances of the ConcreteImpl. To achieve this without creating a source code dependency on the ConcreteImpl, the Application calls the makeSvc method of the ServiceFactory interface. This method is implemented by the ServiceFactoryImpl class, which derives from ServiceFactory. That implementation instantiates the ConcreteImpl and returns it as a Service.\n\n> 下面，我们通过图 11.1 来描述一下该设计模式的结构。如你所见 Application 类是通过 Service 接口来使用 Concretelmpl 类的。然而，Application 类还是必须要构造 Concretelmpl 类实例。于是，为了避免在源代码层次上引入对 Concretelmpl 类具体实现的依赖，我们现在让 Application 类去调用 ServiceFactory 接口的 makeSvc 方法。这个方法就由 ServiceFactorylmpl 类来具体提供，它是 ServiceFactory 的一个衍生类。该方法的具体实现就是初始化一个 Concretelmpl 类的实例，并且将其以 Service 类型返回。\n\n<Figures figure=\"11-1\">Use of the Abstract Factory pattern to manage the dependency</Figures>\n\nThe curved line in Figure 11.1 is an architectural boundary. It separates the abstract from the concrete. All source code dependencies cross that curved line pointing in the same direction, toward the abstract side.\n\n> 图 11.1 中间的那条曲线代表了软件架构中的抽象层与具体实现层的边界。在这里，所有跨越这条边界源代码级别的依赖关系都应该是单向的，即具体实现层依赖抽象层。\n\nThe curved line divides the system into two components: one abstract and the other concrete. The abstract component contains all the high-level business rules of the application. The concrete component contains all the implementation details that those business rules manipulate.\n\n> 这条曲线将整个系统划分为两部分组件：抽象接口与其具体实现。抽象接口组件中包含了应用的所有高阶业务规则，而具体实现组件中则包括了所有这些业务规则所需要做的具体操作及其相关的细节信息。\n\nNote that the flow of control crosses the curved line in the opposite direction of the source code dependencies. The source code dependencies are inverted against the flow of control—which is why we refer to this principle as Dependency Inversion.\n\n> 请注意，这里的控制流跨越架构边界的方向与源代码依赖关系跨越该边界的方向正好相反，源代码依赖方向永远是控制流方向的反转——这就是 DIP 被称为依赖反转原则的原因。\n\n## CONCRETE COMPONENTS 具体实现组件\n\nThe concrete component in Figure 11.1 contains a single dependency, so it violates the DIP. This is typical. DIP violations cannot be entirely removed, but they can be gathered into a small number of concrete components and kept separate from the rest of the system.\n\n> 在图 11.1 中，具体实现组件的内部仅有一条依赖关系，这条关系其实是违反 DIP 的。这种情况很常见，我们在软件系统中并不可能完全消除违反 DIP 的情见通常只需要把它们集中于少部分的具体实现组件中，将其与系统的其他部分隔离即可。\n\nMost systems will contain at least one such concrete component—often called main because it contains the main1 function. In the case illustrated in Figure 11.1, the main function would instantiate the ServiceFactoryImpl and place that instance in a global variable of type ServiceFactory. The Application would then access the factory through that global variable.\n\n> 绝大部分系统中都至少存在一个具体实现组件 我们一般称之为 main 组化 因为它们通常是 main 函数所在之处。在 图 11.1 中，函数应该负责创建 ServiceFactoryImpl 实例，并将其赋值给类型为 ServiceFactory 的全局变量，以便让 Application 类通过这个全局变量来进行相关调用。\n\n## CONCLUSION 本章小结\n\nAs we move forward in this book and cover higher-level architectural principles, the DIP will show up again and again. It will be the most visible organizing principle in our architecture diagrams. The curved line in Figure 11.1 will become the architectural boundaries in later chapters. The way the dependencies cross that curved line in one direction, and toward more abstract entities, will become a new rule that we will call the Dependency Rule.\n\n> 随着本书内容的进一步深入，以及我们对高级系统架构理论的进一步讨论，DIP 出现的频率将会越来越高。在系统架构图中，DIP 通常是最显而易见的组织原此我们在后续章节中会把图 11.1 中的那条曲线称为架构边界，而跨越边界的、朝向抽象层的单向依赖关系则会成为一个设计守则——依赖守则。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Part4. COMPONENT PRINCIPLES 组件构建原则\n\nIf the SOLID principles tell us how to arrange the bricks into walls and rooms, then the component principles tell us how to arrange the rooms into buildings. Large software systems, like large buildings, are built out of smaller components.\n\n> 大型软件系统的构建过程与建筑物修建很类似，都是由一个个小组件组成的。所以，如果说 SOLID 原则是用于指导我们如何将砖块砌成墙与房间的，那么组件构建原则就是用来指导我们如何将这些房间组合成房子的。\n\nIn Part IV, we will discuss what software components are, which elements should compose them, and how they should be composed together into systems.\n\n> 在第 4 部分中，我们会详细讨论软件组件是什么，它们由什么元素构成，以及如何利用组件来构建系统。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap12. COMPONENTS 组件\n\n![](../../images/books/架构整洁之道/CH-UN12.jpg)\n\nComponents are the units of deployment. They are the smallest entities that can be deployed as part of a system. In Java, they are jar files. In Ruby, they are gem files. In .Net, they are DLLs. In compiled languages, they are aggregations of binary files. In interpreted languages, they are aggregations of source files. In all languages, they are the granule of deployment.\n\n> 组件是软件的部署单元，是整个软件系统在部署过程中可以独立完成部署的最小实体。例如，对于 Java 来说，它的组件是阿文件。而在 Ruby 中，它们是 gem 文件。在 .Net 中，它们则是 DLL 文件。总而言之，在编译运行语言中，组件是一组二进制文件的集合。而在解释运行语言中，组件则是一组源代码文件的集合。无论术用什么编程语言来开发软件，组件都是该软件在部署过程中的最小单元。\n\nComponents can be linked together into a single executable. Or they can be aggregated together into a single archive, such as a .war file. Or they can be independently deployed as separate dynamically loaded plugins, such as.jar or .dll or .exe files. Regardless of how they are eventually deployed, well-designed components always retain the ability to be independently deployable and, therefore, independently developable.\n\n> 我们可以将多个组件链接成一个独立可执行文件，也可以将它们汇总成类似.W3：文件这样的部署单元，又或者，组件也可以被打包成 .jar、.dll 或者 .exe 文件，并以可动态加载的插件形式来独立部署。但无论采用哪种部署形式，设计良好的组件都应该永远保持可被独立部署的特性，这同时也意味着这些组件应该可以被单独开发。\n\n## A BRIEF HISTORY OF COMPONENTS 组件发展史\n\nIn the early years of software development, programmers controlled the memory location and layout of their programs. One of the first lines of code in a program would be the origin statement, which declared the address at which the program was to be loaded.\n\n> 在早期的软件开发中，程序员可以完全掌控自己编写的程序所处的内存地址和存放格式。在那时，程序中的第一条语句被称为起源（origin）语句，它的作用是声明该程序应该被加载到的内存位置。\n\nConsider the following simple PDP-8 program. It consists of a subroutine named GETSTR that inputs a string from the keyboard and saves it in a buffer. It also has a little unit test program to exercise GETSTR.\n\n> 例如下面这段简单的 PDP-8 程序。该程序中包含一段名为 GETSTR 的子程序，作用是从键盘上读取一个字符串，并将其存入缓冲区。同时，该程序中还包含一段用于测试 GETSTR 功能的单元测试。\n\n```\n                *200\n                TLS\n     START,     CLA\n                TAD BUFR\n                JMS GETSTR\n                CLA\n                TAD BUFR\n                JMS PUTSTR\n                JMP START\n     BUFR,      3000\n\n     GETSTR,    0\n                DCA PTR\n     NXTCH,     KSF\n                JMP -1\n                KRB\n                DCA I PTR\n                TAD I PTR\n                AND K177\n                ISZ PTR\n                TAD MCR\n                SZA\n                JMP NXTCH\n\n     K177,      177\n     MCR,       -15\n```\n\nNote the `*200` command at the start of this program. It tells the compiler to generate code that will be loaded at address 2008.\n\n> 首先，程序开头的头 200 命令告诉编译器生成后的代码应该加载到内存地址为 200（八进制）的位置。\n\nThis kind of programming is a foreign concept for most programmers today. They rarely have to think about where a program is loaded in the memory of the computer. But in the early days, this was one of the first decisions a programmer needed to make. In those days, programs were not relocatable.\n\n> 当然，上面这种编程方式如今应该已经很少见了，因为现在的程序员一般不需要考虑程序要加载的内存地址。但这的确是早期程序员们在编程初期就要做的一个重要决策，因为当时的程序基本不能被重定位（relocate）。\n\nHow did you access a library function in those olden days? The preceding code illustrates the approach used. Programmers included the source code of the library functions with their application code, and compiled them all as a single program.1 Libraries were kept in source, not in binary.\n\n> 那么，当时是如何调用库函数呢？上述代码演示了具体调用过程。程序员们需要将所有要调用的库函数源代码包含到自己的程序代码中，然后再进行整体编译库函数文件都是以源代码而非二进制的形式保存的。\n\nThe problem with this approach was that, during this era, devices were slow and memory was expensive and, therefore, limited. Compilers needed to make several passes over the source code, but memory was too limited to keep all the source code resident. Consequently, the compiler had to read in the source code several times using the slow devices.\n\n> 在那个年代，存储设备十分缓慢，而内存则非常昂贵，也非常有限。编译器在编译程序的过程中需要数次遍历整个源代码。由于内存非常有限，驻留所有的源代码是不现实的，编译器只能多次从缓慢的存储设备中读取源代码。\n\nThis took a long time—and the larger your function library, the longer the compiler took. Compiling a large program could take hours.\n\n> 这样做是十分耗时的 库函数越多，编译就越慢。大型程序的编译过程经常需要几个小时。\n\nTo shorten the compile times, programmers separated the source code of the function library from the applications. They compiled the function library separately and loaded the binary at a known address—say, 20008. They created a symbol table for the function library and compiled that with their application code. When they wanted to run an application, they would load the binary function library,2 and then load the application. Memory looked like the layout shown in Figure 12.1.\n\n> 为了缩短编译时间，程序员们改将库函数的源代码单独编译。而库函数的源码在单独编译后会被加载到一个指定位置，比如地址 2000（八进制）。然后，编译器会针对该库文件创建一个符号表（symbol table），并将其和应用程序代码编译在一起。当程序运行时，它会先加载二进制形式的库文件，再加载编译过的应用程序，其内存布局如图 12.1 所示。\n\n<Figures figure=\"12-1\">Early memory layout</Figures>\n\nThis worked fine so long as the application could fit between addresses 00008 and 17778. But soon applications grew to be larger than the space allotted for them. At that point, programmers had to split their applications into two address segments, jumping around the function library (Figure 12.2).\n\n> 当然，只要应用程序的代码能够完全存放在地址 0000〜1777（八进制）内，这种组织方式就没有任何问题。但是，应用程序代码的大小很快就会超出这个范围。为了解决这个问题，程序员们必须将应用程序代码切分成两个不同的地址段，以跳过库函数存放的内存范围（具体如图 12.2 所示）。\n\n<Figures figure=\"12-2\">Splitting the application into two address segments</Figures>\n\nObviously, this was not a sustainable situation. As programmers added more functions to the function library, it exceeded its bounds, and they had to allocate more space for it (in this example, near 70008). This fragmentation of programs and libraries necessarily continued as computer memory grew.\n\n> 很显然，这种方案也是不对持续的。因为随着函数用小函数的增加，它的大小也随之增加，我们同样也需要为此划分新的区域，譬如在上述例子中，我们需在 7000（八进制）左右的位置往后追加地址空间。这样一来，程序和函数库的碎片化程度会随着计算机内存的增加而不断增加。\n\nClearly, something had to be done.\n\n> 显而易见，这个问题必须要有一个解决方案。\n\n## RELOCATABILITY 重定位技术\n\nThe solution was relocatable binaries. The idea behind them was very simple. The compiler was changed to output binary code that could be relocated in memory by a smart loader. The loader would be told where to load the relocatable code. The relocatable code was instrumented with flags that told the loader which parts of the loaded data had to be altered to be loaded at the selected address. Usually this just meant adding the starting address to any memory reference addresses in the binary.\n\n> 该解决方案就是生成可重定位的二进制文件。其背后的原理非常简单，即程序员修改编译器输出文件的二进制格式，使其可以由一个智能加载器加载到任意内存位置。当然，这需要我们在加载器启动时为这些文件指定要加载到的内存地址，而且可重定位的代码中还包含了一些记号，加载器将其加载到指定位置时会修改这些记号对应的地址值。一般来说，这个过程只不过就是将二进制文件中包含的内存地址都按照其加载到的内存基础位置进行递增。\n\nNow the programmer could tell the loader where to load the function library, and where to load the application. In fact, the loader would accept several binary inputs and simply load them in memory one right after the other, relocating them as it loaded them. This allowed programmers to load only those functions that they needed.\n\n> 这样一来，程序员们就可以用加载器来调整函数库及应用程序的位置了。事实上，这种加载器还可以接受多个二进制文件的输入，并按顺序在内存中加载它们，再逐个进行重定位。这样，程序员们就可以只加载他们实际会用到的函数了。\n\nThe compiler was also changed to emit the names of the functions as metadata in the relocatable binary. If a program called a library function, the compiler would emit that name as an external reference. If a program defined a library function, the compiler would emit that name as an external definition. Then the loader could link the external references to the external definitions once it had determined where it had loaded those definitions.\n\n> 除此之外，程序员们还对编译器做了另外一个修改，就是在可重定位二进制文 件中将函数名输出为元数据并存储起来。这样一来，如果一段程序调用了某个库函数，编译器就会将这个函数的名字输出为外部引用（external reference），而将库函数的定义输出为外部定义（external definition）。加载器在加载完程序后，会将外部 引用和外部定义链接（link）起来。\n\nAnd the linking loader was born.\n\n> 这就是链接加载器（linking loader）的由来。\n\n## LINKERS 链接器\n\nThe linking loader allowed programmers to divide their programs up onto separately compilable and loadable segments. This worked well when relatively small programs were being linked with relatively small libraries. However, in the late 1960s and early 1970s, programmers got more ambitious, and their programs got a lot bigger.\n\n> 链接加载器让程序员们可以将程序切分成多个可被分别编译、加载的程序段。在程序规模较小、外部链接也较少的情况，这个方案一直都很好用。然而在 20 世纪 60 年代末期到 70 年代初期的那段时间里，程序的规模突然有了大幅的增长，情况就有所不同了。\n\nEventually, the linking loaders were too slow to tolerate. Function libraries were stored on slow devices such a magnetic tape. Even the disks, back then, were quite slow. Using these relatively slow devices, the linking loaders had to read dozens, if not hundreds, of binary libraries to resolve the external references. As programs grew larger and larger, and more library functions accumulated in libraries, a linking loader could take more than an hour just to load the program.\n\n> 显然在这种情况下，链接加载器的处理过程实在是太慢了。且不说函数库当时还存储在磁带卷这样的低速存储设备上，即使是存储在磁盘上，其存取速度也是很慢的。毕竟，链接加载器在加载处理过程中必须要读取几十个甚至几百个二进制库文件来解析外部引用。因此随着程序规模的扩大，以及函数库中函数的累积，链接加载器的加载过程经常会出现需要一个多小时才能完成的情况。\n\nEventually, the loading and the linking were separated into two phases. Programmers took the slow part—the part that did that linking—and put it into a separate application called the linker. The output of the linker was a linked relocatable that a relocating loader could load very quickly. This allowed programmers to prepare an executable using the slow linker, but then they could load it quickly, at any time.\n\n> 最后，程序员们只能将加载过程和链接过程也进行分离。他们将耗时较长的部分——链接部分——放到了一个单独的程序中去进行，这个程序就是所谓的链接器（linker）。链接器的输出是一个已经完成了外部链接的、可以重定位的二进制文件，这种文件可以由一个支持重定位的加载器迅速加载到内存中。这使得程序员可以用缓慢的链接器生产出可以很快进行多次加载的可执行文件。\n\nThen came the 1980s. Programmers were working in C or some other high-level language. As their ambitions grew, so did their programs. Programs that numbered hundreds of thousands of lines of code were not unusual.\n\n> 时间继续推移到了 20 世纪 80 年代，程序员们在那时己经用上了 C 这样的高级编程语言，程序的规模也得到了进一步的扩大，源代码行数超过几十万行在当时己经是很普遍的事了。\n\nSource modules were compiled from .c files into .o files, and then fed into the linker to create executable files that could be quickly loaded. Compiling each individual module was relatively fast, but compiling all the modules took a bit of time. The linker would then take even more time. Turnaround had again grown to an hour or more in many cases.\n\n> 于是，源代码模块会从 .c 文件被编译成 .o 文件，然后再由链接器创建出可被 快速加载的可执行文件。那时，虽然编译每个单独模块的速度相对较快，但所有模块的累计编译时间较长，链接过程则耗时更久，整个修改编译周期经常会超过数个小时。\n\nIt seemed as if programmers were doomed to endlessly chase their tails. Throughout the 1960s, 1970s, and 1980s, all the changes made to speed up workflow were thwarted by programmers’ ambitions, and the size of the programs they wrote. They could not seem to escape from the hour-long turnaround times. Loading time remained fast, but compile-link times were the bottleneck.\n\n> 有时候，程序员们看上去似乎就是一直不停地在原地打转。从 20 世纪 60 年代一直到 80 年代，他们所有为提供编译速度所做的努力都被不断增长的程序规模抵消了。程序员好像永远也脱离不了长达几个小时的修改编译周期。程序加载的速度一直都很快，但是其编译和链接的过程也一直是整个开发过程的瓶颈。\n\nWe were, of course, experiencing Murphy’s law of program size:\n\n> 这被我们称为程序规模上的墨菲定律：\n\nPrograms will grow to fill all available compile and link time.\n\n> 程序的规模会一直不断地增长下去，直到将有限的编译和链接时间填满为止。\n\nBut Murphy was not the only contender in town. Along came Moore,3 and in the late 1980s, the two battled it out. Moore won that battle. Disks started to shrink and got significantly faster. Computer memory started to get so ridiculously cheap that much of the data on disk could be cached in RAM. Computer clock rates increased from 1 MHz to 100 MHz.\n\n> 除了墨菲定律，我们还存摩尔定律。在 20 世纪 80 年代，两个定律一直在互相较量，最终以摩尔定律获胜告终。因为磁盘的物理尺寸一直在不断缩小，速度也在不断提高，同时内存的造价也一直在不断降低，以至于大部分存放在磁盘上的数据可以被缓存在内存中了。而计算机时钟频率则从 1 MHz 上升到了 100 MHz。\n\nBy the mid-1990s, the time spent linking had begun to shrink faster than our ambitions could make programs grow. In many cases, link time decreased to a matter of seconds. For small jobs, the idea of a linking loader became feasible again.\n\n> 到了 20 世纪 90 年代中期，链接速度的提升速度已经远远超过了程序规模的增长速度。在大部分情况下，程序链接的时间已经降低到秒级。这对一些小程序来说.即使使用链接加载器也是可以接受的了。\n\nThis was the era of Active-X, shared libraries, and the beginnings of .jar files. Computers and devices had gotten so fast that we could, once again, do the linking at load time. We could link together several .jar files, or several shared libraries in a matter of seconds, and execute the resulting program. And so the component plugin architecture was born.\n\n> 与此同时，编程领域中还诞生了 Active-X、共享库、.jar 文件等组件形式：由于计算与存储速度的大幅提高，我们又可以在加载过程中进行实时链接了，链接几个 .jar 文件或是共享库文件通常只需要几秒钟时间，由此，插件化架构也就随生了。\n\nToday we routinely ship .jar files or DLLs or shared libraries as plugins to existing applications. If you want to create a mod to Minecraft, for example, you simply include your custom .jar files in a certain folder. If you want to plug Resharper into Visual Studio, you simply include the appropriate DLLs.\n\n> 如今，我们用 .jar 文件、DLL 文件和共享库方式来部署应用的插件已经非常司空见惯了。如果现在我们想要给 Minecraft 增加一个模块，只需要将 .jar 文件放到一个指定的目录中即可。同样的，如果你想给 Visual Studio 增加 Resharper 插件，也只需要安装对应的 DLL 文件即可。\n\n## CONCLUSION 本章小结\n\nThese dynamically linked files, which can be plugged together at runtime, are the software components of our architectures. It has taken 50 years, but we have arrived at a place where component plugin architecture can be the casual default as opposed to the herculean effort it once was.\n\n> 我们常常会在程序运行时插入某些动态链接文件，这些动态链接文件所使用的就是软件架构中的组件概念。在经历了 50 年的演进之后，组件化的插件式架构己经成为我们习以为常的软件构建形式了。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap13. COMPONENT COHESION 组件聚合\n\n![](../../images/books/架构整洁之道/CH-UN13.jpg)\n\nWhich classes belong in which components? This is an important decision, and requires guidance from good software engineering principles. Unfortunately, over the years, this decision has been made in an ad hoc manner based almost entirely on context.\n\n> 那么，究竟是哪些类应该被组合成一个组件呢？这是一个非常重要的设计决策，应该遵循优秀的软件工程经验来行事。但不幸的是，很多年以来，我们对于这么重要的决策经常是根据当下面临的实际情况临时拍脑门决定的。\n\nIn this chapter we will discuss the three principles of component cohesion:\n\n> 在本章中，我们会具体讨论以下三个与构建组件相关的基本原则：\n\n- REP: The Reuse/Release Equivalence Principle\n- CCP: The Common Closure Principle\n- CRP: The Common Reuse Principle\n\n---\n\n> - REP：复用/发布等同原则。\n> - CCP：共同闭包原则。\n> - CRP：共同复用原则。\n\n## THE REUSE/RELEASE EQUIVALENCE PRINCIPLE 复用/发布等同原则\n\nThe granule of reuse is the granule of release.\n\n> 软件复用的最小粒度应等同于其发布的最小粒度。\n\nThe last decade has seen the rise of a menagerie of module management tools, such as Maven, Leiningen, and RVM. These tools have grown in importance because, during that time, a vast number of reusable components and component libraries have been created. We are now living in the age of software reuse—a fulfillment of one of the oldest promises of the object-oriented model.\n\n> 过去十年间，模块管理工具得到了长足的发展，例如 Maven、Leiningen、RVM 等。这些工具日益重要的原因是正好在这十年间出现了大量可复用的组件和组件库应该说，我们现在至少已经实现了面向对象编程的一个原始初衷——软件复用。\n\nThe Reuse/Release Equivalence Principle (REP) is a principle that seems obvious, at least in hindsight. People who want to reuse software components cannot, and will not, do so unless those components are tracked through a release process and are given release numbers.\n\n> REP 原则初看起来好像是不言自明的。毕竟如果想要复用某个软件组件的话，一般就必须要求该组件的开发由某种发布流程来驱动，并且有明确的发布版本号。\n\nThis is not simply because, without release numbers, there would be no way to ensure that all the reused components are compatible with each other. Rather, it also reflects the fact that software developers need to know when new releases are coming, and which changes those new releases will bring.\n\n> 这其中的一个原因是，如果没有设定版本号，我们就没有办法保证所有被复用的组件之间能够彼此兼容。另外更重要的一点是，软件开发者必须要能够知道这些组件的发布时间，以及每次发布带来了哪些变更。\n\nIt is not uncommon for developers to be alerted about a new release and decide, based on the changes made in that release, to continue to use the old release instead. Therefore the release process must produce the appropriate notifications and release documentation so that users can make informed decisions about when and whether to integrate the new release.\n\n> 只有这样，软件工程师才能在收到相关组件新版本发布的通知之后，依据该发布所变更的内容来决定是继续使用旧版本还是做些相应的升级，这是很基本的要求。因此，组件的发布过程还必须要能够产生适当的通知和发布文档，以便让它的用户根据这些信息做出有效的升级决策。\n\nFrom a software design and architecture point of view, this principle means that the classes and modules that are formed into a component must belong to a cohesive group. The component cannot simply consist of a random hodgepodge of classes and modules; instead, there must be some overarching theme or purpose that those modules all share.\n\n> 从软件设计和架构设汁的角度来看，REP 原则就是指组件中的类与模块必须是 彼此紧密相关的。也就是说，一个组件不能由一组毫无关联的类和模块组成，它们之间应该有一个共同的主题或者大方向。\n\nOf course, this should be obvious. However, there is another way to look at this issue that is perhaps not quite so obvious. Classes and modules that are grouped together into a component should be releasable together. The fact that they share the same version number and the same release tracking, and are included under the same release documentation, should make sense both to the author and to the users.\n\n> 但从另外一个视角来看，这个原则就没那么简单了。因为根据该原则，一个组件中包含的类与模块还应该是可以同时发布的。这意味着它们共享相同的版本号与版本跟踪，并且包含在相同的发行文档中，这些都应该同时对该组件的作者和用户有意义。\n\nThis is weak advice: Saying that something should “make sense” is just a way of waving your hands in the air and trying to sound authoritative. The advice is weak because it is hard to precisely explain the glue that holds the classes and modules together into a single component. Weak though the advice may be, the principle itself is important, because violations are easy to detect—they don’t “make sense.” If you violate the REP, your users will know, and they won’t be impressed with your architectural skills.\n\n> 这层建议听起来就比较薄弱了，毕竟说某项事情的安排应该“合理”的确有点假大空，不着实际。该建议薄弱的原因是它没有清晰地定义出到底应该如何将类与模块组合成组件。但即使这样，REP 原则的重要性也是毋庸置疑的，因为违反这个原则的后果事实上很明显——一定会有人抱怨你的安排“不合理”，并进而对你的软件架构能力产生怀疑。\n\nThe weakness of this principle is more than compensated for by the strength of the next two principles. Indeed, the CCP and the CRP strongly define this principle, but in a negative sense.\n\n> 而且，REP 原则的上述薄弱性也会由以下两个原则所补充。CCP 和 CRP 会从相反的角度对这个原则进行有力的补偿。\n\n## THE COMMON CLOSURE PRINCIPLE 共同闭包原则\n\nGather into components those classes that change for the same reasons and at the same times. Separate into different components those classes that change at different times and for different reasons.\n\n> 我们应该将那些会同时修改，并且为相同目的而修改的类放到同一个组件中，而将不会同时修改，并且不会为了相同目的而修改的那些类放到不同的组件中。\n\nThis is the Single Responsibility Principle restated for components. Just as the SRP says that a class should not contain multiples reasons to change, so the Common Closure Principle (CCP) says that a component should not have multiple reasons to change.\n\n> 这其实是 SRP 原则在组件层面上的再度阐述。正如 SRP 原则中提到的“一个类不应该同时存在着多个变更原因”一样，CCP 原则也认为一个组件不应该同时存在着多个变更原因。\n\nFor most applications, maintainability is more important than reusability. If the code in an application must change, you would rather that all of the changes occur in one component, rather than being distributed across many components.1 If changes are confined to a single component, then we need to redeploy only the one changed component. Other components that don’t depend on the changed component do not need to be revalidated or redeployed.\n\n> 对大部分应用程序来说，可维护性的重要性要远远高于可复用性。如果某程序中的代码必须要进行某些变更，那么这些变更最好都体现在同一个组件中，而不是分布于很多个组件中打因为如果这些变更都集中在同一个组件中，我们就只需要重新部署该组件，其他组件则不需要被重新验证、重新部署了。\n\nThe CCP prompts us to gather together in one place all the classes that are likely to change for the same reasons. If two classes are so tightly bound, either physically or conceptually, that they always change together, then they belong in the same component. This minimizes the workload related to releasing, revalidating, and redeploying the software.\n\n> 总而言之，CCP 的主要作用就是提示我们要将所有可能会被一起修改的类集中在一处。也就是说，如果两个类紧密相关，不管是源代码层面还是抽象理念层面，永远都会被一起修改，那么它们就应该被归属为同一个组件。通过遵守这个原则，我们就可以有效地降低因软件发布、验证及部署所带来的工作压力。\n\nThis principle is closely associated with the Open Closed Principle (OCP). Indeed, it is “closure” in the OCP sense of the word that the CCP addresses. The OCP states that classes should be closed for modification but open for extension. Because 100% closure is not attainable, closure must be strategic. We design our classes such that they are closed to the most common kinds of changes that we expect or have experienced.\n\n> 另外 CCP 原则和开闭原则（OCP）也是紧密相关的。CCP 讨论的就是 OCP 中所指的“闭包”。OCP 原则认为一个类应该便于扩展，而抗拒修改。由于 100% 的闭包是不可能的，所以我们只能战略性地选择闭包范围。在设计类的时候，我们需要根据历史经验和预测能力，尽可能地将需要被一同变更的那些点聚合在一起。\n\nThe CCP amplifies this lesson by gathering together into the same component those classes that are closed to the same types of changes. Thus, when a change in requirements comes along, that change has a good chance of being restricted to a minimal number of components.\n\n> 对于 CCP，我们还可以在此基础上做进一步的延伸，即可以将某一类变更所涉及的所有类尽量聚合在一处。这样当此类变更出现时，我们就可以最大限度地做到使该类变更只影响到有限的相关组件。\n\n### SIMILARITY WITH SRP 与 SRP 原则的相似点\n\nAs stated earlier, the CCP is the component form of the SRP. The SRP tells us to separate methods into different classes, if they change for different reasons. The CCP tells us to separate classes into different components, if they change for different reasons. Both principles can be summarized by the following sound bite:\n\n> 如前所述，CCP 原则实际上就是 SRP 原则的组件版。在 SRP 原则的指导下，我们将会把变更原因不同的函数放入不同的类中。而 CCP 原则指导我们应该将变更原因不同的类放入不同的组件中。简而言之，这两个原则都可以用以下一句简短的话来概括：\n\nGather together those things that change at the same times and for the same reasons. Separate those things that change at different times or for different reasons.\n\n> 将由于相同原因而修改，并且需要同时修改的东西放在一起，将由于不同原因而修改，并且不同时修改的东西分开。\n\n## THE COMMON REUSE PRINCIPLE 共同复用原则\n\nDon’t force users of a component to depend on things they don’t need.\n\n> 不要强迫一个组件的用户依赖他们不需要的东西。\n\nThe Common Reuse Principle (CRP) is yet another principle that helps us to decide which classes and modules should be placed into a component. It states that classes and modules that tend to be reused together belong in the same component.\n\n> 共同复用原则（CRP）是另外一个帮助我们决策类和模块归属于哪一个组件的原则。该原则建议我们将经常共同复用的类和模块放在同一个组件中。\n\nClasses are seldom reused in isolation. More typically, reusable classes collaborate with other classes that are part of the reusable abstraction. The CRP states that these classes belong together in the same component. In such a component we would expect to see classes that have lots of dependencies on each other.\n\n> 通常情况下，类很少会被单独复用。更常见的情况是多个类同时作为某个可复用的抽象定义被共同复用。CRP 原则指导我们将这些类放在同一个组件中，而在这样的组件中，我们应该预见到会存在着许多互相依赖的类。\n\nA simple example might be a container class and its associated iterators. These classes are reused together because they are tightly coupled to each other. Thus they ought to be in the same component.\n\n> 一个简单的例子就是容器类与其相关的遍历器类，这些类之间通常是紧密相关的，一般会被共同复用，因此应该被放置在同一个组件中。\n\nBut the CRP tells us more than just which classes to put together into a component: It also tells us which classes not to keep together in a component. When one component uses another, a dependency is created between the components. Perhaps the using component uses only one class within the used component—but that still doesn’t weaken the dependency. The using component still depends on the used component.\n\n> 但是 CRP 的作用不仅是告诉我们应该将哪些类放在一起，更重要的是要告诉我们应该将哪些类分开。因为每当一个组件引用了另一个组件时，就等于增加了一条依赖关系。虽然这个引用关系仅涉及被引用组件中的一个类，但它所带来的依赖关系丝毫没有减弱。也就是说，引用组件已然依赖于被引用组件了。\n\nBecause of that dependency, every time the used component is changed, the using component will likely need corresponding changes. Even if no changes are necessary to the using component, it will likely still need to be recompiled, revalidated, and redeployed. This is true even if the using component doesn’t care about the change made in the used component.\n\n> 由于这种依赖关系的存在，每当被引用组件发生变更时，引用它的组件一般也需要做出相应的变更。即使它们不需要进行代码级的变更，一般也免不了需要被重新编译、验证和部署。哪怕引用组件根本不关心被引用组件中的变更，也要如此。\n\nThus when we depend on a component, we want to make sure we depend on every class in that component. Put another way, we want to make sure that the classes that we put into a component are inseparable—that it is impossible to depend on some and not on the others. Otherwise, we will be redeploying more components than is necessary, and wasting significant effort.\n\n> 因此，当我们决定要依赖某个组件时，最好是实际需要依赖该组件中的每个类。换句话说，我们希望组件中的所有类是不能拆分的，即不应该出现别人只需要依赖它的某几个类而不需要其他类的情况。否则，我们后续就会浪费不少时间与精力来做不必要的组件部署。\n\nTherefore the CRP tells us more about which classes shouldn’t be together than about which classes should be together. The CRP says that classes that are not tightly bound to each other should not be in the same component.\n\n> 因此在 CRP 原则中，关于哪些类不应该被放在一起的建议是其更为重要的内容。简而言之，CRP 原则实际上是在指导我们：不是紧密相连的类不应该被放在同一个组件里。\n\n### RELATION TO ISP 与 ISP 原则的关系\n\nThe CRP is the generic version of the ISP. The ISP advises us not to depend on classes that have methods we don’t use. The CRP advises us not to depend on components that have classes we don’t use.\n\n> CRP 原则实际上是 LSP 原则的一个普适版。ISP 原则是建议我们不要依赖带有不需要的函数的类，而 CRP 原则则是建议我们不要依赖带有不需要的类的组件。不要依赖不需要用到的东西。\n\nAll of this advice can be reduced to a single sound bite:\n\nDon’t depend on things you don’t need.\n\n## THE TENSION DIAGRAM FOR COMPONENT COHESION 组件聚合张力图\n\nYou may have already realized that the three cohesion principles tend to fight each other. The REP and CCP are inclusive principles: Both tend to make components larger. The CRP is an exclusive principle, driving components to be smaller. It is the tension between these principles that good architects seek to resolve.\n\n> 读到这里，读者可能已经意识到上述三个原则之间彼此存在着竞争关系。REP 和 CCP 原则是黏合性原则，它们会让组件变得更大，而 CRP 原则是排除性原则，它会尽量让组件变小。软件架构师的任务就是要在这三个原则中间进行取舍。\n\nFigure 13.1 is a tension diagram2 that shows how the three principles of cohesion interact with each other. The edges of the diagram describe the cost of abandoning the principle on the opposite vertex.\n\n> 下面我们来看一下图 13.1。这是一张组件聚合三大原则的张力图，图的边线所描述的是忽视对应原则的后果。\n\n<Figures figure=\"13-1\">Cohesion principles tension diagram</Figures>\n\nAn architect who focuses on just the REP and CRP will find that too many components are impacted when simple changes are made. In contrast, an architect who focuses too strongly on the CCP and REP will cause too many unneeded releases to be generated.\n\n> 简而言之，只关注 REP 和 CRP 的软件架构师会发现，即使是简单的变更也会同时影响到许多组件。相反，如果软件架构师过于关注 CCP 和 REP，则会导致很多不必要的发布。\n\nA good architect finds a position in that tension triangle that meets the current concerns of the development team, but is also aware that those concerns will change over time. For example, early in the development of a project, the CCP is much more important than the REP, because develop-ability is more important than reuse.\n\n> 优秀的软件架构师应该能在上述三角张力区域中定位一个最适合目前研发团队状态的位置，同时也会根据时间不停调整。例如在项目早期，CCP 原则会比 REP 原则更重要，因为在这一阶段研发速度比复用性更重要。\n\nGenerally, projects tend to start on the right hand side of the triangle, where the only sacrifice is reuse. As the project matures, and other projects begin to draw from it, the project will slide over to the left. This means that the component structure of a project can vary with time and maturity. It has more to do with the way that project is developed and used, than with what the project actually does.\n\n> 一般来说，一个软件项目的重心会从该三角区域的右侧开始，先期主要牺牲的是复用性。然后，随着项目逐渐成熟，其他项目会逐渐开始对其产生依赖，项目重心就会逐渐向该二角区域的左侧滑动。换句话说，一个项目在组件结构设计上的重心是根据该项目的开发时间和成熟度不断变动的，我们对组件结构的安排主要与项目开发的进度和它被使用的方式有关，与项目本身功能的关系其实很小。\n\n## CONCLUSION 本章小结\n\nIn the past, our view of cohesion was much simpler than the REP, CCP, and CRP implied. We once thought that cohesion was simply the attribute that a module performs one, and only one, function. However, the three principles of component cohesion describe a much more complex variety of cohesion. In choosing the classes to group together into components, we must consider the opposing forces involved in reusability and develop-ability. Balancing these forces with the needs of the application is nontrivial. Moreover, the balance is almost always dynamic. That is, the partitioning that is appropriate today might not be appropriate next year. As a consequence, the composition of the components will likely jitter and evolve with time as the focus of the project changes from develop-ability to reusability.\n\n> 过去，我们对组件在构建过程中要遵循的组合原则的理解要比 REP、CCP、CRP 这三个原则更有限。我们最初所理解的组合原则可能完全基于单一职责原则。然而，本章介绍的这三个原则为我们描述了一个更为复杂的决策过程。在决定将哪些类归为同一个组件时，必须要考虑到研发性与复用性之间的矛盾，并根据应用程序的需要来平衡这两个矛盾，这是一件很不容易的事。而且，这种平衡本身也在不断变化。也就是说，当下适用的分割方式可能明年就不再适用了。所以，组件的构成安排应随着项目重心的不同，以及研发性与复用性的不同而不断演化。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap14. COMPONENT COUPLING 组件耦合\n\n![](../../images/books/架构整洁之道/CH-UN14.jpg)\n\nThe next three principles deal with the relationships between components. Here again we will run into the tension between develop-ability and logical design. The forces that impinge upon the architecture of a component structure are technical, political, and volatile.\n\n> 接下来要讨论的三条原则主要关注的是组件之间的关系。在这些原则中，我们同样会面临着研发能力和逻辑设计之间的冲突。毕竟，影响组件结构的不仅有技术水平和公司内部政治斗争这两个因素，其结构本身更是不断变化的。\n\n## THE ACYCLIC DEPENDENCIES PRINCIPLE 无依赖环原则\n\nAllow no cycles in the component dependency graph.\n\n> 组件依赖关系图中不应该出现环。\n\nHave you ever worked all day, gotten some stuff working, and then gone home, only to arrive the next morning to find that your stuff no longer works? Why doesn’t it work? Because somebody stayed later than you and changed something you depend on! I call this “the morning after syndrome.”\n\n> 我们一定都有过这样的经历：当你花了一整天的时间，好不容易搞定了一段代码，第二天上班时却发现这段代码莫名其妙地又不能工作了。这通常是因为有人在你走后修改了你所依赖的某个组件。我给这种情况起了个名字——“一觉醒来综合征”。\n\nThe “morning after syndrome” occurs in development environments where many developers are modifying the same source files. In relatively small projects with just a few developers, it isn’t too big a problem. But as the size of the project and the development team grow, the mornings after can get pretty nightmarish. It is not uncommon for weeks to go by without the team being able to build a stable version of the project. Instead, everyone keeps on changing and changing their code trying to make it work with the last changes that someone else made.\n\n> 这种综合征的主要病因是多个程序员同时修改了同一个源代码文件。虽然在规模相对较小、人员较少的项目中，这种问题或许并不严重，但是随着项目的增长，研发人员的增加，这种每天早上刚上班时都要经历一遍的痛苦就会越来越多。甚至会严重到让有的团队在长达数周的时间内都不能发布一个稳定的项目版本，因为每个人都在不停地修改自己的代码，以适应其他人所提交的变更。\n\nOver the last several decades, two solutions to this problem have evolved, both of which came from the telecommunications industry. The first is “the weekly build,” and the second is the Acyclic Dependencies Principle (ADP).\n\n> 在过去几十年中，针对这个问题逐渐演化出了两种解决方案，它们都来自电信行业。第一种是“每周构建”，第二种是“无依赖环原则（ADP）”。\n\n### THE WEEKLY BUILD 每周构建\n\nThe weekly build used to be common in medium-sized projects. It works like this: All the developers ignore each other for the first four days of the week. They all work on private copies of the code, and don’t worry about integrating their work on a collective basis. Then, on Friday, they integrate all their changes and build the system.\n\n> 每周构建方案是中型项目中很常见的一种管理手段。其具体做法如下：在每周的前四天中，让所有的程序员在自己的私有库上工作，忽略其他人的修改，也不考虑互相之间的集成问题；然后在每周五要求所有人将自己所做的变更提交，进行统一构建。\n\nThis approach has the wonderful advantage of allowing the developers to live in an isolated world for four days out of five. The disadvantage, of course, is the large integration penalty that is paid on Friday.\n\n> 上述方案确实可以让程序员每周都有四天的时间放手干活。然而一到星期五，所有人都必须要花费大量的精力来处理前四天留下来的问题。\n\nUnfortunately, as the project grows, it becomes less feasible to finish integrating the project on Friday. The integration burden grows until it starts to overflow into Saturday. A few such Saturdays are enough to convince the developers that integration should really begin on Thursday—and so the start of integration slowly creeps toward the middle of the week.\n\n> 而且更不幸的是，随着项目越来越大，每周五的集成工作会越来越难以按时完成。而随着集成任务越来越重，周六的加班也会变得越来越频繁。经历过几次这样的加班之后，就会有人提出应该将集成任务提前到星期四开始，就这样一步一步地，集成工作漫漫地就要占用掉差不多半周的时间。\n\nAs the duty cycle of development versus integration decreases, the efficiency of the team decreases, too. Eventually this situation becomes so frustrating that the developers, or the project managers, declare that the schedule should be changed to a biweekly build. This suffices for a time, but the integration time continues to grow with project size.\n\n> 事实上，这个问题最终还会造成更大的麻烦。因为如果我们想歩保持高效率的开发，就不能频繁地进行构建操作，但是如果我们减少了构建次数，延长了项目被构建的时间间隔，又会影响到该项目的质量，增大它的风险。整个项目会变得越来越难以构建与测试，团队反馈周期会越来越长，研发质量自然也会越来越差。\n\nEventually, this scenario leads to a crisis. To maintain efficiency, the build schedule has to be continually lengthened—but lengthening the build schedule increases project risks. Integration and testing become increasingly harder to do, and the team loses the benefit of rapid feedback.\n\n### ELIMINATING DEPENDENCY CYCLES 消除循环依赖\n\nThe solution to this problem is to partition the development environment into releasable components. The components become units of work that can be the responsibility of a single developer, or a team of developers. When developers get a component working, they release it for use by the other developers. They give it a release number and move it into a directory for other teams to use. They then continue to modify their component in their own private areas. Everyone else uses the released version.\n\n> 对于上述情景，我们的解决办法是将研发项目划分为一些可单独发布的组件，这些组件可以交由单人或者某一组程序员来独立完成。当有人或团队完成某个组件的某个版本时，他们就会通过发布机制通知其他程序员，并给该组件打一个版本号，放入一个共享目录。这样一来，每个人都可以依赖于这些组件公开发布的版本来进行开发，而组件开发者则可以继续去修改自己的私有版本。\n\nAs new releases of a component are made available, other teams can decide whether they will immediately adopt the new release. If they decide not to, they simply continue using the old release. Once they decide that they are ready, they begin to use the new release.\n\n> 每当一个组件发布新版本时，其他依赖这个组件的团队都可以自主决定是否立即采用新版本。若不采用，该团队可以选择继续使用旧版组件，直到他们准备好采用新版本为止。\n\nThus no team is at the mercy of the others. Changes made to one component do not need to have an immediate affect on other teams. Each team can decide for itself when to adapt its own components to new releases of the components. Moreover, integration happens in small increments. There is no single point in time when all developers must come together and integrate everything they are doing.\n\n> 这样就不会出现团队之间相互依赖的情况了。任何一个组件上的变更都不会立刻影响到其他团队。每个团队都可以自主决定是否立即集成自己所依赖组件的新版本。更重要的是，这种方法使我们的集成工作能以一种小型渐进的方式来进行。程序员们再也不需要集中在一起，统一集成相互的变更了。\n\nThis is a very simple and rational process, and it is widely used. To make it work successfully, however, you must manage the dependency structure of the components. There can be no cycles. If there are cycles in the dependency structure, then the “morning after syndrome” cannot be avoided.\n\n> 如你所见，上述整个过程既简单又很符合逻辑，因而得到了各个研发团队的广泛采用。但是，如果想要成功推广这个开发流程，就必须控制好组件之间的依赖结构，绝对不能允许该结构中存在着循环依赖关系。如果某项目结构中存在着循环依赖关系，那么“一觉醒来综合征”将是不可避免的。\n\nConsider the component diagram in Figure 14.1. It shows a rather typical structure of components assembled into an application. The function of this application is unimportant for the purpose of this example. What is important is the dependency structure of the components. Notice that this structure is a directed graph. The components are the nodes, and the dependency relationships are the directed edges.\n\n> 下面让我们来看看图 14.1，该图展示了一个典型应用程序的组件结构。当然，这个应用程序的具体功能与我们要讨论的无关，真正重要的是其组件之间的依赖结构。我们应该可以注意到，该组件依赖结构所呈现的是一个有向图，图中的每个节点都是一个项目组件，依赖关系就是有向图中的边。\n\n<Figures figure=\"14-1\">Typical component diagram</Figures>\n\nNotice one more thing: Regardless of which component you begin at, it is impossible to follow the dependency relationships and wind up back at that component. This structure has no cycles. It is a directed acyclic graph (DAG).\n\n> 更重要的是，不管我们从该图中的哪个节点开始，都不能沿着这些代表了依赖关系的边最终走回到起始点。也就是说，这种结构中不存在坏，我们称这种结构为有向无环图（Directed Acyclic Graph，简写为 DAG）。\n\nNow consider what happens when the team responsible for Presenters makes a new release of their component. It is easy to find out who is affected by this release; you just follow the dependency arrows backward. Thus View and Main will both be affected. The developers currently working on those components will have to decide when they should integrate their work with the new release of Presenters.\n\n> 现在，如果负责 Presenters 组件的团队需要发布一个新版本，我们就应该很容易判断出哪些组件会受这个变更的影响——只需要按其依赖关系反向追溯即可。显然在图 14.1 中，View 和 Main 是同时会被影响的两个组件。这两个组件的研发团队需要决定是否采用 Presenters 组件的新版本。\n\nNotice also that when Main is released, it has utterly no effect on any of the other components in the system. They don’t know about Main, and they don’t care when it changes. This is nice. It means that the impact of releasing Main is relatively small.\n\n> 另外值得注意的是，当 Main 组件发布新版本时，它对系统中的其他组件根本就没有影响，既没有一个组件依赖于 Main，也就没有人关系 Main 组件上发生的变更。这太好了，至少表示我们在发布 Main 的新版本时，可以不必考虑它对整个项目微乎其微的影响。\n\nWhen the developers working on the Presenters component would like to run a test of that component, they just need to build their version of Presenters with the versions of the Interactors and Entities components that they are currently using. None of the other components in the system need be involved. This is nice. It means that the developers working on Presenters have relatively little work to do to set up a test, and that they have relatively few variables to consider.\n\n> 当 Presenters 组件的程序员们需要进行一次测试时，他们只需将对应版本的 Presenters 和 Interactors 及 Entities 的当前版本一起构建并测试即可，其他的组件不需要做任何修改。这可以让编写 Presenters 组件的程序员们在编写测试时考虑更少的变量，工作量更小。\n\nWhen it is time to release the whole system, the process proceeds from the bottom up. First the Entities component is compiled, tested, and released. Then the same is done for Database and Interactors. These components are followed by Presenters, View, Controllers, and then Authorizer. Main goes last. This process is very clear and easy to deal with. We know how to build the system because we understand the dependencies between its parts.\n\n> 当我们需要发布整个系统时，可以让整个过程从下至上来进行。貝体来说就是首先对 Entities 组件进行编译、测试、发布。随后是 Database 和 Interactors 这两个组件。再紧随其后的是 Presenters、View、Controllers，以及 Authorizer 四个组件。最后是 Main 组件。这样一来，整个流程会非常清晰，也很容易。只要我们了解系统各部分之间的依赖关系，构建整套系统就会变得很容易。\n\n### THE EFFECT OF A CYCLE IN THE COMPONENT DEPENDENCY GRAPH 循环依赖在组件依赖图中的影响\n\nSuppose that a new requirement forces us to change one of the classes in Entities such that it makes use of a class in Authorizer. For example, let’s say that the User class in Entities uses the Permissions class in Authorizer. This creates a dependency cycle, as shown in Figure 14.2.\n\n> 假设某个新需求使我们修改了 Entities 组件中的某个类，而这个类又依赖于 Authorizer 组件中的某个类。例如，Entities 组件中的 User 类使用了 Authorizer 组件中的 Permissions 类。这就形成了一个循环依赖关系，如图 14.2 所示。\n\nThis cycle creates some immediate problems. For example, the developers working on the Database component know that to release it, the component must be compatible with Entities. However, with the cycle in place, the Database component must now also be compatible with Authorizer. But Authorizer depends on Interactors. This makes Database much more difficult to release. Entities, Authorizer, and Interactors have, in effect, become one large component—which means that all of the developers working on any of those components will experience the dreaded “morning after syndrome.” They will be stepping all over one another because they must all use exactly the same release of one another’s components.\n\n> 这种循环依赖立刻就会给我们的项目带来麻烦。例如，当 Database 组件的程序员需要发布新版本时，他们需要与 Entities 组件进行集成。但现在由于出现了循环依赖，Database 组件就必须也要与 Authorizer 组件兼容，而 Authorizer 组件又依赖于 Interactors 组件。这样一来，Database 组件的发布就会变得非常困难。在这里，Entities、Authorizer 及 Interactors 这三个组件事实上被合并成一个更大的组件。这些组件的程序员现在会互相形成干扰，因为他们在开发中都必须使用完全相同的组件版本。\n\n<Figures figure=\"14-2\">A dependency cycle</Figures>\n\nBut this is just part of the trouble. Consider what happens when we want to test the Entities component. To our chagrin, we find that we must build and integrate with Authorizer and Interactors. This level of coupling between components is troubling, if not intolerable.\n\n> 这还只是问题的冰山一角，请想象一下我们在测试 Entities 组件时会发生什么？情况会让人触目惊心我们会发现自己必须将 Authorizer 和 Interactors 集成到一起测试。即使这不是不能容忍的事，但至少这些组件之间的耦合度也是非常令人不安的。\n\nYou may have wondered why you have to include so many different libraries, and so much of everybody else’s stuff, just to run a simple unit test of one of your classes. If you investigate the matter a bit, you will probably discover that there are cycles in the dependency graph. Such cycles make it very difficult to isolate components. Unit testing and releasing become very difficult and error prone. In addition, build issues grow geometrically with the number of modules.\n\n> 很显然，这样一个小小的测试必须要依赖大量的库就是因为其组件结构依赖图中存在的这个循环依赖。这种循环依赖会使得组件的独立维护工作变得十分困难。不仅如此，单元测试和发布流程也都会变得非常困难，并且很容易出错。此外，项目在构建中出现的问题会随着组件数量的增多而呈现出几何级数的增长。\n\nMoreover, when there are cycles in the dependency graph, it can be very difficult to work out the order in which you must build the components. Indeed, there probably is no correct order. This can lead to some very nasty problems in languages like Java that read their declarations from compiled binary files.\n\n> 所以，当组件结构依赖图中存在循环依赖时，想要按正确的顺序构建组件几乎是不可能的。这种依赖关系将会在 Java 这种需要在编译好的二级制文件中读取声明信息的语言中导致一些非常棘手的问题。\n\n### BREAKING THE CYCLE 打破循环依赖\n\nIt is always possible to break a cycle of components and reinstate the dependency graph as a DAG. There are two primary mechanisms for doing so:\n\n> 当然，我们可以打破这些组件中的循环依赖，并将其依赖图转化为 DAG。目前有以下两种主要机制可以做到这件事情。\n\n1. Apply the Dependency Inversion Principle (DIP). In the case in Figure 14.3, we could create an interface that has the methods that User needs. We could then put that interface into Entities and inherit it into Authorizer. This inverts the dependency between Entities and Authorizer, thereby breaking the cycle.\n\n> 1. 应用依赖反转原则（DIP）：在图 14.3 中，我们可以创建一个 User 类需要使用的接口，然后将这个接口放入 Entities 组件，并在 Authorizer 组件中继承它。这样就将 Entities 与 Authorizer 之间的依赖关系反转了，自然也就打破了循环依赖关系。\n\n<Figures figure=\"14-3\">Inverting the dependency between Entities and Authorizer</Figures>\n\n2. Create a new component that both Entities and Authorizer depend on. Move the class(es) that they both depend on into that new component (Figure 14.4).\n\n> 2. 创建一个新的组件，并让 Entities 与 Authorize 这两个组件都依赖于它。将现有的这两个组件中互相依赖的类全部放入新组件（如图 14.4 所示）。\n\n<Figures figure=\"14-4\">The new component that both Entities and Authorizer depend on</Figures>\n\n### THE “JITTERS” “抖动”\n\nThe second solution implies that the component structure is volatile in the presence of changing requirements. Indeed, as the application grows, the component dependency structure jitters and grows. Thus the dependency structure must always be monitored for cycles. When cycles occur, they must be broken somehow. Sometimes this will mean creating new components, making the dependency structure grow.\n\n> 当然，采用第二种解决方案也意味着在需求变更时，项目的组件结构也要随之变更。确实是这样的，随着应用程序的不断演进，其组件结构也会不停地抖动和扩张。因此，我们必须要持续地监控顶目中的循环依赖关系。当循环依赖出现时，必须以某种力式消除它们。为此，我们有时候不可避免地需要创建新的组件，而使整个组件结构变得更大。\n\n## TOP-DOWN DESIGN 自上而下的设计\n\nThe issues we have discussed so far lead to an inescapable conclusion: The component structure cannot be designed from the top down. It is not one of the first things about the system that is designed, but rather evolves as the system grows and changes.\n\n> 根据上述讨论，我们可以得出一个无法逃避的结论：组件结构图是不可能自上而下被设计出来的。它必须随着软件系统的变化而变化和扩张，而不可能在系统构建的最初就被完美设计出来。\n\nSome readers may find this point to be counterintuitive. We have come to expect that large-grained decompositions, like components, will also be high-level functional decompositions.\n\n> 有些读者可能会觉得这个结论有些反直觉。人们通常会直观地认为，代表项目粗粒度的结构单元，也就是组件，应该与顶层设计中的功能单元是相对应的。\n\nWhen we see a large-grained grouping such as a component dependency structure, we believe that the components ought to somehow represent the functions of the system. Yet this does not seem to be an attribute of component dependency diagrams.\n\n> 同样的，人们也普遍认为项目粗粒度的组件分组规则所产生的就是组件的依赖结构，也应该在某种程度上与项目的系统功能分解的结果相互对应。但是很明显，组件依赖关系图其实不具备这样的属性。\n\nIn fact, component dependency diagrams have very little do to with describing the function of the application. Instead, they are a map to the buildability and maintainability of the application. This is why they aren’t designed at the beginning of the project. There is no software to build or maintain, so there is no need for a build and maintenance map. But as more and more modules accumulate in the early stages of implementation and design, there is a growing need to manage the dependencies so that the project can be developed without the “morning after syndrome.” Moreover, we want to keep changes as localized as possible, so we start paying attention to the SRP and CCP and collocate classes that are likely to change together.\n\n> 事实上，组件依赖结构图并不是用来描述应用程序功能的，它更像是应用程序在构建性与维护性方面的一张地图。这就是组件的依赖结构图不能在项目的开始阶段被设计出来的原因——当时该项目还没有任何被构建和维护的需要，自然也就不需要一张地图来指引。然而，随着早期被设计并实现出来的模块越来越多，项目中就逐渐出现了要对组件依赖关系进行管理的需求，以此来预防“一觉醒来综合征”的爆发。除此之外，我们还希望将项目变更所影响的范围被限制得越小越好，因此需要应用单一职责原则（SRP）和共同闭包原则（CCP）来将经常同时被变更的类聚合在一起。\n\nOne of the overriding concerns with this dependency structure is the isolation of volatility. We don’t want components that change frequently and for capricious reasons to affect components that otherwise ought to be stable. For example, we don’t want cosmetic changes to the GUI to have an impact on our business rules. We don’t want the addition or modification of reports to have an impact on our highest-level policies. Consequently, the component dependency graph is created and molded by architects to protect stable high-value components from volatile components.\n\n> 组件结构图中的一个重要目标是指导如何隔离频繁的变更。我们不希望那些频繁变更的组件影响到其他本来应该很稳定的组件，例如，我们通常不会希望无关紧要的 GUI 变更影响到业务逻辑组件；我们也不希望对报表的增删操作影响到其高阶策略。出于这样的考虑，软件架构师们才有必要设计并且铸造出一套组件依赖关系图来，以便将稳定的高价值组件与常变的组件隔离开，从而起到保护作用。\n\nAs the application continues to grow, we start to become concerned about creating reusable elements. At this point, the CRP begins to influence the composition of the components. Finally, as cycles appear, the ADP is applied and the component dependency graph jitters and grows.\n\n> 另外，随着应用程序的增长，创建可重用组件的需要也会逐渐重要起来。这时 CRP 又会开始影响组件的组成。最后当循环依赖出现时，随着无循环依赖原则（ADP）的应用，组件依赖关系会产生相应的抖动和扩张。\n\nIf we tried to design the component dependency structure before we designed any classes, we would likely fail rather badly. We would not know much about common closure, we would be unaware of any reusable elements, and we would almost certainly create components that produced dependency cycles. Thus the component dependency structure grows and evolves with the logical design of the system.\n\n> 如果我们在设计具体类之前就来设计组件依赖关系，那么几乎是必然要失败的。因为在当下，我们对项目中的共同闭包一无所知，也不可能知道哪些组件可以复用，这样几乎一定会创造出循环依赖的组件。因此，组件依赖关系是必须要随着项目的逻辑设计一起扩张和演进的。\n\n## THE STABLE DEPENDENCIES PRINCIPLE 稳定依赖原则\n\nDepend in the direction of stability.\n\n> 依赖关系必须要指向更稳定的方向。\n\nDesigns cannot be completely static. Some volatility is necessary if the design is to be maintained. By conforming to the Common Closure Principle (CCP), we create components that are sensitive to certain kinds of changes but immune to others. Some of these components are designed to be volatile. We expect them to change.\n\n> 设计这件事不可能是完全静止的，如果我们要让一个设计是可维护的，那么其中某些部分就必须是可变的。通过遵守共同闭包原则（CCP），我们可以创造出对某些变更敏感，对其他变更不敏感的组件。这其中的一些组件在设计上就已经是考虑了易变性，预期它们会经常发生变更的。\n\nAny component that we expect to be volatile should not be depended on by a component that is difficult to change. Otherwise, the volatile component will also be difficult to change.\n\n> 任何一个我们预期会经常变更的组件都不应该被一个难于修改的组件所依赖，否则这个多变的组件也将会变得非常难以被修改。\n\nIt is the perversity of software that a module that you have designed to be easy to change can be made difficult to change by someone else who simply hangs a dependency on it. Not a line of source code in your module need change, yet your module will suddenly become more challenging to change. By conforming to the Stable Dependencies Principle (SDP), we ensure that modules that are intended to be easy to change are not depended on by modules that are harder to change.\n\n> 这就是软件开发的困难之处，我们精心设计的一个容易被修改的组件很可能会由于别人的一条简单依赖而变得非常难以被修改。即使该模块中没有一行代码需要被修改，但是整个模块在被修改时所面临的挑战性也已经存在了。而通过遵守稳定依赖原则（SDP），我们就可以确保自己设计中那些容易变更的模块不会被那些难于修改的组件所依赖。\n\n### STABILITY 稳定性\n\nWhat is meant by “stability”? Stand a penny on its side. Is it stable in that position? You would likely say “no.” However, unless disturbed, it will remain in that position for a very long time. Thus stability has nothing directly to do with frequency of change. The penny is not changing, but it is difficult to think of it as stable.\n\n> 我们该如何定义“稳定性”呢？譬如说将一个硬币立起来放，你认为它会处于一个稳定的位置吗？当然不会。然而，除非受到外界因素干扰，否则硬币本身可以在这个位置保持相当长的一段时间。因此稳定性应该与变更的频繁度没有直接关系但问题是硬币并没有倒，为什么我们却并不认为它是稳定的呢?\n\nWebster’s Dictionary says that something is stable if it is “not easily moved.” Stability is related to the amount of work required to make a change. On the one hand, the standing penny is not stable because it requires very little work to topple it. On the other hand, a table is very stable because it takes a considerable amount of effort to turn it over.\n\n> 下面来看看 Webster 在线字典中的描述：稳定指的是“很难移动”。所以稳定性应该与变更所需的工作量有关。例如，硬币是不稳定的，因为只需要很小的动作就可以推倒它，而桌子则是非常稳定的，因为将它掀翻需要很大的动作。\n\nHow does this relate to software? Many factors may make a software component hard to change—for example, its size, complexity, and clarity, among other characteristics. We will ignore all those factors and focus on something different here. One sure way to make a software component difficult to change, is to make lots of other software components depend on it. A component with lots of incoming dependencies is very stable because it requires a great deal of work to reconcile any changes with all the dependent components.\n\n> 但如果将这套理论关联到软件开发的问题上呢？软件组件的变更困难度与很多因素有关，例如代码的体量大小、复杂度、清晰度等。我们在这里会忽略这些因素，只集中讨论一个特别的因素——让软件组件难于修改的一个最直接的办法就是让很多其他组件依赖于它。带有许多入向依赖关系的组件是非常稳定的，因为它的任何变更都需要应用到所有依赖它的组件上。\n\nThe diagram in Figure 14.5 shows X, which is a stable component. Three components depend on X, so it has three good reasons not to change. We say that X is responsible to those three components. Conversely, X depends on nothing, so it has no external influence to make it change. We say it is independent.\n\n> 在图 14.5 中，X 是一个稳定的组件。因为有三个组件依赖着 X，所以 X 有三个不应该被修改的原因。这里就说 X 要对三个组件负责。另一方面，X 不依赖于任何组件，所以不会有任何原因导致它需要被变更，我们称它为“独立”组件。\n\n<Figures figure=\"14-5\">X: a stable component</Figures>\n\nFigure 14.6 shows Y, which is a very unstable component. No other components depend on Y, so we say that it is irresponsible. Y also has three components that it depends on, so changes may come from three external sources. We say that Y is dependent.\n\n> 下面再来看看图 14.6 中的 Y 组件，这是一个非常不稳定的组件。由于没有其他的组件依赖 Y，所以 Y 并不对任何组件负责。但因为 Y 同时依赖于三个组件，所以它的变更就可能由三个不同的源产生。这里就说 Y 是有依赖性的组件。\n\n<Figures figure=\"14-6\">Y: a very unstable component</Figures>\n\n### STABILITY METRICS 稳定性指标\n\nHow can we measure the stability of a component? One way is to count the number of dependencies that enter and leave that component. These counts will allow us to calculate the positional stability of the component.\n\n> 那么，究竟该如何来量化一个组件的稳定性呢？其中一种方法是计算所有入和出的依赖关系。通过这种方法，我们就可以计算出一个组件的位置稳定性（positional stability）。\n\n- Fan-in: Incoming dependencies. This metric identifies the number of classes outside this component that depend on classes within the component.\n- Fan-out: Outgoing dependencies. This metric identifies the number of classes inside this component that depend on classes outside the component.\n- I: Instability: I = Fan-out / (Fan-in + Fan-out). This metric has the range [0, 1]. I = 0 indicates a maximally stable component. I = 1 indicates a maximally unstable component.\n\n---\n\n> - Fan-in：入向依赖，这个指标指代了组件外部类依赖于组件内部类的数量。\n> - Fan-out：出向依赖，这个指标指代了组件内部类依赖于组件外部类的数量。\n> - I：不稳定性，`I=Fan-out/(Fan-in+Fan-out)`.该指标的范围是[0,1]，I=0 意味着组件是最稳定的，I=1 意味着组件是最不稳定的。\n\nThe Fan-in and Fan-out metrics1 are calculated by counting the number of classes outside the component in question that have dependencies with the classes inside the component in question. Consider the example in Figure 14.7.\n\n> 在这里，Fan-in 和 Fan-out 这两个指标是通过统计和组件内部类有依赖的组件外部类的数量来计算的，具体如图 14.7 所示。\n\n<Figures figure=\"14-7\">Our example</Figures>\n\nLet’s say we want to calculate the stability of the component Cc. We find that there are three classes outside Cc that depend on classes in Cc. Thus, Fan-in = 3. Moreover, there is one class outside Cc that classes in Cc depend on. Thus, Fan-out = 1 and I = 1/4.\n\n> 在这里，我们想要计算组件 Cc 的稳定性指标，可以观察到有 3 个类在 Cc 外部，它们都依赖于 Cc 内部的类，因此 Fan-in=3，此外，Cc 中的一个类也依赖于组件外部的类，因此 Fan-out=1，I=1/4。\n\nIn C++, these dependencies are typically represented by #include statements. Indeed, the I metric is easiest to calculate when you have organized your source code such that there is one class in each source file. In Java, the I metric can be calculated by counting import statements and qualified names.\n\n> 在 C++中，这些依赖关系一般是通过 `#include` 语句来表达的。事实上，当每个源文件只包含一个类的时候，I 指标是最容易计算的。同样在 Java 中，I 指标也可以通过 import 语句和全引用名字的数量来计算。\n\nWhen the I metric is equal to 1, it means that no other component depends on this component (Fan-in = 0), and this component depends on other components (Fan-out > 0). This situation is as unstable as a component can get; it is irresponsible and dependent. Its lack of dependents gives the component no reason not to change, and the components that it depends on may give it ample reason to change.\n\n> 当 I 指标等于 1 时，说明没有组件依赖当前组件（Fan-in=0），同时该组件却依赖于其他组件（Fan-out>0）。这是组件最不稳定的一种情况，我们认为这种组件是“不负责的（irresponsible）、对外依赖的（dependent）”。由于这个组件没有被其他组件依赖，所以自然也就没有力量会干预它的变更，同时也因为该组件依赖于其他组件，所以就必然会经常需要变更。\n\nIn contrast, when the I metric is equal to 0, it means that the component is depended on by other components (Fan-in > 0), but does not itself depend on any other components (Fan-out = 0). Such a component is responsible and independent. It is as stable as it can get. Its dependents make it hard to change the component, and its has no dependencies that might force it to change.\n\n> 相反，当 1=0 的时候，说明当前组件是其他组件所依赖的目标(Fan-in>0)，同时其自身并不依赖任何其他组件（Fan-out=0）。我们通常认为这样的组件是“负责的（responsibile）、不对外依赖的（independent）”。这是组件最具稳定性的一种情况，其他组件对它的依赖关系会导致这个组件很难被变更，同时由于它没有对外依赖关系，所以不会有来自外部的变更理由。\n\nThe SDP says that the I metric of a component should be larger than the I metrics of the components that it depends on. That is, I metrics should decrease in the direction of dependency.\n\n> 稳定依赖原则（SDP）的要求是让每个组件的/指标都必须大于其所依赖组件的 I 指标。也就是说，组件结构依赖图中各组件的/指标必须要按其依赖关系方向递减。\n\n### NOT ALL COMPONENTS SHOULD BE STABLE 并不是所有组件都应该是稳定的\n\nIf all the components in a system were maximally stable, the system would be unchangeable. This is not a desirable situation. Indeed, we want to design our component structure so that some components are unstable and some are stable. The diagram in Figure 14.8 shows an ideal configuration for a system with three components.\n\n> 如果一个系统中的所有组件都处于最高稳定性状态，那么系统就一定无法再进行变更了，这显然不是我们想要的。事实上，我们设计组件架构图的目的就是要决定应该让哪些组件稳定，让哪些组件不稳定。譬如在图 14.8 中，我们所示范的就是一个具有三个组件的系统的理想配置。\n\nThe changeable components are on top and depend on the stable component at the bottom. Putting the unstable components at the top of the diagram is a useful convention because any arrow that points up is violating the SDP (and, as we shall see later, the ADP).\n\n> 在该系统组件结构图中，可变更的组件位于顶层，同时依赖于底层的稳定组件。将不稳定组件放在该结构图的顶层是很有用的，因为这样我们就可以很容易地找出箭头向上的依赖关系，而这些关系是违反 SDP（以及后面将会讨论的 ADP）的。\n\n<Figures figure=\"14-8\">An ideal configuration for a system with three components</Figures>\n\nThe diagram in Figure 14.9 shows how the SDP can be violated.\n\n> 下面再通过图 14.9 来看看违反 SDP 的情况：\n\n<Figures figure=\"14-9\">SDP violation</Figures>\n\nFlexible is a component that we have designed to be easy to change. We want Flexible to be unstable. However, some developer, working in the component named Stable, has hung a dependency on Flexible. This violates the SDP because the I metric for Stable is much smaller than the I metric for Flexible. As a result, Flexible will no longer be easy to change. A change to Flexible will force us to deal with Stable and all its dependents.\n\n> 在图 14.9 中，Flexible 是在设计中要确保其易于变更的组件，因此我们会希望 Flexible 是不稳定的。然而，Stable 组件的开发人员却引入了对 Flexible 组件的依赖。这种情况就违反了 SDP，因为 Stable 组件的 I 指标要远小于 Flexible 的 I 指标。这将导致 Flexible 组件的变更难度大大增加，因为对 Flexible 组件的任何修改都必须要考虑 Stable 组件及该组件自身存在的依赖关系。\n\nTo fix this problem, we somehow have to break the dependence of Stable on Flexible. Why does this dependency exist? Let’s assume that there is a class C within Flexible that another class U within Stable needs to use (Figure 14.10).\n\n> 如果想要修复这个问题，就必须要将 stable 与 Flexible 这两个组件之间的依赖关系打破。为此，我们就需要了解这个依赖关系到底为什么会存在，这里假设是因为 Stable 组件中的某个类 U 需要使用 Flexible 组件中的一个类 C，如图 14.10 所示：\n\n<Figures figure=\"14-10\">U within Stable uses C within Flexible</Figures>\n\nWe can fix this by employing the DIP. We create an interface class called US and put it in a component named UServer. We make sure that this interface declares all the methods that U needs to use. We then make C implement this interface as shown in Figure 14.11. This breaks the dependency of Stable on Flexible, and forces both components to depend on UServer. UServer is very stable (I = 0), and Flexible retains its necessary instability (I = 1). All the dependencies now flow in the direction of decreasing I.\n\n> 我们可以利用 DIP 来修复这个问题。具体来说就是创造一个 UServer 组件，并在其中设置一个 US 接口类。然后，确保这个接口类中包含了所有 U 需要使用的函数，再让 C 实现这个接口，如图 14.11 所示。这样一来，我们就将从 Stable 到 Flexible 的这条依赖关系打破了，强迫这两个组件都依赖于 UServer。现在，UServer 组件会是非常稳定的（I=0），而 Flexibile 组件则会依然保持不稳定的状态（I=1），结构图中所有的依赖关系都流向 I 递减的方向了。\n\n<Figures figure=\"14-11\">C implements the interface class US</Figures>\n\n### Abstract Components 抽象组件\n\nYou may find it strange that we would create a component—in this example, UService—that contains nothing but an interface. Such a component contains no executable code! It turns out, however, that this is a very common, and necessary, tactic when using statically typed languages like Java and C#. These abstract components are very stable and, therefore, are ideal targets for less stable components to depend on.\n\n> 读者可能会觉得创造新组件（譬如上述例子中的 UService 组件，它其实只包含了一个接口类）这种做法挺奇怪的。因为这样的组件中几乎不包含任何可执行的代码！但事实上，这种做法在 C# 或者 Java 这种静态类型语言中是非常普遍的，而且也必须这样做。因为这些抽象组件通常会非常稳定，可以被那些相对不稳定的组件依赖。\n\nWhen using dynamically typed languages like Ruby and Python, these abstract components don’t exist at all, nor do the dependencies that would have targeted them. Dependency structures in these languages are much simpler because dependency inversion does not require either the declaration or the inheritance of interfaces.\n\n> 而当我们使用 Ruby 和 Python 这种动态类型语言时，这些抽象接口事实上并不存在，因此也就没有对它们的依赖。动态类型语言中的依赖关系是非常简单的，因为其依赖反转的过程并不需要声明和继承接口。\n\n## THE STABLE ABSTRACTIONS PRINCIPLE 稳定抽象原则\n\nA component should be as abstract as it is stable.\n\n> 一个组件的抽象化程度应该与其稳定性保持一致。\n\n### WHERE DO WE PUT THE HIGH-LEVEL POLICY? 高阶策略应该放在哪里\n\nSome software in the system should not change very often. This software represents high-level architecture and policy decisions. We don’t want these business and architectural decisions to be volatile. Thus the software that encapsulates the high-level policies of the system should be placed into stable components (I = 0). Unstable components (I = 1) should contain only the software that is volatile—software that we want to be able to quickly and easily change.\n\n> 在一个软件系统中，总有些部分是不应该经常发生变更的。这些部分通常用于表现该系统的高阶架构设计及一些策略相关的高阶决策。我们不想让这些业务决策和架构设计经常发生变更，因此这些代表了系统咼阶策略的组件应该被放到稳定组件（I=0）中，而不稳定的组件（I=1）中应该只包含那些我们想要快速和方便修改的部分。\n\nHowever, if the high-level policies are placed into stable components, then the source code that represents those policies will be difficult to change. This could make the overall architecture inflexible. How can a component that is maximally stable (I = 0) be flexible enough to withstand change? The answer is found in the OCP. This principle tells us that it is possible and desirable to create classes that are flexible enough to be extended without requiring modification. Which kind of classes conform to this principle? Abstract classes.\n\n> 然而，如果我们将高阶策略放入稳定组件中，那么用于描述那些策略的源代码就很难被修改了。这可能会导致整个系统的架构设计难于被修改。如何才能让一个无限稳定的组件（I=0）接受变更呢？开闭原则（OCP）为我们提供了答案。这个原则告诉我们：创造一个足够灵活、能够被扩展，而且不需要修改的类是可能的，而这正是我们所需要的。哪一种类符合这个原则呢？答案是抽象类。\n\n### INTRODUCING THE STABLE ABSTRACTIONS PRINCIPLE 稳定抽象原则简介\n\nThe Stable Abstractions Principle (SAP) sets up a relationship between stability and abstractness. On the one hand, it says that a stable component should also be abstract so that its stability does not prevent it from being extended. On the other hand, it says that an unstable component should be concrete since its instability allows the concrete code within it to be easily changed.\n\n> 稳定抽象原则（SAP）为组件的稳定性与它的抽象化程度建立了一种关联。一方面，该原则要求稳定的组件同时应该是抽象的，这样它的稳定性就不会影响到扩展性。另一方面，该原则也要求一个不稳定的组件应该包含具体的实现代码，这样它的稳定性就可以通过具体的代码被轻易修改。\n\nThus, if a component is to be stable, it should consist of interfaces and abstract classes so that it can be extended. Stable components that are extensible are flexible and do not overly constrain the architecture.\n\n> 因此，如果一个组件想要成为稳定组件，那么它就应该由接口和抽象类组成，以便将来做扩展。如此，这些既稳定又便于扩展的组件可以被组合成既灵活又不会受到过度限制的架构。\n\nThe SAP and the SDP combined amount to the DIP for components. This is true because the SDP says that dependencies should run in the direction of stability, and the SAP says that stability implies abstraction. Thus dependencies run in the direction of abstraction.\n\n> 将 SAP 与 SDP 这两个原则结合起来，就等于组件层次上的 DIP。因为 SDP 要求的是让依赖关系指向更稳定的方向，而 SAP 则告诉我们稳定性本身就隐含了对抽象化的要求，即依赖关系应该指向更抽象的方向。\n\nThe DIP, however, is a principle that deals with classes—and with classes there are no shades of gray. Either a class is abstract or it is not. The combination of the SDP and the SAP deals with components, and allows that a component can be partially abstract and partially stable.\n\n> 然而，DIP 毕竟是与类这个层次有关的原则——对类来说，设计是没有灰色地带的。一个类要么是抽象类，要么就不是。SDP 与 SAP 这对原则是应用在组件层面上的，我们要允许一个组件部分抽象，部分稳定。\n\n### MEASURING ABSTRACTION 衡量抽象化程度\n\nThe A metric is a measure of the abstractness of a component. Its value is simply the ratio of interfaces and abstract classes in a component to the total number of classes in the component.\n\n> 下面，假设 A 指标是对组件抽象化程度的一个衡量，它的值是组件中抽象类与接口所占的比例。那么：\n\n- Nc: The number of classes in the component.\n- Na: The number of abstract classes and interfaces in the component.\n- A: Abstractness. A = Na ÷ Nc.\n\n---\n\n> - Nc：组件中类的数量。\n> - Na：组件中抽象类和接口的数量。\n> - A：抽象程度，A=Na/Nc。\n\nThe A metric ranges from 0 to 1. A value of 0 implies that the component has no abstract classes at all. A value of 1 implies that the component contains nothing but abstract classes.\n\n> A 指标的取值范围是从 0 到 1，值为 0 代表组件中没有任何抽象类，值为 1 就意味着组件中只有抽象类。\n\n### THE MAIN SEQUENCE 主序列\n\nWe are now in a position to define the relationship between stability (I) and abstractness (A). To do so, we create a graph with A on the vertical axis and I on the horizontal axis (Figure 14.12). If we plot the two “good” kinds of components on this graph, we will find the components that are maximally stable and abstract at the upper left at (0, 1). The components that are maximally unstable and concrete are at the lower right at (1, 0).\n\n> 现在，我们可以来定义组件的稳定性 I 与其抽象化程度 A 之间的关系了，具体如图 14.12 所示。在该图中，纵轴为 A 值，横轴为 I 值。如果我们将两个“设计良好”的组件绘制在该图上，那么最稳定的、包含了无限抽象类的组件应该位于左上角(0,1)，最不稳定的、最具体的组件应该位于右下角(1,0)。\n\n<Figures figure=\"14-12\">The I/A graph</Figures>\n\nNot all components fall into one of these two positions, because components often have degrees of abstraction and stability. For example, it is very common for one abstract class to derive from another abstract class. The derivative is an abstraction that has a dependency. Thus, though it is maximally abstract, it will not be maximally stable. Its dependency will decrease its stability.\n\n> 当然，不可能所有的组件都能处于这两个位置上，因为组件通常都有各自的稳定程度和抽象化程度。例如一个抽象类有时会衍生于另一个抽象类，这种情况是很常见的，而这个衍生过程就意味着某种依赖关系的产生。因此，虽然该组件是全抽象的，但它并不是完全稳定的，上述依赖关系降低了它的稳定程度。\n\nSince we cannot enforce a rule that all components sit at either (0, 1) or (1, 0), we must assume that there is a locus of points on the A/I graph that defines reasonable positions for components. We can infer what that locus is by finding the areas where components should not be—in other words, by determining the zones of exclusion (Figure 14.13).\n\n> 既然不能强制要求所有的组件都处于(0,1)和(1,0)这两个位置上，那么就必须假设 A/I 图上存在着一个合理组件的区间。而这个区间应该可以通过排除法推导出来，也就是说，我们可以先找出那些组件不应该处于的位置（请参考图 14.13）：\n\n<Figures figure=\"14-13\">Zones of exclusion</Figures>\n\n### The Zone of Pain 痛苦区\n\nConsider a component in the area of (0, 0). This is a highly stable and concrete component. Such a component is not desirable because it is rigid. It cannot be extended because it is not abstract, and it is very difficult to change because of its stability. Thus we do not normally expect to see well-designed components sitting near (0, 0). The area around (0, 0) is a zone of exclusion called the Zone of Pain.\n\n> 在图 14.13 中，假设某个组件处于(0,0)位置，那么它应该是一个非常稳定但也非常具体的组件。这样的组件在设计上是不佳的，因为它很难被修改，这意味着该组件不能被扩展。这样一来，因为这个组件不是抽象的，而且它又由于稳定性的原因变得特别难以被修改，我们并不希望一个设计良好的组件贴近这个区域，因此(0,0)周围的这个区域被我们称为痛苦区（zone of pain）。\n\nSome software entities do, in fact, fall within the Zone of Pain. An example would be a database schema. Database schemas are notoriously volatile, extremely concrete, and highly depended on. This is one reason why the interface between OO applications and databases is so difficult to manage, and why schema updates are generally painful.\n\n> 当然，有些软件组件确实会处于这个区域中，这方面的一个典型案例就是数据库的表结构（schema）。它在可变性上可谓臭名昭著，但是它同时又非常具体，并被非常多的组件依赖。这就是面向对象应用程序与数据库之间的接口这么难以管理，以及每次更新数据库的过程都那么痛苦的原因。\n\nAnother example of software that sits near the area of (0, 0) is a concrete utility library. Although such a library has an I metric of 1, it may actually be nonvolatile. Consider the String component, for example. Even though all the classes within it are concrete, it is so commonly used that changing it would create chaos. Therefore String is nonvolatile.\n\n> 另一个会处于这个区域的典型软件组件是工具型类库。虽然这种类库的 I 指标为 1，但事实上通常是不可变的。例如 String 组件，虽然其中所有的类都是具体的，但由于它被使用得太过普遍，任何修改都会造成大范围的混乱，因此 String 组件只能是不可变的。\n\nNonvolatile components are harmless in the (0, 0) zone since they are not likely to be changed. For that reason, it is only volatile software components that are problematic in the Zone of Pain. The more volatile a component in the Zone of Pain, the more “painful” it is. Indeed, we might consider volatility to be a third axis of the graph. With this understanding, Figure 14.13 shows only the most painful plane, where volatility = 1.\n\n> 不可变组件落在(0,0)这一区域中是无害的，因为它们不太可能会发生变更。正因为如此，只有多变的软件组件落在痛苦区中才会造成麻烦，而且组件的多变性越强，造成的麻烦就会越大。其实，我们应该将多变性作为图 14.13 的第三个轴，这时图 14.13 所展示的便是多变性=1 时的情况，也就是最痛苦的切面。\n\n### The Zone of Uselessness 无用区\n\nConsider a component near (1, 1). This location is undesirable because it is maximally abstract, yet has no dependents. Such components are useless. Thus this area is called the Zone of Uselessness.\n\n> 现在我们来看看靠近(1,1)这一位置点的组件。该位置上的组件不会是我们想要的，因为这些组件通常是无限抽象的，但是没有被其他组件依赖，这样的组件往往无法使用。因此我们将这个区域称为无用区。\n\nThe software entities that inhabit this region are a kind of detritus. They are often leftover abstract classes that no one ever implemented. We find them in systems from time to time, sitting in the code base, unused.\n\n> 对于这个区域中的软件组件来说，其源码或者类中的设计问题通常是由于历史原因造成的。例如我们常常会在系统的某个角落里看到某个没有人实现的抽象类，它们一直静静地躺在那里，没有人使用。\n\nA component that has a position deep within the Zone of Uselessness must contain a significant fraction of such entities. Clearly, the presence of such useless entities is undesirable.\n\n> 同样的，落在无用区中的组件也一定会包含大量的无用代码。很明显，这类组件也不是我们想要的。\n\n### AVOIDING THE ZONES OF EXCLUSION 避开这两个区域\n\nIt seems clear that our most volatile components should be kept as far from both zones of exclusion as possible. The locus of points that are maximally distant from each zone is the line that connects (1, 0) and (0, 1). I call this line the Main Sequence.2\n\n> 很明显，最多变的组件应该离上述两个区域越远越好。在图 14.13 中，我们可以将距离两个区域最远的点连成一条线，即从(1,0)连接到(0,1)。我将这条线称为主序列线（main sequence）。\n\nA component that sits on the Main Sequence is not “too abstract” for its stability, nor is it “too unstable” for its abstractness. It is neither useless nor particularly painful. It is depended on to the extent that it is abstract, and it depends on others to the extent that it is concrete.\n\n> 坐落于主序列线上的组件不会为了追求稳定性而被设计得“太过抽象”，也不会为了避免抽象化而被设计得“太过不稳定”。这样的组件既不会特别难以被修改，又可以实现足够的功能。对于这些组件来说，通常会有足够多的组件依赖于它们，这使得它们会具有一定程度的抽象，同时它们也依赖了足够多的其他组件，这又使得它一定会包含很多具体实现。\n\nThe most desirable position for a component is at one of the two endpoints of the Main Sequence. Good architects strive to position the majority of their components at those endpoints. However, in my experience, some small fraction of the components in a large system are neither perfectly abstract nor perfectly stable. Those components have the best characteristics if they are on, or close, to the Main Sequence.\n\n> 在这条主序列线上，组件所能处于最优的位置是线的两端。一个优秀的软件架构师应该争取将自己设计的大部分组件尽可能地推向这两个位置。然而，以我的个人经验来说，大型系统中的组件不可能做到完全抽象，也不可能做到完全稳定。所以我们只要追求让这些组件位于主序列线上，或者贴近这条线即可。\n\n### DISTANCE FROM THE MAIN SEQUENCE 离主序列线的距离\n\nThis leads us to our last metric. If it is desirable for components to be on, or close, to the Main Sequence, then we can create a metric that measures how far away a component is from this ideal.\n\n> 接下来介绍最后一个指标：如果让组件位于或者靠近主序列是可取的目标，那么我们就可以创建一个指标来衡量一个组件距离最佳位置的距离。\n\n- D3: Distance. D = |A+I–1| . The range of this metric is [0, 1]. A value of 0 indicates that the component is directly on the Main Sequence. A value of 1 indicates that the component is as far away as possible from the Main Sequence.\n\n> - D 指标：距离 `D=|A+I-1|`，该指标的取值范围是[0,1]。值为 0 意味着组件是直接位于主序列线上的，值为 1 则意味着组件在距离主序列最远的位置。\n\nGiven this metric, a design can be analyzed for its overall conformance to the Main Sequence. The D metric for each component can be calculated. Any component that has a D value that is not near zero can be reexamined and restructured.\n\n> 通过计算每个组件的 D 指标，就可以量化一个系统设计与主序列的契合程度了。另外，我们也可以用 D 指标大于 0 多少来指导组件的重构与重新设计。\n\nStatistical analysis of a design is also possible. We can calculate the mean and variance of all the D metrics for the components within a design. We would expect a conforming design to have a mean and variance that are close to zero. The variance can be used to establish “control limits” so as to identify components that are “exceptional” in comparison to all the others.\n\n> 除此之外，通过计算设计中所有组件的 D 指标的平均值和方差，我们还可以用统计学的方法来量化分析一个系统设计。对于一个良好的系统设计来说，D 指标的平均值和方差都应该接近于 0。其中，方差还可以被当作组件的“达标红线”来使用，我们可以通过它找出系统设计中那些不合常规的组件。\n\nIn the scatterplot in Figure 14.14, we see that the bulk of the components lie along the Main Sequence, but some of them are more than one standard deviation (Z = 1) away from the mean. These aberrant components are worth examining more closely. For some reason, they are either very abstract with few dependents or very concrete with many dependents.\n\n> 在图 14.14 中，我们可以看到大部分的组件都位于主序列附近，但是有些组件处于平均值的标准差（Z=1）以外。这些组件值得被重点分析，它们要么过于抽象依赖不足，要么过于具体而被依赖得太多。\n\n<Figures figure=\"14-14\">Scatterplot of the components</Figures>\n\nAnother way to use the metrics is to plot the D metric of each component over time. The graph in Figure 14.15 is a mock-up of such a plot. You can see that some strange dependencies have been creeping into the Payroll component over the last few releases. The plot shows a control threshold at D = 0.1. The R2.1 point has exceeded this control limit, so it would be worth our while to find out why this component is so far from the main sequence.\n\n> D 指标的另外一种用法是按时间来跟踪每个组件的值，下面用图 14.15 来做一个示范。在该图中可以看到，Payroll 组件在最近几次发布中累积了一些意外的对外依赖。图中的 Q=0.1 是组件的达标红线，R2.1 这个值已经超出了红线范围，这就告诉我们现在值得花一些精力来找出这个组件偏离主序列线的原因了。\n\n<Figures figure=\"14-15\">Plot of D for a single component over time</Figures>\n\n## CONCLUSION 本章小结\n\nThe dependency management metrics described in this chapter measure the conformance of a design to a pattern of dependency and abstraction that I think is a “good” pattern. Experience has shown that certain dependencies are good and others are bad. This pattern reflects that experience. However, a metric is not a god; it is merely a measurement against an arbitrary standard. These metrics are imperfect, at best, but it is my hope that you find them useful.\n\n> 本章介绍了各种可用于依赖关系管理的指标，它们可以被用来里化分析某个系统设计与“优秀”设计模式之间的契合度。根据以往的经验，组件之间有些依赖关系是好的，有些依赖关系则是不好的，这些经验最后都会体现在这个设计模式中。当然，指标并不等同于真理，它只是对我们所定义标准的一个衡量。这些指标肯定是不完美的，但是我希望它们对读者有价值。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Part5. ARCHITECTURE 软件架构\n\n# Chap15. WHAT IS ARCHITECTURE? 什么是软件架构\n\n![](../../images/books/架构整洁之道/CH-UN15.jpg)\n\nThe word “architecture” conjures visions of power and mystery. It makes us think of weighty decisions and deep technical prowess. Software architecture is at the pinnacle of technical achievement. When we think of a software architect, we think of someone who has power, and who commands respect. What young aspiring software developer has not dreamed of one day becoming a software architect?\n\n> “架构”这个词给人的直观感受就充满了权力与神秘感，因此谈论架构总让人有一种正在进行责任重大的决策或者深度技术分析的感觉。毕竟，进阶到软件架构这一层次是我们走技术路线的人的终极目标。一个软件架构师总是给人一种权力非凡、广受尊敬的感觉，有哪个年轻的工程师没有梦想过成为一个软件架构师呢?\n\nBut what is software architecture? What does a software architect do, and when does he or she do it?\n\n> 那么，究竟什么才是“软件架构”呢?软件架构师的工作内容究竟是什么?这项工作又是什么时候进行的呢？\n\nFirst of all, a software architect is a programmer; and continues to be a programmer. Never fall for the lie that suggests that software architects pull back from code to focus on higher-level issues. They do not! Software architects are the best programmers, and they continue to take programming tasks, while they also guide the rest of the team toward a design that maximizes productivity. Software architects may not write as much code as other programmers do, but they continue to engage in programming tasks. They do this because they cannot do their jobs properly if they are not experiencing the problems that they are creating for the rest of the programmers.\n\n> 首先，软件架构师自身需要是程序员，并且必须一直坚持做一线程序员，绝对不要听从那些说应该让软件架构师从代码中解放出来以专心解决高阶问题的伪建议。不是这样的！软件架构师其实应该是能力最强的一群程序员，他们通常会在自身承接编程任务的同时。逐渐引导整个团队向一个能够最大化生产力的系统设计方向前进。也许软件架构师生产的代码量不是最多的，但是他们必须不停地承接编程任务。如果不亲身承受因系统设计而带来的麻烦，就体会不到设计不佳所带来的痛苦，接着就会逐渐迷失正确的设计方向。\n\nThe architecture of a software system is the shape given to that system by those who build it. The form of that shape is in the division of that system into components, the arrangement of those components, and the ways in which those components communicate with each other.\n\n> 软件系统的架构质量是由它的构建者所决定的，软件架构这项工作的实质就是规划如何将系统切分成组件，并安排好组件之间的排列关系，以及组件之间互相通信的方式。\n\nThe purpose of that shape is to facilitate the development, deployment, operation, and maintenance of the software system contained within it.\n\n> 而设计软件架构的目的，就是为了在工作中更好地对这些组件进行研发、部署、运行以及维护。\n\nThe strategy behind that facilitation is to leave as many options open as possible, for as long as possible.\n\n> 如果想设计一个便于推进各项工作的系统，其策略就是要在设计中尽可能长时间地保留尽可能多的可选项。\n\nPerhaps this statement has surprised you. Perhaps you thought that the goal of software architecture was to make the system work properly. Certainly we want the system to work properly, and certainly the architecture of the system must support that as one of its highest priorities.\n\n> 上面这句话可能会让人很意外，也许你一直认为设计软件架构的目的应该是让一个系统能正常地工作。我们当然需要让系统正常工作，软件架构设计最高优先级的目标就是保持系统正常工作。\n\nHowever, the architecture of a system has very little bearing on whether that system works. There are many systems out there, with terrible architectures, that work just fine. Their troubles do not lie in their operation; rather, they occur in their deployment, maintenance, and ongoing development.\n\n> 然而，一个软件系统的架构质量和该系统是否能正常工作的关系并不大，毕竟世界上有很多架构设计糟糕但是工作正常的软件系统。真正的麻烦往往并不会在我们运行软件的过程中出现，而是会出现在这个软件系统的开发、部署以及后续的补充开发中。\n\nThis is not to say that architecture plays no role in supporting the proper behavior of the system. It certainly does, and that role is critical. But the role is passive and cosmetic, not active or essential. There are few, if any, behavioral options that the architecture of a system can leave open.\n\n> 当然，这并不意味着好的软件架构对系统的行为就没有影响了，事实上架构在其中的角色还是很重要的。然而在这个方面，架构能起到的作用更多的时候是被动的，修饰性的，并不是主动的，更不是必不可少的。在系统的架构设计中，能影响系统行为的可选项少之又少。\n\nThe primary purpose of architecture is to support the life cycle of the system. Good architecture makes the system easy to understand, easy to develop, easy to maintain, and easy to deploy. The ultimate goal is to minimize the lifetime cost of the system and to maximize programmer productivity.\n\n> 软件架构设计的主要目标是支撑软件系统的全生命周期，设计良好的架构可以让系统便于理解、易于修改、方便维护，并且能轻松部署。软件架构的终极目标就是最大化程序员的生产力，同时最小化系统的总运营成本。\n\n## DEVELOPMENT 开发（Development）\n\nA software system that is hard to develop is not likely to have a long and healthy lifetime. So the architecture of a system should make that system easy to develop, for the team(s) who develop it.\n\n> 一个开发起来很困难的软件系统一般不太可能会有一个长久、健康的生命周期，所以系统架构的作用就是要方便其开发团队对它的开发。\n\nDifferent team structures imply different architectural decisions. On the one hand, a small team of five developers can quite effectively work together to develop a monolithic system without well-defined components or interfaces. In fact, such a team would likely find the strictures of an architecture something of an impediment during the early days of development. This is likely the reason why so many systems lack good architecture: They were begun with none, because the team was small and did not want the impediment of a superstructure.\n\n> 这意味着，不同的团队结构应该采用不同的架构设计。一方面，对于一个只有五个开发人员的小团队来说，他们完全可以非常高效地共同开发一个没有明确定义组件和接口的单体系统（monolithic system）。事实上，这样的团队可能会发现软件架构在早期开发中反而是一种障碍。这可能就是为什么许多系统都没有设计一个良好架构的原因，因为它们的开发团队起初都很小，不需要设计一些上层建筑来限制某些事情。\n\nOn the other hand, a system being developed by five different teams, each of which includes seven developers, cannot make progress unless the system is divided into well-defined components with reliably stable interfaces. If no other factors are considered, the architecture of that system will likely evolve into five components—one for each team.\n\n> 但另一方面，如果一个软件系统是由五个不同的团队合作开发的，而每个团队各自都有七个开发人员的话，不将系统划分成定义清晰的组件和可靠稳定的接口，开发工作就没法继续推进。通常，如果忽略其他因素，该系统的架构会逐渐演变成五个组件，一个组件对应一个团队。\n\nSuch a component-per-team architecture is not likely to be the best architecture for deployment, operation, and maintenance of the system. Nevertheless, it is the architecture that a group of teams will gravitate toward if they are driven solely by development schedule.\n\n> 当然，这种一个组件对应一个团队的架构不太可能是该系统在部署、运行以及维护方面的最优方案。但不管怎样，如果研发团队只受开发进度来驱动的话，他们的架构设计最终一定会倾向于这个方向。\n\n## DEPLOYMENT 部署（Deployment）\n\nTo be effective, a software system must be deployable. The higher the cost of deployment, the less useful the system is. A goal of a software architecture, then, should be to make a system that can be easily deployed with a single action.\n\n> 为了让开发成为有效的工作，软件系统就必须是可部署的。在通常情况下，一个系统的部署成本越高，可用性就越低。因此，实现一键式的轻松部署应该是我们设计软件架构的一个目标。\n\nUnfortunately, deployment strategy is seldom considered during initial development. This leads to architectures that may make the system easy to develop, but leave it very difficult to deploy.\n\n> 但很不幸，我们在系统的早期开发中很少会考虑部署策略方面的事情，这常常会导致一些易于开发、难于部署的系统架构。\n\nFor example, in the early development of a system, the developers may decide to use a “micro-service architecture.” They may find that this approach makes the system very easy to develop since the component boundaries are very firm and the interfaces relatively stable. However, when it comes time to deploy the system, they may discover that the number of micro-services has become daunting; configuring the connections between them, and the timing of their initiation, may also turn out to be a huge source of errors.\n\n> 例如，在系统的早期开发中，开发人员可能会决定采用某种“微服务架构”。这种架构的组件边界清晰，接口稳定，非常利于开发。但当我们实际部署这种系统时，就会发现其微服务的数量已经大到令人望而生畏，而配置这些微服务之间的连接以及启动时间都会成为系统出错的主要来源。\n\nHad the architects considered deployment issues early on, they might have decided on fewer services, a hybrid of services and in-process components, and a more integrated means of managing the interconnections.\n\n> 如果软件架构师早先就考虑到这些部署问题，可能就会有意地减少微服务的数量，采用进程内部组件与外部服务混合的架构，以及更加集成式的连接管理方式。\n\n## OPERATION 运行（Operation）\n\nThe impact of architecture on system operation tends to be less dramatic than the impact of architecture on development, deployment, and maintenance. Almost any operational difficulty can be resolved by throwing more hardware at the system without drastically impacting the software architecture.\n\n> 软件架构对系统运行的影响远不及它对开发、部署和维护的影响。几乎任何运行问题都可以通过增加硬件的方式来解决，这避免了软件架构的重新设计。\n\nIndeed, we have seen this happen over and over again. Software systems that have inefficient architectures can often be made to work effectively simply by adding more storage and more servers. The fact that hardware is cheap and people are expensive means that architectures that impede operation are not as costly as architectures that impede development, deployment, and maintenance.\n\n> 事实上，我们长期以来就是一直目睹着这种情况一再发生。对于一个因架构设计糟糕而效率低下的系统，我们通常只需要增加更多的存储器与服务器，就能够让它完满地完成任务。另外，硬件也远比人力要便宜，这也是软件架构对系统运行的影响远没有它对开发、部署、维护的影响那么深远的一个原因。\n\nThis is not to say that an architecture that is well tuned to the operation of the system is not desirable. It is! It’s just that the cost equation leans more toward development, deployment, and maintenance.\n\n> 当然，这并不是说我们不应该为了让系统能更好地运转而优化软件的架构设计，这样做是应该的，只是基于投入/产出比的考虑，我们的优化重心应该更倾向于系统的开发、部署以及维护。\n\nHaving said that, there is another role that architecture plays in the operation of the system: A good software architecture communicates the operational needs of the system.\n\n> 即使这样，软件架构在整个系统运行的过程中还发挥着另外一个重要作用，那就是一个设计良好的软件架构应该能明确地反映该系统在运行时的需求。\n\nPerhaps a better way to say this is that the architecture of a system makes the operation of the system readily apparent to the developers. Architecture should reveal operation. The architecture of the system should elevate the use cases, the features, and the required behaviors of the system to first-class entities that are visible landmarks for the developers. This simplifies the understanding of the system and, therefore, greatly aids in development and maintenance.\n\n> 也许我们可以换一个更好的说法，那就是设计良好的系架构应该可以使开发人员对系统的运行过程一目了然。架构应该起到揭示系统运行过程的作用。具体来说，就是该架构应该将系统中的用例、功能以及该系统的必备行为设置为对开发者可见的一级实体，简化它们对于系统的理解，这将为整个系统的开发与维护提供很大的帮助。\n\n## MAINTENANCE 维护（Maintenance）\n\nOf all the aspects of a software system, maintenance is the most costly. The never-ending parade of new features and the inevitable trail of defects and corrections consume vast amounts of human resources.\n\n> 在软件系统的所有方面中，维护所需的成本是最高的。满足永不停歇的新功能需求，以及修改层出不穷的系统缺陷这些工作将会占去绝大部分的人力资源。\n\nThe primary cost of maintenance is in spelunking and risk. Spelunking is the cost of digging through the existing software, trying to determine the best place and the best strategy to add a new feature or to repair a defect. While making such changes, the likelihood of creating inadvertent defects is always there, adding to the cost of risk.\n\n> 系统维护的主要成本集中在“探秘”和“风险”这两件事上。其中，“探秘（spelunking）”的成本主要来自我们对于现有软件系统的挖掘，目的是确定新增功能或被修复问题的最佳位置和最佳方式。而“风险（risk）”，则是指当我们进行上述修改时，总是有可能衍生出新的问题，这种可能性就是风险成本。\n\nA carefully thought-through architecture vastly mitigates these costs. By separating the system into components, and isolating those components through stable interfaces, it is possible to illuminate the pathways for future features and greatly reduce the risk of inadvertent breakage.\n\n> 我们可以通过精雕细琢的架构设计极大地降低这两项成本。通过将系统切分为组件，并使用稳定的接口将组件隔离，我们可以将未来新功能的添加方式明确出来，并大幅度地降低在修改过程中对系统其他部分造成伤害的可能性。\n\n## KEEPING OPTIONS OPEN 保持可选项\n\nAs we described in an earlier chapter, software has two types of value: the value of its behavior and the value of its structure. The second of these is the greater of the two because it is this value that makes software soft.\n\n> 正如我们在之前章节中所说的，软件有行为价值与架构价值两种价值。这其中的第二种价值又比第一种更重要，因为它正是软件之所以“软”的原因。\n\nSoftware was invented because we needed a way to quickly and easily change the behavior of machines. But that flexibility depends critically on the shape of the system, the arrangement of its components, and the way those components are interconnected.\n\n> 软件被发明出来就是因为我们需要一种灵活和便捷的方式来改变机器的行为。而软件的灵活性则取决于系统的整体状况、组件的布置以及组件之间的连接方式。\n\nThe way you keep software soft is to leave as many options open as possible, for as long as possible. What are the options that we need to leave open? They are the details that don’t matter.\n\n> 我们让软件维持“软”性的方法就是尽可能长时间地保留尽可能多的可选项。那么到底哪些选项是我们应该保留的？它们就是那些无关紧要的细节设计。\n\nAll software systems can be decomposed into two major elements: policy and details. The policy element embodies all the business rules and procedures. The policy is where the true value of the system lives.\n\n> 基本上，所有的软件系统部可以降解为策略打细节这两种主要元素。策略体现的是软件中所有的业务规则与操作过程，因此它是系统真正的价值所在。\n\nThe details are those things that are necessary to enable humans, other systems, and programmers to communicate with the policy, but that do not impact the behavior of the policy at all. They include IO devices, databases, web systems, servers, frameworks, communication protocols, and so forth.\n\n> 而细节则是指那些让操作该系统的人、其他系统以及程序员们与策略进行交互，但是又不会影响到策略本身的行为。它们包括 I/O 设备、数据库、Web 系统、服务器、框架、交互协议等。\n\nThe goal of the architect is to create a shape for the system that recognizes policy as the most essential element of the system while making the details irrelevant to that policy. This allows decisions about those details to be delayed and deferred.\n\n> 软件架构师的目标是创建一种系统形态，该形态会以策略为最基本的元素，并让细节与策略脱离关系，以允许在具体决策过程中推迟或延迟与细节相关的内容。\n\nFor example:\n\n> 例如，\n\n- It is not necessary to choose a database system in the early days of development, because the high-level policy should not care which kind of database will be used. Indeed, if the architect is careful, the high-level policy will not care if the database is relational, distributed, hierarchical, or just plain flat files.\n- It is not necessary to choose a web server early in development, because the high-level policy should not know that it is being delivered over the web. If the high-level policy is unaware of HTML, AJAX, JSP, JSF, or any of the rest of the alphabet soup of web development, then you don’t need to decide which web system to use until much later in the project. Indeed, you don’t even have to decide if the system will be delivered over the web.\n- It is not necessary to adopt REST early in development, because the high-level policy should be agnostic about the interface to the outside world. Nor is it necessary to adopt a micro-services framework, or a SOA framework. Again, the high-level policy should not care about these things.\n- It is not necessary to adopt a dependency injection framework early in development, because the high-level policy should not care how dependencies are resolved.\n\n---\n\n> - 在开发的早期阶段应该无须选择数据库系统，因为软件的高层策略不应该关心其底层到底使用哪一种数据库。事实上，如果软件架构师足够小心，软件的高层策略甚至可以不用关心该数据库是关系型数据库，还是分布式数据库，是多级数据库，还只是一些文本文件而已。\n> - 在开发的早期阶段也不应该选定使用的 Web 服务，因为高层策略并不应该知道自己未来要以网页形式发布。如果高层策略能够与 HTML、AJAX、JSP、JSF 或任何 Web 开发技术脱钩，那么我们就可以将对 Web 系统的选择推迟到项目的最后阶段。事实上，很有可能我们压根不需要考虑这个系统到底是不是以网页形式发布的。\n> - 在开发的早期阶段不应该过早地采用 REST 模式，因为软件的高层策略应该与外部接口无关。同样的，我们也不应该过早地考虑采用微服务框架、SOA 框架等。再说一遍，软件的高层策略压根不应该跟这些有关。\n> - 在开发的早期阶段不应过早地采用依赖注入框架（dependency injection framework），因为高层策略不应该操心如何解析系统的依赖关系。\n\nI think you get the point. If you can develop the high-level policy without committing to the details that surround it, you can delay and defer decisions about those details for a long time. And the longer you wait to make those decisions, the more information you have with which to make them properly.\n\n> 说到这里，我想读者应该明白我的意思了。如果在开发高层策略时有意地让自自摆脱具体细节的纠缠，我们就可以将与具体实现相关的细节决策推迟或延后，因为越到项目的后期，我们就拥有越多的信息来做出合理的决策。\n\nThis also leaves you the option to try different experiments. If you have a portion of the high-level policy working, and it is agnostic about the database, you could try connecting it to several different databases to check applicability and performance. The same is true with web systems, web frameworks, or even the web itself.\n\n> 同时，这样做还可以让我们有机会做不同的尝试。例如。如果我们现在手里有一部分与数据库无关的高层策略，那么我们就可以用不同的数据库来做实验，以检验该系统与不同数据库之间的适应性件和性能。类似的情况也适用于各种 Web 框架，甚至 Web 这种发布形式本身。\n\nThe longer you leave options open, the more experiments you can run, the more things you can try, and the more information you will have when you reach the point at which those decisions can no longer be deferred.\n\n> 另外，我们保留这些可选项的时间越长，实验的机会也就越多。而实验做得越多，我们做决策的时候就能拥有越充足的信息。\n\nWhat if the decisions have already been made by someone else? What if your company has made a commitment to a certain database, or a certain web server, or a certain framework? A good architect pretends that the decision has not been made, and shapes the system such that those decisions can still be deferred or changed for as long as possible.\n\n> 那么如果其他人已经替我们做出了决策呢？譬如说，我们的公司已经指定了某个数据库，或某种 Web 服务，或某个框架，这时应该怎么办？通常一个优秀的软件架构师会假装这些决策还没有确定，并尽可能长时间地让系统有推迟或修改这些决策的能力。\n\nA good architect maximizes the number of decisions not made.\n\n> 一个优秀的软件架构师应该致力于最大化可选项数量。\n\n## DEVICE INDEPENDENCE 设备无关性\n\nAs an example of this kind of thinking, let’s take a trip back to the 1960s, when computers were teenagers and most programmers were mathematicians or engineers from other disciplines (and-one third or more were women).\n\n> 如果想要找反映这方面思想的例子，我们还得先回到 20 世纪 60 年代。由于当时的计算机行业还处于萌芽阶段，大部分程序员都来自数学专业，或者是其他工程类专业（当时超过三分之一的程序员是女性）。\n\nIn those days we made a lot of mistakes. We didn’t know they were mistakes at the time, of course. How could we?\n\n> 当时，我们曾经犯过很多错误，而且还没有人知道那些是错误。当然了，那时候我们怎么可能知道?\n\nOne of those mistakes was to bind our code directly to the IO devices. If we needed to print something on a printer, we wrote code that used the IO instructions that would control the printer. Our code was device dependent.\n\n> 其中一个错误就是将代码与 I/O 设备直接紧密地绑定在一起。当时，如果我们需要用打印机打印东西，就得专门写一段 I/O 指令来操作打印机，因此我们的代码是依赖于设备的。\n\nFor example, when I wrote PDP-8 programs that printed on the teleprinter, I used a set of machine instructions that looked like this:\n\n> 例如，当我们要写一段要在电传打印机上输出的 PDP-8 程序时，需要用到像下面这样一组机器指令：\n\n```\nPRTCHR, 0\n        TSF\n        JMP .-1\n        TLS\n        JMP I PRTCHR\n```\n\nPRTCHR is a subroutine that prints one character on the teleprinter. The beginning zero was used as the storage for the return address. (Don’t ask.) The TSF instruction skipped the next instruction if the teleprinter was ready to print a character. If the teleprinter was busy, then TSF just fell through to the JMP .-1 instruction, which just jumped back to the TSF instruction. If the teleprinter was ready, then TSF would skip to the TLS instruction, which sent the character in the A register to the teleprinter. Then the JMP I PRTCHR instruction returned to the caller.\n\n> 这里的 PRTCHR 是电传打印机上一段用来打印字符的子程序。首语句中的 0 是存储其返回地址用的（这里就不要细究这些了）。下来是 TSF 指令，它的作用是告诉电传三印机如果准备就绪，就跳过下一指令。如果电传打印机处于繁忙状态，就继续执行 `JMP.-1` 指令，也就是再跳转回 TSF 指令。一旦电传打印机处于就绪状态，TSF 就会跳转到 TLS 指令，该指令会将 A 寄存器中保存的要打印的字符发送给电传打印机。随后，JMP I PRTCHR 指令会将程序返回给调用方。\n\nAt first this strategy worked fine. If we needed to read cards from the card reader, we used code that talked directly to the card reader. If we needed to punch cards, we wrote code that directly manipulated the punch. The programs worked perfectly. How could we know this was a mistake?\n\n> 一开始，这一策略工作起来完全没有问题。如果我们需要从读卡器中读取卡片，我们就直接用代码与读卡器进行交互。如果我们需要在卡上打孔，就写一段代码直接控制打卡的过程。整套程序运行得非常完美。我们当时怎么会知道这是一个错误呢？\n\nBut big batches of punched cards are difficult to manage. They can be lost, mutilated, spindled, shuffled, or dropped. Individual cards can be lost and extra cards can be inserted. So data integrity became a significant problem.\n\n> 然而，管理大量的卡片是一件很麻烦的事。这些卡片可能会出现丢失、损坏、旋转、排序错误等问题。各部分的卡片都有可能丢失或混入多余的卡片，保持数据的一致性是当时的一大难题。\n\nMagnetic tape was the solution. We could move the card images to tape. If you drop a magnetic tape, the records don’t get shuffled. You can’t accidentally lose a record, or insert a blank record simply by handing the tape. The tape is much more secure. It’s also faster to read and write, and it is very easy to make backup copies.\n\n> 后来就出现了磁带这种解决方案。它允许我们将原本打在卡片上的图像存储在磁带上。如果磁带不小心掉在地上，不会出现顺序被打乱的问题，我们也不会因此意外丢失记录，或者处理磁带时意外插入空白记录。显然，磁带是更安全的选择，而且它的读取和写入也更快，同时也很容易进行备份。\n\nUnfortunately, all our software was written to manipulate card readers and card punches. Those programs had to be rewritten to use magnetic tape. That was a big job.\n\n> 但不幸的是，我们当时所有的软件都是用于直接操作读卡器和打卡器的。为了让这些软件改用磁带，我们不得不花很大的力气重新修改代码。\n\nBy the late 1960s, we had learned our lesson—and we invented device independence. The operating systems of the day abstracted the IO devices into software functions that handled unit records that looked like cards. The programs would invoke operating system services that dealt with abstract unit-record devices. Operators could tell the operating system whether those abstract services should be connected to card readers, magnetic tape, or any other unit-record device.\n\n> 到了 20 世纪 60 年代末期，我们己经吸取了这个教训，并为此提出了设备无关性这个概念。当时的操作系统会将 I/O 设备抽象成打孔卡那样的，处理一条条记录的标准软件函数。我们写的程序会通过调用操作系统提供的服务来与抽象的记录处理函数进行交互。而系统运行人员可以将操作系统的抽象设备与具体的读卡器、磁带读取器以及其他类似的设备进行对接。\n\nNow the same program could read and write cards, or read and write tape, without any change. The Open–Closed Principle was born (but not yet named).\n\n> 这样一来，同一段程序不经任何修改就既可以读/写卡片，也可以读/写磁带。开闭原则（OCP）此时就诞生了（当然，那时候还不叫这个名字）。\n\n## JUNK MAIL 垃圾邮件\n\nIn the late 1960s, I worked for a company that printed junk mail for clients. The clients would send us magnetic tapes with unit records containing the names and addresses of their customers, and we would write programs that printed nice personalized advertisements.\n\n> 20 世纪 60 年底末期，我曾经在一家为客户打印群发垃圾邮件的公司工作。当时，客户会将一条条与消费者名字和地址相关的记录存储在磁带中并寄给我们，我们则负责编写程序为他们打印个人化的广告。\n\nYou know the kind:\n\nHello Mr. Martin,\n\nCongratulations!\n\nWe chose YOU from everyone else who lives on Witchwood Lane to participate in our new fantastic one-time-only offering…\n\n---\n\n> 相信下面这些邮件读者一定不陌生。\n>\n> Hello，马丁先生：\n>\n> 恭喜！\n>\n> 您是 Witchwood Lane 上唯一被选中参加我们仅有一次的特惠活动...\n\nThe clients would send us huge rolls of form letters with all the words except the name and address, and any other element they wanted us to print. We wrote programs that extracted the names, addresses, and other elements from the magnetic tape, and printed those elements exactly where they needed to appear on the forms.\n\n> 客户会给我们寄来一大卷信纸，其中的姓名和地址留空，其他文字都已经填好。我们的程序需要从磁带上读取姓名、地址等信息，然后将这些信息精确地打印在信纸上的对应位置。\n\nThese rolls of form letters weighed 500 pounds and contained thousands of letters. Clients would send us hundreds of these rolls. We would print each one individually.\n\n> 这样的每一卷信纸里面有几千封信，重量近 500 磅，而且通常有数百卷之多，我们必须一封一封地打印。\n\nAt first, we had an IBM 360 doing the printing on its sole line printer. We could print a few thousand letters per shift. Unfortunately, this tied up a very expensive machine for a very long time. In those days, IBM 360s rented for tens of thousands of dollars per month.\n\n> 起初，我们使用的是 IBM 360 自带的单行打印机，它每个工作日可以打印几千张。但是，当时 IBM 360 每个月的租金要几万美金，成本太高了。\n\nSo we told the operating system to use magnetic tape instead of the line printer. Our programs didn’t care, because they had been written to use the IO abstractions of the operating system.\n\n> 这时候，我们只需要让操作系统放弃单行打印机，改用磁带即可，我们的程序不需要做任何的改动，因为它们使用的是操作系统提供的抽象 I/O 设备接口。\n\nThe 360 could pump out a full tape in 10 minutes or so—enough to print several rolls of form letters. The tapes were taken outside of the computer room and mounted on tape drives connected to offline printers. We had five of them, and we ran those five printers 24 hours per day, seven days per week, printing hundreds of thousands of pieces of junk mail every week.\n\n> 而且 IBM 360 机器每 10 分钟就可以写满一卷磁带——这一时间足够单行打印机打印几卷信纸了。然后这些磁带可以从计算机上取下，装载到离线打印机上进行离线打印。当时我们有五台这样的打印机，它们可以 7x24 小时不停地工作，每周可以打印几十万封信。\n\nThe value of device independence was enormous! We could write our programs without knowing or caring which device would be used. We could test those programs using the local line printer connected to the computer. Then we could tell the operating system to “print” to magnetic tape and run off hundreds of thousands of forms.\n\n> 设备无关性的价值真是太巨大了！它使我们的程序不再需要关心具体使用的 I/O 设备。这样一来，我们可以用本地连接的打印机来调试程序，随后将它“打印”到磁带卷上，并放到离线打印机上进行批量打印。\n\nOur programs had a shape. That shape disconnected policy from detail. The policy was the formatting of the name and address records. The detail was the device. We deferred the decision about which device we would use.\n\n> 这段程序是有架构设计的，并且在设计中实现了高层策略与底层实现细节的分离。其策略部分负责格式化姓名和地址，细节部分负责操作具体的 I/O 设备。而我们具体采用哪个设备的决策是最后才做出的。\n\n## PHYSICAL ADDRESSING 物理地址寻址\n\nIn the early 1970s, I worked on a large accounting system for a local truckers union. We had a 25MB disk drive on which we stored records for Agents, Employers, and Members. The different records had different sizes, so we formatted the first few cylinders of the disk so that each sector was just the size of an Agent record. The next few cylinders were formatted to have sectors that fit the Employer records. The last few cylinders were formatted to fit the Member records.\n\n> 20 世纪 70 年代早期，我曾为本地卡车工会编写过一套大型的账务系统。当时，Agent、Employer、Member 这些记录都被存储在一块 25MB 大小的磁盘上。由于不同的记录尺寸不同，所以我们将磁盘的前几个柱面（cylinder）按 Agent 记录的大小格式化每个扇区，中间的按 Employer 记录的大小格式化，最后几个柱面按照 Member 记录的大小格式化。\n\nWe wrote our software to know the detailed structure of the disk. It knew that the disk had 200 cylinders and 10 heads, and that each cylinder had several dozen sectors per head. It knew which cylinders held the Agents, Employers, and Members. All this was hard-wired into the code.\n\n> 当时我们编写的软件需要知道硬盘的具体结构。它知道每个硬盘包含 200 个柱面，10 个磁头，每个柱面每个磁头有几十个扇区。它也知道哪些柱面上包含的是 Agent 记录，哪些柱面上包含的是 Employer 和 Member 记录，我们对所有的这些都进行了硬编码。\n\nWe kept an index on the disk that allowed us to look up each of the Agents, Employers, and Members. This index was in yet another specially formatted set of cylinders on the disk. The Agent index was composed of records that contained the ID of an agent, and the cylinder number, head number, and sector number of that Agent record. Employers and Members had similar indices. Members were also kept in a doubly linked list on the disk. Each Member record held the cylinder, head, and sector number of the next Member record, and of the previous Member record.\n\n> 另外，我们还在磁盘上保留了一个索引，以方便后续的记录查询。该索引也是通过一个特别的格式被存储到磁盘上的。譬如说，Agent 记录的索引中每条记录包括 Agent 的 ID，以及对应的柱面号码、磁头号码、扇区号码。Employer 和 Member 的索引也有类似的结构。其中，Member 记录用一种双向链表结构存储在磁盘上。每条 Member 记录都会包含前一个和后一个 Member 记录所在的柱面号码、磁头号码、扇区号码。\n\nWhat would happen if we needed to upgrade to a new disk drive—one with more heads, or one with more cylinders, or one with more sectors per cylinder? We had to write a special program to read in the old data from the old disk, and then write it out to the new disk, translating all of the cylinder/head/sector numbers. We also had to change all the hard-wiring in our code—and that hard-wiring was everywhere! All the business rules knew the cylinder/head/sector scheme in detail.\n\n> 在这种情况下，如果我们升级新硬盘会发生什么呢？新硬盘可能会有更多的磁头，更多的柱面，或是每个柱面有更多的扇区。这时候，我们就必须编写一介特殊的程序从旧磁盘读取数据，并将其写入新磁盘，同时换掉柱面、磁头、扇区的值。另外，我们还要修改代码中所有硬编码的部分——这样的代码到处都是! 毕竟我们所有的业务逻辑都和柱面、磁头、扇区的分配方案紧密地耦合在了一起。\n\nOne day a more experienced programmer joined our ranks. When he saw what we had done, the blood drained from his face, and he stared aghast at us, as if we were aliens of some kind. Then he gently advised us to change our addressing scheme to use relative addresses.\n\n> 直到有一天，一位更有经验旳程序员加入了我们的团队。当他看到我们的程序实现逻辑时差点吐血，就像见到外星人一样盯着我们看了半天。随后，他温柔地建议我们改用相对地址方式来寻址。\n\nOur wiser colleague suggested that we consider the disk to be one huge linear array of sectors, each addressable by a sequential integer. Then we could write a little conversion routine that knew the physical structure of the disk, and could translate the relative address to a cylinder/head/sector number on the fly.\n\n> 这位聪明的同事建议我们将磁盘当成一个扇区的线性队別来处理，用一串连续的整数来对每个扇区进行寻址。然后，我们可以编写一个针对磁盘物理结构的转换程序，以便将这些相对地址在线转换为柱面、磁头、扇区的号码。\n\nFortunately for us, we took his advice. We changed the high-level policy of the system to be agnostic about the physical structure of the disk. That allowed us to decouple the decision about disk drive structure from the application.\n\n> 幸运的是，我们釆纳了他的建议。我们修改了系统的高层策略，使其与磁盘的物理结构脱钩。这样一来，我们就可以将具体选择哪种磁盘的决策从该应用程序中分离出来。\n\n## CONCLUSION 本章小结\n\nThe two stories in this chapter are examples, in the small, of a principle that architects employ in the large. Good architects carefully separate details from policy, and then decouple the policy from the details so thoroughly that the policy has no knowledge of the details and does not depend on the details in any way. Good architects design the policy so that decisions about the details can be delayed and deferred for as long as possible.\n\n> 在本章中，我们用两个小故事示范了一些架构师们普遍会采用的设计原则。优秀的架构师会小心地将软件的高层策略与其底层实现隔离开，让高层策略与实现细节脱钩，使其策略部分完全不需要关心底层细节，当然也不会对这些细节有任何形式的依赖。另外，优秀的架构师所设计的策略应该允许系统尽可能地推迟与实现细节相关的决策，越晚做决策越好。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap16. INDEPENDENCE 独立性\n\n![](../../images/books/架构整洁之道/CH-UN16.jpg)\n\nAs we previously stated, a good architecture must support:\n\n> 正如我们之前所述，\n\n- The use cases and operation of the system.\n- The maintenance of the system.\n- The development of the system.\n- The deployment of the system.\n\n---\n\n> - 系统的用例与正常运行。\n> - 系统的维护。\n> - 系统的开发。\n> - 系统的部署。\n\n## USE CASES 用例\n\nThe first bullet—use cases—means that the architecture of the system must support the intent of the system. If the system is a shopping cart application, then the architecture must support shopping cart use cases. Indeed, this is the first concern of the architect, and the first priority of the architecture. The architecture must support the use cases.\n\n> 我们先来看第一个支持目标：用例。我们认为一个系统的架构必须能够支持其自身的设计意图。也就是说，如果某系统是一个购物车应用，那么该系统的架构就必须非常直观地支持这类应用可能会涉及的所有用例。事实上，这本来就是架构师们首先要关注的问题，也是架构设计过程中的首要工作。软件的架构必须为其用例提供支持。\n\nHowever, as we discussed previously, architecture does not wield much influence over the behavior of the system. There are very few behavioral options that the architecture can leave open. But influence isn’t everything. The most important thing a good architecture can do to support behavior is to clarify and expose that behavior so that the intent of the system is visible at the architectural level.\n\n> 然而，正如我们前面所讨论的，一个系统的架构对其行为并没有太大的影响。虽然架构也可以限制一些行为选项，但这种影响所涉及的范围并不大。一个设计良好的架构在行为上对系统最重要的作用就是明确和显式地反映系统设计意图的行为，使其在架构层面上可见。\n\nA shopping cart application with a good architecture will look like a shopping cart application. The use cases of that system will be plainly visible within the structure of that system. Developers will not have to hunt for behaviors, because those behaviors will be first-class elements visible at the top level of the system. Those elements will be classes or functions or modules that have prominent positions within the architecture, and they will have names that clearly describe their function.\n\n> 譬如说，一个架构优良的购物车应用看起来就该像是一个购物车应用。该系统的主要用例会在其系统结构上明确可见。开发人员将不需要在系统中查找系统所应有的行为，因为这些行为在系统顶层作为主要元素已经是明确可见的了，这些元素会以类、函数或模块的形式在架构中占据明显位置，它们的名字也能够清晰地描述对应的功能。\n\nChapter 21, “Screaming Architecture,” will make this point much clearer.\n\n> 在第 21 章“尖叫的软件架构”中，我们还会更详细地解释这部分内容。\n\n## OPERATION 运行\n\nArchitecture plays a more substantial, and less cosmetic, role in supporting the operation of the system. If the system must handle 100,000 customers per second, the architecture must support that kind of throughput and response time for each use case that demands it. If the system must query big data cubes in milliseconds, then the architecture must be structured to allow this kind of operation.\n\n> 架构在支持系统运行方面扮演着更实际的角色。如果某个系统每秒要处理 100 000 个用户，该系统的架构就必须能支持这种级别的吞吐量和响应时间。同样的，如果某个系统要在毫秒级的时间内完成对大数据仓库的查询，那么该系统的架构也必须能支持这类操作。\n\nFor some systems, this will mean arranging the processing elements of the system into an array of little services can be run in parallel on many different servers. For other systems, it will mean a plethora of little lightweight threads sharing the address space of a single process within a single processor. Still other systems will need just a few processes running in isolated address spaces. And some systems can even survive as simple monolithic programs running in a single process.\n\n> 对一些系统来说，这意味着它的架构应该支持将其计算部分拆分成一系列小型服务，然后让它们并行运行在不同的服务器上。而在另一些系统中，采用一堆轻量级线程，然后让这些线程共享一个运行在单处理器上的进程的地址空间。还有一些系统，它们可能只是一组运行在独立地址空间内的进程。甚至有些系统设计为一个单进程的单体程序就够了。\n\nAs strange as it may seem, this decision is one of the options that a good architect leaves open. A system that is written as a monolith, and that depends on that monolithic structure, cannot easily be upgraded to multiple processes, multiple threads, or micro-services should the need arise. By comparison, an architecture that maintains the proper isolation of its components, and does not assume the means of communication between those components, will be much easier to transition through the spectrum of threads, processes, and services as the operational needs of the system change over time.\n\n> 虽然看起来有点奇怪，但上述问题的决策的确也应该属于一个优秀的架构师为我们保留的可选项之一。毕竟一个按照单体模式编写的系统，它依赖的必然是单体结构，之后再想把它改造成多进程、多线程或微服务模式可就没有那么容易了。相比之下，如果该系统的架构能够在其组件之间做一些适当的隔离，同时不强制规定组件之间的交互方式，该系统就可以随时根据不断变化的运行需求来转换成各种运行时的线程、进程或服务模型。\n\n## DEVELOPMENT 开发\n\nArchitecture plays a significant role in supporting the development environment. This is where Conway’s law comes into play. Conway’s law says:\n\n> 系统的架构在支持开发环境方面当然扮演着重要的角色，我们在这里可以引述一下康威定律：\n\nAny organization that designs a system will produce a design whose structure is a copy of the organization’s communication structure.\n\n> 任何一个组织在设计系统时，往往都会复制出一个与该组织内沟通结构相同的系统。\n\nA system that must be developed by an organization with many teams and many concerns must have an architecture that facilitates independent actions by those teams, so that the teams do not interfere with each other during development. This is accomplished by properly partitioning the system into well-isolated, independently developable components. Those components can then be allocated to teams that can work independently of each other.\n\n> 一个由多个不同目标的团队协作开发的系统必须具有相应的软件架构。这样，这些团队才可以各自独立地完成工作，不会彼此干扰。这就需要恰当地将系统切分为一系列隔离良好、可独立开发的组件。然后才能将这些组件分配给不同的团队各自独立开发。\n\n## DEPLOYMENT 部署\n\nThe architecture also plays a huge role in determining the ease with which the system is deployed. The goal is “immediate deployment.” A good architecture does not rely on dozens of little configuration scripts and property file tweaks. It does not require manual creation of directories or files that must be arranged just so. A good architecture helps the system to be immediately deployable after build.\n\n> 一个系统的架构在其部署的便捷性方面起到的作用也是非常大的。设计目标一定是实现“立刻部署”。一个设计良好的架构通常不会依赖于成堆的脚本与配置文件，也不需要用户手动创建一堆“有严格要求”的目录与文件。总而言之，一个设计良好的软件架构可以让系统在构建完成之后立刻就能部署。\n\nAgain, this is achieved through the proper partitioning and isolation of the components of the system, including those master components that tie the whole system together and ensure that each component is properly started, integrated, and supervised.\n\n> 同样的，这些也需要通过正确地划分、隔离系统组件来实现，这其中包括开发一些主组件，让它们将整个系统黏合在一起，正确地启动、连接并监控每个组件。\n\n## LEAVING OPTIONS OPEN 保留可选项\n\nA good architecture balances all of these concerns with a component structure that mutually satisfies them all. Sounds easy, right? Well, it’s easy for me to write that.\n\n> 一个设计良好的架构应该充分地权衡以上所述的所有关注点，然后尽可能塔成一个可以同时满足所有需求的组件结构。这说起来还挺容易的，不是吗？\n\nThe reality is that achieving this balance is pretty hard. The problem is that most of the time we don’t know what all the use cases are, nor do we know the operational constraints, the team structure, or the deployment requirements. Worse, even if we did know them, they will inevitably change as the system moves through its life cycle. In short, the goals we must meet are indistinct and inconstant. Welcome to the real world.\n\n> 事实上，要实现这种平衡是很困难的。主要问题是，我们在大部分时间里无法预知系统的所有用例的，而且我们也无法提前预知系统的运行条件、开发团队的结构，或者系统的部署需求。更糟糕的是，就算我们能提前了解这些需求，随着系统生命周期的演进，这些需求也会不可避免地发生变化。总而言之，事实上我们想要达到的目标本身就是模糊多变的。真实的世界就这样。\n\nBut all is not lost: Some principles of architecture are relatively inexpensive to implement and can help balance those concerns, even when you don’t have a clear picture of the targets you have to hit. Those principles help us partition our systems into well-isolated components that allow us to leave as many options open as possible, for as long as possible.\n\n> 然而，我们还是可以通过采用一些实现成本较低的架构原则来做一些事情的。虽然我们没有清晰的目标，但采用一些原则总是有助于提前解决一些平衡问题。通过遵守这些原则可以帮助我们正确地划分为一些隔离良好的组件，以便尽可能长时间地为我们的未来保留尽可能多的可选项。\n\nA good architecture makes the system easy to change, in all the ways that it must change, by leaving options open.\n\n> 一个设计良好的架构应该通过保留可选项的方式，让系统在任何情况下都能方便地做出必要的变更。\n\n## DECOUPLING LAYERS 按层解耦\n\nConsider the use cases. The architect wants the structure of the system to support all the necessary use cases, but does not know what all those use cases are. However, the architect does know the basic intent of the system. It’s a shopping cart system, or it’s a bill of materials system, or it’s an order processing system. So the architect can employ the Single Responsibility Principle and the Common Closure Principle to separate those things that change for different reasons, and to collect those things that change for the same reasons—given the context of the intent of the system.\n\n> 从用例的角度来看，架构师的目标是让系统结构支持其所需要的所有用例。但是问题恰恰是我们无法预知全部的用例。好在架构师应该还是知道整个系统的基本设计意图的。也就是说，架构师应该知道自己要设计的是一个购物车系统，或是运输清单系统，还是订单处理系统。所以架构师可以通过采用单一职责原则（SRP）和共同闭包原则（CCP），以及既定的系统设计意图来隔离那些变更原因不同的部分，集成变更原因相同的部分。\n\nWhat changes for different reasons? There are some obvious things. User interfaces change for reasons that have nothing to do with business rules. Use cases have elements of both. Clearly, then, a good architect will want to separate the UI portions of a use case from the business rule portions in such a way that they can be changed independently of each other, while keeping those use cases visible and clear.\n\n> 哪些部分的变更原因是不同的呢？这在有些情况下是很显而易见的。譬如，用户界面的变更原因肯定和业务逻辑是不相关的，而业务用例则通常在两边都存在着相关的元素。所以很显然，优秀的架构师应该会将用例的 UI 部分与其业务逻辑部分隔离，这样这两部分就既可以各自进行变更，也能保证用例的完整清晰。\n\nBusiness rules themselves may be closely tied to the application, or they may be more general. For example, the validation of input fields is a business rule that is closely tied to the application itself. In contrast, the calculation of interest on an account and the counting of inventory are business rules that are more closely associated with the domain. These two different kinds of rules will change at different rates, and for different reasons—so they should be separated so that they can be independently changed.\n\n> 而业务逻辑则既可以是与应用程序紧密相关的，也可以是更具有普适性的。例如，对输入字段的校验是一个与应用程序本身紧密相关的业务逻辑。相反，计算账户利息以及清点库存则是一个与具体领域更为相关的业务逻辑。这两种不同的业务逻辑通常有着不同的变更速率和变更原因——它们应该被相互隔离，以方便各自的变更。\n\nThe database, the query language, and even the schema are technical details that have nothing to do with the business rules or the UI. They will change at rates, and for reasons, that are independent of other aspects of the system. Consequently, the architecture should separate them from the rest of the system so that they can be independently changed.\n\n> 至于数据库，以及其所采用的查询语言，甚至表结构，这些都是系统的技术细节信息，它们与业务规则或 UI 毫无关系。这就意味着它们的变更原因、变更速率必然与系统的其他方面各不相同。因此，架构师也应该将它们与系统其他部分隔离，以方便各自的变更。\n\nThus we find the system divided into decoupled horizontal layers—the UI, application-specific business rules, application-independent business rules, and the database, just to mention a few.\n\n> 这样一来，我们就发现了一个系统可以被解耦成若干个水平分层应用独有的业务逻辑、领域普适的业务逻辑、数据库等。\n\n## DECOUPLING USE CASES 用例的解耦\n\nWhat else changes for different reasons? The use cases themselves! The use case for adding an order to an order entry system almost certainly will change at a different rate, and for different reasons, than the use case that deletes an order from the system. Use cases are a very natural way to divide the system.\n\n> 接下来，还有什么不同的原因的变更呢？答案正是这些用例本身！譬如说，添加新订单的用例与删除订单的用例在发生变更的原因上几乎肯定是不同的，而且发生变更的速率也不同。因此，我们按照用例来切分系统是非常自然的选择。\n\nAt the same time, use cases are narrow vertical slices that cut through the horizontal layers of the system. Each use case uses some UI, some application-specific business rules, some application-independent business rules, and some database functionality. Thus, as we are dividing the system in to horizontal layers, we are also dividing the system into thin vertical use cases that cut through those layers.\n\n> 与此同时，这些用例也是上述系统水平分层的一个个垂直切面。每个用例都会用到一些 UI、特定应用的业务逻辑、应用无关的业务逻辑以及数据库功能。因此，我们时系统水平切分成多个分层的同时，也在按用例将其切分成多个垂直切分。\n\nTo achieve this decoupling, we separate the UI of the add-order use case from the UI of the delete-order use case. We do the same with the business rules, and with the database. We keep the use cases separate down the vertical height of the system.\n\n> 为了实现这样的解耦，我们应该将增加订单这个用例的 UI 与删除订单用例的 UI 分开。而且，对业务逻辑的部分、数据库的部分，也要做同样的事情，将其按照用例进行垂直切分。\n\nYou can see the pattern here. If you decouple the elements of the system that change for different reasons, then you can continue to add new use cases without interfering with old ones. If you also group the UI and database in support of those use cases, so that each use case uses a different aspect of the UI and database, then adding new use cases will be unlikely to affect older ones.\n\n> 由此，我们可以总结出一个模式：如果我们按照变更原因的不同对系统进行解耦，就可以持续地向系统内添加新的用例，而不会影响旧有的用例。如果我们同时对支持这些用例的 UI 和数据库也进行了分组，那么每个用例使用的就是不同面向的 UI 与数据库，因此增加新用例就更不太可能会影响旧有的用例了。\n\n## DECOUPLING MODE 解耦的模式\n\nNow think of what all that decoupling means for the second bullet: operations. If the different aspects of the use cases are separated, then those that must run at a high throughput are likely already separated from those that must run at a low throughput. If the UI and the database have been separated from the business rules, then they can run in different servers. Those that require higher bandwidth can be replicated in many servers.\n\n> 现在我们来想想所有的这些解耦动作对架构设计的第二个目标——系统运行——究竟有什么意义。如果不同面向之间的用例得到了良好的隔离，那么需要高吞吐量的用例就和需要低吞吐量的用例互相自然分开了。如果 UI 和数据库的部分能从业务逻辑分离出来，那么它们就可以运行在不同的服务器上。而且需要较大带宽的应用也可以在多个服务器上运行多个实例。\n\nIn short, the decoupling that we did for the sake of the use cases also helps with operations. However, to take advantage of the operational benefit, the decoupling must have the appropriate mode. To run in separate servers, the separated components cannot depend on being together in the same address space of a processor. They must be independent services, which communicate over a network of some kind.\n\n> 总而言之，这种按用例解耦的动作是有利于系统运行的。然而出于系统运行效率的考虑，我们旳解耦动作还应该注意选择恰当的模式。譬如，为了在不同的服务器上运行，被隔离的组件不能依赖于某个处理器上的同一个地址空间，它们必须是独立的服务，然后通过某种网络来进行通信。\n\nMany architects call such components “services” or “micro-services,” depending upon some vague notion of line count. Indeed, an architecture based on services is often called a service-oriented architecture.\n\n> 许多架构帅将上面这种组件称为“服务”，或“微服务”，至于是前者还是后者，往往取决于某些非常模糊的代码行数阈值。对于这种基于服务来构建的架构，架构师们通常称之为面向服务的架构（service-oriented architecture）。\n\nIf that nomenclature set off some alarm bells in your mind, don’t worry. I’m not going to tell you that SoA is the best possible architecture, or that micro-services are the wave of the future. The point being made here is that sometimes we have to separate our components all the way to the service level.\n\n> 如果因为这里提到了 SOA 这个概念而引起了某些读者的警觉，请不用担心，在这里并没有鼓吹 SOA 是一种最佳的软件架构，或者微服务就是未来的潮流。我只是认为有时候我们必须把组件切割到服务这个应用层次。\n\nRemember, a good architecture leaves options open. The decoupling mode is one of those options.\n\n> 请记住，一个设计良好的架构总是要为将来多留一些可选项，这里所讨论的解耦模式也是这样的可选项之一。\n\nBefore we explore that topic further, let’s look to the other two bullets.\n\n> 接下来，在我们继续深入探讨这个话题之前，先回过头来看看其他两个设计目标。\n\n## INDEPENDENT DEVELOP-ABILITY 开发的独立性\n\nThe third bullet was development. Clearly when components are strongly decoupled, the interference between teams is mitigated. If the business rules don’t know about the UI, then a team that focuses on the UI cannot much affect a team that focuses on the business rules. If the use cases themselves are decoupled from one another, then a team that focuses on the addOrder use case is not likely to interfere with a team that focuses on the deleteOrder use case.\n\n> 我们进行架构设计的第三个目标是支持系统的开发。很显然，当系统组件之间被高度解耦之后，开发团队之间的干扰就大大减少了。譬如说，如果系统的业务逻辑与其 UI 无关，那么专注于 UI 开发的团队就不会对专注于业务逻辑开发的团队造成多大的影响。同样的，如果系统的各个用例之间相互隔离，那么专注于 addOrder 用例的团队就不太可能干扰到负责 deleteOrder 用例的团队。\n\nSo long as the layers and use cases are decoupled, the architecture of the system will support the organization of the teams, irrespective of whether they are organized as feature teams, component teams, layer teams, or some other variation.\n\n> 只要系统按照其水平分层和用例进行了恰当的解耦，整个系统的架构就可以支持多团队开发，不管团队组织形式是分功能开发、分组件开发、分层开发，还是按照别的什么变量分工都可以。\n\n## INDEPENDENT DEPLOYABILITY 部署的独立性\n\nThe decoupling of the use cases and layers also affords a high degree of flexibility in deployment. Indeed, if the decoupling is done well, then it should be possible to hot-swap layers and use cases in running systems. Adding a new use case could be as simple as adding a few new jar files or services to the system while leaving the rest alone.\n\n> 这种按用例和水平分层的解耦也会给系统的部署带来极大的灵活性。实际上，如果解耦工作做得好，我们甚至可以在系统运行过程中热切换（hot-swap）其各个分层实现和具体的用例。在这种情况下，我们增加新测试用例就只需要在系统中添加一些新的 jar 文件，或启动一些服务即可，其他部分将完全不受影响。\n\n## DUPLICATION 重复\n\nArchitects often fall into a trap—a trap that hinges on their fear of duplication.\n\n> 架构师们经常会钻进一个牛角尖——害怕重复。\n\nDuplication is generally a bad thing in software. We don’t like duplicated code. When code is truly duplicated, we are honor-bound as professionals to reduce and eliminate it.\n\n> 当然，重复在软件行业里一般来说都是坏事。我们不喜欢重复的代码，当代码真的出现重复时，我们经常会感到作为一个专业人士’自己是有责任减少或消除这种重复的。\n\nBut there are different kinds of duplication. There is true duplication, in which every change to one instance necessitates the same change to every duplicate of that instance. Then there is false or accidental duplication. If two apparently duplicated sections of code evolve along different paths—if they change at different rates, and for different reasons—then they are not true duplicates. Return to them in a few years, and you’ll find that they are very different from each other.\n\n> 但是重复也存在着很多种情况。其中有些是真正的重复，在这种情况下，每个实例上发生的每项变更都必须同时应用到其所有的副本上。重复的情况中也有一些是假的，或者说这种重复只是表面性的。如果有两段看起来重复的代码，它们走的是不同的演进路径，也就是说它们有着不同的变更速率和变更缘由，那么这两段代码就不是真正的重复。等我们几年后再回过头来看，可能就会发现这两段代码是非常不一样的了。\n\nNow imagine two use cases that have very similar screen structures. The architects will likely be strongly tempted to share the code for that structure. But should they? Is that true duplication? Or it is accidental?\n\n> 现在，我们假设某系统中有两个用例在屏幕展现形式上非常类似。每当这种时候，架构师们就很可能非常想复用同一段代码来处理它们的屏幕展示。那么，我们到底是否应该这样做呢？这里是真正的重复，还只是一种表面性的重复？\n\nMost likely it is accidental. As time goes by, the odds are that those two screens will diverge and eventually look very different. For this reason, care must be taken to avoid unifying them. Otherwise, separating them later will be a challenge.\n\n> 恐怕这里很可能只是表面性的重复。随着时间推移，这两个用例的屏幕展示功能可能会各自演变，最终很可能完全不同。正是由于这样的原因，我们必须加倍小心地避免让这两个用例复用同一段代码，否则，未来再想将它们分开会面临很大的挑战。\n\nWhen you are vertically separating use cases from one another, you will run into this issue, and your temptation will be to couple the use cases because they have similar screen structures, or similar algorithms, or similar database queries and/or schemas. Be careful. Resist the temptation to commit the sin of knee-jerk elimination of duplication. Make sure the duplication is real.\n\n> 当我们按用例垂直切分系统时，这样的问题会经常出现。我们经常遇到一些不同的用例为了上述原因被耦合在了一起。不管是因为它们展现形式类似，还是使用了相似的语法、相似的数据库查询/表结构等，总之，我们一定要小心避免对任何重复都要立即消除的应激反应模式中。一定要确保这些消除动作只针对那些真正意义上的重复。\n\nBy the same token, when you are separating layers horizontally, you might notice that the data structure of a particular database record is very similar to the data structure of a particular screen view. You may be tempted to simply pass the database record up to the UI, rather than to create a view model that looks the same and copy the elements across. Be careful: This duplication is almost certainly accidental. Creating the separate view model is not a lot of effort, and it will help you keep the layers properly decoupled.\n\n> 同样的道理，当我们对系统进行水平分层时，也可能会发现某个数据库记录的结构和某个屏幕展示的数据接口非常相似。我们可能也会为了避免再创建一个看起来相同的视图模型并在两者之间复制元素，而选择直接将数据库记录传递给 UI 层。我们也一定要小心，这里几乎肯定只是一种表面性的重复。而且，另外创建一个视图模型并不会花费太多力气，这可以帮助我们保持系统水平分层之间的隔离。\n\n## DECOUPLING MODES (AGAIN) 再谈解耦模式\n\nBack to modes. There are many ways to decouple layers and use cases. They can be decoupled at the source code level, at the binary code (deployment) level, and at the execution unit (service) level.\n\n> 让我们再回到解耦模式的问题上来。按水平分层和用例解耦一个系统有很多种方式。例如，我们可以在源码层次上解耦、二进制层次上解耦（部署），也可以在执行单元层次上解耦（服务）。\n\n- Source level. We can control the dependencies between source code modules so that changes to one module do not force changes or recompilation of others (e.g., Ruby Gems).\n\n> - 源码层次：我们可以控制源代码模块之间的依赖关系，以此来实现一个模块的变更不会导致其他模块也需要变更或重新编译（例如 Ruby Gem）。\n\nIn this decoupling mode the components all execute in the same address space, and communicate with each other using simple function calls. There is a single executable loaded into computer memory. People often call this a monolithic structure.\n\n> 在这种解耦模式下，系统所有的组件都会在同一个地址空间内执行，它们会通过简单的函数调用来进行彼此的交互。这类系统在运行时是作为一个执行文件被统一加载到计算机内存中的。人们经常把这种模式叫作单体结构。\n\n- Deployment level. We can control the dependencies between deployable units such as jar files, DLLs, or shared libraries, so that changes to the source code in one module do not force others to be rebuilt and redeployed.\n\n> - 部署层次：我们可以控制部署单元（譬如 jar 文件、DLL、共享库等）之间 的依赖关系，以此来实现一个模块的变更不会导致其他模块的重新构建和部署。\n\nMany of the components may still live in the same address space, and communicate through function calls. Other components may live in other processes in the same processor, and communicate through interprocess communications, sockets, or shared memory. The important thing here is that the decoupled components are partitioned into independently deployable units such as jar files, Gem files, or DLLs.\n\n> 在这种模式下，大部分组件可能还是依然运行在同一个地址空间内，通过彼此的函数调用通信。但有一些别的组件可能会运行在同一个处理器下的其他进程内，使用跨进程通信，或者通过 socket 或共享内存进行通信。这里最重要的是，这些组件的解耦产生出许多可独立部署的单元，例如 jar 文件、Gem 文件和 DLL 等。\n\n- Service level. We can reduce the dependencies down to the level of data structures, and communicate solely through network packets such that every execution unit is entirely independent of source and binary changes to others (e.g., services or micro-services).\n\n> - 服务层次：我们可以将组件间的依赖关系降低到数据结构级别’然后仅通过网络数据包来进行通信。这样系统的每个执行单元在源码层和二进制层都会是一个独立的个体，它们的变更不会影响其他地方（例如常见的服务或微服务就都是如此的）。\n\nWhat is the best mode to use?\n\n> 现在，我们要问的是究竟哪个模式是最好的呢？\n\nThe answer is that it’s hard to know which mode is best during the early phases of a project. Indeed, as the project matures, the optimal mode may change.\n\n> 答案是，在项目早期很难知道哪种模式是最好的。事实上，随着项目的逐渐成熟，最好的模式可能会发生变化。\n\nFor example, it’s not difficult to imagine that a system that runs comfortably on one server right now might grow to the point where some of its components ought to run on separate servers. While the system runs on a single server, the source-level decoupling might be sufficient. Later, however, it might require decoupling into deployable units, or even services.\n\n> 例如，我们不难想象，一个在某台服务器上运行良好的程序发展到一定程度，可能就会需要将其某些组件迁移到其他服务器上才能满足运行要求。当该系统只运行在一台服务器上时，我们进行源码层次的解耦就已经足够了。但在这之后，我们可能需要进行部署单元层次的解耦，甚至服务层次的解耦。\n\nOne solution (which seems to be popular at the moment) is to simply decouple at the service level by default. A problem with this approach is that it is expensive and encourages coarse-grained decoupling. No matter how “micro” the micro-services get, the decoupling is not likely to be fine-grained enough.\n\n> 另一个解决方案（似乎也是目前最流行的方案）是，默认就采用服务层次的解耦。这种做法的问题主要在于它的成本很高，并且是在鼓励粗粒度的解耦。毕竟，无论微服务有多么“微”，其解耦的精细度都可能是不够的。\n\nAnother problem with service-level decoupling is that it is expensive, both in development time and in system resources. Dealing with service boundaries where none are needed is a waste of effort, memory, and cycles. And, yes, I know that the last two are cheap—but the first is not.\n\n> 服务层次解耦的另一个问题是不仅系统资源成本高昂，而且研发成本更高。处理服务边界不仅非常耗费内存、处理器资源，而且更耗费人力。虽然内存和处理器越来越便宜，但是人力成本可一直都很高。\n\nMy preference is to push the decoupling to the point where a service could be formed. should it become necessary; but then to leave the components in the same address space as long as possible. This leaves the option for a service open.\n\n> 通常，我会倾向于将系统的解耦推行到某种一旦有需要就可以随时转变为服务的程度即可，让整个程序尽量长时间地保持单体结构，以便给未来留下可选项。\n\nWith this approach, initially the components are separated at the source code level. That may be good enough for the duration of the project’s lifetime. If, however, deployment or development issues arise, driving some of the decoupling to a deployment level may be sufficient—at least for a while.\n\n> 在这种方式下，系统最初的组件隔离措施都是做在源码层次上的，这样的解耦可能在整个项目的生命周期里已经足够了。然而，如果部署和开发方面有更高的需求出现，那么将某些组件解耦到部署单元层次就可能够了，起码能撑上一阵。\n\nAs the development, deployment, and operational issues increase, I carefully choose which deployable units to turn into services, and gradually shift the system in that direction.\n\n> 当然，随着系统在开发、部署、运行各方面所面临问题持续增加，我们应该挑选一下可以将哪些可部署单元转化为服务，并且逐渐将系统向这个方向转变。\n\nOver time, the operational needs of the system may decline. What once required decoupling at the service level may now require only deployment-level or even source-level decoupling.\n\n> 而随着时间的流逝，系统的运维需求可能又会降低。之前需要进行服务层次解耦的系统可能现在只需要进行部署层次或源码层次的解耦就够了。\n\nA good architecture will allow a system to be born as a monolith, deployed in a single file, but then to grow into a set of independently deployable units, and then all the way to independent services and/or micro-services. Later, as things change, it should allow for reversing that progression and sliding all the way back down into a monolith.\n\n> 一个设计良好的架构应该允许一个系统从单体结构开始，以单一文件的形式部署，然后逐渐成长为一组相互独立的可部署单元，甚至是独立的服务或者微服务。最后还能随着情况的变化，允许系统逐渐回退到单体结构。\n\nA good architecture protects the majority of the source code from those changes. It leaves the decoupling mode open as an option so that large deployments can use one mode, whereas small deployments can use another.\n\n> 并且，一个设计良好的架构在上述过程中还应该能保护系统的大部分源码不受变更影响。对整个系统来说，解耦模式也应该是一个可选项。我们在进行大型部署时可以采用一种模式，而在进行小型部署时则可以釆用另一种模式。\n\n## CONCLUSION 本章小结\n\nYes, this is tricky. And I’m not saying that the change of decoupling modes should be a trivial configuration option (though sometimes that is appropriate). What I’m saying is that the decoupling mode of a system is one of those things that is likely to change with time, and a good architect foresees and appropriately facilitates those changes.\n\n> 是的，要达到上述要求难度不小。我并没有说系统的部署模式就一定要是某种简单的配置项（虽然在某些情况下的确应该这样做）。这里的主要观点认为，一个系统所适用的解耦模式可能会随着时间而变化，优秀的架构师应该能预见这一点，并且做岀相应的对策。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap17. BOUNDARIES: DRAWING LINES 划分边界\n\n![](../../images/books/架构整洁之道/CH-UN18.jpg)\n\nSoftware architecture is the art of drawing lines that I call boundaries. Those boundaries separate software elements from one another, and restrict those on one side from knowing about those on the other. Some of those lines are drawn very early in a project’s life—even before any code is written. Others are drawn much later. Those that are drawn early are drawn for the purposes of deferring decisions for as long as possible, and of keeping those decisions from polluting the core business logic.\n\n> 软件架构设计本身就是一门划分边界的艺术。也界的作用是将软件分割成各种元素，以便约束边界两侧之间的依赖关系。其中有一些边界是作项目初期——甚至在编写代码之前——就已经划分好，而其他的边界则是后来才划分的。在项目初期划分这些边界的目的是方便我们尽量将一些决策延后进行，并且确保未来这些决策不会对系统的核心业务逻辑产生干扰。\n\nRecall that the goal of an architect is to minimize the human resources required to build and maintain the required system. What it is that saps this kind of people-power? Coupling—and especially coupling to premature decisions.\n\n> 正如我们之前所说，架构师们所追求的目标是最大限度地降低构建和维护一个系统所需的人力资源。那么我们就需要了解一个系统最消耗人力资源的是什么？答案是系统中存在的耦合尤其是那些过早做出的、不成熟的决策所导致的耦合。\n\nWhich kinds of decisions are premature? Decisions that have nothing to do with the business requirements—the use cases—of the system. These include decisions about frameworks, databases, web servers, utility libraries, dependency injection, and the like. A good system architecture is one in which decisions like these are rendered ancillary and deferrable. A good system architecture does not depend on those decisions. A good system architecture allows those decisions to be made at the latest possible moment, without significant impact.\n\n> 那么，怎样的决策会被认为是过早且不成熟的呢？答案是那些决策与系统的业务需求（也就是用例）无关。这部分决策包括我们要采用的框架、数据库、Web 服务器、工具库、依赖注入等。在一个设计良好的系统架构中，这些细节性的决策都应该是辅助性的，可以被推迟的。一个设计良好的系统架构不应该依赖于这些细节?而应该尽可能地推迟这些细节性的决策，并致力于将这种推迟所产生的影响降到最低。\n\n## A COUPLE OF SAD STORIES 几个悲伤的故事\n\nHere’s the sad story of company P, which serves as a warning about making premature decisions. In the 1980s the founders of P wrote a simple monolithic desktop application. They enjoyed a great deal of success and grew the product through the 1990s into a popular and successful desktop GUI application.\n\n> 下面要讲的是一个来自 P 公司的悲伤的故事，我们在这里是将它作为一个草率决策的反面案例给大家展示的。在 20 世纪 80 年代，P 公司的创始团队开发了一个单体结构的简单桌面应用。然后，产品获得了极大的成功，并在 20 世纪 90 年代成功地成长为一个广为人知的桌面 GUI 应用。\n\nBut then, in the late 1990s, the web emerged as a force. Suddenly everybody had to have a web solution, and P was no exception. P’s customers clamored for a version of the product on the web. To meet this demand, the company hired a bunch of hotshot twenty-something Java programmers and embarked upon a project to webify their product.\n\n> 然而到了 20 世纪 90 年代末期，Web 卷起了一股浪潮，突然间每个公司都在推出自己的 Web 解决方案，P 公司自然也不能置身事外。P 公司的客户吵闹着要求它提供一个 Web 版的产品。为了应对这种需求，该公司雇用了一群二十几岁的 Java 程序员，开始着手将他们的产品 Web 化。\n\nThe Java guys had dreams of server farms dancing in their heads, so they adopted a rich three-tiered “architecture”1 that they could distribute through such farms. There would be servers for the GUI, servers for the middleware, and servers for the database. Of course.\n\n> 结果，这群 Java 小子满脑子朝思暮想的就是如何将大规模服务器集群应用起来，所以他们采用了一个三层的富“架构”，将系统的各层应用分布到一个大型服务集群中，这样一来，GUI、中间件和数据库自然就都要运行在不同的服务器上。\n\nThe programmers decided, very early on, that all domain objects would have three instantiations: one in the GUI tier, one in the middleware tier, and one in the database tier. Since these instantiations lived on different machines, a rich system of interprocessor and inter-tier communications was set up. Method invocations between tiers were converted to objects, serialized, and marshaled across the wire.\n\n> 这帮程序员在开发初期就决定系统中所有领域对象都要有三份实例：GUI 层一份、中间件层一份、数据库层一份。而由于这些实例要运行在不同的机器上，于是一套完整的跨处理器，跨层通信的富系统被设计了出来。该系统各层之间的函数调用都会被转变为对象，这些对象在经过序列化和编码处理之后进行网络传输。\n\nNow imagine what it took to implement a simple feature like adding a new field to an existing record. That field had to be added to the classes in all three tiers, and to several of the inter-tier messages. Since data traveled in both directions, four message protocols needed to be designed. Each protocol had a sending and receiving side, so eight protocol handlers were required. Three executables had to be built, each with three updated business objects, four new messages, and eight new handlers.\n\n> 现在假设我们想要增加一个特别简单的功能，为现有的记录添加一个字段。在上述情况下，这个字段必须被同步添加到系统所有三个分层的类，以及几个用于跨层通信的消息结构中。由于数据是双向流动的，这意味着我们要为此设计四个传输协议。而又由于每个协议都有各自的发送方和接收方，所以我们总共需要实现八个传输协议处理函数。总结一下，我们需要做的是同时构建三个可执行文件，每个文件都要包含三个变更过的业务对象、四个新的消息结构以及八个新的处理函数。\n\nAnd think of what those executables had to do to implement the simplest of features. Think of all the object instantiations, all the serializations, all the marshaling and de-marshaling, all the building and parsing of messages, all the socket communications, timeout managers, retry scenarios, and all the other extra stuff that you have to do just to get one simple thing done.\n\n> 这就是我们添加一个最简单的功能所需要做的事情。读者可以想想所有这些新增对象要进行的初始化、序列化、编码和反编码、消息构建和解析、socket 通信、超时管理、重试情况处理等过程，我们做所有的这些事情就只是为了完成一点小小的功能吗？这代价未免太大了点。\n\nOf course, during development the programmers did not have a server farm. Indeed, they simply ran all three executables in three different processes on a single machine. They developed this way for several years. But they were convinced that their architecture was right. And so, even though they were executing in a single machine, they continued all the object instantiations, all the serializations, all the marshaling and de-marshaling, all the building and parsing of messages, all the socket communications, and all the extra stuff in a single machine.\n\n> 当然，这帮程序员在开发过程中实际上是没有大型服务器集群可以用的。他们其实仍然是在一台机器上运行那三个可执行文件，而且就这样开发了几年时间。然而，即使这个系统只在一台机器上执行，也还是要经历所有这些对象的初始化、序列化、编码与反编码、消息的构建和解析、socket 通信等过程的，但他们直到最后还是坚信自己的架构是正确的。\n\nThe irony is that company P never sold a system that required a server farm. Every system they ever deployed was a single server. And in that single server all three executables continued all the object instantiations, all the serializations, all the marshaling and de-marshaling, all the building and parsing of messages, all the socket communications, and all the extra stuff, in anticipation of a server farm that never existed, and never would.\n\n> 这里最讽刺的是，P 公司从来就没有销售过一个需要服务器集群的系统，他们所有曾经部署过的系统都是在一台机器上完成的。然后在这台机器上，系统中所有的三个可执行文件仍然继续着这些对象初始化、序列化、编码与反编码、消息的构建与解析、socket 通信等不必要的工作，就是为了适应一个并不存在且也永远不会存在的集群环境。\n\nThe tragedy is that the architects, by making a premature decision, multiplied the development effort enormously.\n\n> 这个故事的悲剧之处在于，软件架构师通过一个草率的决定无谓地将开发成本放大了数倍之多。\n\nThe story of P is not isolated. I’ve seen it many times and in many places. Indeed, P is a superposition of all those places.\n\n> 而且，P 公司的故事绝不是个案，我在很多地方看到过这个故事的各种版本。\n\nBut there are worse fates than P.\n\n> 接下来，还有比 P 公司更糟糕的故事。\n\nConsider W, a local business that manages fleets of company cars. They recently hired an “Architect” to get their rag-tag software effort under control. And, let me tell you, control was this guy’s middle name. He quickly realized that what this little operation needed was a full-blown, enterprise-scale, service-oriented “ARCHITECTURE.” He created a huge domain model of all the different “objects” in the business, designed a suite of services to manage these domain objects, and put all the developers on a path to Hell. As a simple example, suppose you wanted to add the name, address, and phone number of a contact person to a sales record. You had to go to the ServiceRegistry and ask for the service ID of the ContactService. Then you had to send a CreateContact message to the ContactService. Of course, this message had dozens of fields that all had to have valid data in them—data to which the programmer had no access, since all the programmer had was a name, address, and phone number. After faking the data, the programmer had to jam the ID of the newly created contact into the sales record and send the UpdateContact message to the SaleRecordService.\n\n> 我们再来看一下 W 公司的故事。该公司有一项管理其租赁车队的本地业务，他们最近招聘了一位“架构师”来控制他们目前的软件开发成本。而且据说“控制”这个词就是这家伙的中间名- 总之这位“架构师”来了之后很快做了判断，认为运作这个小小的业务需要的是一个全套的、企业级的、面向服务的“架构\"。于是，他就创建了一个巨大的域模型，其中包含了该业务所涉及的所有“对象”，并设计了一整套服务来管理这些对象，差点将所有开发人员逼疯。在他这套“架构”中，如果我们想在销售记录中添加一个联系人，提供名字、地址和电话号码，就必须先访问 ServiceRegistry，查询 ContactService 的 ID。然后需要发送一条 CreateContact 消息给 ContactService。当然，这个消息结构有几十个字段，每一个字段都需要有效的数据来填充——这些数据是普通程序员无法访问的，他们手里只有名字、地址和电话号码。只有在伪造数据之后，程序员才能将新建的 Contact 记录 ID 填入 UpdateContact 消息中，最后还要发送给 SaleRecordService。\n\nOf course, to test anything you had to fire up all the necessary services, one by one, and fire up the message bus, and the BPel server, and … And then, there were the propagation delays as these messages bounced from service to service, and waited in queue after queue.\n\n> 当然，为了测试这一切，我们还必须将所有的服务全部运行起来，同时还要运行消息总线、BPel 服务器等。更糟糕的是，这些消息还会在每个服务之间传递时出现延迟，需要一个队列接一个队列地等待。\n\nAnd then if you wanted to add a new feature—well, you can imagine the coupling between all those services, and the sheer volume of WSDLs that needed changing, and all the redeployments those changes necessitated …\n\n> 如果还需要添加新功能的话，读者可以想象一下所有这些服务之间的耦合关系、那些需要修改的大量 WSDL 文件以及需要进行的重新部署。\n\nHell starts to seem like a nice place by comparison.\n\n> 说真的，地狱看起来也不过如此吧!\n\nThere’s nothing intrinsically wrong with a software system that is structured around services. The error at W was the premature adoption and enforcement of a suite of tools that promised SoA—that is, the premature adoption of a massive suite of domain object services. The cost of those errors was sheer person-hours—person-hours in droves—flushed down the SoA vortex.\n\n> 按照服务来组织一个软件系统的结构这件事本身并没有什么问题，W 公司的错误主要在于太过草率地采用和强制推广了一套号称是 SOA 体系的工具——也就是说，他们过于草率地采用了一整套域对象服务体系。这个错误让公司大量的人力都耗费在了实现这个所谓的 SOA 架构上。\n\nI could go on describing one architectural failure after another. But let’s talk about an architectural success instead.\n\n> 我们还可以一个接一个地描述很多这类架构设计失败的案例，但还是先来讲一些成功的案例吧。\n\n## FITNESSE\n\nMy Son, Micah, and I started work on FitNesse in 2001. The idea was to create a simple wiki that wrapped Ward Cunningham’s FIT tool for writing acceptance tests.\n\n> 我和我儿子 Micah 在 2001 年创立了一家叫 FitNesse 的公司。想法很简单，就是用一个简单的 wiki 来包装一下 Ward Cunningham 的 FIT 工具，以编写验收测试（acceptance test）。\n\nThis was back in the days before Maven “solved” the jar file problem. I was adamant that anything we produced should not require people to download more than one jar file. I called this rule, “Download and Go.” This rule drove many of our decisions.\n\n> 这件事情发生在 Maven 工具面世并“解决了” jar 文件问题之前。我当时坚信我们的产品不应该让用户下载超过一个的 jar 文件，我称这条规则为“下载即可执行”。这条规则指导了我们之后的很多决策。\n\nOne of the first decisions was to write our own web server, specific to the needs of FitNesse. This might sound absurd. Even in 2001 there were plenty of open source web servers that we could have used. Yet writing our own turned out to be a really good decision because a bare-bones web server is a very simple piece of software to write and it allowed us to postpone any web framework decision until much later.2\n\n> 第一个决策是根据 FitNesse 的需要专门编写了属于我们自己的 Web 服务器。这可能听起来很傻，即使在 2001 年，市面上也有足够多的开源的 Web 服务器可供选用。然而编写属于自己的 Web 服务器实际上是一个非常好的决策，因为一个只包含基本功能的 Web 服务器部署起来非常简单，它允许我们将任何与具体 Web 框架相关的决策延后。\n\nAnother early decision was to avoid thinking about a database. We had MySQL in the back of our minds, but we purposely delayed that decision by employing a design that made the decision irrelevant. That design was simply to put an interface between all data accesses and the data repository itself.\n\n> 我们做的另一个早期决策是避免考虑数据库问题。我们当时确实考虑过使用 MySQL，但最后还是故意采用了一种与数据库无关的设计，而延后了这方面的决策。这部分的设计也很简单，就是在所有数据访问逻辑与数据仓库之间增加一个接口。\n\nWe put the data access methods into an interface named WikiPage. Those methods provided all the functionality we needed to find, fetch, and save pages. Of course, we didn’t implement those methods at first; we simply stubbed them out while we worked on features that didn’t involve fetching and saving the data.\n\n> 我们将数据访问方法放在一个名为 WikiPage 的接口中。这部分方法负责提供所需的查找、获取和保存页面的功能。当然，我们最初并没有具体实现这些方法，在开发不需要获取和保存数据的那部分功能时，我们只写了一个占位方法。\n\nIndeed, for three months we simply worked on translating wiki text into HTML. This didn’t require any kind of data storage, so we created a class named MockWikiPage that simply left the data access methods stubbed.\n\n> 确实，我们花了三个月时间来解决 wiki 文本与 HTML 之间的转换问题，这部分的工作与任何类型的数据存储都无关。所以我们在创建名为 MockWikiPage 的模块时，只与了一些空的数据访问方法。\n\nEventually, those stubs became insufficient for the features we wanted to write. We needed real data access, not stubs. So we created a new derivative of WikiPage named InMemoryPage. This derivative implemented the data access method to manage a hash table of wiki pages, which we kept in RAM.\n\n> 最终，当这些占位方法不再支持我们所要开发的功能时，我们才需要真正实现数据访问。为此我们创建了一个名为 InMemoryPage 的 WikiPage 的派生类。在这个派生类中，实现了一系列数据访问方法来管理与 wiki 页面相关的哈希表（该哈希表会一直存在于内存中）。\n\nThis allowed us to write feature after feature for a full year. In fact, we got the whole first version of the FitNesse program working this way. We could create pages, link to other pages, do all the fancy wiki formatting, and even run tests with FIT. What we couldn’t do was save any of our work.\n\n> 就这样，我们一个接一个地开发这些业务功能，花了整整一年时间。事实上，FitNesse 程序能正常运行的第一个版本是这样的，它能让我们创建页面、链接其他页面、使用 wiki 格式完成所有的装饰，甚至用 FIT 工具运行测试。唯一不能做的就是真正地保存数据。\n\nWhen it came time to implement persistence, we thought again about MySQL, but decided that wasn’t necessary in the short term, because it would be really easy to write the hash tables out to flat files. So we implemented FileSystemWikiPage, which just moved the functionality out to flat files, and then we continued developing more features.\n\n> 当该系统需要实现持久化时，我们又仔细考虑了一下是否采用 MySQL，最终还是觉得短期内没有必要，因为将哈希表写入文件是非常简单的。所以我们实现了一个 FileSystemWikiPmge，用单一的大文件实现了这一功能，同时将我们的精力投入继续开发更多的新功能上。\n\nThree months later, we reached the conclusion that the flat file solution was good enough; we decided to abandon the idea of MySQL altogether. We deferred that decision into nonexistence and never looked back.\n\n> 三个月之后，我们得出一个结论，大文件的存储己经足够好了，完全没有必要使 MySQL。就这样，我们不断推迟这个决策，到最后发现这个决策不需要做了。\n\nThat would be the end of the story if it weren’t for one of our customers who decided that he needed to put the wiki into MySQL for his own purposes. We showed him the architecture of WikiPages that had allowed us to defer the decision. He came back a day later with the whole system working in MySQL. He simply wrote a MySqlWikiPage derivative and got it working.\n\n> 如果不是我们的一个客户由于自己的需要而希望将数据存入 MySQL，我们的故事就到此为止了。事实上，在我们给他展示了 WikiPage 架构细节之后，他只用了一天时间就实现了一个能在 MySQL 上运行的系统，他所做的就是写了一个名为 MySQLWikiPage 的派生类，该系统就可以正常工作了。\n\nWe used to bundle that option with FitNesse, but nobody else ever used it, so eventually we dropped it. Even the customer who wrote the derivative eventually dropped it.\n\n> 我们曾经将这个实现和 FitNesse 一起打包分发，但是后来没有人真正用到过它，甚至连实现这个功能的用户最终也不再使用它了。\n\nEarly in the development of FitNesse, we drew a boundary line between business rules and databases. That line prevented the business rules from knowing anything at all about the database, other than the simple data access methods. That decision allowed us to defer the choice and implementation of the database for well over a year. It allowed us to try the file system option, and it allowed us to change direction when we saw a better solution. Yet it did not prevent, or even impede, moving in the original direction (MySQL) when someone wanted it.\n\n> 在开发 FitNesse 的早期，我们在业务逻辑和数据库之间画了一条边界线。这条线有效地防止了业务逻辑对数据库产生依赖，它只能访问简单的数据访问方法。这个决策使我们将与数据库选型和实现的决策推迟了超过一年。同时我们还能用文件系统进行实验。使我们最终换了一个更好的解决方案。更重要的是，该架构在需求真的出现时，没有阻止任何人采用 MySQL，甚至没有为其制造任何障碍。\n\nThe fact that we did not have a database running for 18 months of development meant that, for 18 months, we did not have schema issues, query issues, database server issues, password issues, connection time issues, and all the other nasty issues that raise their ugly heads when you fire up a database. It also meant that all our tests ran fast, because there was no database to slow them down.\n\n> 在长达 18 个月的开发过程中，我们事实上没有用到过数据库，这意味着我们不需要面对表结构问题、查询问题、数据库服务器问题、密码问题、链接时间问题等一系列由于数据库带来的棘手问题。这样我们所有的测试都会进行得很快，因为它们都不依赖数据库。\n\nIn short, drawing the boundary lines helped us delay and defer decisions, and it ultimately saved us an enormous amount of time and headaches. And that’s what a good architecture should do.\n\n> 简单来说，通过划清边界，我们可以推迟和延后一些细节性的决策，这最终会为我们节省大量的时间、避免大量的问题。这就是一个设计良好的架构所应该带来的助益。\n\n## WHICH LINES DO YOU DRAW, AND WHEN DO YOU DRAW THEM? 应在何时、何处画这些线\n\nYou draw lines between things that matter and things that don’t. The GUI doesn’t matter to the business rules, so there should be a line between them. The database doesn’t matter to the GUI, so there should be a line between them. The database doesn’t matter to the business rules, so there should be a line between them.\n\n> 边界线应该画在那些不相关的事情中间。GUI 与业务逻辑无关，所以两者之间应该有一条边界线。数据库与 GUI 无关，这两者之间也应该有一条边界线。数据库只与业务逻辑无关，所以两者之间也应该有一条边界线。\n\nSome of you may have rejected one or more of those statements, especially the part about the business rules not caring about the database. Many of us have been taught to believe that the database is inextricably connected to the business rules. Some of us have even been convinced that the database is the embodiment of the business rules.\n\n> 上面这些话，尤其是关于业务逻辑与数据库无关的部分可能会遭到部分读者的反对。大部分人都已经习惯性地认为数据库是与业务逻辑不可分割的了，有些人甚至认为，数据库相关逻辑部分本身就是业务逻辑的具体体现。\n\nBut, as we shall see in another chapter, this idea is misguided. The database is a tool that the business rules can use indirectly. The business rules don’t need to know about the schema, or the query language, or any of the other details about the database. All the business rules need to know is that there is a set of functions that can be used to fetch or save data. This allows us to put the database behind an interface.\n\n> 然而正如我们在第 18 章中将会讲到的，这个想法从根本上就是错误的。数据库应该是业务逻辑间接使用的一个工具。业务逻辑并不需要了解数据库的表结构、查询语言或其他任何数据库内部的实现细节。业务逻辑唯一需要知道的，就是有一组可以用来查询和保存数据的函数。这样一来，我们才可以将数据库隐藏在接口后面。\n\nYou can see this clearly in Figure 17.1. The BusinessRules use the DatabaseInterface to load and save data. The DatabaseAccess implements the interface and directs the operation of the actual Database.\n\n> 我们可以从图 17.1 中清晰地看到，BusinessRules 是通过 DatabaseInterface 来加载和保存数据的。而 DatabaseAccess 则负责实现该接口，以及其与实际 Database 的交互。\n\n<Figures figure=\"17-1\">The database behind an interface</Figures>\n\nThe classes and interfaces in this diagram are symbolic. In a real application, there would be many business rule classes, many database interface classes, and many database access implementations. All of them, though, would follow roughly the same pattern.\n\n> 这里的类与接口仅仅是一个例子。在一个真实的应用程序中，将会有很多业务逻辑类、很多数据库接口类以及很多数据库访问的实现。不过，所有一切所遵循的模式应该是相似的。\n\nWhere is the boundary line? The boundary is drawn across the inheritance relationship, just below the DatabaseInterface (Figure 17.2).\n\n> 那么这里的边界线应该被画在哪里？边界应该穿过继承关系，在 DatabaseInterface 之下（见图 17.2）。\n\n<Figures figure=\"17-2\">The boundary line</Figures>\n\nNote the two arrows leaving the DatabaseAccess class. Those two arrows point away from the DatabaseAccess class. That means that none of these classes knows that the DatabaseAccess class exists.\n\n> 请注意，DatabaseAccess 类的那两个对外的箭头。这两个箭头都指向了远离 DatabaseAccess 类的方向，这意味着它们所指向的两个类都不知道 DatabaseAccess 类的存在。\n\nNow let’s pull back a bit. We’ll look at the component that contains many business rules, and the component that contains the database and all its access classes (Figure 17.3).\n\n> 下面让我们把抽象层次拉高一点，看一下包含多个业务逻辑类的组件与包含数据库及其访问类的组件之间是什么关系（见图 17.3）。\n\n<Figures figure=\"17-3\">The business rules and database components</Figures>\n\nNote the direction of the arrow. The Database knows about the BusinessRules. The BusinessRules do not know about the Database. This implies that the DatabaseInterface classes live in the BusinessRules component, while the DatabaseAccess classes live in the Database component.\n\n> 请注意，图 17.3 中的箭头指向，它说明了 Database 组件知道 BusinessRules 组件的存在，而 BusinessRules 组件则不知道 Database 组件的存在。这意味着 DatabaseInterface 类是包含在 BusinessRules 组件中的，而 DatabaseAccess 类则被包含在 Database 组件中。\n\nThe direction of this line is important. It shows that the Database does not matter to the BusinessRules, but the Database cannot exist without the BusinessRules.\n\n> 这个箭头的方向很重要。因为它意味着 Database 组件不会对 BusinessRules 组件形成的干扰，但 Database 组件却不能脫离 BusinessRules 组件而存在。\n\nIf that seems strange to you, just remember this point: The Database component contains the code that translates the calls made by the BusinessRules into the query language of the database. It is that translation code that knows about the BusinessRules.\n\n> 如果读者对上面这段话感到困惑，请记住一点，Database 组件中包含了将 BusinessRules 组件中的函数调用转化为具体数据库查询语言的代码。这些转换代码当然必须知道 BusinessRules 组件的存在。\n\nHaving drawn this boundary line between the two components, and having set the direction of the arrow toward the BusinessRules, we can now see that the BusinessRules could use any kind of database. The Database component could be replaced with many different implementations—the BusinessRules don’t care.\n\n> 通过在这两个组件之间画边界线，并且让箭头指向 BusinessRules 组件，我们现在可以很容易地明白为什么 BusinessRules 组件可以使用任何一种数据库。在这里，Database 组件可以被替换为多种实现，BusinessRules 组件并不需要知道这件事。\n\nThe database could be implemented with Oracle, or MySQL, or Couch, or Datomic, or even flat files. The business rules don’t care at all. And that means that the database decision can be deferred and you can focus on getting the business rules written and tested before you have to make the database decision.\n\n> 数据库可以用 Oracle、MySQL、Couch 或者 Datomic，甚至大文件来实现。业务逻辑并不需要关心这件事。这意味着我们叫以将与数据库相关的决策延后，先专注于编写业务逻辑的代码，进行测试，直到不得不选择数据库为止。\n\n## WHAT ABOUT INPUT AND OUTPUT? 输入和输出怎么办\n\nDevelopers and customers often get confused about what the system is. They see the GUI, and think that the GUI is the system. They define a system in terms of the GUI, so they believe that they should see the GUI start working immediately. They fail to realize a critically important principle: The IO is irrelevant.\n\n> 开发者和使用者经常会对系统边界究竟如何定义而感到困惑。由于 GUI 能够直观看到，就很自然地把 GUI 当成了系统本身。这些人以 GUI 的视角来定义整个系统，所以认为从系统开发一开始 GUI 部分就应该正常工作。这是错误的，这里他们没有意识到一个非常重要的原则，即 I/O 是无关紧要的。\n\nThis may be hard to grasp at first. We often think about the behavior of the system in terms of the behavior of the IO. Consider a video game, for example. Your experience is dominated by the interface: the screen, the mouse, the buttons, and the sounds. You forget that behind that interface there is a model—a sophisticated set of data structures and functions—driving it. More importantly, that model does not need the interface. It would happily execute its duties, modeling all the events in the game, without the game ever being displayed on the screen. The interface does not matter to the model—the business rules.\n\n> 这个原则可能一开始比较难以理解，毕竟我们经常从直觉上会以 I/O 的行为来定义系统的行为。以视频游戏为例，我们的主观体验是以界面反应为主的，这些反应来自屏幕、鼠标、按钮和声音等。但请不要忘了，这些界面背后存在着一个模型——一套非常复杂的数据结构和函数，那才是游戏真正的核心驱动力。更重要的是，该模型并不一定非要有一个界面。就算该游戏不显不在屏幕上，其模型也应该可以完成所有的任务逻辑，处理所有的游戏事件。因此，界面对模型——也就是业务逻辑来说——一点都不重要。\n\nAnd so, once again, we see the GUI and BusinessRules components separated by a boundary line (Figure 17.4). Once again, we see that the less relevant component depends on the more relevant component. The arrows show which component knows about the other and, therefore, which component cares about the other. The GUI cares about the BusinessRules.\n\n> 所以，GUI 和 BusinessRules 这两个组件之间也应该有一条边界线（见图 17.4）。再强调一次，在这里不重要的组件依赖于较为重要的组件，箭头指向的方向代表着组件之间的关系，GUI 关心 BusinessRules。\n\n<Figures figure=\"17-4\">The boundary between GUI and BusinessRules components</Figures>\n\nHaving drawn this boundary and this arrow, we can now see that the GUI could be replaced with any other kind of interface—and the BusinessRules would not care.\n\n> 通过这条边界线以及这个箭头，我们可以看出 GUI 可以用任何一种其他形式的界面来代替。BusinessRules 组件不需要了解这些细节。\n\n## PLUGIN ARCHITECTURE 插件式架构\n\nTaken together, these two decisions about the database and the GUI create a kind of pattern for the addition of other components. That pattern is the same pattern that is used by systems that allow third-party plugins.\n\n> 综上所述，我们似乎可以基于数据库和 GUI 这两个为例来建立一种向系统添加其他组件的模式。这种模式与支持第三方插件的系统模式是一样的。\n\nIndeed, the history of software development technology is the story of how to conveniently create plugins to establish a scalable and maintainable system architecture. The core business rules are kept separate from, and independent of, those components that are either optional or that can be implemented in many different forms (Figure 17.5).\n\n> 事实上，软件开发技术发展的历史就是一个如何想方设法方便地增加插件，从而构建一个可扩展、可维护的系统架构的故事。系统的核心业务逻辑必须和其他组件隔离，保持独立，而这些其他组件要么是可以去掉的，要么是有多种实现的（见图 17.5）。\n\n<Figures figure=\"17-5\">Plugging in to the business rules</Figures>\n\nBecause the user interface in this design is considered to be a plugin, we have made it possible to plug in many different kinds of user interfaces. They could be web based, client/server based, SOA based, Console based, or based on any other kind of user interface technology.\n\n> 由于用户界面在这个设计中是以插件形式存在的，所以我们可以用插拔的方式切换很多不同类型的用户界面。可以是基于 Web 模式的、基于客户端/服务器端模式的、基于 SOA 模式的、基于命令行模式的或者基于其他任何类型的用户界面技术。\n\nThe same is true of the database. Since we have chosen to treat it as a plugin, we can replace it with any of the various SQL databases, or a NOSQL database, or a file system-based database, or any other kind of database technology we might deem necessary in the future.\n\n> 数据库也类似。因为我们现在是将数据库作为插件来对待的，所以它就可以被替换成不同类型的 SQL 数据库、NoSQL 数据库，其至基于文件系统的数据库，以及未来任何一种我们认为有必要发展的数据库技术。\n\nThese replacements might not be trivial. If the initial deployment of our system was web-based, then writing the plugin for a client-server UI could be challenging. It is likely that some of the communications between the business rules and the new UI would have to be reworked. Even so, by starting with the presumption of a plugin structure, we have at very least made such a change practical.\n\n> 当然，这些替换工作可能并不轻松，如果我们的系统一开始是按照 Web 方式部署的，那么为它写一个客户端/服务器端模型的 UI 插件就可能会比较困难一些。很可能业务逻辑与新 UI 之间的交互方式也要重新修改。但即使这样，插件式架构也至少为我们提供了这种实现的可能性。\n\n## THE PLUGIN ARGUMENT 插件式架构的好处\n\nConsider the relationship between ReSharper and Visual Studio. These components are produced by completely different development teams in completely different companies. Indeed, JetBrains, the maker of ReSharper, lives in Russia. Microsoft, of course, resides in Redmond, Washington. It’s hard to imagine two development teams that are more separate.\n\n> 我们可以来看一下 ReSharper 和 Visual Studio 之间的关系。这两部分组件是由两个完全不同公司的人各自独立开发的，ReSharper 的开发者是 JetBrains 公司，它位于俄罗斯，而 Microsoft 公司则位于华盛顿州的雷德蒙市。很难想象有哪两个开发团队会比它们隔离得更彻底的了。\n\nWhich team can damage the other? Which team is immune to the other? The dependency structure tells the story (Figure 17.6). The source code of ReSharper depends on the source code of Visual Studio. Thus there is nothing that the ReSharper team can do to disturb the Visual Studio team. But the Visual Studio team could completely disable the ReSharper team if they so desired.\n\n> 那么他们之间，是哪个团队可以影响另一个团队的工作呢？又是哪个团队可以对另一个团队的工作免疫呢？我们可以通过图 17.6 中的依赖关系来回答。很显然，是 ReSharper 的源代码依赖于 Visual Studio 的源代码。因此，是 ReSharper 团队无法干扰 Visual Studio 团队的工作，而 Visual Studio 团队却可以单方面中止 ReSharper 团队的任何工作。\n\n<Figures figure=\"17-6\">ReSharper depends on Visual Studio</Figures>\n\nThat’s a deeply asymmetric relationship, and it is one that we desire to have in our own systems. We want certain modules to be immune to others. For example, we don’t want the business rules to break when someone changes the format of a web page, or changes the schema of the database. We don’t want changes in one part of the system to cause other unrelated parts of the system to break. We don’t want our systems to exhibit that kind of fragility.\n\n> 这是一种非常不对称的关系，但我们确实希望在自己的系统中构建这样的关系因为这可以让部分组件对其他组件的变更免疫。例如，当有人修改 Web 页面格式或修改数据库表结构时，系统的业务逻辑部分就不应该受到影响。另外，我们也不希望系统中某一个部分发生的变更会导致其他不相关的部分出现问题，系统不应该这么脆弱。\n\nArranging our systems into a plugin architecture creates firewalls across which changes cannot propagate. If the GUI plugs in to the business rules, then changes in the GUI cannot affect those business rules.\n\n> 将系统设计为插件式架构，就等于构建起了一面变更无法逾越的防火墙，换句话说，只要 GUI 是以插件形式插入系统的业务逻辑中的，那么 GUI 这边所发生的变更就不会影响系统的业务逻辑。\n\nBoundaries are drawn where there is an axis of change. The components on one side of the boundary change at different rates, and for different reasons, than the components on the other side of the boundary.\n\n> 所以，边界线也应该沿着系统的变更轴来画。也就是说，位于边界线两侧的组件应该以不同原因、不同速率变化着。\n\nGUIs change at different times and at different rates than business rules, so there should be a boundary between them. Business rules change at different times and for different reasons than dependency injection frameworks, so there should be a boundary between them.\n\n> 一个系统的 GUI 与业务逻辑的变更原因、变更速率显然是不同的，所以二者中间应该有一条边界线。同样的，一个系统的业务逻辑与依赖注入框架之间的变更原因和变更速度也会不同，它们之间也应该画边界线。\n\nThis is simply the Single Responsibility Principle again. The SRP tells us where to draw our boundaries.\n\n> 这其实就是单一职责原则（SRP）的具体实现，SRP 的作用就是告诉我们应该在哪里画边界线。\n\n## CONCLUSION 本章小结\n\nTo draw boundary lines in a software architecture, you first partition the system into components. Some of those components are core business rules; others are plugins that contain necessary functions that are not directly related to the core business. Then you arrange the code in those components such that the arrows between them point in one direction—toward the core business.\n\n> 为了在软件架构中画边界线，我们需要先将系统分割成组件，其中一部分是系统的核心业务逻辑组件，而另一部分则是与核心业务逻辑无关但负责提供必要功能的插件。然后通过对源代码的修改，让这些非核心组件依赖于系统的核心业务逻辑组件。\n\nYou should recognize this as an application of the Dependency Inversion Principle and the Stable Abstractions Principle. Dependency arrows are arranged to point from lower-level details to higher-level abstractions.\n\n> 其实，这也是一种对依赖反转原则（DIP）和稳定抽象原则（SAP）的具体应用，依赖箭头应该由底层具体实现细节指向高层抽象的方向。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap18. BOUNDARY ANATOMY 边界剖析\n\n![](../../images/books/架构整洁之道/CH-UN18.jpg)\n\nThe architecture of a system is defined by a set of software components and the boundaries that separate them. Those boundaries come in many different forms. In this chapter we’ll look at some of the most common.\n\n> 一个系统的架构是由一系列软件组件以及它们之间的边界共同定义的。而这些边界有着多种不同的存在形式。在本章中和我们看看其中最常见的一些形式。\n\n## BOUNDARY CROSSING 跨边界调用\n\nAt runtime, a boundary crossing is nothing more than a function on one side of the boundary calling a function on the other side and passing along some data. The trick to creating an appropriate boundary crossing is to manage the source code dependencies.\n\n> 在运行时，跨边界调用指的是边界线一侧的函数调用另一侧的函数，并同时传递数据的行为。构造合理的跨边界调用需要我们对源码中的依赖关系进行合理管控。\n\nWhy source code? Because when one source code module changes, other source code modules may have to be changed or recompiled, and then redeployed. Managing and building firewalls against this change is what boundaries are all about.\n\n> 为什么需要管控源码中的依赖关系呢？因为当一个模块的源码发生变更时，其他模块的源码也可能会随之发生变更或重新编译，并需要重新部署。所谓划分边界，就是指在这些模块之间建立这种针对变更的防火墙。\n\n## THE DREADED MONOLITH 令人生畏的单体结构\n\nThe simplest and most common of the architectural boundaries has no strict physical representation. It is simply a disciplined segregation of functions and data within a single processor and a single address space. In a previous chapter, I called this the source-level decoupling mode.\n\n> 最简单、最常见的架构边界通常并没有一个固定的物理形式，它们只是对同一个进程、同一个地址空间内的函数和数据进行了某种划分。在第 16 章中，我们称之为源码层次上的解耦模式。\n\nFrom a deployment point of view, this amounts to nothing more than a single executable file—the so-called monolith. This file might be a statically linked C or C++ project, a set of Java class files bound together into an executable jar file, a set of .NET binaries bound into a single .EXE file, and so on.\n\n> 但是从部署的角度来看，这一切到最后都产生了一个单独的可执行文件——这就是所谓的单体结构。这个文件可能是一个静态链接形成的 C/C++ 项目，或是一个将一堆 Java 类绑定在一起的 jar 可执行文件，或是由一系列 .NET 二进制文件组成的 .EXE 文件等。\n\nThe fact that the boundaries are not visible during the deployment of a monolith does not mean that they are not present and meaningful. Even when statically linked into a single executable, the ability to independently develop and marshal the various components for final assembly is immensely valuable.\n\n> 虽然这类系统的架构边界在部署过程中并不可见，但这并不意味着它们就不存在或者没有意义。因为即使最终所有的组件都被静态链接成了一个可执行文件，这些边界的划分对该系统各组件的独立开发也是非常有意义的。\n\nSuch architectures almost always depend on some kind of dynamic polymorphism1 to manage their internal dependencies. This is one of the reasons that object-oriented development has become such an important paradigm in recent decades. Without OO, or an equivalent form of polymorphism, architects must fall back on the dangerous practice of using pointers to functions to achieve the appropriate decoupling. Most architects find prolific use of pointers to functions to be too risky, so they are forced to abandon any kind of component partitioning.\n\n> 因为这类架构一般都需要利用某种动态形式的多态来管理其内部的依赖关系。这也是为什么面向对象编程近几十年来逐渐成为一种重要编程范式的原因之一。如果不采用面向对象编程模式或是类似的多态实现，架构师们就只能退回到用函数指针这种危险的模式来进行组件解耦的时代。由于大部分架构师认为大量采用函数指针过于危险，所以在那样的情况卜，他们通常都在权衡利弊之后就干脆放弃划分组件了。\n\nThe simplest possible boundary crossing is a function call from a low-level client to a higher-level service. Both the runtime dependency and the compile-time dependency point in the same direction, toward the higher-level component.\n\n> 最简单的跨边界调用形式，是由低层客户端来调用高层服务函数，这种依赖关系在运行时和编译时会保持指向一致，都是从低层组件指向高层组件。\n\nIn Figure 18.1, the flow of control crosses the boundary from left to right. The Client calls function f() on the Service. It passes along an instance of Data. The `<DS>` marker simply indicates a data structure. The Data may be passed as a function argument or by some other more elaborate means. Note that the definition of the Data is on the called side of the boundary.\n\n> 在图 18.1 中，我们可以看到控制流跨越边界的方向是从左向右的，Client 调用了 Service 上的函数 `f()`，并向它传递了一个 Data 实例。这里的 `<DS>` 标记是指 Data 是一个数据结构。Data 实例的具体传递方法可以是函数的调用参数，也可以是其他更复杂的传递方式。读者在这里需要注意的是，Data 的定义位于边界的被调用方一侧。\n\n<Figures figure=\"18-1\">Flow of control crosses the boundary from a lower level to a higher level</Figures>\n\nWhen a high-level client needs to invoke a lower-level service, dynamic polymorphism is used to invert the dependency against the flow of control. The runtime dependency opposes the compile-time dependency.\n\n> 但当高层组件中的客户端需要调用低层组件中的服务时，我们就需要运用动态形式的多态来反转依赖关系了。在这种情况下，系统在运行时的依赖关系与编译时的依赖关系就是相反的。\n\nIn Figure 18.2, the flow of control crosses the boundary from left to right as before. The high-level Client calls the f() function of the lower-level ServiceImpl through the Service interface. Note, however, that all dependencies cross the boundary from right to left toward the higher-level component. Note, also, that the definition of the data structure is on the calling side of the boundary.\n\n> 在图 18.2 中，控制流跨越边界的方向与之前是一样的，都是从左至右的。这里是高层组件 Client 通过 Service 接口调用了低层组件 Servicelmpl 上的函数 `f()`。但请读者注意，图 18.2 中所有的依赖关系却都是从右向左跨越边界的，方向是由低层组件指向高层组件的。同时，我们也应该注意到，这一次数据结构的定义是位于调用方这一侧的。\n\n<Figures figure=\"18-2\">Crossing the boundary against the flow of control</Figures>\n\nEven in a monolithic, statically linked executable, this kind of disciplined partitioning can greatly aid the job of developing, testing, and deploying the project. Teams can work independently of each other on their own components without treading on each other’s toes. High-level components remain independent of lower-level details.\n\n> 即使是在一个单体部署、静态链接的可执行文件中，这种自律式的组件划分仍然可以极大地帮助整个项目的开发、测试与部署，使不同的团队可以独立开发不同的组件，不会互相干扰。高层组件与低层细节之间也可以得到良好的隔离，独立演进。\n\nCommunications between components in a monolith are very fast and inexpensive. They are typically just function calls. Consequently, communications across source-level decoupled boundaries can be very chatty.\n\n> 在单体结构中，组件之间的交互一般情况下都只是普通的函数调用，迅速而廉价，这就意味着这种跨源码层次解耦边界的通信会很频繁。\n\nSince the deployment of monoliths usually requires compilation and static linking, components in these systems are typically delivered as source code.\n\n> 由于单体结构的部署需要编译所有源码，并且进行静态链接，这就意味着这些系统中的组件一般都会以源码形式交付。\n\n## DEPLOYMENT COMPONENTS 部署层次的组件\n\nThe simplest physical representation of an architectural boundary is a dynamically linked library like a .Net DLL, a Java jar file, a Ruby Gem, or a UNIX shared library. Deployment does not involve compilation. Instead, the components are delivered in binary, or some equivalent deployable form. This is the deployment-level decoupling mode. The act of deployment is simply the gathering of these deployable units together in some convenient form, such as a WAR file, or even just a directory.\n\n> 下面我们来看看系统架构最常见的物理边界形式：动态链接库。这种形式包括 .Net 的 DLL、Java 的 jar 文件、Ruby Gem 以及 UNIX 的共享库等。这种类型的组件在部署时不需要重新编译，因为它们都是以二进制形式或其他等价的可部署形式交付的。这里采用的就是部署层次上的解耦模式。部署这种类型的项目，就是将其所有可部署的单元打包成一个便于操作的文件格式，例如 WAR 文件，甚至可以只是一个目录（或者文件夹）。\n\nWith that one exception, deployment-level components are the same as monoliths. The functions generally all exist in the same processor and address space. The strategies for segregating the components and managing their dependencies are the same.2\n\n> 除这一点以外，这种按部署层次解耦的组件与单体结构几乎是一样的，其所有的函数仍然处于同一个进程、同一个地址空间中。管理组件划分依赖关系的策略也基本上是和上文一致的。\n\nAs with monoliths, communications across deployment component boundaries are just function calls and, therefore, are very inexpensive. There may be a one-time hit for dynamic linking or runtime loading, but communications across these boundaries can still be very chatty.\n\n> 与单体结构类似，按部署层次解耦的组件之间的跨也界调用也只是普通的函数调用，成本很低。虽然动态链接或运行时加载的过程本身可能会有一个一次性的调用成本，但它们之间的跨边界通信调用依然会很频繁。\n\n## THREADS 线程\n\nBoth monoliths and deployment components can make use of threads. Threads are not architectural boundaries or units of deployment, but rather a way to organize the schedule and order of execution. They may be wholly contained within a component, or spread across many components.\n\n> 单体结构和按部署层次划分的组件都可以采用线程模型。当然，线程既不属于架构边界，也不属于部署单元，它们仅仅是一种管理并调度程序执行的方式。一个线程既可以被包含在单一组件中，也可以横跨多个组件。\n\n## LOCAL PROCESSES 本地进程\n\nA much stronger physical architectural boundary is the local process. A local process is typically created from the command line or an equivalent system call. Local processes run in the same processor, or in the same set of processors within a multicore, but run in separate address spaces. Memory protection generally prevents such processes from sharing memory, although shared memory partitions are often used.\n\n> 系统架构还有一个更明显的物理边界形式，那就是本地进程。本地进程一般是由命令行启动或其他等价的系统调用产生的。本地进程往往运行于单个处理器或多核系统的同一组处理器上，但它们拥有各自不同的地址空间。一般来说，现有的内存保护机制会使这些进程无法共享其内存，但它们通常可以用某种独立的内存区域来实现共享。\n\nMost often, local processes communicate with each other using sockets, or some other kind of operating system communications facility such as mailboxes or message queues.\n\n> 最常见的情况是，这些本地进程会用 socket 来实现彼此的通信。当然，它们也可以通过一些操作系统提供的方式来通信，例如共享邮件或消息队列。\n\nEach local process may be a statically linked monolith, or it may be composed of dynamically linked deployment components. In the former case, several monolithic processes may have the same components compiled and linked into them. In the latter, they may share the same dynamically linked deployment components.\n\n> 每个本地进程都既可以是一个静态链接的单体结构，也可以是一个由动态链接组件组成的程序。在前一种情况下，若干个单体过程会被链接到同一个组件中。而在后一种情况下，这些单体过程可以共享同一个动态链接的可部署组件。\n\nThink of a local process as a kind of uber-component: The process consists of lower-level components that manage their dependencies through dynamic polymorphism.\n\n> 我们在这里可以将本地进程看成某种超级组件，该进程由一系列较低层次的组件组成，我们将通过动态形式的多态来管理它们之间的依赖关系。\n\nThe segregation strategy between local processes is the same as for monoliths and binary components. Source code dependencies point in the same direction across the boundary, and always toward the higher-level component.\n\n> 另外.本地进程之间的隔离策略也与单体结构、二进制组件基本相同，其源码中的依赖关系跨越架构边界的方向是一致的，始终指向更高层次的组件。\n\nFor local processes, this means that the source code of the higher-level processes must not contain the names, or physical addresses, or registry lookup keys of lower-level processes. Remember that the architectural goal is for lower-level processes to be plugins to higher-level processes.\n\n> 对本地进程来说，这就意味着高层进程的源码中不应该包含底层进程的名字、物理内存地址或是注册表键名。请渎职务必要记住，该系统架构的设计目标是让低层进程成为高层进程的一个插件。\n\nCommunication across local process boundaries involve operating system calls, data marshaling and decoding, and interprocess context switches, which are moderately expensive. Chattiness should be carefully limited.\n\n> 本地进程之间的跨边界通信需要用到系统调用、数据的编码和解码，以及进程间的上下文切换，成本相对来说会更高一些，所以这里而要谨慎地控制通信的次数。\n\n## SERVICES 服务\n\nThe strongest boundary is a service. A service is a process, generally started from the command line or through an equivalent system call. Services do not depend on their physical location. Two communicating services may, or may not, operate in the same physical processor or multicore. The services assume that all communications take place over the network.\n\n> 系统架构中最强的边界形式就是服务。一个服务就是一个进程，它们通常由命令行环境或其他等价的系统调用来产生。服务并不依赖于具体的运行位置，两个互相通信的服务既可以处于单一物理处理器或多核系统的同一组处理器上，也可以彼此位于不同的处理器上。服务会始终假设它们之间的通信将全部通过网络进行。\n\nCommunications across service boundaries are very slow compared to function calls. Turnaround times can range from tens of milliseconds to seconds. Care must be taken to avoid chatting where possible. Communications at this level must deal with high levels of latency.\n\n> 服务之间的跨边界通信相对于函数调用来说，速度是非常缓慢的，其往返时间可以从几十毫秒到几秒不等。因此我们在划分架构边界时，一定要尽可能地控制通信次数。在这个层次上通信必须能够适应高延时情况。\n\nOtherwise, the same rules apply to services as apply to local processes. Lower-level services should “plug in” to higher-level services. The source code of higher-level services must not contain any specific physical knowledge (e.g., a URI) of any lower-level service.\n\n> 除此之外，我们可以在服务层次上使用与本地进程相同的规则。也就是让较低层次服务成为较高层次服务的“插件”。为此，我们要确保高层服务的源码中没有包含任何与低层服务相关的物理信息（例如 URI）。\n\n## CONCLUSION 本章小结\n\nMost systems, other than monoliths, use more than one boundary strategy. A system that makes use of service boundaries may also have some local process boundaries. Indeed, a service is often just a facade for a set of interacting local processes. A service, or a local process, will almost certainly be either a monolith composed of source code components or a set of dynamically linked deployment components.\n\n> 除单体结构以外，大部分系统都会同时采用多种边界划分策略。一个按照服务层次划分边界的系统也可能会在某一部分采用本地进程的边界划分模式。事实上，服务经常不过就是一系列互相作用的本地进程的某种外在形式。无论是服务还是本地进程，它们几乎肯定都是由一个或多个源码组件组成的单体结构，或者一组动态链接的可部署组件。\n\nThis means that the boundaries in a system will often be a mixture of local chatty boundaries and boundaries that are more concerned with latency.\n\n> 这也意味着一个系统中通常会同时包含高通信量、低延迟的本地架构边界和低通信量、高延迟的服务边界。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap19. POLICY AND LEVEL 策略与层次\n\n![](../../images/books/架构整洁之道/CH-UN19.jpg)\n\nSoftware systems are statements of policy. Indeed, at its core, that’s all a computer program actually is. A computer program is a detailed description of the policy by which inputs are transformed into outputs.\n\n> 本质上，所有的软件都是一组策略语句的集合。是的，可以说计算机程序不过就是一组仔细描述如何将输入转化为输出的策略语句的集合。\n\nIn most nontrivial systems, that policy can be broken down into many different smaller statements of policy. Some of those statements will describe how particular business rules are to be calculated. Others will describe how certain reports are to be formatted. Still others will describe how input data are to be validated.\n\n> 在大多数非小型系统（nontrivial system）中，整体业务策略通常都可以被拆解为多组更小的策略语句。一部分策略语句专门用于描述计算部分的业务逻辑，另一部分策略语句则负责描述计算报告的格式。除此之外，可能还会有一些用于描述如何校验输入数据的策略。\n\nPart of the art of developing a software architecture is carefully separating those policies from one another, and regrouping them based on the ways that they change. Policies that change for the same reasons, and at the same times, are at the same level and belong together in the same component. Policies that change for different reasons, or at different times, are at different levels and should be separated into different components.\n\n> 软件架构设计的工作重点之一就是，将这些策略彼此分离，然后将它们按照变更的方式进行重新分组。其中变更原因、时间和层次相同的策略应该被分到同一个组件中。反之，变更原因、时间和层次不同的策略则应该分属于不同的组件。\n\nThe art of architecture often involves forming the regrouped components into a directed acyclic graph. The nodes of the graph are the components that contain policies at the same level. The directed edges are the dependencies between those components. They connect components that are at different levels.\n\n> 架构设计的工作常常需要将组件重排组合成为一个有向无环图。图中的每一个节点代表的是一个拥有相同层次策略的组件，每一条单向链接都代表了一种组件之间的依赖关系，它们将不同级别的组件链接起来。\n\nThose dependencies are source code, compile-time dependencies. In Java, they are import statements. In C#, they are using statements. In Ruby, they are require statements. They are the dependencies that are necessary for the compiler to function.\n\n> 这里提到的依赖关系是源码层次上的、编译期的依赖关系。这在 Java 语言中就是指 import 语句，在 C# 语言中就是指 using 语句，在 Ruby 语言中就是指 require 语句。这里的依赖关系都是在编译过程中所必需的。\n\nIn a good architecture, the direction of those dependencies is based on the level of the components that they connect. In every case, low-level components are designed so that they depend on high-level components.\n\n> 在一个设计良好的架构中，依赖关系的方向通常取决于它们所关联的组件层次。一般来说，低层组件被设计为依赖于高层组件。\n\n## LEVEL 层次（Level）\n\nA strict definition of “level” is “the distance from the inputs and outputs.” The farther a policy is from both the inputs and the outputs of the system, the higher its level. The policies that manage input and output are the lowest-level policies in the system.\n\n> 我们对“层次”是严格按照“输入与输出之间的距离”来定义的。也就是说，一条策略距离系统的输入/输出越远，它所属的层次就越高。而直接管理输入/输出的策略在系统中的层次是最低的。\n\nThe data flow diagram in Figure 19.1 depicts a simple encryption program that reads characters from an input device, translates the characters using a table, and then writes the translated characters to an output device. The data flows are shown as curved solid arrows. The properly designed source code dependencies are shown as straight dashed lines.\n\n> 在图 19.1 中，我们看到的是一个简单加密程序的数据流向图，该程序从输入设备读取字符，然后用查表法转换这些字符'并将转换后的字符输出到输出设备。我们将图中数据的流向用弯曲实心箭头标识了出来，而对于经精妙设计过的源码中的依赖关系则使用直虚线来标识。\n\n<Figures figure=\"19-1\">A simple encryption program</Figures>\n\nThe Translate component is the highest-level component in this system because it is the component that is farthest from the inputs and outputs.1\n\n> 在图 19.1 中，Translate 组件是这个系统中层次最高的组件，因为该组件距离系统输入/输出距离最远。\n\nNote that the data flows and the source code dependencies do not always point in the same direction. This, again, is part of the art of software architecture. We want source code dependencies to be decoupled from data flow and coupled to level.\n\n> 另外需要注意的是，图 19.1 中的数据流向和源码中的依赖关系并不总处于同一方向上。这也是软件架构设计工作的一部分。我们希望源码中的依赖关系与其数据流向脫钩，而与组件所在的层次挂钩。\n\nIt would be easy to create an incorrect architecture by writing the encryption program like this:\n\n> 但我们很容易将这个加密程序写成下面这样，这就构成了一个不正确的架构：\n\n```js\nfunction encrypt() {\n  while (true) writeChar(translate(readChar()));\n}\n```\n\nThis is incorrect architecture because the high-level encrypt function depends on the lower-level readChar and writeChar functions.\n\n> 上面这个程序架构设计的错误在于，它让高层组件中的函数 encrypt() 依赖于低层组件中的函数 readChar() 与 writeChar()。\n\nA better architecture for this system is shown in the class diagram in Figure 19.2. Note the dashed border surrounding the Encrypt class, and the CharWriter and CharReader interfaces. All dependencies crossing that border point inward. This unit is the highest-level element in the system.\n\n> 更好的系统架构设计应如图 19.2 所示。请注意图 19.2 中被虚线框起来的 Encrypt 类及其两个接口 CharReader 和 CharWriter。所有的依赖关系都指向了边界内部。这一切都说明它是系统中最高层次的组件。\n\n<Figures figure=\"19-2\">Class diagram showing a better architecture for the system</Figures>\n\nConsoleReader and ConsoleWriter are shown here as classes. They are low level because they are close to the inputs and outputs.\n\n> 在图 19.2 中，ConsoleReader 和 Consolewriter 都属于具体类。由于它们与输入/输出最近，因此属于低层组件。\n\nNote how this structure decouples the high-level encryption policy from the lower-level input/output policies. This makes the encryption policy usable in a wide range of contexts. When changes are made to the input and output policies, they are not likely to affect the encryption policy.\n\n> 另外应该注意的是，这个架构将高层的加密策略与低层的输入/输出策略解耦了。也就是说，当输入/输出部分的策略发生变更时，它们不太可能会影响加密部分的策略。\n\nRecall that policies are grouped into components based on the way that they change. Policies that change for the same reasons and at the same times are grouped together by the SRP and CCP. Higher-level policies—those that are farthest from the inputs and outputs—tend to change less frequently, and for more important reasons, than lower-level policies. Lower-level policies—those that are closest to the inputs and outputs—tend to change frequently, and with more urgency, but for less important reasons.\n\n> 正如之前提到的，我们应该根据策略发生变更的方式来将它们分成不同的组件。变更原因和变更时间相同的策略应在 SRP 和 CCP 这两个原则的指导下合并为同一组件。离输入/输出最远的策略——高层策略——一般变更没有那么频繁。即使发生变更，其原因也比低层策略所在的组件更重大。反之，低层策略则很有可能会频繁地进行一些小变更。\n\nFor example, even in the trivial example of the encryption program, it is far more likely that the IO devices will change than that the encryption algorithm will change. If the encryption algorithm does change, it will likely be for a more substantive reason than a change to one of the IO devices.\n\n> 例如，即使在这个简单的加密程序中，加密算法发生变更的可能性也要远小于 IO 设备发生变更的可能性。如果加密算法真的要变更，也很有可能比 I/O 设备的变更更重大。\n\nKeeping these policies separate, with all source code dependencies pointing in the direction of the higher-level policies, reduces the impact of change. Trivial but urgent changes at the lowest levels of the system have little or no impact on the higher, more important, levels.\n\n> 通过将策略隔离，并让源码中的依赖方向都统一调整为指向高层策略，我们可以大幅度降低系统变更所带来的影响。因为一些针对系统低层组件的紧急小修改几乎不会影响系统中更高级、更重要的组件。\n\nAnother way to look at this issue is to note that lower-level components should be plugins to the higher-level components. The component diagram in Figure 19.3 shows this arrangement. The Encryption component knows nothing of the IODevices component; the IODevices component depends on the Encryption component.\n\n> 从另一个角度来说，低层组件应该成为高层组件的插件。图 19.3 中的组件图展示了这种关系，我们可以看到 Encryption 组件对 IODevices 组件的情况一无所知，而 IODevices 组件则依赖于 Encryption 组件。\n\n<Figures figure=\"19-3\">Lower-level components should plug in to higher-level components</Figures>\n\n## CONCLUSION 本章小结\n\nAt this point, this discussion of policies has involved a mixture of the Single Responsibility Principle, the Open-Closed Principle, the Common Closure Principle, the Dependency Inversion Principle, the Stable Dependencies Principle, and the Stable Abstractions Principle. Look back and see if you can identify where each principle was used, and why.\n\n> 综上所述，本章针对策略的讨论涉及单一职责原则（SRP）、开闭原则（OCP）、共同闭包原则（CCP）、依赖反转原则（DIP）、稳定依赖原则（SDP）以及稳定抽象原则（SAP）。读者可以自行结合之前的内容来匹配每个原则所适用的场景以及背后的原因。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap20. BUSINESS RULES 业务逻辑\n\n![](../../images/books/架构整洁之道/CH-UN20.jpg)\n\nIf we are going to divide our application into business rules and plugins, we’d better get a good grasp on just what business rules actually are. It turns out there are several different kinds.\n\n> 如果我们要将自己的应用程序划分为业务逻辑和插件两部分，就必须更仔细地了解业务逻辑究竟是什么它到底有几种类型。\n\nStrictly speaking, business rules are rules or procedures that make or save the business money. Very strictly speaking, these rules would make or save the business money, irrespective of whether they were implemented on a computer. They would make or save money even if they were executed manually.\n\n> 严格地讲，业务逻辑就是程序中那些真正用于赚钱或省钱的业务逻辑与国产。更严格地讲，无论这些业务逻辑是在计算机上实现的，还是人工执行的，它们在省钱/赚钱上的作用都是一样的。\n\nThe fact that a bank charges N% interest for a loan is a business rule that makes the bank money. It doesn’t matter if a computer program calculates the interest, or if a clerk with an abacus calculates the interest.\n\n> 例如，银张行要对借贷收取 N% 利息这个逻辑就是银行获取收入方面的一条业务逻辑，对它来说，我们通过计算机来计算利息，还是让一个银行职员用计算器来计算利息并不重要。\n\nWe shall call these rules Critical Business Rules, because they are critical to the business itself, and would exist even if there were no system to automate them.\n\n> 我们通常称这些逻辑为“关键业务逻辑”，因为它们是一项业务的关键部分，不管有没有自动化系统来执行这项业务，这—点是不会改变的。\n\nCritical Business Rules usually require some data to work with. For example, our loan requires a loan balance, an interest rate, and a payment schedule.\n\n> “关键业务逻辑”通常会需要处理一些数据，例如，在借贷的业务逻辑中，我们需要知道借贷的数量、利率以及还款日程。\n\nWe shall call this data Critical Business Data. This is the data that would exist even if the system were not automated.\n\n> 我们将这些数据称为“关键业务数据”，这是因为这些数据无论自动化程序存在与否，都必须要存在。\n\nThe critical rules and critical data are inextricably bound, so they are a good candidate for an object. We’ll call this kind of object an Entity.1\n\n> 关键业务逻辑和关键业务数据是紧密相关的，所以它们很适合被放在同一个对象中处理。我们将这种对象称为“业务实体（Entity）”。\n\n## ENTITIES 业务实体\n\nAn Entity is an object within our computer system that embodies a small set of critical business rules operating on Critical Business Data. The Entity object either contains the Critical Business Data or has very easy access to that data. The interface of the Entity consists of the functions that implement the Critical Business Rules that operate on that data.\n\n> 业务实体实际上就是计算机系统中的一种对象，这种对象中包含了一系列用于操作关键数据的业务逻辑。这些实体对象要么直接包含关键业务数据，要么可以很容易地访问这些数据。业务实体的接口层则是由那些实现关键业务逻辑、操作关键业务数据的函数组成的。\n\nFor example, Figure 20.1 shows what our Loan entity might look like as a class in UML. It has three pieces of Critical Business Data, and presents three related Critical Business Rules at its interface.\n\n> 例如，在图 20.1 中，我们看到的是一个对应于借贷业务的实体类 Loan 的 UML 图。如你所见，该类中包含了三个关键业务数据，以及三个代表了其关键业务逻辑的接口。\n\n<Figures figure=\"20-1\">Loan entity as a class in UML</Figures>\n\nWhen we create this kind of class, we are gathering together the software that implements a concept that is critical to the business, and separating it from every other concern in the automated system we are building. This class stands alone as a representative of the business. It is unsullied with concerns about databases, user interfaces, or third-party frameworks. It could serve the business in any system, irrespective of how that system was presented, or how the data was stored, or how the computers in that system were arranged. The Entity is pure business and nothing else.\n\n> 当我们创建这样一个类时，其实就是在将软件中具体实现了该关键业务的部分聚合在一起，将其与自动化系统中我们所构建的其他部分隔离区分。这个类独自代表了整个业务逻辑，它与数据库、用户界面、第三方框架等内容无关。该类可以在任何一个系统中提供与其业务逻辑相关的服务，它不会去管这个系统是如何呈现给用户的，数据是如何存储的，或者是以何种方式运行的。总而言之，业务实体这个概念中应该只有业务逻辑，没有别的。\n\nSome of you may be concerned that I called it a class. Don’t be. You don’t need to use an object-oriented language to create an Entity. All that is required is that you bind the Critical Business Data and the Critical Business Rules together in a single and separate software module.\n\n> 有些读者可能会担心我在这里把业务实体解释成一个类。不是这样的，业务实体不一定非要用面向对象编程语言的类来实现。业务实体这个概念只要求我们将关键业务数据和关键业务逻辑绑定在一个独立的软件模块内。\n\n## USE CASES 用例\n\nNot all business rules are as pure as Entities. Some business rules make or save money for the business by defining and constraining the way that an automated system operates. These rules would not be used in a manual environment, because they make sense only as part of an automated system.\n\n> 并不是所有的业务逻辑都是一个纯粹的业务实体。例如，有些业务逻辑是通过定义或限制自动化系统的运行方式来实现赚钱或省钱的业务的。这些业务逻辑就不能靠人工来执行，它们只有作为自动化系统的一部分时才有意义。\n\nFor example, imagine an application that is used by bank officers to create a new loan. The bank may decide that it does not want the loan officers to offer loan payment estimates until they have first gathered, and validated, contact information and ensured that the candidate’s credit score is 500 or higher. For this reason, the bank may specify that the system will not proceed to the payment estimation screen until the contact information screen has been filled out and verified, and the credit score has been confirmed to be greater than the cutoff.\n\n> 例如，假设我们现在有一个银行职员们用来新建借贷的应用程序，银行可能设计的业务逻辑是，银行职员必须首先收集、验证客户的联系信息，确保客户的信用值在 500 以上，然后才允许向用户提供借贷还款的预估值。因此，银行就必须要求在设计其计算机系统时确保两件事：首先，客户必须能通过屏幕填写所有的联系信息并且让其通过相关验证；其次，客户只有在其信用值大于既定阈值时才能进入还款预估页。\n\nThis is a use case.2 A use case is a description of the way that an automated system is used. It specifies the input to be provided by the user, the output to be returned to the user, and the processing steps involved in producing that output. A use case describes application-specific business rules as opposed to the Critical Business Rules within the Entities.\n\n> 我们在上面所描述的就是一个用例（user case）。用例本质上就是关于如何操作一个自动化系统的描述，它定义了用户需要提供的输入数据、用户应该得到的输出信息以及产生输出所应该采取的处理步骤。当然，用例所描述的是某种特定应用情景下的业务逻辑，它并非业务实体中所包含的关键业务逻辑。\n\nFigure 20.2 shows an example of a use case. Notice that in the last line it mentions the Customer. This is a reference to the Customer entity, which contains the Critical Business Rules that govern the relationship between the bank and its customers.\n\n> 下面，让我们来看看图 20.2 中的这个用例。请注意，图 20.2 的最后一行中提到的“客户”，这里的客户是指代表客户的业务实体，其中包含了处理银行与客户之间关系的关键业务逻辑。\n\n<Figures figure=\"20-2\">Example use case</Figures>\n\nUse cases contain the rules that specify how and when the Critical Business Rules within the Entities are invoked. Use cases control the dance of the Entities.\n\n> 如上所示，用例中包含了对如何调用业务实体中的关键业务逻辑的定义。简而言之，用例控制着业务实体之间的交互方式。\n\nNotice also that the use case does not describe the user interface other than to informally specify the data coming in from that interface, and the data going back out through that interface. From the use case, it is impossible to tell whether the application is delivered on the web, or on a thick client, or on a console, or is a pure service.\n\n> 除此之外，这里还应该注意，用例除非正式地描述了数据流入/流出接口以外，并不详细描述用户界面。也就是说，如果我们只看用例，是没有办法分辨出系统是在 Web 平台上交付的，还是交付了某种常客门端；或后是以命令行模式交付的，还是以一个内部服务模式交付的。\n\nThis is very important. Use cases do not describe how the system appears to the user. Instead, they describe the application-specific rules that govern the interaction between the users and the Entities. How the data gets in and out of the system is irrelevant to the use cases.\n\n> 这是非常重要的。用例并不描述系统与用户之间的接口，它只描述该应用在某些特定情境下的业务逻辑，这些业务逻辑所规范的是用户与业务实体之间的交互方式，它与数据流入/流出系统的方式无关。\n\nA use case is an object. It has one or more functions that implement the application-specific business rules. It also has data elements that include the input data, the output data, and the references to the appropriate Entities with which it interacts.\n\n> 在我们的系统中，用例本身也是一个对象，该对象中包含了一个或多个实现了特定应用情景的业务逻辑函数。当然除此之外，用例对象中也包含了输入数据、输出数据以及相关业务实体的引用，以方便调用。\n\nEntities have no knowledge of the use cases that control them. This is another example of the direction of the dependencies following the Dependency Inversion Principle. High-level concepts, such as Entities, know nothing of lower-level concepts, such as use cases. Instead, the lower-level use cases know about the higher-level Entities.\n\n> 当然，业务实体并不会知道是哪个业务用例在控制它们，这也是依赖反转原则（DIP）的另一个应用情景。也就是像业务实体这样的高层概念是无须了解像用例这样的低层概念的。反之，低层的业务用例却需要了解高层的业务实体。\n\nWhy are Entities high level and use cases lower level? Because use cases are specific to a single application and, therefore, are closer to the inputs and outputs of that system. Entities are generalizations that can be used in many different applications, so they are farther from the inputs and outputs of the system. Use cases depend on Entities; Entities do not depend on use cases.\n\n> 那么，为什么业务实体属于高层概念，而用例属于低层概念呢？因为用例描述的是一个特定的应用情景，这样一来，用例必然会更靠近系统的输入和输出。而业务实体是一个可以适用于多个应用情景的一般化概念，相对地离系统的输入和输出更远。所以，用例依赖于业务实体，而业务实体并不依赖于用例。\n\n## REQUEST AND RESPONSE MODELS 请求和响应模型\n\nUse cases expect input data, and they produce output data. However, a well-formed use case object should have no inkling about the way that data is communicated to the user, or to any other component. We certainly don’t want the code within the use case class to know about HTML or SQL!\n\n> 在通常情况下，用例会接收输入数据，并产生输出数据。但在一个设计良好的架构中，用例对象通常不应该知道数据展现给用户或者其他组件的方式。很显然我们当然不会希望这些用例类中的代码出现 HTML 和 SQL。\n\nThe use case class accepts simple request data structures for its input, and returns simple response data structures as its output. These data structures are not dependent on anything. They do not derive from standard framework interfaces such as HttpRequest and HttpResponse. They know nothing of the web, nor do they share any of the trappings of whatever user interface might be in place.\n\n> 因此，用例类所接收的输入应该是一个简单的请求性数据结构，而返回输出的应该是一个简单的响应性数据结构。这些数据结构中不应该存在任何依赖关系，它们并不派生自 HttpRequest 和 HttpRespons 这样的标准框架接口。这些数据接口应该与 Web 无关，也不应该了解任何有关用户界面的细节。\n\nThis lack of dependencies is critical. If the request and response models are not independent, then the use cases that depend on them will be indirectly bound to whatever dependencies the models carry with them.\n\n> 这种独立性非常关键，如果这里的请求和响应模型不是完全独立的，那么用到这些模型的用例就会依赖于这些模型所带来的各种依赖关系。\n\nYou might be tempted to have these data structures contain references to Entity objects. You might think this makes sense because the Entities and the request/response models share so much data. Avoid this temptation! The purpose of these two objects is very different. Over time they will change for very different reasons, so tying them together in any way violates the Common Closure and Single Responsibility Principles. The result would be lots of tramp data, and lots of conditionals in your code.\n\n> 可能有些读者会选择直接在数据结构中使用对业务实体对象的引用。毕竟，业务请求响应模型之间有很多相同的数据。但请一定不要这样做！这两个对象存在的意义是非常、非常不一样的。随着时间的推移，这两个对象会以不同的原因、不同的速率发生变更。所以将它们以任何方式整合在一起都是对共同闭包原则（CCP）和单一职责原则（SRP）的违反。这样做的后果，往往会导致代码中出现很多分支判断语句和中间数据。\n\n## CONCLUSION 本章小结\n\nBusiness rules are the reason a software system exists. They are the core functionality. They carry the code that makes, or saves, money. They are the family jewels.\n\n> 业务逻辑是一个软件系统存在的意义，它们属于核心功能，是系统用来赚钱或省钱的那部分代码，是整个系统中的皇冠明珠。\n\nThe business rules should remain pristine, unsullied by baser concerns such as the user interface or database used. Ideally, the code that represents the business rules should be the heart of the system, with lesser concerns being plugged in to them. The business rules should be the most independent and reusable code in the system.\n\n> 这些业务逻辑应该保持纯净，不要掺杂用户界面或者所使用的数据库相关的东西。在理想情况下，这部分代表业务逻辑的代码应该是整个系统的核心，其他低层概念的实现应该以插件形式接入系统中。业务逻辑应该是系统中最独立、复用性最高的代码。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap21. SCREAMING ARCHITECTURE 尖叫的软件架构\n\n![](../../images/books/架构整洁之道/CH-UN21.jpg)\n\nImagine that you are looking at the blueprints of a building. This document, prepared by an architect, provides the plans for the building. What do these plans tell you?\n\n> 假设我们现在正在查看某个建筑的设计架构图，那么在这个反映建筑设计师精心设计成果的文件中，究竟应该是怎样的架构图呢？\n\nIf the plans you are viewing are for a single-family residence, then you’ll likely see a front entrance, a foyer leading to a living room, and perhaps a dining room. There will likely be a kitchen a short distance away, close to the dining room. Perhaps there is a dinette area next to the kitchen, and probably a family room close to that. When you looked at those plans, there would be no question that you were looking at a single family home. The architecture would scream: “HOME.”\n\n> 如果这是一幅单户住宅的建筑架构图，那么我们很可能会先看到一个大门，然后是一条连接到起居室的通道，同时可能还会看到一个餐厅。接着，距离餐厅不远处应该会有一个厨房，可能厨房附件还会有一个非正式用餐区，或一个亲子房。当我们阅读这个架构图时，应该不会怀疑这是一个单户住宅。几乎整个建筑设计都在尖叫着告诉你：这是一个“家”。\n\nNow suppose you were looking at the architecture of a library. You would likely see a grand entrance, an area for check-in/out clerks, reading areas, small conference rooms, and gallery after gallery capable of holding bookshelves for all the books in the library. That architecture would scream: “LIBRARY.”\n\n> 假设我们阅读的是一幅图书馆的建筑设计图，情况也差不多。我们应该会先看到一个超大入口，然后是一个用于签到/签出的办公区，接下来是阅读区、小型会议室，以及一排排的书架区。同样，几乎整个建筑设计都在尖叫着跟你说：这是一个“图书馆”。\n\nSo what does the architecture of your application scream? When you look at the top-level directory structure, and the source files in the highest-level package, do they scream “Health Care System,” or “Accounting System,” or “Inventory Management System”? Or do they scream “Rails,” or “Spring/Hibernate,” or “ASP”?\n\n> 那么，我们的应用程序的架构设计又会“喊”些什么呢？当我们查看它的顶层结构目录，以及顶层软件包中的源代码时，它们究竟是在喊“健康管理系统”“账务系统” “库存管理系统”，还是在喊：“Rails” “Spring/Hibernate” “ASP” 这样的技术名词呢？\n\n## THE THEME OF AN ARCHITECTURE 架构设计的主题\n\nGo back and read Ivar Jacobson’s seminal work on software architecture: Object Oriented Software Engineering. Notice the subtitle of the book: A Use Case Driven Approach. In this book Jacobson makes the point that software architectures are structures that support the use cases of the system. Just as the plans for a house or a library scream about the use cases of those buildings, so should the architecture of a software application scream about the use cases of the application.\n\n> 在这里，再次推荐读者仔细阅读 Ivar Jacobson 关于软件架构设计的那本书：Object Oriented Software Engineering，请读者注意这本书的副标题 A Use Case Driven Approach（业务用例驱动的设计方式）。在这本书中，Jacobson 提出了一个观点：软件的系统架构应该为该系统的用例提供支持。这就像住宅和图书馆的建筑计划满篇都在非常明显地凸显这些建筑的用例一样，软件系统的架构设计图也应该非常明确地凸显该应用程序会有哪些用例。\n\nArchitectures are not (or should not be) about frameworks. Architectures should not be supplied by frameworks. Frameworks are tools to be used, not architectures to be conformed to. If your architecture is based on frameworks, then it cannot be based on your use cases.\n\n> 架构设计不是（或者说不应该是）与框架相关的，这件事不应该是基于框架来完成的。对于我们来说，框架只是一个可用的工具和手段，而不是一个架构所规范的内容。如果我们的架构是基于框架来设计的，它就不能基于我们的用例来设计了。\n\n## THE PURPOSE OF AN ARCHITECTURE 架构设计的核心目标\n\nGood architectures are centered on use cases so that architects can safely describe the structures that support those use cases without committing to frameworks, tools, and environments. Again, consider the plans for a house. The first concern of the architect is to make sure that the house is usable—not to ensure that the house is made of bricks. Indeed, the architect takes pains to ensure that the homeowner can make decisions about the exterior material (bricks, stone, or cedar) later, after the plans ensure that the use cases are met.\n\n> 一个良好的架构设计应该围绕着用例来展开，这样的架构设计可以在脱离框架、工具以及使用环境的情况下完整地描述用例。这就好像一个住宅建筑设计的首要目标应该是满足住宅的使用需求，而不是确保一定要用砖来构建这个房子。架构师应该花费更多的精力来确保该架构的设计在满足用例需求的情况下，尽可能地允许用户能自由地选择建筑材料（砖头、石料或者木材）。\n\nA good software architecture allows decisions about frameworks, databases, web servers, and other environmental issues and tools to be deferred and delayed. Frameworks are options to be left open. A good architecture makes it unnecessary to decide on Rails, or Spring, or Hibernate, or Tomcat, or MySQL, until much later in the project. A good architecture makes it easy to change your mind about those decisions, too. A good architecture emphasizes the use cases and decouples them from peripheral concerns.\n\n> 而且，良好的架构设计应该尽可能地允许用户推迟和延后决定釆用什么框架、数据库、Web 服务以及其他与环境相关的工具。框架应该是一个可选项，良好的架构设计应该允许用户在项目后期再决定是否采用 Rails、Spring、Hibernate、Tomcat、MySQL 这些工具。同时，良好的架构设计还应该让我们很容易改变这些决定。总之，良好的架构设计应该只关注用例，并能将它们与其他的周边因素隔离。\n\n## BUT WHAT ABOUT THE WEB? 那 Web 呢\n\nIs the web an architecture? Does the fact that your system is delivered on the web dictate the architecture of your system? Of course not! The web is a delivery mechanism—an IO device—and your application architecture should treat it as such. The fact that your application is delivered over the web is a detail and should not dominate your system structure. Indeed, the decision that your application will be delivered over the web is one that you should defer. Your system architecture should be as ignorant as possible about how it will be delivered. You should be able to deliver it as a console app, or a web app, or a thick client app, or even a web service app, without undue complication or change to the fundamental architecture.\n\n> Web 究竟是不是一种架构？如果我们的系统需要以 Web 形式来交付，这是否意味着我们只能采用某种系统架构？当然不是！Web 只是一种交付手段——一种 IO 设备——这就是它在应用程序的架构设计中的角色。换句话说，应用程序采用 Web 方 式来交付只是一个实现细节，这不应该主导整个项目的结构设计。事实上，关于一个应用程序是否应该以 Web 形式来交付这件事，它本身就应该是一个被推迟和延后的决策。一个系统应该尽量保持它与交付方式之间的无关性。在不更改基础架构设计的情况下，我们应该可以将一个应用程序交付成命令行程序、Web 程序、富客户端程序、Web 服务程序等任何一种形式的程序。\n\n## FRAMEWORKS ARE TOOLS, NOT WAYS OF LIFE 框架是工具而不是生活信条\n\nFrameworks can be very powerful and very useful. Framework authors often believe very deeply in their frameworks. The examples they write for how to use their frameworks are told from the point of view of a true believer. Other authors who write about the framework also tend to be disciples of the true belief. They show you the way to use the framework. Often they assume an all-encompassing, all-pervading, let-the-framework-do-everything position.\n\n> 当然，框架通常可以是非常强大、非常有用的。但框架作者往往对自己写出的框架有着极深的信念，他们所写出来的使用手册一般都是从如何成为该框架的虔诚信徒的角度来描绘如何使用这个框架的。甚至这些框架的使用者所写的教程也会出现这种传教士模式。他们会告诉你某个框架是能包揽一切、超越一切、解决一切问题的存在。\n\nThis is not the position you want to take.\n\n> 这不应该成为你的观点。\n\nLook at each framework with a jaded eye. View it skeptically. Yes, it might help, but at what cost? Ask yourself how you should use it, and how you should protect yourself from it. Think about how you can preserve the use-case emphasis of your architecture. Develop a strategy that prevents the framework from taking over that architecture.\n\n> 我们一定要带着怀疑的态度审视每一个框架。是的，采用框架可能会很有帮助，但采用它们的成本呢？我们一定要懂得权衡如何使用一个框架，如何保护自己。无论如何，我们需要仔细考虑如何能保持对系统用例的关注，避免让框架主导我们的架构设计。\n\n## TESTABLE ARCHITECTURES 可测试的架构设计\n\nIf your system architecture is all about the use cases, and if you have kept your frameworks at arm’s length, then you should be able to unit-test all those use cases without any of the frameworks in place. You shouldn’t need the web server running to run your tests. You shouldn’t need the database connected to run your tests. Your Entity objects should be plain old objects that have no dependencies on frameworks or databases or other complications. Your use case objects should coordinate your Entity objects. Finally, all of them together should be testable in situ, without any of the complications of frameworks.\n\n> 如果系统架构的所有设计都是围绕着用例来展开的，并且在使用框架的问题上保持谨慎的态度，那么我们就应该可以在不依赖任何框架的情况下针对这些用例进行单元测试。另外，我们在运行测试的时候不应该运行 Web 服务，也不应该需要连接数据库。我们测试的应该只是一个简单的业务实体对象，没有任何与框架、数据库相关的依赖关系。总而言之，我们应该通过用例对象来调度业务实体对象，确保所有的测试都不需要依赖框架。\n\n## CONCLUSION 本章小结\n\nYour architecture should tell readers about the system, not about the frameworks you used in your system. If you are building a health care system, then when new programmers look at the source repository, their first impression should be, “Oh, this is a heath care system.” Those new programmers should be able to learn all the use cases of the system, yet still not know how the system is delivered. They may come to you and say:\n\n> 一个系统的架构应该着重于展示系统本身的设计，而并非该系统所使用的框架。如果我们要构建的是一个医疗系统，新来的程序员第一次看到其源码时就应该知道这是一个医疗系统。新来的程序员应该先了解该系统的用例，而非系统的交付方式。他们可能会走过来问你：\n\n“We see some things that look like models—but where are the views and controllers?”\n\n> \"我看到了一些看起来像是模型的代码——但它们的视图和控制器在哪里？”\n\nAnd you should respond:\n\n> 这时你的回答应该是：\n\n“Oh, those are details that needn’t concern us at the moment. We’ll decide about them later.”\n\n> “哦，我们现在先不考虑这些细节问题，回头再来决定应该怎么做。”\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap22. THE CLEAN ARCHITECTURE 整洁架构\n\n![](../../images/books/架构整洁之道/CH-UN22.jpg)\n\nOver the last several decades we’ve seen a whole range of ideas regarding the architecture of systems. These include:\n\n> 在过去的几十年中，我们曾见证过一系列关于系统架构的想法被提出，列举如下。\n\n- Hexagonal Architecture (also known as Ports and Adapters), developed by Alistair Cockburn, and adopted by Steve Freeman and Nat Pryce in their wonderful book Growing Object Oriented Software with Tests\n- DCI from James Coplien and Trygve Reenskaug\n- BCE, introduced by Ivar Jacobson from his book Object Oriented Software Engineering: A Use-Case Driven Approach\n\n---\n\n> - 六边形架构 （Hexagonal Architecture）（也称为端口与适配器架构，Ports and Adpaters）： 该架构由 Alistair Cockburn 首先提出。Steve Freeman 和 Nat Pryce 在他们合写的著作 Growing Object oriented software with Tests 一书中对该架构做了隆重的推荐。\n> - DCI 架构：由 James Coplien 和 Trygve Reenskaug 首先提出。\n> - BCE 架构：由 Ivar Jacobson 在他的 Object Oriented Software Engineer： A Use-Case Driven Approach 一书中首先提出。\n\nAlthough these architectures all vary somewhat in their details, they are very similar. They all have the same objective, which is the separation of concerns. They all achieve this separation by dividing the software into layers. Each has at least one layer for business rules, and another layer for user and system interfaces.\n\n> 虽然这些架构在细节上各有不同，但总体来说是非常相似的。它们都具有同一个设计目标：按照不同关注点对软件进行切割。也就是说，这些架构都会将软件切割成不同的层，至少有一层是只包含该软件的业务逻辑的，而用户接口、系统接口则属于其他层。\n\nEach of these architectures produces systems that have the following characteristics:\n\n> 按照这些架构设计出来的系统，通常都具有以下特点。\n\n- Independent of frameworks. The architecture does not depend on the existence of some library of feature-laden software. This allows you to use such frameworks as tools, rather than forcing you to cram your system into their limited constraints.\n- Testable. The business rules can be tested without the UI, database, web server, or any other external element.\n- Independent of the UI. The UI can change easily, without changing the rest of the system. A web UI could be replaced with a console UI, for example, without changing the business rules.\n- Independent of the database. You can swap out Oracle or SQL Server for Mongo, BigTable, CouchDB, or something else. Your business rules are not bound to the database.\n- Independent of any external agency. In fact, your business rules don’t know anything at all about the interfaces to the outside world.\n\n---\n\n> - 独立于框架：这些系统的架构并不依赖某个功能丰富的框架之中的某个函数。框架可以被当成工具来使用，但不需要让系统来适应框架。\n> - 可被测试：这些系统的业务逻辑可以脱离 UI、数据库、Web 服务以及其他的外部元素来进行测试。\n> - 独立于 UI：这些系统的 UI 变更起来很容易，不需要修改其他的系统部分。例如，我们可以在不修改业务逻辑的前提下将一个系统的 UI 由 Web 界面替换成命令行界面。\n> - 独立于数据库：我们可以轻易将这些系统使用的 Oracle 、SQL Server 替换成 Mongo、BigTable、CouchDB 之类的数据库。因为业务逻辑与数据库之间已经完成了解耦。\n> - 独立于任何外部机构：这些系统的业务逻辑并不需要知道任何其他外部接口的存在。\n\nThe diagram in Figure 22.1 is an attempt at integrating all these architectures into a single actionable idea.\n\n> 下面我们要通过图 22.1 将上述所有架构的设计理念综合成为一个独立的理念。\n\n<Figures figure=\"22-1\">The clean architecture</Figures>\n\n## THE DEPENDENCY RULE 依赖关系规则\n\nThe concentric circles in Figure 22.1 represent different areas of software. In general, the further in you go, the higher level the software becomes. The outer circles are mechanisms. The inner circles are policies.\n\n> 图 22.1 中的同心圆分别代表了软件系统中的不同层次，通常越靠近中心，其所在的软件层次就越高。基本上，外层圆代表的是机制，内层圆代表的是策略。\n\nThe overriding rule that makes this architecture work is the Dependency Rule:\n\n> 当然这其中有一条贯穿整个架构设计的规则，即它的依赖关系规则：\n\nSource code dependencies must point only inward, toward higher-level policies.\n\n> 源码中的依赖关系必须只指向同心圆的内层，即由低层机制指向高层策略。\n\nNothing in an inner circle can know anything at all about something in an outer circle. In particular, the name of something declared in an outer circle must not be mentioned by the code in an inner circle. That includes functions, classes, variables, or any other named software entity.\n\n> 换句话说，就是任何属于内层圆中的代码都不应该牵涉外层圆中的代码，尤其是内层圆中的代码不应该引用外层圆中代码所声明的名字，包括函数、类、变量以及一切其他有命名的软件实体。\n\nBy the same token, data formats declared in an outer circle should not be used by an inner circle, especially if those formats are generated by a framework in an outer circle. We don’t want anything in an outer circle to impact the inner circles.\n\n> 同样的道理，外层圆中使用的数据格式也不应该被内层圆中的代码所使用，尤其是当数据格式是由外层圆的框架所生成。总之，我们不应该让外层圆中发生的任何变更影响到内层圆的代码。\n\n### ENTITIES 业务实体\n\nEntities encapsulate enterprise-wide Critical Business Rules. An entity can be an object with methods, or it can be a set of data structures and functions. It doesn’t matter so long as the entities can be used by many different applications in the enterprise.\n\n> 业务实体这一层中封装的是整个系统的关键业务逻辑，一个业务实体既可以是一个带有方法的对象，也可以是一组数据结构和函数的集合。无论如何，只要它能被系统中的其他不同应用复用就可以。\n\nIf you don’t have an enterprise and are writing just a single application, then these entities are the business objects of the application. They encapsulate the most general and high-level rules. They are the least likely to change when something external changes. For example, you would not expect these objects to be affected by a change to page navigation or security. No operational change to any particular application should affect the entity layer.\n\n> 如果我们在写的不是一个大型系统，而是一个单一应用的话，那么我们的业务实体就是该应用的业务对象。这些对象封装了该应用中最通用、最高层的业务逻辑，它们应该属于系统中最不容易受外界影响而变动的部分。例如，一个针对页面导航方式或者安全问题的修改不应该触及这些对象，一个针对应用在运行时的行为所做的变更也不应该影响业务实体。\n\n### USE CASES 用例\n\nThe software in the use cases layer contains application-specific business rules. It encapsulates and implements all of the use cases of the system. These use cases orchestrate the flow of data to and from the entities, and direct those entities to use their Critical Business Rules to achieve the goals of the use case.\n\n> 软件的用例层中通常包含的是特定应用场景下的业务逻辑，这里面封装并实现了整个系统的所有用例。这些用例引导了数据在业务实体之间的流入/流出，并指挥着业务实体利用其中的关键业务逻辑来实现用例的设计目标。\n\nWe do not expect changes in this layer to affect the entities. We also do not expect this layer to be affected by changes to externalities such as the database, the UI, or any of the common frameworks. The use cases layer is isolated from such concerns.\n\n> 我们既不希望在这一层所发生的变更影响业务实体，同时也不希望这一层受外部因素（譬如数据库、UI、常见框架）的影响。用例层应该与它们都保持隔离。\n\nWe do, however, expect that changes to the operation of the application will affect the use cases and, therefore, the software in this layer. If the details of a use case change, then some code in this layer will certainly be affected.\n\n> 然而，我们知道应用行为的变化会影响用例本身，因此一定会影响用例层的代码。因为如果一个用例的细节发生了变化，这一层中的某些代码自然要受到影响。\n\n### INTERFACE ADAPTERS 接口适配器\n\nThe software in the interface adapters layer is a set of adapters that convert data from the format most convenient for the use cases and entities, to the format most convenient for some external agency such as the database or the web. It is this layer, for example, that will wholly contain the MVC architecture of a GUI. The presenters, views, and controllers all belong in the interface adapters layer. The models are likely just data structures that are passed from the controllers to the use cases, and then back from the use cases to the presenters and views.\n\n> 软件的接口适配器层中通常是一组数据转换器，它们负责将数据从对用例和业务实体而言最方便操作的格式，转化成外部系统（譬如数据库以及 Web）最方便操作的格式。例如，这一层中应该包含整个 GUI MVC 框架。展示器、视图、控制器都应该属于接口适配器层。而模型部分则应该由控制器传递给用例，再由用例传回展示器和视图。\n\nSimilarly, data is converted, in this layer, from the form most convenient for entities and use cases, to the form most convenient for whatever persistence framework is being used (i.e., the database). No code inward of this circle should know anything at all about the database. If the database is a SQL database, then all SQL should be restricted to this layer—and in particular to the parts of this layer that have to do with the database.\n\n> 同样的，这一层的代码也会负责将数据从对业务实体与用例而言最方便操作的格式，转化为对所采用的持久性框架（譬如数据库）最方便的格式。总之，在从该层再向内的同心圆中，其代码就不应该依赖任何数据库了。譬如说，如果我们采用的是 SQL 数据库，那么所有的 SQL 语句都应该被限制在这一层的代码中——而且是仅限于那些需要操作数据库的代码。\n\nAlso in this layer is any other adapter necessary to convert data from some external form, such as an external service, to the internal form used by the use cases and entities.\n\n> 当然，这一层的代码也会负责将来自外部服务的数据转换成系统内用例与业务实体所需的格式。\n\n### FRAMEWORKS AND DRIVERS 框架与驱动程序\n\nThe outermost layer of the model in Figure 22.1 is generally composed of frameworks and tools such as the database and the web framework. Generally you don’t write much code in this layer, other than glue code that communicates to the next circle inward.\n\n> 图 22.1 中最外层的模型层一般是由工具、数据库、Web 框架等组成的。在这一层中，我们通常只需要编写一些与内层沟通的黏合性代码。\n\nThe frameworks and drivers layer is where all the details go. The web is a detail. The database is a detail. We keep these things on the outside where they can do little harm.\n\n> 框架与驱动程序层中包含了所有的实现细节。Web 是一个实现细节，数据库也是一个实现细节。我们将这些细节放在最外层，这样它们就很难影响到其他层了。\n\n### ONLY FOUR CIRCLES? 只有四层吗\n\nThe circles in Figure 22.1 are intended to be schematic: You may find that you need more than just these four. There’s no rule that says you must always have just these four. However, the Dependency Rule always applies. Source code dependencies always point inward. As you move inward, the level of abstraction and policy increases. The outermost circle consists of low-level concrete details. As you move inward, the software grows more abstract and encapsulates higher-level policies. The innermost circle is the most general and highest level.\n\n> 图 22.1 中所显示的同心圆只是为了说明架构的结构，真正的架构很可能会超过四层。并没有某个规则约定一个系统的架构有且只能有四层。然而，这其中的依赖关系原则是不变的。也就是说，源码层面的依赖关系一定要指向同心圆的内侧。层次越往内，其抽象和策略的层次越高，同时软件的抽象程度就越高，其包含的高层策略就越多。最内层的圆中包含的是最通用、最高层的策略，最外层的圆包含的是最具体的实现细节。\n\n### CROSSING BOUNDARIES 跨越边界\n\nAt the lower right of the diagram in Figure 22.1 is an example of how we cross the circle boundaries. It shows the controllers and presenters communicating with the use cases in the next layer. Note the flow of control: It begins in the controller, moves through the use case, and then winds up executing in the presenter. Note also the source code dependencies: Each points inward toward the use cases.\n\n> 在图 22.1 的右下侧，我们示范的是在架构中跨边界的情况。具体来说就是控制器、展示器与下一层的用例之间的通信过程。请注意这里控制流的方向：它从控制器开始，穿过用例，最后执行展示器的代码。但同时我们也该注意到，源码中的依赖方向却都是向内指向用例的。\n\nWe usually resolve this apparent contradiction by using the Dependency Inversion Principle. In a language like Java, for example, we would arrange interfaces and inheritance relationships such that the source code dependencies oppose the flow of control at just the right points across the boundary.\n\n> 这里，我们通常釆用依赖反转原则（DIP）来解决这种相反性。例如，在 Java 这一类的语言中，可以通过调整代码中的接口和继承关系，利用源码中的依赖关系来限制控制流只能在正确的地方跨越架构边界。\n\nFor example, suppose the use case needs to call the presenter. This call must not be direct because that would violate the Dependency Rule: No name in an outer circle can be mentioned by an inner circle. So we have the use case call an interface (shown in Figure 22.1 as “use case output port”) in the inner circle, and have the presenter in the outer circle implement it.\n\n> 假设某些用例代码需要调用展示器，这里一定不能直接调用，因为这样做会违反依赖关系原则：内层圆中的代码不能引用其外层的声明。我们需要让业务逻辑代码调用一个内层接口（图 22.1 中的“用例输出端”），并让展示器来负责实现这个接口。\n\nThe same technique is used to cross all the boundaries in the architectures. We take advantage of dynamic polymorphism to create source code dependencies that oppose the flow of control so that we can conform to the Dependency Rule, no matter which direction the flow of control travels.\n\n> 我们可以采用这种方式跨越系统中所有的架构边界。利用动态多态技术，我们将源码中的依赖关系与控制流的方向进行反转。不管控制流原本的方向如何，我们都可以让它遵守架构的依赖关系规则。\n\n### WHICH DATA CROSSES THE BOUNDARIES 哪些数据会跨越边界\n\nTypically the data that crosses the boundaries consists of simple data structures. You can use basic structs or simple data transfer objects if you like. Or the data can simply be arguments in function calls. Or you can pack it into a hashmap, or construct it into an object. The important thing is that isolated, simple data structures are passed across the boundaries. We don’t want to cheat and pass Entity objects or database rows. We don’t want the data structures to have any kind of dependency that violates the Dependency Rule.\n\n> 一般来说，会跨越边界的数据在数据结构上都是很简单的。如果可以的话，我们会尽量采用一些基本的结构体或简单的可传输数据对象。或者直接通过函数调用的参数来传递数据。另外，我们也可以将数据放入哈希表，或整合成某种对象。这里最重要的是这个跨边界传输的对象应该有一个独立、简单的数据结构。总之，不要投机取巧直接传递业务实体或数据库记录对象。同时，这些传递的数据结构中也不应该存在违反依赖规则的依赖关系。\n\nFor example, many database frameworks return a convenient data format in response to a query. We might call this a “row structure.” We don’t want to pass that row structure inward across a boundary. Doing so would violate the Dependency Rule because it would force an inner circle to know something about an outer circle.\n\n> 例如，很多数据库框架会返回一个便于查询的结果对象，我们称之为“行结构体”。这个结构体不应该跨边界向架构的内层传递。因为这等于让内层的代码引用外层代码，违反依赖规则。\n\nThus, when we pass data across a boundary, it is always in the form that is most convenient for the inner circle.\n\n> 因此，当我们进行跨边界传输时，一定要采用内层最方便使用的形式。\n\n## A TYPICAL SCENARIO 一个常见的应用场景\n\nThe diagram in Figure 22.2 shows a typical scenario for a web-based Java system using a database. The web server gathers input data from the user and hands it to the Controller on the upper left. The Controller packages that data into a plain old Java object and passes this object through the InputBoundary to the UseCaseInteractor. The UseCaseInteractor interprets that data and uses it to control the dance of the Entities. It also uses the DataAccessInterface to bring the data used by those Entities into memory from the Database. Upon completion, the UseCaseInteractor gathers data from the Entities and constructs the OutputData as another plain old Java object. The OutputData is then passed through the OutputBoundary interface to the Presenter.\n\n> 接下来，我们将会在图 22.2 中看到一个基于 Web 的使用数据库的 Java 系统。在该系统中，Web 服务器会从用户那里收集信息，并将它们交给左上角的 controller。然后，controller 将这些信息包装成一个简单的 Java 对象，并让该对象穿越 InputBoundary 被传递到 UseCaseInteractor。接下来，我们会让 UseCaseInteractor 解析数据，并通过它来控制与 Entities 的交互。同时，我们还会用 DataAccessInterface 将 Entities 需要用到的数据从 Database 加载到内存中。随后，UseCaselnteractor 会负责从 Entities 收集数据，并将 OutputData 组装成另一个简单的 Java 对象。最后，OutputData 会穿越 OutputBoundary 被传递给 Presenter。\n\n<Figures figure=\"22-2\">A typical scenario for a web-based Java system utilizing a database</Figures>\n\nThe job of the Presenter is to repackage the OutputData into viewable form as the ViewModel, which is yet another plain old Java object. The ViewModel contains mostly Strings and flags that the View uses to display the data. Whereas the OutputData may contain Date objects, the Presenter will load the ViewModel with corresponding Strings already formatted properly for the user. The same is true of Currency objects or any other business-related data. Button and MenuItem names are placed in the ViewModel, as are flags that tell the View whether those Buttons and MenuItems should be gray.\n\n> 接下来，Presenter 的任务是将 OutPutData 重新打包成可展示的 ViewModel，这也是一个简单的 Java 对象。ViewModel 中基本上只包含字符串和一些 View 都会用到的开关数据。同时，OutputData 中可能会包含一些 D ate 对象，Presenter 会将其格式化成可对用户展示的字符串，并将其填充到 ViewModel 中。同理，Currency 对象和其他业务相关的数据也会经历类似的操作。如你所见，Button 和 Menuitems 的命名定义位于 ViewModel 中，并且其中还包括了用于告知 View 层 Button 和 Menuitems 是否可用的开关数据。\n\nThis leaves the View with almost nothing to do other than to move the data from the ViewModel into the HTML page.\n\n> 我们可以看出，View 除了将 ViewModel 中的数据转换成 HTML 格式之外，并没有其他功能。\n\nNote the directions of the dependencies. All dependencies cross the boundary lines pointing inward, following the Dependency Rule.\n\n> 最后，读者必须注意一下这里的依赖关系方向。所有跨边界的依赖线都是指向内的，这很好地遵守了架构的依赖关系规则。\n\n## CONCLUSION 本章小结\n\nConforming to these simple rules is not difficult, and it will save you a lot of headaches going forward. By separating the software into layers and conforming to the Dependency Rule, you will create a system that is intrinsically testable, with all the benefits that implies. When any of the external parts of the system become obsolete, such as the database, or the web framework, you can replace those obsolete elements with a minimum of fuss.\n\n> 如你所见，遵守上面这些简单的规范并不困难，这样做能在未来避免各种令人头疼的问题。通过将系统划分层次，并确保这些层次遵守依赖关系规则，就可以构建出一个天生可测试的系统，这其中的好处是不言而喻的。而且，当系统外层的这些数据库或 Web 框架过时的时候，我们还可以很轻松地替换它们。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap23. PRESENTERS AND HUMBLE OBJECTS 展示器和谦卑对象\n\n![](../../images/books/架构整洁之道/CH-UN23.jpg)\n\nIn Chapter 22, we introduced the notion of presenters. Presenters are a form of the Humble Object pattern, which helps us identify and protect architectural boundaries. Actually, the Clean Architecture in the last chapter was full of Humble Object implementations.\n\n> 在第 22 章中，我们引入了展示器（presenter）的概念，展示器实际上是采用谦卑对象（humble object）模式的一种形式，这种设计模式可以很好地帮助识别和系统架构的边界。事实上，第 22 章所介绍的整洁架构中就充满了大量谦卑对象的实现体。\n\n## THE HUMBLE OBJECT PATTERN 谦卑对象模式\n\nThe Humble Object pattern1 is a design pattern that was originally identified as a way to help unit testers to separate behaviors that are hard to test from behaviors that are easy to test. The idea is very simple: Split the behaviors into two modules or classes. One of those modules is humble; it contains all the hard-to-test behaviors stripped down to their barest essence. The other module contains all the testable behaviors that were stripped out of the humble object.\n\n> 谦卑对象模式最初的设计目的是帮助单元测试的编写者区分容易测试的行为与难以测试的行为，并将它们隔离。其设计思路非常简单，就是将这两类行为拆分成两组模块或类。其中一组模块被称为谦卑（Humble）组，包含了系统中所有难以 测试的行为，而这些行为已经被简化到不能再简化了。另一组模块则包含了所有不属于谦卑对象的行为。\n\nFor example, GUIs are hard to unit test because it is very difficult to write tests that can see the screen and check that the appropriate elements are displayed there. However, most of the behavior of a GUI is, in fact, easy to test. Using the Humble Object pattern, we can separate these two kinds of behaviors into two different classes called the Presenter and the View.\n\n> 例如，GUI 通常是很难进行单元测试的，因为让计算机自行检视屏幕内容，并检查指定元素是否出现是非常难的事情。然而，GUI 中的大部分行为实际上是很容易被测试的。这时候，我们就可以利用谦卑对象模式将 GUI 的这两种行为拆分成展示器与视图两部分。\n\n## PRESENTERS AND VIEWS 展示器与视图\n\nThe View is the humble object that is hard to test. The code in this object is kept as simple as possible. It moves data into the GUI but does not process that data.\n\n> 视图部分属于难以测试的谦卑对象。这种对象的代码通常应该越简单越好，它只应负责将数据填充到 GUI 上，而不应该对数据进行任何处理。\n\nThe Presenter is the testable object. Its job is to accept data from the application and format it for presentation so that the View can simply move it to the screen. For example, if the application wants a date displayed in a field, it will hand the Presenter a Date object. The Presenter will then format that data into an appropriate string and place it in a simple data structure called the View Model, where the View can find it.\n\n> 展示器则是可测试的对象。展示器的工作是负责从应用程序中接收数据，然后按视图的需要将这些数据格式化，以便视图将其呈现在屏幕上。例如，如果应用程序需要在屏幕上展示一个日期，那么它传递给展示器的应该是一个 Date 对象。然后展示器会将该对象格式化成所需的字符串形式，并将其填充到视图模型中。\n\nIf the application wants to display money on the screen, it might pass a Currency object to the Presenter. The Presenter will format that object with the appropriate decimal places and currency markers, creating a string that it can place in the View Model. If that currency value should be turned red if it is negative, then a simple boolean flag in the View model will be set appropriately.\n\n> 如果应用程序需要在屏幕上展示金额，那么它应该将 Currency 对象传递给展示器。展示器随后会将这个对象按所需的小数位数进行格式化，并加上对应的货币标识符，形成一个字符串存放在视图模型中。如果需要将负数金额显示成红色，那么该视图模型中就应该有一个简单的布尔值被恰当地设置。\n\nEvery button on the screen will have a name. That name will be a string in the View Model, placed there by the presenter. If those buttons should be grayed out, the Presenter will set an appropriate boolean flag in the View model. Every menu item name is a string in the View model, loaded by the Presenter. The names for every radio button, check box, and text field are loaded, by the Presenter, into appropriate strings and booleans in the View model. Tables of numbers that should be displayed on the screen are loaded, by the Presenter, into tables of properly formatted strings in the View model.\n\n> 另外，应用程序在屏幕上的每个按钮都应该有其对应的名称，这些名称也是由展示器在视图模型中设置的。如果某个按钮需要变灰，展示器就应该将相应的开关变量设置成对应的布尔值。同样，菜单中每个菜单项所显示的值，也应该是一个个由展示器加载到视图模型中的字符串。应用程序在屏幕上显示的每个单选项、多选项以及文本框的名字也都如此，在视图模型中都有相应的字符串和布尔值可供展示器做对应的设置。即使屏幕上要加载的是一个数值表，展示器也应该负责把这些数值格式化成具有表格属性的字符串，以供视图使用。\n\nAnything and everything that appears on the screen, and that the application has some kind of control over, is represented in the View Model as a string, or a boolean, or an enum. Nothing is left for the View to do other than to load the data from the View Model into the screen. Thus the View is humble.\n\n> 总而言之，应用程序所能控制的、要在屏幕上显示的一切东西，都应该在视图模型中以字符串、布尔值或枚举值的形式存在。然后，视图部分除了加载视图模型所需要的值，不应该再做任何其他事情。因此，我们才能说视图是谦卑对象。\n\n## TESTING AND ARCHITECTURE 测试与架构\n\nIt has long been known that testability is an attribute of good architectures. The Humble Object pattern is a good example, because the separation of the behaviors into testable and non-testable parts often defines an architectural boundary. The Presenter/View boundary is one of these boundaries, but there are many others.\n\n> 众所周知，强大的可测试性是一个架构的设计是否优秀的显著衡量标准之一。谦卑对象模式就是这方面的一个非常好的例子。我们将系统行为分割成可测试和不可测试两部分的过程常常就也定义了系统的架构边界。展示器与视图之间的边界只是多种架构边界中的一种，另外还有许多其他边界。\n\n## DATABASE GATEWAYS 数据库网关\n\nBetween the use case interactors and the database are the database gateways.2 These gateways are polymorphic interfaces that contain methods for every create, read, update, or delete operation that can be performed by the application on the database. For example, if the application needs to know the last names of all the users who logged in yesterday, then the UserGateway interface will have a method named getLastNamesOfUsersWhoLoggedInAfter that takes a Date as its argument and returns a list of last names.\n\n> 对于用例交互（interactor）与数据库中间的组件，我们通常称之为数据库网关。这些数据库网关本身是一个多态接口，包含了应用程序在数据库上所要执行的创建、读取、更新、删除等所有操作。例如，如果应用程序需要知道所有昨天登录系统的用户姓，那么 UserGateway 接口就应该包含一个 getLastNamesOfUsersWhoLoggedlnAfter 方法，接收一个 Date 参数，并返回一个包含姓的列表。\n\nRecall that we do not allow SQL in the use cases layer; instead, we use gateway interfaces that have appropriate methods. Those gateways are implemented by classes in the database layer. That implementation is the humble object. It simply uses SQL, or whatever the interface to the database is, to access the data required by each of the methods. The interactors, in contrast, are not humble because they encapsulate application-specific business rules. Although they are not humble, those interactors are testable, because the gateways can be replaced with appropriate stubs and test-doubles.\n\n> 另外，我们之前说过，SQL 不应该出现在用例层的代码中，所以这部分的功能就需要通过网关接口来提供，而这些接口的实现则要由数据库层的类来负责。显然，这些实现也应该都属于谦卑对象，它们应该只利用 SQL 或其他数据库提供的接口来昉问所需要的数据。与之相反，交互器则不属于谦卑对象，因为它们封装的是特定应用场景下的业务逻辑。不过，交互器尽管不属于谦卑对象，却是可测试的，因为数据库网关通常可以被替换成对应的测试桩和测试替身类。\n\n## DATA MAPPERS 数据映射器\n\nGoing back to the topic of databases, in which layer do you think ORMs like Hibernate belong?\n\n> 让我们继续数据库方面的话题，现在我们来思考一下 Hibernate 这类的 ORM 框架应该属于系统架构中的哪一层呢？\n\nFirst, let’s get something straight: There is no such thing as an object relational mapper (ORM). The reason is simple: Objects are not data structures. At least, they are not data structures from their users’ point of view. The users of an object cannot see the data, since it is all private. Those users see only the public methods of that object. So, from the user’s point of view, an object is simply a set of operations.\n\n> 首先我们要弄清楚一件事：对象关系映射器（ORM）事实上是压根就不存在的。带来很简单，对象不是数据结构。至少从用户的角度来说，对象内部的数据应该都是私有的，不可见的，用户在通常情况下只能看到对象的公有函数。因此从用户角度来说，对象是一些操作的集合，而不是简单的数据结构体。\n\nA data structure, in contrast, is a set of public data variables that have no implied behavior. ORMs would be better named “data mappers,” because they load data into data structures from relational database tables.\n\n> 与之相反，数据结构体则是一组公开的数据变量其中不包含任何行为信息。所以 ORM 更应该被称为“数据映射器”，因为它们只是将数据从关系型数据库加载到了对应的数据结构中。\n\nWhere should such ORM systems reside? In the database layer of course. Indeed, ORMs form another kind of Humble Object boundary between the gateway interfaces and the database.\n\n> 那么，这样的 ORM 系统应该属于系统架构中的哪一层呢？当然是数据库层。ORM 其实就是在数据库和数据库网关之间构建了另一种谦卑对象的边界。\n\n## SERVICE LISTENERS 服务监听器\n\nWhat about services? If your application must communicate with other services, or if your application provides a set of services, will we find the Humble Object pattern creating a service boundary?\n\n> 如果我们的应用程序需要与其他服务进行某种交互，或者该应用本身要提供某一套服务，我们在相关服务的边界处也会看到谦卑对象模式吗？\n\nOf course! The application will load data into simple data structures and then pass those structures across the boundary to modules that properly format the data and send it to external services. On the input side, the service listeners will receive data from the service interface and format it into a simple data structure that can be used by the application. That data structure is then passed across the service boundary.\n\n> 答案是肯定的。我们的应用程序会将数据加载到简单的数据结构中，并将这些数据结构跨边界传输给那些能够将其格式化并传递其他外部服务的模块。在输入端，服务监听器会负责从服务接口中接收数据，并将其格式化成该应用程序易用的格式。总而言之，上述数据结构可以进行跨服务边界的传输。\n\n## CONCLUSION 本章小结\n\nAt each architectural boundary, we are likely to find the Humble Object pattern lurking somewhere nearby. The communication across that boundary will almost always involve some kind of simple data structure, and the boundary will frequently divide something that is hard to test from something that is easy to test. The use of this pattern at architectural boundaries vastly increases the testability of the entire system.\n\n> 在每个系统架构的边界处，都有可能发现谦卑对象模式的存在。因为跨边界的通信肯定需要用到某种简单的数据结构，而边界会自然而然地将系统分割成难以测试的部分与容易测试的部分，所以通过在系统的边界处运用谦卑对象模式，我们可以大幅地提高整个系统的可测试性。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap24. PARTIAL BOUNDARIES 不完全边界\n\n![](../../images/books/架构整洁之道/CH-UN24.jpg)\n\nFull-fledged architectural boundaries are expensive. They require reciprocal polymorphic Boundary interfaces, Input and Output data structures, and all of the dependency management necessary to isolate the two sides into independently compilable and deployable components. That takes a lot of work. It’s also a lot of work to maintain.\n\n> 构建完整的架构边界是一件很耗费成本的事。在这个过程中，需要为系统设计双向的多态边界接口，用于输入和输出的数据结构，以及所有相关的依赖关系管理，以便将系统分割成可独立编译与部署的组件。这里会涉及大量的前期工作以及大量的后期维护工作。\n\nIn many situations, a good architect might judge that the expense of such a boundary is too high—but might still want to hold a place for such a boundary in case it is needed later.\n\n> 在很多情况下，一位优秀的架构师都会认为设计架构边界的成本太高了——但为了应对将来可能的需要，通常还是希望预留一个边界。\n\nThis kind of anticipatory design is often frowned upon by many in the Agile community as a violation of YAGNI: “You Aren’t Going to Need It.” Architects, however, sometimes look at the problem and think, “Yeah, but I might.” In that case, they may implement a partial boundary.\n\n> 但这种预防性设计在敏捷社区里是饱受诟病的，因为它显然违背了 YAGNI 原则（\"You Are’t Going to Need It”，意即“不要预测未来的需要”）。然而，架构师的工作本身就是要做这样的预见性设计，这时候，我们就需要引入不完全边界（partial boundary）的概念了。\n\n## SKIP THE LAST STEP 省掉最后一步\n\nOne way to construct a partial boundary is to do all the work necessary to create independently compilable and deployable components, and then simply keep them together in the same component. The reciprocal interfaces are there, the input/output data structures are there, and everything is all set up—but we compile and deploy all of them as a single component.\n\n> 构建不完全边界的一种方式就是在将系统分割成一系列可以独立编译、独立部署的组件之后，再把它们构建成一个组件。换句话说，在将系统中所有的接口、用于输入/输出的数据格式等每一件事都设置好之后，仍选择将它们统一编译和部署为一个组件。\n\nObviously, this kind of partial boundary requires the same amount of code and preparatory design work as a full boundary. However, it does not require the administration of multiple components. There’s no version number tracking or release management burden. That difference should not be taken lightly.\n\n> 显然，这种不完全边界所需要的代码量以及设计的工作量，和设计完整边界时是完全一样的。但它省去了多组件管理这部分的工作，这就等于省去了版本号管理和发布管理方面的工作——这其中的工作量其实可不小。\n\nThis was the early strategy behind FitNesse. The web server component of FitNesse was designed to be separable from the wiki and testing part of FitNesse. The idea was that we might want to create other web-based applications by using that web component. At the same, we did not want users to have to download two components. Recall that one of our design goals was “download and go.” It was our intent that users would download one jar file and execute it without having to hunt for other jar files, work out version compatibilities, and so on.\n\n> 这也是 FitNesse 项目早期所采取的策略。我们在设计 Web 服务器之初就将它设计为一个可以独立于 wiki 和测试部分的组件。该设计背后的想法是我们未来可能需要使用该 Web 组件来构建其他应用程序。但是同时，我们又不想让用户下载两个组件。正如我们之前所说，该项目其中的一个设计目标是实现让用户下载即可运行。我们希望用户只需下载一个 jar 文件就立即可以执行，不需要再去寻找其他的 jar 文件，更不需要操心版本兼容性等问题。\n\nThe story of FitNesse also points out one of the dangers of this approach. Over time, as it became clear that there would never be a need for a separate web component, the separation between the web component and the wiki component began to weaken. Dependencies started to cross the line in the wrong direction. Nowadays, it would be something of a chore to re-separate them.\n\n> 在这里，FitNcssc 项目的故事也可以作为一个反例来说明这种设计的危害性。随着时间的推移，我们慢慢发现，将 Web 组件独立的需求越来越少，Wiki 组件与 Web 组件的隔离也弱化了。到如今，如果真想要再分离 Web 组件的话，会需要不少工作量。\n\n## ONE-DIMENSIONAL BOUNDARIES 单向边界\n\nThe full-fledged architectural boundary uses reciprocal boundary interfaces to maintain isolation in both directions. Maintaining separation in both directions is expensive both in initial setup and in ongoing maintenance.\n\n> 在设计一套完整的系统架构边界时，往往需要用反向接口来维护边界两侧组件的隔离性。而且，维护这种双向的隔离性，通常不会是一次性的工作，它需要我们持续地长期投入资源维护下去。\n\nA simpler structure that serves to hold the place for later extension to a full-fledged boundary is shown in Figure 24.1. It exemplifies the traditional Strategy pattern. A ServiceBoundary interface is used by clients and implemented by ServiceImpl classes.\n\n> 在图 24.1 中，你会看到一个临时占位的，将来可被替换成完整架构边界的更简单的结构。这个结构采用了传统的策略模式（strategy pattern）。如你所见，其 Client 使用的是一个由 ServiceImpl 类实现的 ServiceBoundary 接口。\n\n<Figures figure=\"24-1\">The Strategy pattern</Figures>\n\nIt should be clear that this sets the stage for a future architectural boundary. The necessary dependency inversion is in place in an attempt to isolate the Client from the ServiceImpl. It should also be clear that the separation can degrade pretty rapidly, as shown by the nasty dotted arrow in the diagram. Without reciprocal interfaces, nothing prevents this kind of backchannel other than the diligence and discipline of the developers and architects.\n\n> 很明显，上述设计为未来构建完整的系统架构边界打下了坚实基础。为了未来将 Client 与 ServiceImpl 隔离，必要的依赖反转已经做完了。同时，我们也能清楚地看到，图中的虚线箭头代表了未来有可能很快就会出问题的隔离问题。由于没有采用双向反向接口，这部分就只能依赖开发者和架构师的自律性来保证组件持久隔离了。\n\n## FACADES 门户模式\n\nAn even simpler boundary is the Facade pattern, illustrated in Figure 24.2. In this case, even the dependency inversion is sacrificed. The boundary is simply defined by the Facade class, which lists all the services as methods, and deploys the service calls to classes that the client is not supposed to access.\n\n> 下面，我们再来看一个更简单的架构边界设计：采用门户模式（facade pattern），其架构如图 24.2 所示。在这种模式下，我们连依赖反转的工作都可以省了。这里的边界将只能由 Facade 类来定义，这个类的背后是一份包含了所有服务函数的列表，它会负责将 Client 的调用传递给对 client 不可见的服务函数。\n\n<Figures figure=\"24-2\">The Facade pattern</Figures>\n\nNote, however, that the Client has a transitive dependency on all those service classes. In static languages, a change to the source code in one of the Service classes will force the Client to recompile. Also, you can imagine how easy backchannels are to create with this structure.\n\n> 但需要注意的是，在该设计中 Client 会传递性地依赖于所有的 Service 类。在静态类型语言中，这就意味着对 Service 类的源码所做的任何修改都会导致 Client 的重新编译。另外，我们应该也能想象得到为这种结构建立反向通道是多容易的事。\n\n## CONCLUSION 本章小结\n\nWe’ve seen three simple ways to partially implement an architectural boundary. There are, of course, many others. These three strategies are simply offered as examples.\n\n> 在本章，我们介绍了三种不完全地实现架构边界的简单方法。当然，这类边界还有许多种其他实现方式，本章所介绍的这三种策略只为示范之用。\n\nEach of these approaches has its own set of costs and benefits. Each is appropriate, in certain contexts, as a placeholder for an eventual full-fledged boundary. Each can also be degraded if that boundary never materializes.\n\n> 每种实现方式都有相应的成本和收益。每种方式都有自己所适用的场景，它们可以被用来充当最终完整架构边界的临时替代品。同时，瞅这些边界最终被证明是没有必要存在的，那么也可以被自然降解。\n\nIt is one of the functions of an architect to decide where an architectural boundary might one day exist, and whether to fully or partially implement that boundary.\n\n> 架构师的职责之一就是预判未来哪里有可能会需要设置架构边界，并决定应该以完全形式还是不完全形式来实现它们。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap25. LAYERS AND BOUNDARIES 层次与边界\n\n![](../../images/books/架构整洁之道/CH-UN25.jpg)\n\nIt is easy to think of systems as being composed of three components: UI, business rules, and database. For some simple systems, this is sufficient. For most systems, though, the number of components is larger than that.\n\n> 人们通常习惯于将系统分成三个组件：UI、业务逻辑和数据库。对于一些简单系统来说，的确可以这样，但稍复杂一些系统的组件就远不止三个了。\n\nConsider, for example, a simple computer game. It is easy to imagine the three components. The UI handles all messages from the player to the game rules. The game rules store the state of the game in some kind of persistent data structure. But is that all there is?\n\n> 以一个简单的计算机游戏为例。粗略看来，它好像也很符合三个组件的架构设定。首先，让 UI 负责接收用户输入的数据，并将数据传递给游戏的业务逻辑。然后，游戏的业务逻辑会将游戏状态保存在某种持久化数据结构中。但是，仅仅是这样而已吗？\n\n## HUNT THE WUMPUS 基于文本的冒险游戏：Hunt The Wumpus\n\nLet’s put some flesh on these bones. Let’s assume that the game is the venerable Hunt the Wumpus adventure game from 1972. This text-based game uses very simple commands like GO EAST and SHOOT WEST. The player enters a command, and the computer responds with what the player sees, smells, hears, and experiences. The player is hunting for a Wumpus in a system of caverns, and must avoid traps, pits, and other dangers lying in wait. If you are interested, the rules of the game are easy to find on the web.\n\n> 现在让我们往上面的设想中加入一些细节。假设这个游戏是 1972 年风靡一时的基于文本的冒险游戏：Hunt the Wumpus 这个游戏的操作是通过一些像 GO EAST 和 SHOOT WEST 这样的简单文字命令来完成的。玩家在输入命令之后，计算机就会返回玩家角色所看到的、闻到的、听到的或体会到的事情。在这个游戏中，玩家会在一系列洞穴中追捕 Wumpus。玩家必须避开陷阱、陷坑以及其他一系列危险。如果有兴趣，在网上很容易找到该游戏的规则说明。\n\nLet’s assume that we’ll keep the text-based UI, but decouple it from the game rules so that our version can use different languages in different markets. The game rules will communicate with the UI component using a language-independent API, and the UI will translate the API into the appropriate human language.\n\n> 现在，假设我们决定保留这种基于文本的 UI，但是需要将 UI 与游戏业务逻辑之间的耦合解开，以便我们的游戏版本可以在不同地区使用不同的语言。也就是说，游戏的业务逻辑与 UI 之间应该用一种与自然语言无关的 API 来进行通信，而由 UI 负责将 API 传递进来的信息转换成合适的自然语言。\n\nIf the source code dependencies are properly managed, as shown in Figure 25.1, then any number of UI components can reuse the same game rules. The game rules do not know, nor do they care, which human language is being used.\n\n> 如果我们能管理好源码中的依赖关系，就应该像图 25.1 所展示的那样，多个 UI 组件复用同一套游戏业务逻辑。而游戏的业务逻辑组件不知道，也不必知道 UI 正在使用哪一种自然语言。\n\n<Figures figure=\"25-1\">Any number of UI components can reuse the game rules</Figures>\n\nLet’s also assume that the state of the game is maintained on some persistent store—perhaps in flash, or perhaps in the cloud, or maybe just in RAM. In any of those cases, we don’t want the game rules to know the details. So, again, we’ll create an API that the game rules can use to communicate with the data storage component.\n\n> 同时，假设玩家在游戏中的状态会被保存在某种持久化存储介质中——有可能闪存，也有可能是某种云端存储，或只是本机内存。无论怎样，我们都并不希望游戏引擎了解这些细节。所以，我们仍然需要创建一个 API 来负责游戏的业务逻辑组件与数据存储组件之间的通信。\n\nWe don’t want the game rules to know anything about the different kinds of data storage, so the dependencies have to be properly directed following the Dependency Rule, as shown in Figure 25.2.\n\n> 由于我们不会希望让游戏的业务逻辑依赖于不同种类的数据存储，所以这里的设计也要合理地遵守依赖关系原则，这样的话，该游戏的结构应如图 25.2 所示。\n\n<Figures figure=\"25-2\">Following the Dependency Rule</Figures>\n\n## CLEAN ARCHITECTURE? 可否采用整洁架构\n\nIt should be clear that we could easily apply the clean architecture approach in this context,1 with all the use cases, boundaries, entities, and corresponding data structures. But have we really found all the significant architectural boundaries?\n\n> 很显然，这里具备了采用整洁架构方法所需要的—切，包括用例、业务实体以及对应的数据结构都有了，但我们是否已经找到了所有相应的架构边界呢？\n\nFor example, language is not the only axis of change for the UI. We also might want to vary the mechanism by which we communicate the text. For example, we might want to use a normal shell window, or text messages, or a chat application. There are many different possibilities.\n\n> 例如，语言并不是 UI 变更的唯一方向。我们可能还会需要变更文字输入/输出的方式。例如我们的输入/输出可以采用命令行窗口，或者用短信息，或者采用某种聊天程序。这里的可能性有很多。\n\nThat means that there is a potential architectural boundary defined by this axis of change. Perhaps we should construct an API that crosses that boundary and isolates the language from the communications mechanism; that idea is illustrated in Figure 25.3.\n\n> 这就意味着这类变更应该有一个对应的架构边界。也许我们需要构造一个 API，以便将语言部分与通信部分隔开，这样一来，该设计的结构应如图 25.3 所示。\n\n<Figures figure=\"25-3\">The revised diagram</Figures>\n\nThe diagram in Figure 25.3 has gotten a little complicated, but should contain no surprises. The dashed outlines indicate abstract components that define an API that is implemented by the components above or below them. For example, the Language API is implemented by English and Spanish.\n\n> 在图 25.3 中可以看到，现在系统的结构已经变得有点复杂了。在该图中，虚线框代表的是抽象组件，它们所定义的 API 通常要交由其上下层的组件来实现。例如 Language 部分的 API 是由 English 和 Spanish 这两个组件来实现的。\n\nGameRules communicates with Language through an API that GameRules defines and Language implements. Language communicates with TextDelivery using an API that Language defines but TextDelivery implements. The API is defined and owned by the user, rather than by the implementer.\n\n> 我们也可以看到 GameRules 与 Language 这两个组件之间的交互是通过一个由 GameRules 定义，并由 Language 实现的 API 来完成的。同样的，Language 与 TextDelievery 之间的交互也是通过由 Language 定义，并由 TextDelievery 实现的 API 来完成。这些 API 的定义和维护都是由使用方来负责的，而非实现方。\n\nIf we were to look inside GameRules, we would find polymorphic Boundary interfaces used by the code inside GameRules and implemented by the code inside the Language component. We would also find polymorphic Boundary interfaces used by Language and implemented by code inside GameRules.\n\n> 如果我们进一步查看 GameRules 内部，就会发现 GameRules 组件的代码中使用的 Boundary 多态接口是由 Language 组件来实现的；同时还会发现 Language 组件使用的 Boundary 多态接口由 GameRules 代码实现。\n\nIf we were to look inside of Language, we would find the same thing: Polymorphic Boundary interfaces implemented by the code inside TextDelivery, and polymorphic Boundary interfaces used by TextDelivery and implemented by Language.\n\n> 如果再探究一下 Language 组件，我们也会看到类似的情况：它的 Boundary 多态接口是在 TextDelievery 组件的代码中实现的，而 TextDelievery 使用的 Boundary 多态接口则由 Language 来实现。\n\nIn each case, the API defined by those Boundary interfaces is owned by the upstream component.\n\n> 在所有这些场景中，由 Boundary 接口所定义的 API 都是由其使用者的上一层组件负责维护的。\n\nThe variations, such as English, SMS, and CloudData, are provided by polymorphic interfaces defined in the abstract API component, and implemented by the concrete components that serve them. For example, we would expect polymorphic interfaces defined in Language to be implemented by English and Spanish.\n\n> 不同的具体实现类，例如 English、SMS、CloudData 都实现了由抽象的 API 组件所定义的多态接口。例如，Language 组件中定义的多态接口是由 English 和 Spanish 这两个组件来定义的。\n\nWe can simplify this diagram by eliminating all the variations and focusing on just the API components. Figure 25.4 shows this diagram.\n\n> 我们可以去掉所有的具体实现类，只保留 API 组件来进一步简化上面这张设计图，其简化的结果如图 25.4 所示。\n\n<Figures figure=\"25-4\">Simplified diagram</Figures>\n\nNotice that the diagram is oriented in Figure 25.4 so that all the arrows point up. This puts GameRules at the top. This orientation makes sense because GameRules is the component that contains the highest-level policies.\n\n> 请注意图 25.4 中的朝向设计，所有的箭头都是朝上的。这样 GameRules 组件就被放在顶层的位置。这种朝向设计很好地反映了 GameRules 作为最高层策略组件的事买。\n\nConsider the direction of information flow. All input comes from the user through the TextDelivery component at the bottom left. That information rises through the Language component, getting translated into commands to GameRules. GameRules processes the user input and sends appropriate data down to DataStorage at the lower right.\n\n> 下面，我们来考虑一些信息流的方向。首先，所有来自用户的信息都会通过左下角的 TextDelievery 组件传入。当这些信息被上传到 Language 组件时，就会转换为具体的命令输入给 GameRules 组件。然后，GameRules 组件会负责处理用户的输入，并将数据发送给右下角的 Datastorage 组件。\n\nGameRules then sends output back down to Language, which translates the API back to the appropriate language and then delivers that language to the user through TextDelivery.\n\n> 接下来，GameRules 会将输出向下传递到 Language 组件，将其转成合适的语言并通过 TextDJievery 将该语言传递给用户。\n\nThis organization effectively divides the flow of data into two streams.2 The stream on the left is concerned with communicating with the user, and the stream on the right is concerned with data persistence. Both streams meet at the top3 at GameRules, which is the ultimate processor of the data that goes through both streams.\n\n> 这种设计方式将数据流分成两路。左侧的数据流关注如何与用户通信，而右侧的数据流关注的是数据持久化。两条数据流在顶部的 GameRules 汇聚。GameRules 组件是所有数据的最终处理者。\n\n## CROSSING THE STREAMS 交汇数据流\n\nAre there always two data streams as in this example? No, not at all. Imagine that we would like to play Hunt the Wumpus on the net with multiple players. In this case, we would need a network component, like that shown in Figure 25.5. This organization divides the data flow into three streams, all controlled by the GameRules.\n\n> 那么，这个例子中是否永远只有这两条数据流呢？当然不是。假设我们现在要在网络上与多个其他玩家一起玩这个游戏，就会需要一个网络组件，如图 25.5 所示。这样一来，我们有了三条数据流，它们都由 GameRules 组件所控制。\n\n<Figures figure=\"25-5\">Adding a network component</Figures>\n\nSo, as systems become more complex, the component structure may split into many such streams.\n\n> 由此可见，随着系统的复杂化，组件在架构中自然会分裂出多条数据流来。\n\n## SPLITTING THE STREAMS 数据流的分割\n\nAt this point you may be thinking that all the streams eventually meet at the top in a single component. If only life were so simple! The reality, of course, is much more complex.\n\n> 此时你可能会认为所有的数据流最终都会汇聚到一个组件上。生活要是果真如此简单，那就真是太好了！现实情况往往不如人所愿啊。\n\nConsider the GameRules component for Hunt the Wumpus. Part of the game rules deal with the mechanics of the map. They know how the caverns are connected, and which objects are located in each cavern. They know how to move the player from cavern to cavern, and how to determine the events that the player must deal with.\n\n> 我们可以再来看一下 Hunt The Wumpu 这个游戏的 GameRules 组件。游戏的部分业务逻辑处理的是玩家在地图中的行走。这一部分需要知道游戏中的洞穴如何相连，每个洞穴中有什么物体存在，还要知道如何将玩家从一个洞穴移到另一个洞穴，以及如何触发各种需要玩家处理的事件。\n\nBut there is another set of policies at an even higher level—policies that know the health of the player, and the cost or benefit of a particular event. These policies could cause the player to gradually lose health, or to gain health by discovering food. The lower-level mechanics policy would declare events to this higher-level policy, such as FoundFood or FellInPit. The higher-level policy would then manage the state of the player (as shown in Figure 25.6). Eventually that policy would decide whether the player wins or loses.\n\n> 但是，游戏中还有一组更高层次的策略——这些策略负责了解玩家的血量，以及每个事件的后果和影响。这些策略既可以让玩家逐渐损失血量，也可能由于发现事物而增加血量。总而言之，游戏的低层策略会负责向高层策略传递事件，例如 FoundFood 和 FelllnPito 而高层组件则要管理玩家状态（如图 25.6 所示），最终该策略将会决定玩家在游戏中的输赢。\n\n<Figures figure=\"25-6\">The higher-level policy manages the player</Figures>\n\nIs this an architectural boundary? Do we need an API that separates MoveManagement from PlayerManagement? Well, let’s make this a bit more interesting and add micro-services.\n\n> 这些究竟是否属于架构边界呢？是否需要设计一个 API 来分割 MoveManagement 和 PlayerManagement 呢？在回答这些问题之前，让我们把问题弄得更有意思一点，再往里面加上微服务吧！\n\nLet’s assume that we’ve got a massive multiplayer version of Hunt the Wumpus. MoveManagement is handled locally within the player’s computer, but PlayerManagement is handled by a server. PlayerManagement offers a micro-service API to all the connected MoveManagement components.\n\n> 假设我们现在面对的是一个可以面向海量玩家的新版 Hurit The Wumpus 游戏。它的 MoveManagmenet 组合是由玩家的本地计算机来处理的 。而 PlayerManagement 组件则由服务端来处理。但 PlayerManagement 组件会为所有连接上它的 MoveManagement 组件提供一个微服务的 API。\n\nThe diagram in Figure 25.7 depicts this scenario in a somewhat abbreviated fashion. The Network elements are a bit more complex than depicted—but you can probably still get the idea. A full-fledged architectural boundary exists between MoveManagement and PlayerManagement in this case.\n\n> 在图 25.7 中，我们为该游戏绘制了一个简化版的设计图。现实中的 Network 组件通常会比图中的更复杂一些 但这里的已经足够说明情况了。在图中，可以看到 MoveMangament PlayerManagment 之间存在一个完整的系统架构边界。\n\n<Figures figure=\"25-7\">Adding a micro-service API</Figures>\n\n## CONCLUSION 本章小结\n\nWhat does all this mean? Why have I taken this absurdly simply program, which could be implemented in 200 lines of Kornshell, and extrapolated it out with all these crazy architectural boundaries?\n\n> 本章究竟想讨论什么呢？为什么要将一个极为简单的、在 Komshell 中只需 200 行代码就能写完的小程序扩展成具有这些系统架构边界的复杂程序？\n\nThis example is intended to show that architectural boundaries exist everywhere. We, as architects, must be careful to recognize when they are needed. We also have to be aware that such boundaries, when fully implemented, are expensive. At the same time, we have to recognize that when such boundaries are ignored, they are very expensive to add in later—even in the presence of comprehensive test-suites and refactoring discipline.\n\n> 我们设计这个例子的目的就是为了证明架构边界可以存在于任何地方。作为架构师，我们必须要小心审视究竟在什么地方才需要设计架构边界。另外，我们还必须弄清楚完全实现这些边界将会带来多大的成本。同时，我们也必须要了解如果事先忽略了这些边界，后续再添加会有多么困难——哪怕有覆盖广泛的测试，严加小心的重构也于事无补。\n\nSo what do we do, we architects? The answer is dissatisfying. On the one hand, some very smart people have told us, over the years, that we should not anticipate the need for abstraction. This is the philosophy of YAGNI: “You aren’t going to need it.” There is wisdom in this message, since over-engineering is often much worse than under-engineering. On the other hand, when you discover that you truly do need an architectural boundary where none exists, the costs and risks can be very high to add such a boundary.\n\n> 所以作为架构师，我们应该怎么办？这个问题恐怕没有答案。一方面，就像一些很聪明的人多年来一直告诉我们的那样，不应该将未来的需求抽象化。这就是 YAGNI 原则：“You aren't going to need it”，臆想中的需求事实上住往是不存在的。这是一句饱含智慧的建议，因为过度的工程设计往往比工程设计不足还要糟糕。但另一方面，如果我们发现自己在某个位置确实需要设置架构边界，却又没有事先准备的时候，再添加边界所需要的成本和风险往往是很高的。\n\nSo there you have it. O Software Architect, you must see the future. You must guess—intelligently. You must weigh the costs and determine where the architectural boundaries lie, and which should be fully implemented, and which should be partially implemented, and which should be ignored.\n\n> 现实就是这样。作为软件架构师，我们必须有一点未卜先知的能力。有时候要依靠猜测——当然还要用点脑子。软件架构师必须仔细权衡成本，决定哪里需要设计架构边界，以及这些地方需要的是完整的边界，还是不完全的边界，还是可以忽略的边界。\n\nBut this is not a one-time decision. You don’t simply decide at the start of a project which boundaries to implement and which to ignore. Rather, you watch. You pay attention as the system evolves. You note where boundaries may be required, and then carefully watch for the first inkling of friction because those boundaries don’t exist.\n\n> 而且，这不是一次性的决定。我们不能在项目开始时就决定好哪里需要边界，哪里不需要。相反，架构师必须持续观察系统的演进，时刻注意哪里可能需要设计边界，然后仔细观察这些地方会由于不存在边界而出现哪些问题。\n\nAt that point, you weigh the costs of implementing those boundaries versus the cost of ignoring them—and you review that decision frequently. Your goal is to implement the boundaries right at the inflection point where the cost of implementing becomes less than the cost of ignoring.\n\n> 当出现问题时，我们还需要权衡一下实现这个边界的成本，并拿它与不实现这个边界的成本对比——这种对比经常需要反复地进行。我们的目标是找到设置边界的优势超过其成本的拐点，那就是实现该边界的最佳时机。\n\nIt takes a watchful eye.\n\n> 持之以恒，一刻也不能放松。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap26. THE MAIN COMPONENT Main 组件\n\n![](../../images/books/架构整洁之道/CH-UN26.jpg)\n\nIn every system, there is at least one component that creates, coordinates, and oversees the others. I call this component Main.\n\n> 在所有的系统中，都至少要有一个组件来负责创建、协调、监督其他组件的运转。我们将其称为 Main 组件。\n\n## THE ULTIMATE DETAIL 最细节化的部分\n\nThe Main component is the ultimate detail—the lowest-level policy. It is the initial entry point of the system. Nothing, other than the operating system, depends on it. Its job is to create all the Factories, Strategies, and other global facilities, and then hand control over to the high-level abstract portions of the system.\n\n> Main 组件是系统中最细节化的部分——也就是底层的策略，它是整个系统的初始点。在整个系统中，除了操作系统不会再有其他组件依赖于它了。Main 组件的任务是创建所有的工厂类、策略类以及其他的全局设施，并最终将系统的控制权转交给最高抽象层的代码来处理。\n\nIt is in this Main component that dependencies should be injected by a Dependency Injection framework. Once they are injected into Main, Main should distribute those dependencies normally, without using the framework.\n\n> Main 组件中的依赖关系通常应该由依赖注入框架来注入。在该框架将依赖关系注入到 Main 组件之后，Main 组件就应该可以在不依赖于该框架的情况下自行分配这些依赖关系了。\n\nThink of Main as the dirtiest of all the dirty components.\n\n> 请记住，Main 组件是整个系统中细节信息最多的组件。\n\nConsider the following Main component from a recent version of Hunt the Wumpus. Notice how it loads up all the strings that we don’t want the main body of the code to know about.\n\n> 下面，我们来看一下最新版 Hunt the Wumpus 游戏的 Main 组件。请注意这里加载字符串的方法，这些字符串全都是我们不想让游戏主体代码了解的内容。\n\n```java\npublic class Main implements HtwMessageReceiver {\n  private static HuntTheWumpus game;\n  private static int hitPoints = 10;\n  private static final List<String> caverns = new   ArrayList<>();\n  private static final String[] environments = new String[]{\n    \"bright\",\n    \"humid\",\n    \"dry\",\n    \"creepy\",\n    \"ugly\",\n    \"foggy\",\n    \"hot\",\n    \"cold\",\n    \"drafty\",\n    \"dreadful\"\n  };\n\n  private static final String[] shapes = new String[] {\n    \"round\",\n    \"square\",\n    \"oval\",\n    \"irregular\",\n    \"long\",\n    \"craggy\",\n    \"rough\",\n    \"tall\",\n    \"narrow\"\n  };\n\n  private static final String[] cavernTypes = new String[] {\n    \"cavern\",\n    \"room\",\n    \"chamber\",\n    \"catacomb\",\n    \"crevasse\",\n    \"cell\",\n    \"tunnel\",\n    \"passageway\",\n    \"hall\",\n    \"expanse\"\n  };\n\n  private static final String[] adornments = new String[] {\n   \"smelling of sulfur\",\n    \"with engravings on the walls\",\n    \"with a bumpy floor\",\n    \"\",\n    \"littered with garbage\",\n    \"spattered with guano\",\n    \"with piles of Wumpus droppings\",\n    \"with bones scattered around\",\n    \"with a corpse on the floor\",\n    \"that seems to vibrate\",\n    \"that feels stuffy\",\n    \"that fills you with dread\"\n  };\n```\n\nNow here’s the main function. Notice how it uses the HtwFactory to create the game. It passes in the name of the class, htw.game.HuntTheWumpusFacade, because that class is even dirtier than Main. This prevents changes in that class from causing Main to recompile/redeploy.\n\n> 接下来是 main 函数。请注意这里是如何使用 HtwFactory 来构建这个游戏的。我们可以看到这里传入了 一个名为 `htw.game.HuntTheWumpusFacade` 的类。由于这个类中的细节信息比 Main 组件还多，变更也更频繁，因此这样做可以避免这个类的变更导致 Main 组件的重新编译和重新部署。\n\n```java\npublic static void main(String[] args) throws IOException {\n   game = HtwFactory.makeGame(\"htw.game.HuntTheWumpusFacade\",\n                                 new Main());\n   createMap();\n   BufferedReader br =\n     new BufferedReader(new InputStreamReader(System.in));\n   game.makeRestCommand().execute();\n   while (true) {\n     System.out.println(game.getPlayerCavern());\n     System.out.println(\"Health: \" + hitPoints + \" arrows: \" +\n                           game.getQuiver());\n     HuntTheWumpus.Command c = game.makeRestCommand();\n      System.out.println(\">\");\n      String command = br.readLine();\n      if (command.equalsIgnoreCase(\"e\"))\n        c = game.makeMoveCommand(EAST);\n      else if (command.equalsIgnoreCase(\"w\"))\n        c = game.makeMoveCommand(WEST);\n      else if (command.equalsIgnoreCase(\"n\"))\n        c = game.makeMoveCommand(NORTH);\n      else if (command.equalsIgnoreCase(\"s\"))\n        c = game.makeMoveCommand(SOUTH);\n      else if (command.equalsIgnoreCase(\"r\"))\n        c = game.makeRestCommand();\n      else if (command.equalsIgnoreCase(\"sw\"))\n        c = game.makeShootCommand(WEST);\n      else if (command.equalsIgnoreCase(\"se\"))\n        c = game.makeShootCommand(EAST);\n      else if (command.equalsIgnoreCase(\"sn\"))\n        c = game.makeShootCommand(NORTH);\n      else if (command.equalsIgnoreCase(\"ss\"))\n        c = game.makeShootCommand(SOUTH);\n      else if (command.equalsIgnoreCase(\"q\"))\n        return;\n\n      c.execute();\n    }\n  }\n```\n\nNotice also that main creates the input stream and contains the main loop of the game, interpreting the simple input commands, but then defers all processing to other, higher-level components.\n\n> 你还应该注意到 main 函数中创建了输入数据流，并纳入了游戏的主循环。主循环将负责处理简单的输入指令，但它会将具体的处理过程交给其他更高层次的组件来处理。\n\nFinally, notice that main creates the map.\n\n> 最后，Main 组件还要负责生成整个游戏的地图。\n\n```java\nprivate static void createMap() {\n   int nCaverns = (int) (Math.random() * 30.0 + 10.0);\n   while (nCaverns-- > 0)\n     caverns.add(makeName());\n\n    for (String cavern : caverns) {\n      maybeConnectCavern(cavern, NORTH);\n      maybeConnectCavern(cavern, SOUTH);\n      maybeConnectCavern(cavern, EAST);\n      maybeConnectCavern(cavern, WEST);\n    }\n\n    String playerCavern = anyCavern();\n    game.setPlayerCavern(playerCavern);\n    game.setWumpusCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n\n    game.addPitCavern(anyOther(playerCavern));\n    game.addPitCavern(anyOther(playerCavern));\n    game.addPitCavern(anyOther(playerCavern));\n\n    game.setQuiver(5);\n  }\n\n  // much code removed…\n}\n```\n\nThe point is that Main is a dirty low-level module in the outermost circle of the clean architecture. It loads everything up for the high level system, and then hands control over to it.\n\n> 我们在这里的重点是要说明 Main 组件是整个系统中的一个底层模块，它处于整洁架构的最外圈，主要负责为系统加载所有必要的信息，然后再将控制权转交回系统的高层组件。\n\n## CONCLUSION 本章小结\n\nThink of Main as a plugin to the application—a plugin that sets up the initial conditions and configurations, gathers all the outside resources, and then hands control over to the high-level policy of the application. Since it is a plugin, it is possible to have many Main components, one for each configuration of your application.\n\n> Main 组件也可以被视为应用程序的一个插件——这个插件负责设置起始状态、配置信息、加载外部资源，最后将控制权转交给应用程序的其他高层组件。另外，由于 Main 组件能以插件形式存在于系统中，因此我们可以为一个系统设计多个 Main 组件，让它们各自对应于不同的配置。\n\nFor example, you could have a Main plugin for Dev, another for Test, and yet another for Production. You could also have a Main plugin for each country you deploy to, or each jurisdiction, or each customer.\n\n> 例如，我们既可以设计专门针对开发环境的 Main 组件，也可以设计专门针对测试的或者生产环境的 Main 组件。除此之外，我们还可以针对要部署的国家、地区甚至客户设计不同的 Main 组件。\n\nWhen you think about Main as a plugin component, sitting behind an architectural boundary, the problem of configuration becomes a lot easier to solve.\n\n> 当我们将 Main 组件视为一种插件时，用架构边界将它与系统其他部分隔离开这件事，在系统的配置上是不是就变得更容易了呢？\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap27. SERVICES: GREAT AND SMALL 服务：宏观与微观\n\n![](../../images/books/架构整洁之道/CH-UN27.jpg)\n\nService-oriented “architectures” and micro-service “architectures” have become very popular of late. The reasons for their current popularity include the following:\n\n> 面向服务的“架构”以及微服务“架构”近年来非常流行，其中的原因如下：\n\n- Services seem to be strongly decoupled from each other. As we shall see, this is only partially true.\n- Services appear to support independence of development and deployment. Again, as we shall see, this is only partially true.\n\n---\n\n> - 服务之间似乎是强隔离的，但是下文我们会讲到，并不完全是这样。\n> - 服务被认为是支持独立开发和部署的，同样，下文我们也会讲到，并不完全是这样。\n\n## SERVICE ARCHITECTURE? 面向服务的架构\n\nFirst, let’s consider the notion that using services, by their nature, is an architecture. This is patently untrue. The architecture of a system is defined by boundaries that separate high-level policy from low-level detail and follow the Dependency Rule. Services that simply separate application behaviors are little more than expensive function calls, and are not necessarily architecturally significant.\n\n> 首先，我们来批判“只要使用了服务，就等于有了一套架构”这种思想。这显然是完全错误的。如前文所述，架构设计的任务就是找到高层策略与低层细节之间的架构边界，同时保证这些边界遵守依赖关系规则。所谓的服务本身只是一种比函数调用方式成本稍高的，分割应用程序行为的一种形式，与系统架构无关。\n\nThis is not to say that all services should be architecturally significant. There are often substantial benefits to creating services that separate functionality across processes and platforms—whether they obey the Dependency Rule or not. It’s just that services, in and of themselves, do not define an architecture.\n\n> 当然，这里并不是说所有的服务都应该具有系统架构上的意义。有时候，用服务这种形式来隔离不同平台或进程中的程序行为这件事本身就很重要——不管它们是否遵守依赖关系规则。我们只是认为，服务本身并不能完全代表系统架构。\n\nA helpful analogy is the organization of functions. The architecture of a monolithic or component-based system is defined by certain function calls that cross architectural boundaries and follow the Dependency Rule. Many other functions in those systems, however, simply separate one behavior from another and are not architecturally significant.\n\n> 为了帮助读者理解上面所说的区别，我们用函数的组织形式来做个类比。不管是单体程序，还是多组件程序，系统架构都是由那些跨越架构边界的关键函数调用来定义的，并且整个架构必须遵守依赖关系规则。系统中许多其他的函数虽然也起到了隔离行为的效果，但它们显然并不具有架构意义。\n\nSo it is with services. Services are, after all, just function calls across process and/or platform boundaries. Some of those services are architecturally significant, and some aren’t. Our interest, in this chapter, is with the former.\n\n> 服务的情况也一样，服务这种形式说到底不过是一种跨进程/平台边界的函数调用而己。有些服务会具有架构上的意义，有些则没有。我们这里重点要讨论的，当然是前者。\n\n## SERVICE BENEFITS? 服务所带来的好处\n\nThe question mark in the preceding heading indicates that this section is going to challenge the current popular orthodoxy of service architecture. Let’s tackle the benefits one at a time.\n\n> 我在本节的标题后面打了个问号，意味着我打算在这一节好好挑战一下目前流行的针对服务架构的崇拜情节。下面就让我们针对那些所谓的好处，一个一个地来批驳。\n\n### THE DECOUPLING FALLACY 解耦合的谬论\n\nOne of the big supposed benefits of breaking a system up into services is that services are strongly decoupled from each other. After all, each service runs in a different process, or even a different processor; therefore those services do not have access to each other’s variables. What’s more, the interface of each service must be well defined.\n\n> 很多人认为将系统拆分成服务的一个最忙要的好处就是让每个服务之间实现强解耦。毕竟，每个服务都是以一个不同的进程来运行的，甚至运行在不同处理器上。因此，服务之间通常不能访问彼此的变量。其外，服务之间的接口一定是充分定义的。\n\nThere is certainly some truth to this—but not very much truth. Yes, services are decoupled at the level of individual variables. However, they can still be coupled by shared resources within a processor, or on the network. What’s more, they are strongly coupled by the data they share.\n\n> 从一定程度上来说，这是对的。确实，服务之间的确在变量层面做到了彼此隔离。然而，它们之间还是可能会因为处理器内的共享资源，或者通过网络共享资源而彼此耦合的。另外，任何形式的共享数据行为都会导致强耦合。\n\nFor example, if a new field is added to a data record that is passed between services, then every service that operates on the new field must be changed. The services must also strongly agree about the interpretation of the data in that field. Thus those services are strongly coupled to the data record and, therefore, indirectly coupled to each other.\n\n> 例如，如果给服务之间传递的数据记录中增加了一个新字段，那么每个需要操作这个字段的服务都必须要做出相应的变更，服务之间必须对这条数据的解读达成一致。因此其实这些服务全部是强耦合于这条数据结构的，因此它们是间接彼此耦合的。\n\nAs for interfaces being well defined, that’s certainly true—but it is no less true for functions. Service interfaces are no more formal, no more rigorous, and no better defined than function interfaces. Clearly, then, this benefit is something of an illusion.\n\n> 再来说说服务能很好地定义接口——它确实能很好地定义接口——但函数也能做到这一点。事实上，服务的接口与普通的函数接口相比，并没有比后者更正式、更严谨，也没有更好，这一点根本算不上什么好处。\n\n### THE FALLACY OF INDEPENDENT DEVELOPMENT AND DEPLOYMENT 独立开发部署的谬论\n\nAnother of the supposed benefits of services is that they can be owned and operated by a dedicated team. That team can be responsible for writing, maintaining, and operating the service as part of a dev-ops strategy. This independence of development and deployment is presumed to be scalable. It is believed that large enterprise systems can be created from dozens, hundreds, or even thousands of independently developable and deployable services. Development, maintenance, and operation of the system can be partitioned between a similar number of independent teams.\n\n> 人们认为的另一个使用服务的好处就是，不同的服务可以由不同的专门团队负责和运维。这让开发团队可以釆用 dev-ops 混合的形式来编写、维护以及运维各自的服务，这种开发和部署上的独立性被认为是可扩展的。这种观点认为大型系统可以由几十个、几百个、甚至几千个独立开发部署的服务组成。整个系统的研发、维护以及运维工作就可以由同等量级的团队来共同完成。\n\nThere is some truth to this belief—but only some. First, history has shown that large enterprise systems can be built from monoliths and component-based systems as well as service-based systems. Thus services are not the only option for building scalable systems.\n\n> 这种理念有一些道理——但也仅仅是一些而已。首先，无数历史事实证明，大型系统一样可以釆用单体模式，或打组件模式来构建，不一定非得服务化。因此服务化并不是构建大型系统的唯一选择。\n\nSecond, the decoupling fallacy means that services cannot always be independently developed, deployed, and operated. To the extent that they are coupled by data or behavior, the development, deployment, and operation must be coordinated.\n\n> 其次，上文说到的解耦合谬论已经说明拆分服务并不意味着这些服务可以彼此独立开发、部署和运维。如果这些服务之间以数据形式或者行为形式相耦合，那么它们的开发、部署和运维也必须彼此协调来进行。\n\n## THE KITTY PROBLEM 运送猫咪的难题\n\nAs an example of these two fallacies, let’s look at our taxi aggregator system again. Remember, this system knows about many taxi providers in a given city, and allows customers to order rides. Let’s assume that the customers select taxis based on a number of criteria, such as pickup time, cost, luxury, and driver experience.\n\n> 下面，我们再以之前那个出租车调度系统为例来说明上面那两个谬论。各位还记得吗？该系统会负责统一调度给定城市中的多个出租车提供商，而用户可以集中在它那里下订单。在这里，我们假设用户在租车时往往会附带一组参考条件，例如接送时间、价格、豪华程度、司机的经验，等等。\n\nWe wanted our system to be scalable, so we chose to build it out of lots of little micro-services. We subdivided our development staff into many small teams, each of which is responsible for developing, maintaining, and operating a correspondingly1 small number of services.\n\n> 我们希望整个系统是可扩展的，于是该系统大量采用了微服务架构。然后，我们进一步将整个研发团队划分为许多个小团队，每个团队都负责开发、维护和运维相应的小数量的微服务。\n\nThe diagram in Figure 27.1 shows how our fictitious architects arranged services to implement this application. The TaxiUI service deals with the customers, who use mobile devices to order taxis. The TaxiFinder service examines the inventories of the various TaxiSuppliers and determines which taxies are possible candidates for the user. It deposits these into a short-term data record attached to that user. The TaxiSelector service takes the user’s criteria of cost, time, luxury, and so forth, and chooses an appropriate taxi from among the candidates. It hands that taxi off to the TaxiDispatcher service, which orders the appropriate taxi.\n\n> 这个虚构系统的架构如图 27.1 所示，整个系统都是依靠服务来构建的。TaxiUI 服务负责与用户打交道，用户会通过移动设备向它下订单。TaxiFinder 服务负责调用不同的 TaxiSupplier 服务来获取可用车辆的信息，并且找出可用的出租车以作为可推荐项。这些可推荐项会短期地被固化成一条数据记录，与用户信息挂钩。TaxiSelector 服务则负责根据用户所选择的价格、时间、豪华程度等条件从可选项中筛选结果，最后这些结果会被传递给 TaxiDispatcher 服务，由它负责分派订单。\n\n<Figures figure=\"27-1\">Services arranged to implement the taxi aggregator system</Figures>\n\nNow let us suppose that this system has been in operation for more than a year. Our staff of developers have been happily developing new features while maintaining and operating all these services.\n\n> 现在，假设我们的系统已经运行了一年有余，其研发团队在持续开发新功能的同时，维护着所有的服务。\n\nOne bright and cheerful day, the marketing department holds a meeting with the development team. In this meeting, they announce their plans to offer a kitten delivery service to the city. Users can order kittens to be delivered to their homes or to their places of business.\n\n> 在一个阳光明媚的早上，市场部召集整个研发部开会。会议上，市场部宣布了他们在该城市升展猫咪送达服务的计划。该计划将允许用户向系统下订单，要求将他们的猫咪送到自己家里或者办公室。\n\nThe company will set up several kitten collection points across the city. When a kitten order is placed, a nearby taxi will be selected to collect a kitten from one of those collection points, and then deliver it to the appropriate address.\n\n> 公司的计划是在城市中建立几个猫咪集散点。当用户下订单时，附近的一辆出租车将被选中去集散点取猫，并将猫送到指定地点。\n\nOne of the taxi suppliers has agreed to participate in this program. Others are likely to follow. Still others may decline.\n\n> 现在已经有一家出租车公司参加了这项活动，未来可能还会有其他公司参与进来，但肯定也会有不参与的公司。\n\nOf course, some drivers may be allergic to cats, so those drivers should never be selected for this service. Also, some customers will undoubtedly have similar allergies, so a vehicle that has been used to deliver kittens within the last 3 days should not be selected for customers who declare such allergies.\n\n> 当然，由于有些司机会对猫过敏，所以系统还必须要避免选中这些人去运送猫咪。同样的，由于出租车的乘客中也会有对猫过敏的人，所以当他们叫车时，系统也必须避免指派过去三天内运送过猫咪的车。\n\nLook at that diagram of services. How many of those services will have to change to implement this feature? All of them. Clearly, the development and deployment of the kitty feature will have to be very carefully coordinated.\n\n> 现在根据上述需求再来看我们的系统架构图，数一数有多少个服务需要变更？答案是全部！显然，为了增加这个运送猫咪的功能，该系统所有的服务都需要做变更，而且这些服务之间还要彼此做好协调。\n\nIn other words, the services are all coupled, and cannot be independently developed, deployed, and maintained.\n\n> 换句话说，这些服务事实上全都是强耦合的，并不能真正做到独立开发、部署和维护。\n\nThis is the problem with cross-cutting concerns. Every software system must face this problem, whether service oriented or not. Functional decompositions, of the kind depicted in the service diagram in Figure 27.1, are very vulnerable to new features that cut across all those functional behaviors.\n\n> 这就是所谓的横跨型变更（cross-cutting concern）问题，它是所有软件系统都要面对的问题，无论服务化还是非服务化的。其中，图 27.1 所示的这种按功能划分服务的架构方式，在跨系统的功能变更时是最脆弱的。\n\n## OBJECTS TO THE RESCUE 对象化是救星\n\nHow would we have solved this problem in a component-based architecture? Careful consideration of the SOLID design principles would have prompted us to create a set of classes that could be polymorphically extended to handle new features.\n\n> 如果采用组件化的系统架构，如何解决这个难题呢？通过对 SOLID 设计原则的仔细考虑，我们应该一开始就设计一系列多态化的类，以应对将来新功能的扩展需要。\n\nThe diagram in Figure 27.2 shows the strategy. The classes in this diagram roughly correspond to the services shown in Figure 27.1. However, note the boundaries. Note also that the dependencies follow the Dependency Rule.\n\n> 这种策略下的系统架构如图 27.2 所示，我们可以看到该图中的类与图 27.1 中的服务大致是相互对应的。然而，请读者注意这里设置了架构边界，并且遵守了依赖关系原则。\n\nMuch of the logic of the original services is preserved within the base classes of the object model. However, that portion of the logic that was specific to rides has been extracted into a Rides component. The new feature for kittens has been placed into a Kittens component. These two components override the abstract base classes in the original components using a pattern such as Template Method or Strategy.\n\n> 现在，原先服务化设计中的大部分逻辑都被包含在对象模型的基类中。然而，针对每次特定行程的逻辑被抽离到一个单独的 Rides 组件中。运送猫咪的新功能被放入到 Kittens 组件中。这两个组件覆盖了原始组件中的抽象基类，这种设计模式被称作模板方法模式或策略模式。\n\nNote again that the two new components, Rides and Kittens, follow the Dependency Rule. Note also that the classes that implement those features are created by factories under the control of the UI.\n\n> 同时，我们也会注意到 Rides 和 Kittens 这两个新组件都遵守了依赖关系原则。另外，实现功能的类也都是由 UI 控制下的工厂类创建出来的。\n\nClearly, in this scheme, when the Kitty feature is implemented, the TaxiUI must change. But nothing else needs to be changed. Rather, a new jar file, or Gem, or DLL is added to the system and dynamically loaded at runtime.\n\n> 显然，如果我们在这种架构下引入运送猫咪的功能，TaxiUI 组件就必须随之变更，但其他的组件就无须变更了。这里只需要引入一个新的 jar 文件或者 Gem、DLL。系统在运行时就会自动动态地加载它们。\n\nThus the Kitty feature is decoupled, and independently developable and deployable.\n\n> 这样一来，运送猫咪的功能就与系统的其他部分实现了解耦，可以实现独立开发和部署了。\n\n<Figures figure=\"27-2\">Using an object-oriented approach to deal with cross-cutting concerns</Figures>\n\n## COMPONENT-BASED SERVICES 基于组件的服务\n\nThe obvious question is: Can we do that for services? And the answer is, of course: Yes! Services do not need to be little monoliths. Services can, instead, be designed using the SOLID principles, and given a component structure so that new components can be added to them without changing the existing components within the service.\n\n> 那么，问题来了：服务化也可以做到这一点吗？答案是肯定的。服务并不一定必须是小型的单体程序。服务也可以按照 SOLID 原则来设计，按照组件结构来部署，这样就可以做到在添加/删除组件时不影响服务中的其他组件。\n\nThink of a service in Java as a set of abstract classes in one or more jar files. Think of each new feature or feature extension as another jar file that contains classes that extend the abstract classes in the first jar files. Deploying a new feature then becomes not a matter of redeploying the services, but rather a matter of simply adding the new jar files to the load paths of those services. In other words, adding new features conforms to the Open-Closed Principle.\n\n> 我们可以将 Java 中的服务看作是一个或多个 jar 文件中的一组抽象类，而每个新功能或功能扩展都是另一个 jar 文件中的类，它们都扩展了之前 jar 文件中的抽象类。这样一来，部署新功能就不再是部署服务了，而只是简单地在服务的加载路径下增加一个 jar 文件。换句话说，这种增加新功能的过程符合开闭原则（OCP）。\n\nThe service diagram in Figure 27.3 shows the structure. The services still exist as before, but each has its own internal component design, allowing new features to be added as new derivative classes. Those derivative classes live within their own components.\n\n> 这种服务的架构如图 27.3 所示。我们可以看到，在该架构中服务仍然和之前一样，但是每个服务中都增加了内部组件结构，以便使用衍生类来添加新功能，而这些衍生类都有各自所生存的组件。\n\n<Figures figure=\"27-3\">Each service has its own internal component design, enabling new features to be added as new derivative classes</Figures>\n\n## CROSS-CUTTING CONCERNS 横跨型变更\n\nWhat we have learned is that architectural boundaries do not fall between services. Rather, those boundaries run through the services, dividing them into components.\n\n> 现在我们应该已经明白了，系统的架构边界事实上并不落在服务之间，而是穿透所有服务，在服务内部以组件的形式存在。\n\nTo deal with the cross-cutting concerns that all significant systems face, services must be designed with internal component architectures that follow the Dependency Rule, as shown in the diagram in Figure 27.4. Those services do not define the architectural boundaries of the system; instead, the components within the services do.\n\n> 为了处理这个所有大型系统都会遇到的横跨型变更问题，我们必须在服务内部采用遵守依赖关系原则的组件设计方式，如图 27.4 所示。总而言之，服务边界并不能代表系统的架构边界，服务内部的组件边界才是。\n\n<Figures figure=\"27-4\">Services must be designed with internal component architectures that follow the Dependency Rule</Figures>\n\n## CONCLUSION 本章小结\n\nAs useful as services are to the scalability and develop-ability of a system, they are not, in and of themselves, architecturally significant elements. The architecture of a system is defined by the boundaries drawn within that system, and by the dependencies that cross those boundaries. That architecture is not defined by the physical mechanisms by which elements communicate and execute.\n\n> 虽然服务化可能有助于提升系统的可扩展性和可研发性，但服务本身却并不能代表整个系统的架构设计。系统的架构是由系统内部的架构边界，以及边界之间的依赖关系所定义的，与系统中各组件之间的调用和通信方式无关。\n\nA service might be a single component, completely surrounded by an architectural boundary. Alternatively, a service might be composed of several components separated by architectural boundaries. In rare2 cases, clients and services may be so coupled as to have no architectural significance whatever.\n\n> 一个服务可能是一个独立组件，以系统架构边界的形式隔开。一个服务也可能由几个组件组成，其中的组件以架构边界的形式互相隔离。在极端情况下，客户端和服务端甚至可能会由于耦合得过于紧密而不具备系统架构意义上的隔离性。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap28. THE TEST BOUNDARY 测试边界\n\n![](../../images/books/架构整洁之道/CH-UN28.jpg)\n\nYes, that’s right: The tests are part of the system, and they participate in the architecture just like every other part of the system does. In some ways, that participation is pretty normal. In other ways, it can be pretty unique.\n\n> 对，你没看错：和程序代码一样，测试代码也是系统的一部分。甚至，测试代码有时在系统架构中的地位还要比其他部分更独特一些。\n\n## TESTS AS SYSTEM COMPONENTS 测试也是一种系统组件\n\nThere is a great deal of confusion about tests. Are they part of the system? Are they separate from the system? Which kinds of tests are there? Are unit tests and integration tests different things? What about acceptance tests, functional tests, Cucumber tests, TDD tests, BDD tests, component tests, and so on?\n\n> 讨论测试的时候，业界总会有许多自相矛盾的声音。测试应该是系统的一部分吗？还是应该独立于系统之外存在呢？测试分为哪几种？单元测试与集成测试是不同的东西吗？质量检查测试、功能性测试、Cucumber 测试、TDD 测试、BDD 测试、组件测试分别又都是什么？\n\nIt is not the role of this book to get embroiled in that particular debate, and fortunately it isn’t necessary. From an architectural point of view, all tests are the same. Whether they are the tiny little tests created by TDD, or large FitNesse, Cucumber, SpecFlow, or JBehave tests, they are architecturally equivalent.\n\n> 在本书中我们并不想卷入对这些问题的辩论中，而且也很庆幸没有卷入的必要。因为从架构的角度来讲，所有的测试都是一样的。不论它们是小型的 TDD 测试，还是大型的 FitNesse、Cucumber、SpecFlow 或 JBehave 测试，对架构来说都是一样的。\n\nTests, by their very nature, follow the Dependency Rule; they are very detailed and concrete; and they always depend inward toward the code being tested. In fact, you can think of the tests as the outermost circle in the architecture. Nothing within the system depends on the tests, and the tests always depend inward on the components of the system.\n\n> 究其本质而言，测试组件也是要遵守依赖关系原则的。因为其中总是充满了各种细节信息，非常具体，所以它始终都是向内依赖于被测试部分的代码的。事实上，我们可以将测试组件视为系统架构中最外圈的程序。它们始终是向内依赖的，而且系统中没有其他组件依赖于它们。\n\nTests are also independently deployable. In fact, most of the time they are deployed in test systems, rather than in production systems. So, even in systems where independent deployment is not otherwise necessary, the tests will still be independently deployed.\n\n> 另外，测试组件是可以独立部署的。事实上，大部分测试组件都是被部署在测试环境中，而不是生产环境中。所以，即使是那些本身不需要独立部署的系统中，其测试代码也总是独立部署的。\n\nTests are the most isolated system component. They are not necessary for system operation. No user depends on them. Their role is to support development, not operation. And yet, they are no less a system component than any other. In fact, in many ways they represent the model that all other system components should follow.\n\n> 测试组件通常是一个系统中最独立的组件。系统的正常运行并不需要用到测试组件，用户也不依赖于测试组件。测试组件的存在是为了支持开发过程，而不是运行过程。然而，测试组件仍然是系统中不可或缺的一个组件。事实上，测试组件在许多方面都反映了系统中其他组件所应遵循的设计模型。\n\n## DESIGN FOR TESTABILITY 可测试性设计\n\nThe extreme isolation of the tests, combined with the fact that they are not usually deployed, often causes developers to think that tests fall outside of the design of the system. This is a catastrophic point of view. Tests that are not well integrated into the design of the system tend to be fragile, and they make the system rigid and difficult to change.\n\n> 由于测试代码的独立性，以及往往不会被部署到生产坏境的特点，开发者常常会在系统设计中忽视测试的重要性，这种做法是极为错误的。测试如果没有被集成到系统设计中，往往是非常脆弱的，这种脆弱性会使得系统变得死板，非常难以更改。\n\nThe issue, of course, is coupling. Tests that are strongly coupled to the system must change along with the system. Even the most trivial change to a system component can cause many coupled tests to break or require changes.\n\n> 当然，这里的关键之处就是耦合。如果测试代码与系统是强耦合的，它就得随着系统变更而变更。哪怕只是系统中组件的一点小变化，都可能会导致许多与之相耦合的测试出现问题，需要做出相应的变更。\n\nThis situation can become acute. Changes to common system components can cause hundreds, or even thousands, of tests to break. This is known as the Fragile Tests Problem.\n\n> 这个问题可能会很严重。修改一个通用的系统组件可能会导致成百上千个测试出现问题，我们通常将这类问题称为脆弱的测试问题（fragile tests problem）。\n\nIt is not hard to see how this can happen. Imagine, for example, a suite of tests that use the GUI to verify business rules. Such tests may start on the login screen and then navigate through the page structure until they can check particular business rules. Any change to the login page, or the navigation structure, can cause an enormous number of tests to break.\n\n> 这类问题的发生过程并不难想象。例如，假设我们有一套利用 GUI 来校验系统业务逻辑的测试。这些测试可能从登录页面开始，按照导航顺序遍历整个页面结构，直到完成某个特定的业务逻辑为止。这时候，任何针对登录页面或导航顺序的变更，都可能导致大量的测试出错。\n\nFragile tests often have the perverse effect of making the system rigid. When developers realize that simple changes to the system can cause massive test failures, they may resist making those changes. For example, imagine the conversation between the development team and a marketing team that requests a simple change to the page navigation structure that will cause 1000 tests to break.\n\n> 另外，脆弱的测试还往往会让系统变得非常死板。当开发者意识到一些简单的修改就会导致大量的测试出错时，他们自然就会抵制修改。请想象一下，如果市场部门所要求的一个针对页面导航结构的简单变更会导致一千个测试出错时，开发部门会怎么说吧。\n\nThe solution is to design for testability. The first rule of software design—whether for testability or for any other reason—is always the same: Don’t depend on volatile things. GUIs are volatile. Test suites that operate the system through the GUI must be fragile. Therefore design the system, and the tests, so that business rules can be tested without using the GUI.\n\n> 要想解决这个问题，就必须在设计中考虑到系统的可测试性。软件设计的第一条原则——不管是为了可测试性还是其他什么东西——是不变的，就是不要依赖于多变的东西。譬如，GUI 往往是多变的，因此通过 GUI 来验证系统的测试一定是脆弱的。因此，我们在系统设汁与测试设计时，应该让业务逻辑不通过 GUI 也可以被测试。\n\n## THE TESTING API 测试专用 API\n\nThe way to accomplish this goal is to create a specific API that the tests can use to verify all the business rules. This API should have superpowers that allow the tests to avoid security constraints, bypass expensive resources (such as databases), and force the system into particular testable states. This API will be a superset of the suite of interactors and interface adapters that are used by the user interface.\n\n> 设计这样一个系统的方法之一就是专门为验证业务逻辑的测试创建一个 API。这个 API 应该被授予超级用户权限，允许测试代码可以忽视安全限制，绕过那些成本高昂的资源（例如数据库），强制将系统设置到某种可测试的状态中。总而言之，该 API 应该成为用户界面所用到的交互器与接口适配器的一个超集。\n\nThe purpose of the testing API is to decouple the tests from the application. This decoupling encompasses more than just detaching the tests from the UI: The goal is to decouple the structure of the tests from the structure of the application.\n\n> 设置测试 API 是为了将测试部分从应用程序中分离出来。换句话说，这种解耦动作不只是为了分隔测试部分与 UI 部分，而是要将测试代码的结构与应用程序其他部分的代码结构分开。\n\n### STRUCTURAL COUPLING 结构性耦合\n\nStructural coupling is one of the strongest, and most insidious, forms of test coupling. Imagine a test suite that has a test class for every production class, and a set of test methods for every production method. Such a test suite is deeply coupled to the structure of the application.\n\n> 结构性耦合是测试代码所具有的耦合关系中最强大、最阴险的一种形式。假设我们现在有一组测试套件，它针对每个产品类都有一个对应的测试类，每个产品函数都有一个对应的测试函数。显然，该测试套件与应用程序在结构上是紧耦合的。\n\nWhen one of those production methods or classes changes, a large number of tests must change as well. Consequently, the tests are fragile, and they make the production code rigid.\n\n> 每当应用程序中的一个函数或类发生变更时，该测试套件就必须进行大量相应的修改。因此，这些测试是非常脆弱的，它们也会让产品代码变得非常死板。\n\nThe role of the testing API is to hide the structure of the application from the tests. This allows the production code to be refactored and evolved in ways that don’t affect the tests. It also allows the tests to be refactored and evolved in ways that don’t affect the production code.\n\n> 测试专用 API 的作用就是将应用程序与测试代码解耦。这样，我们的产品代码就可以在不影响测试的情况下进行重构和演进。同样的，这种设计也允许测试代码在不影响生产代码的情况下进行重构和演进。\n\nThis separation of evolution is necessary because as time passes, the tests tend to become increasingly more concrete and specific. In contrast, the production code tends to become increasingly more abstract and general. Strong structural coupling prevents—or at least impedes—this necessary evolution, and prevents the production code from being as general, and flexible, as it could be.\n\n> 这种对演进过程的隔离是很重要的，因为随着时间的推移，测试代码趋向于越来越具体和详细。相比之下，我们的产品代码则会趋向于越来越抽象和通用。结构性的强耦合可能会让这种必需的演进无法进行——至少会形成强烈的干扰。\n\n### SECURITY 安全性\n\nThe superpowers of the testing API could be dangerous if they were deployed in production systems. If this is a concern, then the testing API, and the dangerous parts of its implementation, should be kept in a separate, independently deployable component.\n\n> 当然，这种具有超级权限的测试专用 API 如果被部署到我们的产品系统中，可能会是非常危险的。如果要避免这种情况发生，应该将测试专用 API 及其对应的具体实现放置在一个单独的、可独立部署的组件中。\n\n## CONCLUSION 本章小结\n\nTests are not outside the system; rather, they are parts of the system that must be well designed if they are to provide the desired benefits of stability and regression. Tests that are not designed as part of the system tend to be fragile and difficult to maintain. Such tests often wind up on the maintenance room floor—discarded because they are too difficult to maintain.\n\n> 测试并不是独立于整个系统之外的，恰恰相反，它们是系统的一个重要组成部分。我们需要精心设计这些测试，才能让它们发挥验证系统稳定性和预防问题复发的作用。没有按系统组成部分来设计的测试代码，往往是非常脆弱且难以维护的。这种测试最后常常会被抛弃，因为它们终究会出问题。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap29. CLEAN EMBEDDED ARCHITECTURE 整洁的嵌入式架构\n\n![](../../images/books/架构整洁之道/CH-UN29.jpg)\n\nBy James Grenning\n\nA while ago I read an article entitled “The Growing Importance of Sustaining Software for the DoD”1 on Doug Schmidt’s blog. Doug made the following claim:\n\n> 前一段时间，我在 Doug Schmidt 的个人博客上看到了一篇文章，标题是“The Growing Importance of Sustaining Software for the DoD”，Doug 在这篇文章中提出了以下观点：\n\n“Although software does not wear out, firmware and hardware become obsolete, thereby requiring software modifications.”\n\n> “虽然软件本身并不会随时间推移而磨损，但硬件及其固件却会随时间推移而过时，随即也需要对软件做相应改动。”\n\nIt was a clarifying moment for me. Doug mentioned two terms that I would have thought to be obvious—but maybe not. Software is this thing that can have a long useful life, but firmware will become obsolete as hardware evolves. If you have spent any time in embedded systems development, you know the hardware is continually evolving and being improved. At the same time, features are added to the new “software,” and it continually grows in complexity.\n\n> 这句话对我有如醍醐灌顶。Doug 在这里用到了两个专业名词，我一直认为是显而易见的，但是其他人可能并没有这么觉得。其中，软件（software）应该是一种使用周期很长的东西，而固件（firmware）则会随着硬件演进而淘汰过时。曾经开发过嵌入式系统的人一定都知道，硬件系统是在持续不断地演进的。与此同时，随着新功能不断地增加，软件复杂度也在不断上升。\n\nI’d like to add to Doug’s statement:\n\n> 在这里，我想对 Dough 上面的那个观点做一点补充：\n\nAlthough software does not wear out, it can be destroyed from within by unmanaged dependencies on firmware and hardware.\n\n> “虽然软件质量本身并不会随时间推移而损耗，但是未妥善管理的硬件依赖和固件依赖却是软件的头号杀手。”\n\nIt is not uncommon for embedded software to be denied a potentially long life due to being infected with dependencies on hardware.\n\n> 也就是说，本可以长期使用的嵌入式软件可能会由于其中隐含的硬件依赖关系而无法继续使用，这种情况是很常见的。\n\nI like Doug’s definition of firmware, but let’s see which other definitions are out there. I found these alternatives:\n\n> 我个人很喜欢 Doug 对固件所做的定义，但我们也可以来看一下其他人对固件的定义，以下是我目前所找到的一些说法：\n\n- “Firmware is held in non-volatile memory devices such as ROM, EPROM, or flash memory.” (<https://en.wikipedia.org/wiki/Firmware>)\n- “Firmware is a software program or set of instructions programmed on a hardware device.” (<https://techterms.com/definition/firmware>)\n- “Firmware is software that is embedded in a piece of hardware.” (<https://www.lifewire.com/what-is-firmware-2625881>)\n- Firmware is “Software (programs or data) that has been written onto read-only memory (ROM).” (<http://www.webopedia.com/TERM/F/firmware.html>)\n\n---\n\n> - “固件通常被存储在非可变内存设备，例如 ROM、EPROM 或者闪存中。”（<https://en.wikipedia.org/wiki/Firmware>）\n> - “固件是直接编程在一个硬件设备上的一组指令或者一段程序。”（<https://techterms.com/definition/firmware>）\n> - “固件是嵌入在一个硬件中的软件程序。”（<https://www.lifewire.com/what-is-firmware-2625881>）\n> - “固件是被写入到只读内存设备中的（ROM）程序或数据。”（<http://www.webopedia.com/TERM/F/firmware.html>）\n\nDoug’s statement makes me realize that these accepted definitions of firmware are wrong, or at least obsolete. Firmware does not mean code lives in ROM. It’s not firmware because of where it is stored; rather, it is firmware because of what it depends on and how hard it is to change as hardware evolves. Hardware does evolve (pause and look at your for phone for evidence), so we should structure our embedded code with that reality in mind.\n\n> Doug 的这段观点表述让我意识到，大家普遍所认知的固件定义是错误的，或者至少是过时的。固件并不一定是存储在 ROM 中的代码。固件也不是依据其存储的位置来定义的，而是由其代码的依赖关系，及其随着硬件的演进在变更难度上的变化来定义的。硬件的演进是显而易见的（如果对此有任何疑问，请想一想你手中的手机），我们在架构嵌入式代码时要时刻记住这一点。\n\nI have nothing against firmware, or firmware engineers (I’ve been known to write some firmware myself). But what we really need is less firmware and more software. Actually, I am disappointed that firmware engineers write so much firmware!\n\n> 我并不反对固件，也不反对固件工程师（我自己也曾经写过固件）。但是我们真的应该少写点固件，而多写点软件。事实上，我最失望的是固件工程师竟然要写那么多固件程序！\n\nNon-embedded engineers also write firmware! You non-embedded developers essentially write firmware whenever you bury SQL in your code or when you spread platform dependencies throughout your code. Android app developers write firmware when they don’t separate their business logic from the Android API.\n\n> 还有，非嵌入式工程师竟然也要写固件程序！虽然你可能并不是嵌入式系统的开发者，但如果你在代码中嵌入了 SQL 或者是代码中引入了对某个平台的依赖的话，其实就是在写固件代码。譬如，Android 工程师在没有将业务逻辑与 Android API 分离之前，实际上也是在写固件代码。\n\nI’ve been involved in a lot of efforts where the line between the product code (the software) and the code that interacts with the product’s hardware (the firmware) is fuzzy to the point of nonexistence. For example, in the late 1990s I had the fun of helping redesign a communications subsystem that was transitioning from time-division multiplexing (TDM) to voice over IP (VOIP). VOIP is how things are done now, but TDM was considered the state of the art from the 1950s and 1960s, and was widely deployed in the 1980s and 1990s.\n\n> 我参与过很多软件项目，其中一些产品的功能代码（软件）与硬件支持代码（固件）的边界模糊得几乎不存在。例如，在 20 世纪 90 年代末，我有幸参与了一套通信系统的重新设计，将其从时分复用（TDM）模式迁移到 VOIP 模式。虽然 VOIP 如今已经是行业标准，但是从 20 世纪 50 年代到 60 年代，TDM 一直都是非常先进的技术，直到 20 世纪 80 年代和 90 年代它也被广泛部署在各种系统中。\n\nWhenever we had a question for the systems engineer about how a call should react to a given situation, he would disappear and a little later emerge with a very detailed answer. “Where did he get that answer?” we asked. “From the current product’s code,” he’d answer. The tangled legacy code was the spec for the new product! The existing implementation had no separation between TDM and the business logic of making calls. The whole product was hardware/technology dependent from top to bottom and could not be untangled. The whole product had essentially become firmware.\n\n> 每当我们向系统工程师提出一个产品问题——系统在某个情况下应该如何处理某通电话，这位系统工程师就会消失一段时间，然后给出一个非常具体的答案。我们问他是从哪里查到这个结果的？答案是“从当前的产品代码里！”这些复杂交错的老代码己经成为系统定义的一部分。该系统在实现过程中并没有区分 TDM 技术代码和拨打电话这样的业务逻辑代码。整个产品从头到尾都与具体技术、具体硬件息息相关，无法分割。可以说整个产品已经成为事实上的固件。\n\nConsider another example: Command messages arrive to this system via serial port. Unsurprisingly, there is a message processor/dispatcher. The message processor knows the format of messages, is able to parse them, and can then dispatch the message to the code that can handle the request. None of this is surprising, except that the message processor/dispatcher resides in the same file as code that interacts with a UART2 hardware. The message processor is polluted with UART details. The message processor could have been software with a potentially long useful life, but instead it is firmware. The message processor is denied the opportunity to become software—and that is just not right!\n\n> 再来看另外一个例子：我们都知道命令消息是通过串行端口传递给系统的。这自然就要有一个消息的处理器/分发器系统。其中，消息处理器得了解消息格式，可以解析消息，然后将消息分发给具体的处理代码。这些都很正常，但消息处理器分发器的代码和操作 UART 硬件的代码往往会被放存同一个文件中消息处理器的代码中常常充斥着与 UART 相关的实现细节。这样一来，本可以长时间使用的消息处理器代码变成了一段固件代码，这太不应该了！\n\nI’ve known and understood the need for separating software from hardware for a long time, but Doug’s words clarified how to use the terms software and firmware in relationship to each other.\n\n> 虽然我意识到要从使用意义上将软件与硬件、固件区分开来也已经有一段时间了，但是借助 Doug 对软件和固件的定义，我现在可以吧这件事情说得更明白一些。\n\nFor engineers and programmers, the message is clear: Stop writing so much firmware and give your code a chance at a long useful life. Of course, demanding it won’t make it so. Let’s look at how we can keep embedded software architecture clean to give the software a fighting chance of having a long and useful life.\n\n> 对于程序员和工程师，我的意思很明确：不要再写固件代码了，让我们的代码活得更久点！当然，我们也不能总是空谈理念，下面就来看一下应该如何通过好的架构设计让嵌入式代码拥有更长的有效生命周期。\n\n## APP-TITUDE TEST “程序适用测试”测试\n\nWhy does so much potential embedded software become firmware? It seems that most of the emphasis is on getting the embedded code to work, and not so much emphasis is placed on structuring it for a long useful life. Kent Beck describes three activities in building software (the quoted text is Kent’s words and the italics are my commentary):\n\n> 为什么这么多嵌入式软件最后都成了固件？看起来，很可能是因为我们在做嵌入式设计时只关注代码能否顺利运行，并不太关心其结构能否撑起一个较长的有效生命周期。Kent Beck 描述了软件构建过程中的三个阶段（引号部分是他的原话，楷体部分是我的注解）：\n\n1. “First make it work.” You are out of business if it doesn’t work.\n2. “Then make it right.” Refactor the code so that you and others can understand it and evolve it as needs change or are better understood.\n3. “Then make it fast.” Refactor the code for “needed” performance.\n\n---\n\n> 1. “先让代码工作起来”——如果代码不能工作，就不能产生价值。\n> 2. “然后再试图将它变好——通过对代码进行重构，让我们自己和其他人更好地理解代码，并能按照需求不断地修改代码。\n> 3. “最后再试着让它运行得更快”——按照性能提升的“需求”来重构代码。\n\nMuch of the embedded systems software that I see in the wild seems to have been written with “Make it work” in mind—and perhaps also with an obsession for the “Make it fast” goal, achieved by adding micro-optimizations at every opportunity. In The Mythical Man-Month, Fred Brooks suggests we “plan to throw one away.” Kent and Fred are giving virtually the same advice: Learn what works, then make a better solution.\n\n> 我所见过的大部分“野生”的嵌入式代码，都只关注“先让它工作起来”这个目标——也许还有些团队会同时痴迷于“让它更快”这个目标，不放过任何一个机会加入各种微优化。在《人月神话》这本书中，Fred Brooks 建议我们应该随时准备“抛弃一个设计”。Kent 和 Fred 说的其实是同一件事：“在实践中学习正确的工作方法，然后再重写一个更好的版本”。\n\nEmbedded software is not special when it comes to these problems. Most non-embedded apps are built just to work, with little regard to making the code right for a long useful life.\n\n> 这个建议对非嵌入式软件系统开发同样有用。毕竟目前大部分非嵌入式应用也仅仅停留在“可用”这个目标上，很少考虑为了长久使用而进行正确的设计。\n\nGetting an app to work is what I call the App-titude test for a programmer. Programmers, embedded or not, who just concern themselves with getting their app to work are doing their products and employers a disservice. There is much more to programming than just getting an app to work.\n\n> 对于程序员来说，让他的程序工作这件事只能被称为“程序适用测试（app-titude test）”。一个程序员，不论他写的是否是嵌入式程序，如果目标仅仅是让程序可以工作，恐怕对他的老板和这个程序本身而言都是一件坏事。毕竟，编程这件事可远不止是让程序可以工作这么简单。\n\nAs an example of code produced while passing the App-titude test, check out these functions located in one file of a small embedded system:\n\n> 下面我们来示范一下可以通过“程序适用测试”的代码是什么样子的。先来看一个小型嵌入式系统中某个源文件中的一段函数声明：\n\n```c\nISR(TIMER1_vect) { ... }\nISR(INT2_vect) { ... }\nvoid btn_Handler(void) { ... }\nfloat calc_RPM(void) { ... }\nstatic char Read_RawData(void) { ... }\nvoid Do_Average(void) { ... }\nvoid Get_Next_Measurement(void) { ... }\nvoid Zero_Sensor_1(void) { ... }\nvoid Zero_Sensor_2(void) { ... }\nvoid Dev_Control(char Activation) { ... }\nchar Load_FLASH_Setup(void) { ... }\nvoid Save_FLASH_Setup(void) { ... }\nvoid Store_DataSet(void) { ... }\nfloat bytes2float(char bytes[4]) { ... }\nvoid Recall_DataSet(void) { ... }\nvoid Sensor_init(void) { ... }\nvoid uC_Sleep(void) { ... }\n```\n\nThat list of functions is in the order I found them in the source file. Now I’ll separate them and group them by concern:\n\n> 可以看到该源文件中的函数是按一定顺序列出来的。现在我们要按照功能进行分组：\n\n- Functions that have domain logic\n\n> - 用于定义域逻辑（domain logic）的函数\n\n```c\nfloat calc_RPM(void) { ... }\n\nvoid Do_Average(void) { ... }\n\nvoid Get_Next_Measurement(void) { ... }\n\nvoid Zero_Sensor_1(void) { ... }\n\nvoid Zero_Sensor_2(void) { ... }\n```\n\n- Functions that set up the hardware platform\n\n> - 用于设置硬件平台的函数\n\n```c\nISR(TIMER1_vect) { ... }*\n\nISR(INT2_vect) { ... }\n\nvoid uC_Sleep(void) { ... }\n\nFunctions that react to the on off button press\n\nvoid btn_Handler(void) { ... }\n\nvoid Dev_Control(char Activation) { ... }\n```\n\nA Function that can get A/D input readings from the hardware\n\n```java\nstatic char Read_RawData(void) { ... }\n```\n\n- Functions that store values to the persistent storage\n\n> - 用于执行持久化存储的函数\n\n```java\nchar Load_FLASH_Setup(void) { ... }\n\nvoid Save_FLASH_Setup(void) { ... }\n\nvoid Store_DataSet(void) { ... }\n\nfloat bytes2float(char bytes[4]) { ... }\n\nvoid Recall_DataSet(void) { ... }\n```\n\n- Function that does not do what its name implies\n\n> - 功能与其名字不符的函数\n\n```java\nvoid Sensor_init(void) { ... }\n```\n\nLooking at some of the other files in this application, I found many impediments to understanding the code. I also found a file structure that implied that the only way to test any of this code is in the embedded target. Virtually every bit of this code knows it is in a special microprocessor architecture, using “extended” C constructs3 that tie the code to a particular tool chain and microprocessor. There is no way for this code to have a long useful life unless the product never needs to be moved to a different hardware environment.\n\n> 在查看该应用程序其他源代码文件的过程中，我同样发现了许多理解上的障碍点。同时，我还发现这个项目的结构决定了该应用程序的所有代码只有在指定硬件平台上才能被测试。几乎代码的所有部分都知道它要运行在一个特殊的微处理器平台上，因为它们用的是“被扩展了的” C 结构，需要特殊的工具链和微处理器才能执行。除非这个产品永远不需要迁移到另一个硬件平台上，否则这段代码几乎不可能有长久的使用价值。\n\nThis application works: The engineer passed the App-titude test. But the application can’t be said to have a clean embedded architecture.\n\n> 所以你看，这段代码的确能够正常工作：它的工程师也通过了“程序适用性测试”，但我们不能说该应用程序有一套整洁的嵌入式架构。\n\n## THE TARGET-HARDWARE BOTTLENECK 目标硬件瓶颈\n\nThere are many special concerns that embedded developers have to deal with that non-embedded developers do not—for example, limited memory space, real-time constraints and deadlines, limited IO, unconventional user interfaces, and sensors and connections to the real world. Most of the time the hardware is concurrently developed with the software and firmware. As an engineer developing code for this kind of system, you may have no place to run the code. If that’s not bad enough, once you get the hardware, it is likely that the hardware will have its own defects, making software development progress even slower than usual.\n\n> 嵌入式系统的程序员通常需要处理很多在写非嵌入式系统时不需要关心的事情——例如，有限的地址空间、实时性限制、运行截止时间、有限的 I/O 能力、非常规的用户接口、感应器，以及其他与物理世界的实际链接。大部分时候，这些系统的硬件是和它的软件、固件并行开发的。工程师在为这种系统编写代码的时候，往往没有任何地方可以运行。如果你认为这还不算糟糕的话，请想象一下，如果我们要等到真正拿到硬件时，才能了解代码在该硬件上存在着哪些意料之外的缺陷，这会在多大程度上拖慢我们的开发进度?\n\nYes, embedded is special. Embedded engineers are special. But embedded development is not so special that the principles in this book are not applicable to embedded systems.\n\n> 是的，我们承认嵌入式系统的开发有其特殊性，嵌入式工程师的工作有其特殊性，但我们并不认为嵌入式开发特殊到本书所讲的原则都不适用的程度。\n\nOne of the special embedded problems is the target-hardware bottleneck. When embedded code is structured without applying clean architecture principles and practices, you will often face the scenario in which you can test your code only on the target. If the target is the only place where testing is possible, the target-hardware bottleneck will slow you down.\n\n> 标硬件瓶颈（target-hardware bottleneck）是嵌入式开发所特有的一个问题，如果我们没有采用某种清晰的架构来设计嵌入式系统的代码结构，就经常会面临只能在目标系统平台上测试代码的难题。如果只能在特定的平台上测试代码，那么这一定会拖慢项目的开发进度。\n\n### A CLEAN EMBEDDED ARCHITECTURE IS A TESTABLE EMBEDDED ARCHITECTURE 整洁的嵌入式架构就是可测试的嵌入式架构\n\nLet’s see how to apply some of the architectural principles to embedded software and firmware to help you eliminate the target-hardware bottleneck.\n\n> 下面，我们来看一下具体应如何将架构设计的原则应用在嵌入式软件和固件上，以避免陷入目标硬件瓶颈。\n\n### Layers 分层\n\nLayering comes in many flavors. Let’s start with three layers, as shown in Figure 29.1. At the bottom, there is the hardware. As Doug warns us, due to technology advances and Moore’s law, the hardware will change. Parts become obsolete, and new parts use less power or provide better performance or are cheaper. Whatever the reason, as an embedded engineer, I don’t want to have a bigger job than is necessary when the inevitable hardware change finally happens.\n\n> 分层可以有很多种方式，这里先按图 29.1 所示的设计将系统分成三层。首先，底层是硬件层。正如 Doug 警告我们的那样，由于科技的进步与摩尔定律，硬件是一定会改变的。旧的硬件不见将会被淘汰，新的硬件部件可能耗电量更少，或者性能更好，或者价格更便宜。不管硬件更新的原因是什么，作为嵌入式工程师，我们都不会希望这些不可避免的硬件变动带来更多的工作量。\n\n<Figures figure=\"29-1\">Three layers</Figures>\n\nThe separation between hardware and the rest of the system is a given—at least once the hardware is defined (Figure 29.2). Here is where the problems often begin when you are trying to pass the App-titude test. There is nothing that keeps hardware knowledge from polluting all the code. If you are not careful about where you put things and what one module is allowed to know about another module, the code will be very hard to change. I’m not just talking about when the hardware changes, but when the user asks for a change, or when a bug needs to be fixed.\n\n> 硬件与系统其他部分的分隔是既定的——至少在硬件设计完成之后如此（如图 29.2 所示）。这也是在我们试图通过程序适用测试之时往往会发生问题的地方。因为没有什么东西可以真正阻碍硬件实现细节污染到应用代码。如果我们在构建代码的时候不够小心，没有小心安排哪些模块之间可以互相依赖，代码很快就非常难以更改了。请注意，这里所说的变更不仅仅是指来自硬件的变更，还包括用户的功能性变更、修复代码中的 Bug。\n\n<Figures figure=\"29-2\">Hardware must be separated from the rest of the system</Figures>\n\nSoftware and firmware intermingling is an anti-pattern. Code exhibiting this anti-pattern will resist changes. In addition, changes will be dangerous, often leading to unintended consequences. Full regression tests of the whole system will be needed for minor changes. If you have not created externally instrumented tests, expect to get bored with manual tests—and then you can expect new bug reports.\n\n> 另外，软件与固件集成在一起也属于设计上的反模式（anti-pattern）。符合这种反模式的代码修改起来都会很困难。同时，这种代码也很危险，容易造成意外事故，这导致它经历任何微少的改动都需要进行完整的回归测试。如果没有完善的测试流程，那么你就等着无穷无尽的手工测试吧——同时还有纷沓而来的 Bug 报告。\n\n### The Hardware Is a Detail 硬件是实现细节\n\nThe line between software and firmware is typically not so well defined as the line between code and hardware, as shown in Figure 29.3.\n\n> 软件与固件之间的边界往往没有代码与硬件之间的边界那么清晰，如图 29.3 所示。\n\n<Figures figure=\"29-3\">The line between software and firmware is a bit fuzzier than the line between code and hardware</Figures>\n\nOne of your jobs as an embedded software developer is to firm up that line. The name of the boundary between the software and the firmware is the hardware abstraction layer (HAL) (Figure 29.4). This is not a new idea: It has been in PCs since the days before Windows.\n\n> 所以，我们的工作之一就是将这个边界定义得更清晰一些。软件与固件之间的边界被称为硬件抽象层（HAL），如图 29.4 所示。这不是一个新概念，它在 PC 上的存在甚至可以追溯到 Windows 诞生之前。\n\n<Figures figure=\"29-4\">The hardware abstraction layer</Figures>\n\nThe HAL exists for the software that sits on top of it, and its API should be tailored to that software’s needs. As an example, the firmware can store bytes and arrays of bytes into flash memory. In contrast, the application needs to store and read name/value pairs to some persistence mechanism. The software should not be concerned that the name/value pairs are stored in flash memory, a spinning disk, the cloud, or core memory. The HAL provides a service, and it does not reveal to the software how it does it. The flash implementation is a detail that should be hidden from software.\n\n> HAL 的存在是为了给它上层的软件提供服务，HAL 的 API 应该按照这些软件的需要来量身定做。例如，固件可以直接将字节和字节组存入闪存中。相比之下，软件需要的是从某种持久化平台保存和读取 name/value 对信息，它不应该关心自己信息到底是被存储到闪存中、磁盘中、云端存储中，还是在内存中读取/存储这些信息。总之，HAL 的作用是为软件部分提供一种服务，以便隐藏具体的实现细节。毕竟是专门针对闪存的实现代码是一种细节信息，它应该与软件部分隔离。\n\nAs another example, an LED is tied to a GPIO bit. The firmware could provide access to the GPIO bits, where a HAL might provide Led_TurnOn(5). That is a pretty low-level hardware abstraction layer. Let’s consider raising the level of abstraction from a hardware perspective to the software/product perspective. What is the LED indicating? Suppose that it indicated low battery power. At some level, the firmware (or a board support package) could provide Led_TurnOn(5), while the HAL provides Indicate_LowBattery(). You can see the HAL expressing services needed by the application. You can also see that layers may contain layers. It is more of a repeating fractal pattern than a limited set of predefined layers. The GPIO assignments are details that should be hidden from the software.\n\n> 我们再来看另一个例子：有一个 LED 被连接到一个 GPIO 比特位上。固件可以直接操作 GPIO 比特位，而 HAL 则会提供一个 Led_TurnOn(5) 数。这种硬件抽象层的层次是相当低的。现在，假设我们想将抽象层次从硬件层次提升到软件/产品的层次。这时候就要弄清楚这个 LED 到底代表的是什么。假设它代表了电池电量不足，那么其固码（或该电路板的支持包）可能就会负责提供 Led_TurnOn(5) 函数，而 HAL 则负责提供 Indicate_LowBattery() 函数。由此可见，HAL 层是按照应用程序的需要来提供服务的。同时，我们也能看出来系统的每一个分层中都可以包含许多分层。相对于之前的固定分层法，这里更像是一种无限分层模式。总之，GPIO 位的对应关系应该是一个具体的实现细节，它应该与软件部分隔离。\n\n### DON’T REVEAL HARDWARE DETAILS TO THE USER OF THE HAL 不要向 HAL 的用户暴露硬件细节\n\nA clean embedded architecture’s software is testable off the target hardware. A successful HAL provides that seam or set of substitution points that facilitate off-target testing.\n\n> 依照整洁的嵌入式架构所建构的软件应该是可以脱离目标硬件平台来进行测试的。因为设计合理的 HAL 可以为我们脱离硬件平台的测试提供相应的支撑。\n\n### The Processor Is a Detail\n\nWhen your embedded application uses a specialized tool chain, it will often provide header files to `<i>`help you`</i>`.4 These compilers often take liberties with the C language, adding new keywords to access their processor features. The code will look like C, but it is no longer C.\n\n> 当我们的嵌入式应用依赖于某种特殊的工具链时，该工具链通常会为我们提供一些“`<i>帮助</i>`\"性质的头文件。这些编译器往往会自带一些基于 C 语言的扩展库，并添加一些用于访问特殊功能的关键词。这会导致这些程序的代码看起来仍然用的是 C 语言，但实际上它们已经不是 C 语言了。\n\nSometimes vendor-supplied C compilers provide what look like global variables to give access directly to processor registers, IO ports, clock timers, IO bits, interrupt controllers, and other processor functions. It is helpful to get access to these things easily, but realize that any of your code that uses these helpful facilities is no longer C. It won’t compile for another processor, or maybe even with a different compiler for the same processor.\n\n> 有时候，这些嵌入式应用的提供商所指定的 C 编译器还会提供类似于全局变量的功能，以便我们直接访问寄存器、I/O 端口、时钟信息、I/O 位、中断控制器以及其他处理器函数，这些函数会极大地方便我们对相关硬件的访问。但请注意，一旦你在代码中使用了这些函数，你写的就不再是 C 语言程序，它就不能用其他编译器来编译了，甚至可能连同一个处理器的不同编译器也不行。\n\nI would hate to think that the silicon and tool provider is being cynical, tying your product to the compiler. Let’s give the provider the benefit of a doubt by assuming that it is truly trying to help. But now it’s up to you to use that help in a way that does not hurt in the future. You will have to limit which files are allowed to know about the C extensions.\n\n> 我不想说这是提供商故意给我们设置的陷阱，即便我们假设这些硬件提供商这样做真的是为了“帮助”我们，我们自己也要知道如何来利用这些“帮助”，这才是问题的关键。为避免自己的代码在未来出现问题，我们就必须限制这些 C 扩展的使用范围。\n\nLet’s look at this header file designed for the ACME family of DSPs—you know, the ones used by Wile E. Coyote:\n\n> 下面来看一下针对 ACME DSP（数字信号处理器）系统设计的头文件——While E Coyote 采用的就是这个系统：\n\n```c\n#ifndef _ACME_STD_TYPES\n#define _ACME_STD_TYPES\n```\n\n```c\n#if defined(_ACME_X42)\n    typedef unsigned int        Uint_32;\n    typedef unsigned short      Uint_16;\n    typedef unsigned char       Uint_8;\n\n    typedef int                 Int_32;\n    typedef short               Int_16;\n    typedef char                Int_8;\n\n#elif defined(_ACME_A42)\n    typedef unsigned long       Uint_32;\n    typedef unsigned int        Uint_16;\n    typedef unsigned char       Uint_8;\n\n    typedef long                Int_32;\n    typedef int                 Int_16;\n    typedef char                Int_8;\n#else\n    #error <acmetypes.h> is not supported for this environment\n#endif\n\n#endif\n```\n\nThe acmetypes.h header file should not be used directly. If you do, your code gets tied to one of the ACME DSPs. You are using an ACME DSP, you say, so what is the harm? You can’t compile your code unless you include this header. If you use the header and define `__ACME_X42` or `__ACME_A42`, your integers will be the wrong size if you try to test your code off-target. If that is not bad enough, one day you’ll want to port your application to another processor, and you will have made that task much more difficult by not choosing portability and by not limiting what files know about ACME.\n\n> 该 `acmetypes.h` 头文件通常不应该直接使用。因为如果这样做的话，代码就和某个 ACME DSP 绑定在一起了。这时候你可能会问，我们在这里写代码不就是为了使用 ACME DSP 吗？不引用这个头文件如何编译代码呢？但如果引用了这个头文件，就等于同时定义了 `__ACME_X42` 和 `__ACME_A42`，那么我们的代码在平台之外进行测试的时候整数类型的大小就会是错误的。更糟糕的是，有一天当我们想将代码迁移到另外一个处理器上的时候，如果没有在这里限制 ACME 头文件被引用的范围，就会大大增加这项迁移工作的难度。\n\nInstead of using acmetypes.h, you should try to follow a more standardized path and use stdint.h. But what if the target compiler does not provide stdint.h? You can write this header file. The stdint.h you write for target builds uses the acmetypes.h for target compiles like this:\n\n> 因此在这里，我们应该用标准的 `stdint.h` 来替代 `acmetypes.h`。如果目标编译器没有提供 `stdint.h` 的话，我们可以自己写一个。例如，下面就是一个针对目标编译器的，可以用 `acmetypes.h` 来构建目标的自定义 `stdint.h`：\n\n```c\n#ifndef _STDINT_H_#define _STDINT_H_#include <acmetypes.h>typedef Uint_32 uint32_t;typedef Uint_16 uint16_t;typedef Uint_8  uint8_t;typedef Int_32  int32_t;typedef Int_16  int16_t;typedef Int_8   int8_t;#endif\n```\n\nHaving your embedded software and firmware use stdint.h helps keep your code clean and portable. Certainly, all of the software should be processor independent, but not all of the firmware can be. This next code snippet takes advantage of special extensions to C that gives your code access to the peripherals in the micro-controller. It’s likely your product uses this micro-controller so that you can use its integrated peripherals. This function outputs a line that says \"hi\" to the serial output port. (This example is based on real code from the wild.)\n\n> 使用 `stdint.h` 来编写嵌入式的软件和固件，你的代码会是整洁且可移植的。当然，我们应该让所有的软件都独立于处理器，但这并不是所有固件都可以做到的。下面这段代码使用了特殊的 C 扩展来访问微处理器的配件，这样做的目的很可能就是为了使用这个配件。这个函数的作用就是输出一行\"hi\"到串口。（该例子来自于一个真实项目。）\n\n```c\nvoid say_hi(){  IE = 0b11000000;  SBUF0 = (0x68);  while(TI_0 == 0);  TI_0 = 0;  SBUF0 = (0x69);  while(TI_0 == 0);  TI_0 = 0;  SBUF0 = (0x0a);  while(TI_0 == 0);  TI_0 = 0;  SBUF0 = (0x0d);  while(TI_0 == 0);  TI_0 = 0;  IE = 0b11010000;}\n```\n\nThere are lots of problems with this small function. One thing that might jump out at you is the presence of 0b11000000. This binary notation is cool; can C do that? Unfortunately, no. A few other problems relate to this code directly using the custom C extensions:\n\n> 这个小函数中存在大量的问题。首先，你注意到的可能就是 `0b11000000`。二进制表示法的确很酷，但 C 语言支持它吗？并不支持。另外还有一些问题也与 C 语言的扩展有关。\n\nIE: Interrupt enable bits.\n\nSBUF0: Serial output buffer.\n\nTI_0: Serial transmit buffer empty interrupt. Reading a 1 indicates the buffer is empty.\n\n> IE：设置中断比特位。\n>\n> SBUF0：串口输出缓冲区。\n>\n> TI_0：串口传输区空中断。读取到 1 表明缓冲区为空。\n\nThe uppercase variables actually access micro-controller built-in peripherals. If you want to control interrupts and output characters, you must use these peripherals. Yes, this is convenient—but it’s not C.\n\n> 这些名字大写的变量实际上都是用来访问微处理器的内置部件的。如果我们需要控制中断并且输出字符，就必须使用这些部件，它们也确实很方便——但这不是 C 代码。\n\nA clean embedded architecture would use these device access registers directly in very few places and confine them totally to the firmware. Anything that knows about these registers becomes firmware and is consequently bound to the silicon. Tying code to the processor will hurt you when you want to get code working before you have stable hardware. It will also hurt you when you move your embedded application to a new processor.\n\n> 在整洁的嵌入式架构中，我们会将这些用于设备访问的寄存器访问集中在一起，并将其限制在固件层中。这样一来，任何需要知道这些寄存器值的代码都必须成为固件代码，与硬件实现绑定。一旦这些代码与处理器实现强绑定，那么在处理器稳定工作之前它们是无法工作的，并且在需要将其迁移到一个新处理器上时也会遇到麻烦。\n\nIf you use a micro-controller like this, your firmware could isolate these low-level functions with some form of a processor abstraction layer (PAL). Firmware above the PAL could be tested off-target, making it a little less firm.\n\n> 如果我们真的需要使用这种微处理器，固件就必须将这类底层函数隔离成处理器抽象层（PAL），这样一来，使用 PAL 的固件代码就可以在目标平台之外被测试了。\n\n### The Operating System Is a Detail 操作系统是实现细节\n\nA HAL is necessary, but is it sufficient? In bare-metal embedded systems, a HAL may be all you need to keep your code from getting too addicted to the operating environment. But what about embedded systems that use a real-time operating system (RTOS) or some embedded version of Linux or Windows?\n\n> HAL 的必要性是不言而喻的，但光有 HAL 就够了吗？在裸机的嵌入式系统中，HAL 的确可能可以保证我们的代码不会和运行环境绑定得太紧密。但如果嵌入式系统使用了某种实时操作系统（RTOS），或者某种嵌入式的 Linux 或 Windows 呢？\n\nTo give your embedded code a good chance at a long life, you have to treat the operating system as a detail and protect against OS dependencies.\n\n> 为了延长代码的生命周期，我们必须将操作系统也定义为实现细节，让代码避免与操作系统层产生依赖。\n\nThe software accesses the services of the operating environment through the OS. The OS is a layer separating the software from firmware (Figure 29.5). Using an OS directly can cause problems. For example, what if your RTOS supplier is bought by another company and the royalties go up, or the quality goes down? What if your needs change and your RTOS does not have the capabilities that you now require? You’ll have to change lots of code. These won’t just be simple syntactical changes due to the new OS’s API, but will likely have to adapt semantically to the new OS’s different capabilities and primitives.\n\n> 软件通过操作系统来访问运行环境服务。操作系统是将软件与固件隔离的那一层（见图 29.5），直接使用操作系统服务可能会带来问题。例如，如果更换了 RTOS 操作系统厂商，授权费用提高，或者质量下降怎么办？如果需求发生变化，RTOS 无法满足怎么办？很多代码都需要变动，不仅要更改语法适应新操作系统 API，很有可能需要重新适应新操作系统的语义与原语。\n\n<Figures figure=\"29-5\">Adding in an operating system</Figures>\n\nA clean embedded architecture isolates software from the operating system, through an operating system abstraction layer (OSAL) (Figure 29.6). In some cases, implementing this layer might be as simple as changing the name of a function. In other cases, it might involve wrapping several functions together.\n\n> 整洁的嵌入式架构会引入操作系统抽象层（OSAL，如图 29.6 所示），将软件与操作系统分割开。在某些情况下，实现这个抽象层就像给函数改个名字那么简单。而在另一些情况下，则需要将几个函数封装在一起。\n\n<Figures figure=\"29-6\">The operating system abstraction layer</Figures>\n\nIf you have ever moved your software from one RTOS to another, you know it is painful. If your software depended on an OSAL instead of the OS directly, you would largely be writing a new OSAL that is compatible with the old OSAL. Which would you rather do: modify a bunch of complex existing code, or write new code to a defined interface and behavior? This is not a trick question. I choose the latter.\n\n> 如果你有迁移过 RTOS 系统的经历，就一定知道那有多痛苦。如果我们能让自己的软件依赖于 OSAL，而不是直接依赖于操作系统，我们就只需要写一个兼容以前的 OSAL 实现的新版本即可。你觉得哪一种方式更好？是修改一堆复杂的现有代码，还是按照接口和行为定义来写一套新代码？这里显而易见，后者更好。\n\nYou might start worrying about code bloat about now. Really, though, the layer becomes the place where much of the duplication around using an OS is isolated. This duplication does not have to impose a big overhead. If you define an OSAL, you can also encourage your applications to have a common structure. You might provide message passing mechanisms, rather than having every thread handcraft its concurrency model.\n\n> 当然，我们可能会担心代码膨胀的问题。但是，其实上面这种分层已经将因为使用操作系统所带来的重复性代码隔离开了，因此这种重复不一定会带来很大的额外负担。而且，如果我们定义了 OSAL，还可以让自己的应用共享一种公用结构。比如采用一套标准的消息传递机制，这样每个线程就不用自己定义一个并行模型了。\n\nThe OSAL can help provide test points so that the valuable application code in the software layer can be tested off-target and off-OS. A clean embedded architecture’s software is testable off the target operating system. A successful OSAL provides that seam or set of substitution points that facilitate off-target testing.\n\n> 另外，OSAL 还可以帮助高价值的应用程序实现在目标平台、目标操作系统之外进行测试。一个由整洁的嵌入式架构所构建出来的软件是可以在目标操作系统之外被测试的。设计良好的 OSAL 会为这种目标环境外的测试提供支撑点。\n\n### PROGRAMMING TO INTERFACES AND SUBSTITUTABILITY 面向接口编程与可替代性\n\nIn addition to adding a HAL and potentially an OSAL inside each of the major layers (software, OS, firmware, and hardware), you can—and should—apply the principles described throughout this book. These principles encourage separation of concerns, programming to interfaces, and substitutability.\n\n> 除了在嵌入式系统的主要分层（指软件、操作系统、固件、硬件这四层）之中增加 HAL 和 OSAL 之外，我们还可以——也应该——应用本书中提到的其他设计原则。这些设计原则可以帮助我们按功能模块、接口编程以及可替代性来划分系统。\n\nThe idea of a layered architecture is built on the idea of programming to interfaces. When one module interacts with another though an interface, you can substitute one service provider for another. Many readers will have written their own small version of printf for deployment in the target. As long as the interface to your printf is the same as the standard version of printf, you can override the service one for the other.\n\n> 分层架构的理念是基于接口编程的理念来设计的。当模块之间能以接口形式交互时，我们就可以将一个服务替换成另外一个服务。例如，很多读者应该都写过能在某个目标机器上运行的、小型的自定义的 printf 函数。只要我们的 printf 与标准的 printf 函数接口一致，它们就可以互相替换。\n\nOne basic rule of thumb is to use header files as interface definitions. When you do so, however, you have to be careful about what goes in the header file. Limit header file contents to function declarations as well as the constants and struct names that are needed by the function.\n\n> 目前的普适规则之一就是用头丈件来充当接口的定义。然而，如果真的要这样做的话，就需要小心控制头文件中的内容，尽量确保头文件中只包括函数声明，以及函数所需要的结构体名字和常量。\n\nDon’t clutter the interface header files with data structures, constants, and typedefs that are needed by only the implementation. It’s not just a matter of clutter: That clutter will lead to unwanted dependencies. Limit the visibility of the implementation details. Expect the implementation details to change. The fewer places where code knows the details, the fewer places where code will have to be tracked down and modified.\n\n> 另外，不要在定义接口的头文件中包含只有具体实现代码才需要的数据结构、常量以及类型定义（typedef）。这不仅仅是架构是否整洁的问题，而是这样做可能会导致意外的依赖关系。总之，我们必须控制好实现细节的可见性，因为这些实现细节是肯定会变化的。关注实现细节的代码越少，它们所需的变更就越少。\n\nA clean embedded architecture is testable within the layers because modules interact through interfaces. Each interface provides that seam or substitution point that facilitates off-target testing.\n\n> 由整洁的嵌入式架构所构建的系统应该在每一个分层中都是可测试的，因为它的模块之间采用接口通信，每一个接口都为平台之外的测试提供了替换点。\n\n### DRY CONDITIONAL COMPILATION DIRECTIVES DRY 条件性编译命令\n\nOne use of substitutability that is often overlooked relates to how embedded C and C++ programs handle different targets or operating systems. There is a tendency to use conditional compilation to turn on and off segments of code. I recall one especially problematic case where the statement #ifdef BOARD_V2 was mentioned several thousand times in a telecom application.\n\n> 另一个经常被忽视的可替代换性规则的实际案例是嵌入式 C/C++ 程序对不同平台和操作系统的处理方式。这些程序经常会用条件性编译命令来根据不同的平台启用和禁用某一段代码。例如，我曾经遇到过 `#ifdef BOARD_V2` 这条语句在一个电信应用程序中出现了几千次的情况。\n\nThis repetition of code violates the Don’t Repeat Yourself (DRY) principle.5 If I see #ifdef BOARD_V2 once, it’s not really a problem. Six thousand times is an extreme problem. Conditional compilation identifying the target-hardware’s type is often repeated in embedded systems. But what else can we do?\n\n> 很显然，这种代码的重复违背了“不要重复自己（DRY）”原则。如果 `#ifdef BOARD_V2` 只出现一次，这当然不是什么问题，而如果出现了 6000 次，那就非常严重了。但这类条件性编译语句在嵌入式编程中非常常见，有什么好的解决方案吗？\n\nWhat if there is a hardware abstraction layer? The hardware type would become a detail hidden under the HAL. If the HAL provides a set of interfaces, instead of using conditional compilation, we could use the linker or some form of runtime binding to connect the software to the hardware.\n\n> 使用硬件抽象层如何？这样的话，硬件类型就只是 HAL 中的一个实现细节了。而且，如果系统中使用的是 HAL 所提供的一系列接口，而不是条件性编译语句，那么我们就可以用链接器，或者某种运行时加载器来将软件与硬件相结合了。\n\n## CONCLUSION 本章小结\n\nPeople who are developing embedded software have a lot to learn from experiences outside of embedded software. If you are an embedded developer who has picked up this book, you will find a wealth of software development wisdom in the words and ideas.\n\n> 嵌入式编程人员应该多学习一些非嵌入式系统的编程经验。如果你从事的是嵌入式编程工作，相信你一定会从本章的建议中得到很多启发。\n\nLetting all code become firmware is not good for your product’s long-term health. Being able to test only in the target hardware is not good for your product’s long-term health. A clean embedded architecture is good for your product’s long-term health.\n\n> 为了让我们的产品能长期地保持健康，请别让你的代码都变成固件。如果一个系统的代码只能在目标硬件上测试，那么它的开发过程会变得非常艰难。总之，为产品的长期健康着想而采用一套整洁的嵌入式架构是很有必要的。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Part6. DETAILS 实现细节\n\n# Chap30. THE DATABASE IS A DETAIL 数据库只是实现细节\n\n![](../../images/books/架构整洁之道/CH-UN30.jpg)\n\nFrom an architectural point of view, the database is a non-entity—it is a detail that does not rise to the level of an architectural element. Its relationship to the architecture of a software system is rather like the relationship of a doorknob to the architecture of your home.\n\n> 从系统架构的角度来看，数据库并不重要——它只是一个实现细节，在系统架构中并不占据重要角色。如果就数据库与整个系统架构的关系打个比方，它们之间就好比是门把手和整个房屋架构的关系。\n\nI realize that these are fighting words. Believe me, I’ve had the fight. So let me be clear: I am not talking about the data model. The structure you give to the data within your application is highly significant to the architecture of your system. But the database is not the data model. The database is piece of software. The database is a utility that provides access to the data. From the architecture’s point of view, that utility is irrelevant because it’s a low-level detail—a mechanism. And a good architect does not allow low-level mechanisms to pollute the system architecture.\n\n> 这个比喻肯定会招来非议。相信我，这种架我吵过很多次了。所以我在这里要把话说得清楚一点：这里讨论的不是数据模型。为应用程序中的数据设计结构，对于系统架构来说当然是很重要的，但是数据库并不是数据模型。数据库只是一款软件，是用来存取数据的工具。从系统架构的角度来看，工具通常是无关紧要的——因为这只是一个底层的实现细节，一种达成目标的手段。一个优秀的架构师是不会让实现细节污染整个系统架构的。\n\n## RELATIONAL DATABASES 关系型数据库\n\nEdgar Codd defined the principles of relational databases in 1970. By the mid-1980s, the relational model had grown to become the dominant form of data storage. There was a good reason for this popularity: The relational model is elegant, disciplined, and robust. It is an excellent data storage and access technology.\n\n> 关系型数据库的基本原理是 Edgar Codd 在 1970 年定义的。到了 20 世纪 80 年代中期，这种关系模型已经成为数据存储设计的主流。由于关系模型优雅、自律、非常稳健，因此得到了非常广泛的应用。总之，关系型数据库是一种非常优秀的数据存储与访问技术。\n\nBut no matter how brilliant, useful, and mathematically sound a technology it is, it is still just a technology. And that means it’s a detail.\n\n> 但不管关系型数据库的设计有多么有智慧，多么精巧，多么符合数学原理，它仍然也只是一种技术。换句话说，它终究只是一种实现细节。\n\nWhile relational tables may be convenient for certain forms of data access, there is nothing architecturally significant about arranging data into rows within tables. The use cases of your application should neither know nor care about such matters. Indeed, knowledge of the tabular structure of the data should be restricted to the lowest-level utility functions in the outer circles of the architecture.\n\n> 虽然关系型数据的表模型设计对某一类数据访问需要来说可能很方便，但是把数据按行组成表结构本身并没有什么系统架构意义上的重要性。应用程序的用例不应该知道，也不应该关心这么低层次的实现细节，需要了解数据表结构的代码应该被局限在系统架构的最外圈、最低层的工具函数中。\n\nMany data access frameworks allow database rows and tables to be passed around the system as objects. Allowing this is an architectural error. It couples the use cases, business rules, and in some cases even the UI to the relational structure of the data.\n\n> 很多数据访问框架允许将数据行和数据表以对象的形式在系统内部传递。这么做在系统架构上来说是完全错误的，这会导致程序的用例、业务逻辑、甚至 UI 与数据的关系模型相互绑定在一起。\n\n## WHY ARE DATABASE SYSTEMS SO PREVALENT? 为什么数据库系统如此流行\n\nWhy are software systems and software enterprises dominated by database systems? What accounts for the preeminence of Oracle, MySQL, and SQL Server? In a word: disks.\n\n> 为什么数据库系统在软件系统和企业软件领域如此流行？ Oracle、MySQL 和 SQL Server 这些产品广泛流行的原因是什么？答案是硬盘。\n\nThe rotating magnetic disk was the mainstay of data storage for five decades. Several generations of programmers have known no other form of data storage. Disk technology has grown from huge stacks of massive platters 48 inches in diameter that weighed thousands of pounds and held 20 megabytes, to single thin circles, 3 inches in diameter, that weigh just a few grams and hold a terabyte or more. It’s been a wild ride. And throughout that ride programmers have been plagued by one fatal trait of disk technology: Disks are slow.\n\n> 带有高速旋转的盘片，以磁感应方式读取数据的硬盘在过去五十年成为数据存储的主流手段，以至于最近几代软件工程师对其他类型的数据存储几乎一无所知。而且硬盘技术一直在发展，早先一大摞重达数吨的直径 48 英寸的盘片只能存储 20 兆字节，现在单个直径 3 英寸、重量仅仅几克的薄薄的一张硬盘就能存储上 TB 的数据。这发展得实在是太快了！但是在硬盘的整个发展过程中，程序员们始终被一个限制困扰着：磁盘的访问速度太慢了！\n\nOn a disk, data is stored within circular tracks. Those tracks are divided into sectors that hold a convenient number of bytes, often 4K. Each platter may have hundreds of tracks, and there can be a dozen or so platters. If you want to read a particular byte off the disk, you have to move the head to the proper track, wait for the disk to rotate to the proper sector, read all 4K of that sector into RAM, and then index into that RAM buffer to get the byte you want. And all that takes time—milliseconds of times.\n\n> 在磁盘上，数据是按照环形轨道存储的。这些轨道又会进一步被划分成一系列扇区，这些扇区的大小通常是 4 KB。而每个盘片上都有几百条轨道，整个硬盘可能由十几个盘片组成。如果要从硬盘上读取某一个特定字节，需要将磁头挪到正确的轨道上，等待盘片旋转到正确的位置上，再将整个扇区读入内存中，从内存中查询对应的字节。这些过程当然需要时间，所以硬盘的访问速度一般在毫秒级。\n\nMilliseconds might not seem like a lot, but a millisecond is a million times longer than the cycle time of most processors. If that data was not on a disk, it could be accessed in nanoseconds, instead of milliseconds.\n\n> 毫秒级的速度看起来好像并不是很慢，但这已经比大多数处理器的速度慢一百万倍了。如果数据不在硬盘上，访问速度通常就通常是纳秒级，而不是毫秒级了。\n\nTo mitigate the time delay imposed by disks, you need indexes, caches, and optimized query schemes; and you need some kind of regular means of representing the data so that these indexes, caches, and query schemes know what they are working with. In short, you need a data access and management system. Over the years these systems have split into two distinct kinds: file systems and relational database management systems (RDBMS).\n\n> 为了应对硬盘访问速度带来的限制，必须使用索引、缓存以及查询优化器等技术。同时，我们还需要一种数据的标准展现格式，以便让索引、缓存及查询优化器来使用。概括来说，我们需要的就是某种数据访问与管理系统。过去几十年内，业界逐渐发展出了两种截然不同的系统：文件系统与关系型数据库系统（RDBMS）。\n\nFile systems are document based. They provide a natural and convenient way to store whole documents. They work well when you need to save and retrieve a set of documents by name, but they don’t offer a lot of help when you’re searching the content of those documents. It’s easy to find a file named login.c, but it’s hard, and slow, to find every .c file that has a variable named x in it.\n\n> 文件系统是基于文档格式的，它提供的是一种便于存储整个文档的方式。当需要按照名字存储数据和查找一系列文档时，文件系统很有用，但当我们需要检索文档内容时，它就没那么有用了。也就是说，我们在文件系统中查找一个名字为`login.c` 的文件很容易，但要检索出所有包括变量 x 的 `.c` 文件就很困难，速度也很慢。\n\nDatabase systems are content based. They provide a natural and convenient way to find records based on their content. They are very good at associating multiple records based on some bit of content that they all share. Unfortunately, they are rather poor at storing and retrieving opaque documents.\n\n> 而数据库系统则主要关注的是内容，它提供的是一种便于进行内容检索的存储方式。其最擅长的是根据某些共同属性而检索一系列记录。然而它对存储和访问内容不透明的文档的支持就没那么强了。\n\nBoth of these systems organize the data on disk so that it can be stored and retrieved in as efficient a way as possible, given their particular access needs. Each has their own scheme for indexing and arranging the data. In addition, each eventually brings the relevant data into RAM, where it can be quickly manipulated.\n\n> 这两种系统都是为了优化磁盘存储而设计的，人们需要根据它们的特点来将数据组织成最便于访问的模式。每个系统都有一套索引和安排数据的方式。同时，每种系统最终都会将数据缓存在内存中，方便快速操作。\n\n## WHAT IF THERE WERE NO DISK? 假设磁盘不存在会怎样\n\nAs prevalent as disks once were, they are now a dying breed. Soon they will have gone the way of tape drives, floppy drives, and CDs. They are being replaced by RAM.\n\n> 虽然硬盘现在还是很常见，但其实已经在走下坡路了。很快它们就会和磁带、软盘、CD 一样成为历史，RAM 正在替代一切。\n\nAsk yourself this question: When all the disks are gone, and all your data is stored in RAM, how will you organize that data? Will you organize it into tables and access it with SQL? Will you organize it into files and access it through a directory?\n\n> 现在，我们要来考虑一下：如果所有的数据都存在内存中，应该如何组织它们呢？需要按表格存储并且用 SQL 查询吗？需要用文件形式存储，然后按目录查找吗？\n\nOf course not. You’ll organize it into linked lists, trees, hash tables, stacks, queues, or any of the other myriad data structures, and you’ll access it using pointers or references—because that’s what programmers do.\n\n> 当然不，我们会将数据存储为链表、树、哈希表、堆栈、队列等各种各样的数据结构，然后用指针或者引用来访问这些数据——因为这对程序员来说是最自然的方式。\n\nIn fact, if you think carefully about this issue, you’ll realize that this is what you already do. Even though the data is kept in a database or a file system, you read it into RAM and then you reorganize it, for your own convenience, into lists, sets, stacks, queues, trees, or whatever data structure meets your fancy. It is very unlikely that you leave the data in the form of files or tables.\n\n> 事实上，如果你再仔细想想，就会发现我们已经在这样做了。即使数据保存在数据库或者文件系统中，我们最终也会将其读取到内存中，并按照最方便的形式将其组织成列表、集合、堆栈、队列、树等各种数据结构，继续按文件和表格的形式来操作数据是非常少见的。\n\n## DETAILS 实现细节\n\nThis reality is why I say that the database is a detail. It’s just a mechanism we use to move the data back and forth between the surface of the disk and RAM. The database is really nothing more than a big bucket of bits where we store our data on a long-term basis. But we seldom use the data in that form.\n\n> 上面所说的，就是为什么我们认为数据库只是一种实现细节的原因。数据库终究只是在硬盘与内存之间相互传输数据的一种手段而已，它真的可以被认为只是一个长期存储数据的、装满字节的大桶。我们通常并不会真的以这种形式来使用数据。\n\nThus, from an architectural viewpoint, we should not care about the form that the data takes while it is on the surface of a rotating magnetic disk. Indeed, we should not acknowledge that the disk exists at all.\n\n> 因此，从系统架构的视角来看，真的不应该关系数据在旋转的磁盘表面上以什么样的格式存在。实际上，系统架构应该对磁盘本身的存在完全不关心。\n\n## BUT WHAT ABOUT PERFORMANCE? 但性能怎么办呢\n\nIsn’t performance an architectural concern? Of course it is—but when it comes to data storage, it’s a concern that can be entirely encapsulated and separated from the business rules. Yes, we need to get the data in and out of the data store quickly, but that’s a low-level concern. We can address that concern with low-level data access mechanisms. It has nothing whatsoever to do with the overall architecture of our systems.\n\n> 性能难道不是系统架构的一个考量标准吗？当然是——但当问题涉及数据存储时，这方面的操作通常是被封装起来，隔离在业务逻辑之外的。也就是说，我们确实需要从数据存储中快速地存取数据，但这终究只是一个底层实现问题。我们完全可以在数据访问这一较低的层面上解决这个问题，而不需要让它与系统架构相关联。\n\n## ANECDOTE 一段轶事\n\nIn the late 1980s, I led a team of software engineers at a startup company that was trying to build and market a network management system that measured the communications integrity of T1 telecommunication lines. The system retrieved data from the devices at the endpoints of those lines, and then ran a series of predictive algorithms to detect and report problems.\n\n> 在 20 世纪 80 年代末，我曾在一家创业公司中带领一组软件工程师开发和推广一个用于监控 T1 线路通信质量的网络管理系统。该系统从 T1 线路两端的设备抓取数据，然后利用预测算法来检测和汇报问题。\n\nWe were using UNIX platforms, and we stored our data in simple random access files. We had no need of a relational database because our data had few content-based relationships. It was better kept in trees and linked lists in those random access files. In short, we kept the data in a form that was most convenient to load into RAM where it could be manipulated.\n\n> 我们当时采用的是 UNIX 平台，并将数据存储成简单的可随机访问的格式。该项目当时也不需要用到关系型数据库，因为数据之间几乎没有内容之间的关系，用树以及链表的形式来存储数据就够了。简单来说，我们的数据存储格式是为了便于加载到内存中处理而设计的。\n\nWe hired a marketing manager for this startup—a nice and knowledgeable guy. But he immediately told me that we had to have a relational database in the system. It wasn’t an option and it wasn’t an engineering issue—it was a marketing issue.\n\n> 创业公司后来招聘了一个市场推广经理 他人很好，知识也很全面。然而他告诉我的第一件事就是我们系统中必须有一个关系型数据库。这容不得商量，也不是一个工程问题——而是一个市场问题。\n\nThis made no sense to me. Why in the world would I want to rearrange my linked lists and trees into a bunch of rows and tables accessed through SQL? Why would I introduce all the overhead and expense of a massive RDBMS when a simple random access file system was more than sufficient? So I fought him, tooth and nail.\n\n> 这对我来说很难接受，为什么我要将链表和树重新按照表格与行模式重组，并且用 SQL 方式存储呢？为什么我们要在随机访问文件系统已经足够用的情况下引入大型关系型数据库系统？所以我一直和他针锋相对，互不相让。\n\nWe had a hardware engineer at this company who took up the RDBMS chant. He became convinced that our software system needed an RDBMS for technical reasons. He held meetings behind my back with the executives of the company, drawing stick figures on the whiteboard of a house balancing on a pole, and he would ask the executives, “Would you build a house on a pole?” His implied message was that an RDBMS that keeps its tables in random access files was somehow more reliable than the random access files that we were using.\n\n> 后来公司内有一位硬件工程师被关系型数据库大潮所感染：它坚信我们的软件系统在技术上有必要采用关系型数据库，他背着我召集了公司的管理层开会，在白板上画了一间用几根杆子支撑的房子，问道：“谁会会把房子建在几根杆子搭起来的地基上？”这背后的逻辑是：通过关系型数据库将数据存储于文件系统中，在某种程度上要比我们自己存储这些文件更可靠。\n\nI fought him. I fought the marketing guy. I stuck to my engineering principles in the face of incredible ignorance. I fought, and fought, and fought.\n\n> 我当然没有放弃，一直不停地和他还有市场部斗争到底。我誓死捍卫了自己的工程原则，不停地开会、斗争。\n\nIn the end, the hardware developer was promoted over my head to become the software manager. In the end, they put a RDBMS into that poor system. And, in the end, they were absolutely right and I was wrong.\n\n> 最终，这位硬件工程师被提拔为软件开发经理，最终，系统中也加入了一个关系型数据库。最终，我不得不承认，他们是对的，而我是错的。\n\nNot for engineering reasons, mind you: I was right about that. I was right to fight against putting an RDBMS into the architectural core of the system. The reason I was wrong was because our customers expected us to have a relational database. They didn’t know what they would do with it. They didn’t have any realistic way of using the relational data in our system. But it didn’t matter: Our customers fully expected an RDBMS. It had become a check box item that all the software purchasers had on their list. There was no engineering rationale—rationality had nothing to do with it. It was an irrational, external, and entirely baseless need, but it was no less real.\n\n> 但这里说的不是软件工程问题：在这个问题上我仍然坚持自己没有错，在系统的核心架构中的确不应该引入关系型数据库。这里说我错了的原因，是因为我们的客户希望该系统中能有一个关系型数据库。他们其实也不知道为什么需要，因为他们自己是没有任何机会使用这个关系型数据库的。但这不是重点，问题的重点是我们的客户需要一个关系型数据库。它已经成为当时所有软件购买合同中的一个必选项。这背后毫无工程逻辑——是不理智的。但尽管它是不理智的、外行的、毫无根基的需求，但却是真实存在的。\n\nWhere did that need come from? It originated from the highly effective marketing campaigns employed by the database vendors at the time. They had managed to convince high-level executives that their corporate “data assets” needed protection, and that the database systems they offered were the ideal means of providing that protection.\n\n> 这种需求是从哪里来的？其实是来自于当时数据库厂商非常有效的市场推广。他们说服了企业高管，他们的“数据资产”需要某种保护，数据库则提供了非常便捷的保护能力。\n\nWe see the same kind of marketing campaigns today. The word “enterprise” and the notion of “Service-Oriented Architecture” have much more to do with marketing than with reality.\n\n> 直到今天我们也能看到这种市场宣传，譬如“企业级”“面向服务的架构”这样的措辞大部分都是市场宣传噱头，而跟实际的工程质量无关。\n\nWhat should I have done in that long-ago scenario? I should have bolted an RDBMS on the side of the system and provided some narrow and safe data access channel to it, while maintaining the random access files in the core of the system. What did I do? I quit and became a consultant.\n\n> 回头想想，我在这个场景中应该怎么做呢？事实上，我当时应该在系统的某个角落接上一个关系型数据库，在维持系统核心数据结构的同时给关系型数据库提供一些安全的、受限的数据访问方式。但我没这么做，我辞职了，干起了咨询这一行。\n\n## CONCLUSION 本章小结\n\nThe organizational structure of data, the data model, is architecturally significant. The technologies and systems that move data on and off a rotating magnetic surface are not. Relational database systems that force the data to be organized into tables and accessed with SQL have much more to do with the latter than with the former. The data is significant. The database is a detail.\n\n> 数据的组织结构，数据的模型，都是系统架构中的重要部分，但是从磁盘上存储、读取数据的机制和手段却没那么重要。关系型数据库强制我们将数据存储成表格并且以 SQL 访问，主要是为了后者。总而言之，数据本身很重要，但数据库系统仅仅是一个实现细节。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap31. THE WEB IS A DETAIL Web 是实现细节\n\n![](../../images/books/架构整洁之道/CH-UN31.jpg)\n\nWere you a developer in the 1990s? Do you remember how the web changed everything? Do you remember how we looked at our old client–server architectures with disdain in the face of the shiny new technology of The Web?\n\n> 20 世纪 90 年代的时候，你已经是程序员了吗？还记得 Web 是如何改变一切的吗？你记得我们在有了崭新的 Web 技术之后，是如何鄙视那些老旧的客户端/服务器架构的吗？\n\nActually the web didn’t change anything. Or, at least, it shouldn’t have. The web is just the latest in a series of oscillations that our industry has gone through since the 1960s. These oscillations move back and forth between putting all the computer power in central servers and putting all computer power out at the terminals.\n\n> 然而，Web 技术事实上并没有改变任何东西，或者说它也没有能力改变任何东西。这一次 Web 热潮只是软件行业从 1960 年来经历的数次震荡中的一次。这些振荡一会儿将全部计算资源集中在中央服务器上，一会儿又将计算资源分散到各个终端上。\n\nWe’ve seen several of these oscillations just in the last decade or so since the web became prominent. At first we thought all the computer power would be in server farms, and the browsers would be stupid. Then we started putting applets in the browsers. But we didn’t like that, so we moved dynamic content back to the servers. But then we didn’t like that, so we invented Web 2.0 and moved lots of processing back into the browser with Ajax and JavaScript. We went so far as to create whole huge applications written to execute in the browsers. And now we’re all excited about pulling that JavaScript back into the server with Node.\n\n> 事实上，在过去十年内，或者说自 Web 技术被普遍应用以来，这样的振荡也发生了几次。一开始我们以为计算资源应该集中在服务器集群中，浏览器应该保持简单。但随后我们又开始在浏览器中引入 Applets-再后来我们又改了主意，发明了 Web 2.0，用 Ajax 和 JavaScript 将很多计算过程挪回浏览器中。我们先是非常兴奋地将整个应用程序挪到浏览器去执行，后来又非常开心地采用 Node 技术将那些 JavaScript 代码挪回服务器上执行。\n\n(Sigh.)\n\n> 一声叹息!\n\n## THE ENDLESS PENDULUM 无尽的钟摆\n\nOf course, it would be incorrect to think that those oscillations started with the web. Before the web, there was client–server architecture. Before that, there were central minicomputers with arrays of dumb terminals. Before that, there were mainframes with smart green-screen terminals (that were very much analogous to modern-day browsers). Before that, there were computer rooms and punched cards …\n\n> 当然，这些振荡也不是从 Web 技术开始的。在 Web 出现之前，这种振荡在客户端/服务器架构中就很普遍。再往前，就是中央小型机/瘦终端的模型（这里的瘦终端和现在我们所谓的现代浏览器非常相似）。再往前则是大型计算机与打孔卡……\n\nAnd so the story goes. We can’t seem to figure out where we want the computer power. We go back and forth between centralizing it and distributing it. And, I imagine, those oscillations will continue for some time to come.\n\n> 而且这样的故事还会继续下去，我们似乎永远也决定不了应该将计算资源放在哪里。我们不停地在集中式和分布式之间来回切换。看起来，这样的震荡还要再持续一段时间。\n\nWhen you look at it in the overall scope of IT history, the web didn’t change anything at all. The web was simply one of many oscillations in a struggle that began before most of us were born and will continue well after most of us have retired.\n\n> 但从 IT 技术发展历史的整体来看，我们会发现 Web 技术的出现并没有改变任何东西。Web 技术的热潮只是在这个早于我们出生，也肯定会超过我们职业生涯的振荡周期中的一瞬间。\n\nAs architects, though, we have to look at the long term. Those oscillations are just short-term issues that we want to push away from the central core of our business rules.\n\n> 而且作为一名系统架构师，我们应该把眼光放长远一点，这些震荡只是端期问题，不应该把它们放在系统的核心业务逻辑中来考虑。\n\nLet me tell you the story of company Q. Company Q built a very popular personal finance system. It was a desktop app with a very useful GUI. I loved using it.\n\n> 下面，我们来聊聊 Q 公司的故事。该公司构建了一个非常流行的个人财务系统，这是一个 GUI 很好用的桌面程序，我很喜欢它。\n\nThen came the web. In its next release, company Q changed the GUI to look, and behave, like a browser. I was thunderstruck! What marketing genius decided that personal finance software, running on a desktop, should have the look and feel of a web browser?\n\n> 然后 Web 技术的热潮到来了，Q 公司打算在下一个版本中将该系统的 GUI 改成了浏览器风格。这真是犹如晴天霹雳！究竟是市场部哪位“大神”决定要让一个桌面版的个人财务软件展示浏览器风格的呢？\n\nOf course, I hated the new interface. Apparently everyone else did, too—because after a few releases, company Q gradually removed the browser-like feel and turned its personal finance system back into a regular desktop GUI.\n\n> 我当然非常痛恨新的 UI，显然其他人也这么认为——因此在随后的几个版本里，Q 公司又逐渐将浏览器相关的设计从界面中去掉了，最终这个软件又回到正常的桌面 UI 模式。\n\nNow imagine you were a software architect at Q. Imagine that some marketing genius convinces upper management that the whole UI has to change to look more like the web. What do you do? Or, rather, what should you have done before this point to protect your application from that marketing genius?\n\n> 假设你是 Q 公司的软件架构师，市场人员说服了高层管理者，要将整个 UI 重新设计为“Web”版。你应该怎么办？换句话说，在这类事情发生之前，我们应该提前做好哪方面的准备，才能应对这种无厘头的要求？\n\nYou should have decoupled your business rules from your UI. I don’t know whether the Q architects had done that. One day I’d love to hear their story. Had I been there at the time, I certainly would have lobbied very hard to isolate the business rules from the GUI, because you never know what the marketing geniuses will do next.\n\n> 我们应该做的就是将业务规则与 UI 解耦。我不知道 Q 公司的软件架构师是否是这么做的，我也很想了解他们的故事。如果当时我在，我一定会全力游说他们将业务逻辑与 UI 解耦，因为谁知道市场推广人员接下来会想出什么好点子？\n\nNow consider company A, which makes a lovely smartphone. Recently it released an upgraded version of its “operating system” (it’s so strange that we can talk about the operating system inside a phone). Among other things, that “operating system” upgrade completely changed the look and feel of all the applications. Why? Some marketing genius said so, I suppose.\n\n> 再说一下 A 公司的故事，他们的产品是智能手机。最近他们发布了一个“操作系统”的升级版（谈论一个手机的操作系统本身就够奇怪的了！）。抛去别的改动不说，这次“操作系统”的更新大幅修改了各种应用程序的外观。为什么？估计是因为市场部某位“大神”的要求吧。\n\nI’m not an expert on the software within that device, so I don’t know if that change caused any significant difficulties for the programmers of the apps that run in company A’s phone. I do hope the architects at A, and the architects of the apps, keep their UI and business rules isolated from each other, because there are always marketing geniuses out there just waiting to pounce on the next little bit of coupling you create.\n\n> 我不了解这个设备中软件的细节，所以不知道这次改动是否显著影响了那些给 A 公司的手机开发应用程序的人。我只能希望 A 公司的系统架构师，以及应用程序的系统架构师能将 UI 和业务逻辑分离，因为这些市场推广人员是不会错过这里任何一丁点儿的耦合关系的。\n\n## THE UPSHOT 总结一下\n\nThe upshot is simply this: The GUI is a detail. The web is a GUI. So the web is a detail. And, as an architect, you want to put details like that behind boundaries that keep them separate from your core business logic.\n\n> 将上面的故事总结成一句话，就是：GUI 只是一个实现细节。而 Web 则是 GUI 的一种，所以也是一个实现细节。作为一名软件架构师，我们需要将这类细节与核心业务逻辑隔离开来。\n\nThink about it this way: The WEB is an IO device. In the 1960s, we learned the value of writing applications that were device independent. The motivation for that independence has not changed. The web is not an exception to that rule.\n\n> 其实我们可以这样考虑这个问题：Web 只是一种 I/O 设备。早在 20 世纪 60 年代，我们就已经了解编写设备无关应用程序的重要性。这种独立性的重要性至今仍然没有变化，Web 也不例外。\n\nOr is it? The argument can be made that a GUI, like the web, is so unique and rich that it is absurd to pursue a device-independent architecture. When you think about the intricacies of JavaScript validation or drag-and-drop AJAX calls, or any of the plethora of other widgets and gadgets you can put on a web page, it’s easy to argue that device independence is impractical.\n\n> 是这样的吗？有人可能会辩称 Web 这样的 GUI 是非常特殊的，它能力强大，强大到让我们追求设备无关的架构变得毫无意义。当我们考虑到 JavaScript 数据校验的复杂程度、可拖拽的 Ajax 调用，以及无数可以轻松引入的设计组件时，很容易认为追求设备无关性是不现实的。\n\nTo some extent, this is true. The interaction between the application and the GUI is “chatty” in ways that are quite specific to the kind of GUI you have. The dance between a browser and a web application is different from the dance between a desktop GUI and its application. Trying to abstract out that dance, the way devices are abstracted out of UNIX, seems unlikely to be possible.\n\n> 从某种程度上来说，的确如此。应用程序和 GUI 之间的频繁交互的确是与 GUI 的类型密切相关的。浏览器与 Web 应用之间的交互模式也的确与桌面客户端/服务器之间的交互模式区别很大。想要让浏览器上的 Web 操作模仿我们在 UNIX 中对 I/O 设备那样的操作，将其抽象成界面交互模型几乎是不可能的。\n\nBut another boundary between the UI and the application can be abstracted. The business logic can be thought of as a suite of use cases, each of which performs some function on behalf of a user. Each use case can be described based on the input data, the processing preformed, and the output data.\n\n> 但我们其实可以从 UI 和应用程序之间的另一条边界出发来进行抽象化。因为业务逻辑可以被视为是一组用例的集合。而每个用例都是以用户的身份来执行某种操作的，所以它们都可以用输入数据、处理过程以及输出数据这个流程来描述。\n\nAt some point in the dance between the UI and the application, the input data can be said to be complete, allowing the use case to be executed. Upon completion, the resultant data can be fed back into the dance between the UI and the application.\n\n> 也就是说，在 UI 和应用程序之间的某一点上，输入数据会被认为达到了一个完整状态，然后用例就被允许进入执行阶段了。在用例执行完之后，其生成的返回数据又继续在 UI 与应用程序之间传递。\n\nThe complete input data and the resultant output data can be placed into data structures and used as the input values and output values for a process that executes the use case. With this approach, we can consider each use case to be operating the IO device of the UI in a device-independent manner.\n\n> 这样一来，完整的输入数据，以及完整的输出数据就可以被标准化为数据结构，并提供给执行用例的进程了。通过这种方法，我们就可以认为用例都是以设备无关的方式在操作 I/O 设备。\n\n## CONCLUSION 本章小结\n\nThis kind of abstraction is not easy, and it will likely take several iterations to get just right. But it is possible. And since the world is full of marketing geniuses, it’s not hard to make the case that it’s often very necessary.\n\n> 这种抽象化处理并不容易，很有可能需要经历几个来回才能找到正确的方向，但这是完全可行的。由于世界上最不缺少的就是市场“大神”，很多时候做这些事情还真的是非常有必要的。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap32. FRAMEWORKS ARE DETAILS 应用程序框架是实现细节\n\n![](../../images/books/架构整洁之道/CH-UN32.jpg)\n\nFrameworks have become quite popular. Generally speaking, this is a good thing. There are many frameworks out there that are free, powerful, and useful.\n\n> 应用程序框架现在非常流行，这在通常情况下是一件好事。许多框架都非常有效，非常有用，而且是免费的。\n\nHowever, frameworks are not architectures—though some try to be.\n\n> 但框架并不等同于系统架构——尽管有些框架确实以此为目标。\n\n## FRAMEWORK AUTHORS 框架作者\n\nMost framework authors offer their work for free because they want to be helpful to the community. They want to give back. This is laudable. However, regardless of their high-minded motives, those authors do not have your best interests at heart. They can’t, because they don’t know you, and they don’t know your problems.\n\n> 大部分框架的作者愿意免费提供自己的工作成果，是因为他们想要帮助整个社群，想要回馈社会。这值得鼓励，但不管这些作者的动机有多么高尚，恐怕也并没有提供针对你个人的最佳方案。即使他们想，也做不到，因为他们并不了解你，也不了解你遇到的问题。\n\nFramework authors know their own problems, and the problems of their coworkers and friends. And they write their frameworks to solve those problems—not yours.\n\n> 这些框架作者所了解的都是他们自己遇到的问题，可能还包括亲戚朋友所遇到的。他们创造框架的目的是解决这些问题——而不是解决你遇到的问题。\n\nOf course, your problems will likely overlap with those other problems quite a bit. If this were not the case, frameworks would not be so popular. To the extent that such overlap exists, frameworks can be very useful indeed.\n\n> 当然，你所遇到的问题可能和其他人遇到的大体上一致。如果不是这样，框架也就不会那么流行了。正是由于这种重合性的存在，框架才这么有用。\n\n## ASYMMETRIC MARRIAGE 单向婚姻\n\nThe relationship between you and the framework author is extraordinarily asymmetric. You must make a huge commitment to the framework, but the framework author makes no commitment to you whatsoever.\n\n> 我们与框架作者之间的关系是非常不对等的。我们要采用某个框架就意味着自己要遵守一大堆约定，但框架作者却完全不需要为我们遵守什么约定。\n\nThink about this point carefully. When you use a framework, you read through the documentation that the author of that framework provides. In that documentation, the author, and other users of that framework, advise you on how to integrate your software with the framework. Typically, this means wrapping your architecture around that framework. The author recommends that you derive from the framework’s base classes, and import the framework’s facilities into your business objects. The author urges you to couple your application to the framework as tightly as possible.\n\n> 请仔细想想这一关系，当我们决定采用一个框架时，就需要完整地阅读框架作者提供的文档。在这个文档中，框架作者和框架其他用户对我们提出进行应用整合的一些建议。一般来说，这些建议就是在要求我们围绕着该框架来设计自己的系统架构。譬如，框架作者会建议我们基于框架中的基类来创建一些派生类，并在业务对象中引入一些框架的工具。框架作者还会不停地催促我们将应用与框架结合得越紧密越好。\n\nFor the framework author, coupling to his or her own framework is not a risk. The author wants to couple to that framework, because the author has absolute control over that framework.\n\n> 对框架作者来说，应用程序与自己的框架耦合是没有风险的。毕竟作为作者，他们对框架有绝对的控制权，强耦合是应该的。\n\nWhat’s more, the author wants you to couple to the framework, because once coupled in this way, it is very hard to break away. Nothing feels more validating to a framework author than a bunch of users willing to inextricably derive from the author’s base classes.\n\n> 与此同时，作者当然是非常希望让我们的应用与其框架紧密结合的，因为这意味着脱离框架会很困堆。作为框架作者来说，没有什么比让一堆用户心甘情愿地基于他的框架基类来构建派生类更自豪的事情了。\n\nIn effect, the author is asking you to marry the framework—to make a huge, long-term commitment to that framework. And yet, under no circumstances will the author make a corresponding commitment to you. It’s a one-directional marriage. You take on all the risk and burden; the framework author takes on nothing at all.\n\n> 换句话说，框架作者想让我们与框架订终身——这相当于我们要对他们的框架做一个巨大而长期的承诺，而在任何情况下框架作者都不会对我们做出同样的承诺。这种婚姻是单向的。我们要承担所有的风险，而框架作者则没有任何风险。\n\n## THE RISKS 风险\n\nWhat are the risks? Here are just a few for you to consider.\n\n> 那么我们要承担的风险究竟有哪些呢？我们可以想到的至少有以下这几项：\n\n- The architecture of the framework is often not very clean. Frameworks tend to violate the Dependency Rule. They ask you to inherit their code into your business objects—your Entities! They want their framework coupled into that innermost circle. Once in, that framework isn’t coming back out. The wedding ring is on your finger; and it’s going to stay there.\n- The framework may help you with some early features of your application. However, as your product matures, it may outgrow the facilities of the framework. If you’ve put on that wedding ring, you’ll find the framework fighting you more and more as time passes.\n- The framework may evolve in a direction that you don’t find helpful. You may be stuck upgrading to new versions that don’t help you. You may even find old features, which you made use of, disappearing or changing in ways that are difficult for you to keep up with.\n- A new and better framework may come along that you wish you could switch to.\n\n---\n\n> - 框架自身的架构设计很多时候并不是特别正确的。框架本身可能经常违反依赖关系原则。譬如，框架可能会要求我们将代码引入到业务对象中——甚至是业务实体中。框架可能会想要我们将框架耦合在最内圈代码中。而我们一旦引入，就再也不会离开该框架了，这就像戴上结婚戒指一样，从此一生不离不弃了。\n> - 框架可能会帮助我们实现一些应用程序的早期功能，但随着产品的成熟，功能要求很可能超出框架所能提供的范围。而且随着时间的推移，我们也会发现在应用的开发过程中，自己与框架斗争的时间要比框架帮助我们的时间长得多。\n> - 框架本身可能朝着我们不需要的方向演进。也许我们会被迫升级到一个并不需要的新版本，甚至会发现自己之前所使用的旧功能突然消失了，或悄悄改变了行为。\n> - 未来我们可能会想要切换到一个更新、更好的框架上。\n\n## THE SOLUTION 解决方案\n\nWhat is the solution?\n\n> 解决方案是什么呢？\n\nDon’t marry the framework!\n\n> 请不要嫁给框架\n\nOh, you can use the framework—just don’t couple to it. Keep it at arm’s length. Treat the framework as a detail that belongs in one of the outer circles of the architecture. Don’t let it into the inner circles.\n\n> 我们可以使用框架——但要时刻警惕，别被它拖住。我们应该将框架作为架构最外圈的一个实现细节来使用，不要让它们进入内圈。\n\nIf the framework wants you to derive your business objects from its base classes, say no! Derive proxies instead, and keep those proxies in components that are plugins to your business rules.\n\n> 如果框架要求我们根据它们的基类来创建派生类，就请不要这样做！我们可以创造一些代理类，同时把这些代理类当作业务逻辑的插件来管理。\n\nDon’t let frameworks into your core code. Instead, integrate them into components that plug in to your core code, following the Dependency Rule.\n\n> 另外，不要让框架污染我们的核心代码，应该依据依赖关系原则，将它们当作核心代码的插件来管理。\n\nFor example, maybe you like Spring. Spring is a good dependency injection framework. Maybe you use Spring to auto-wire your dependencies. That’s fine, but you should not sprinkle @autowired annotations all throughout your business objects. Your business objects should not know about Spring.\n\n> 以 Spring 为例，它作为一个依赖注入框架是不错的，也许我们会需要用 Spnng 来自动连接应用程序中的各种依赖关系。这不要紧，但是千万别在业务对象里到处写 `@autowired` 注解。业务对象应该对 Spring 完全不知情才对。\n\nInstead, you can use Spring to inject dependencies into your Main component. It’s OK for Main to know about Spring since Main is the dirtiest, lowest-level component in the architecture.\n\n> 反之，我们也可以利用 Spring 将依赖关系注入到 Main 组件中，毕竟 Main 组件作为系统架构中最低层、依赖最多的组件，它依赖于 Spring 并不是问题。\n\n## I NOW PRONOUNCE YOU … 不得不接受的依赖\n\nThere are some frameworks that you simply must marry. If you are using C++, for example, you will likely have to marry STL—it’s hard to avoid. If you are using Java, you will almost certainly have to marry the standard library.\n\n> 有一些框架是避免不了使用的。例如，如果你在用 C++，那么 STL 就是很难避免使用的。如果你在用 Java，那么标准类库也是不太可能避免使用的。\n\nThat’s normal—but it should still be a decision. You must understand that when you marry a framework to your application, you will be stuck with that framework for the rest of the life cycle of that application. For better or for worse, in sickness and in health, for richer, for poorer, forsaking all others, you will be using that framework. This is not a commitment to be entered into lightly.\n\n> 这很正常——但这仍然应该是你主动选择的结果。你必须明白，如果一旦在项目中引入一个框架，很有可能在整个生命周期中都要依赖于它，不管后来情形怎么变化，这个决定都很难更改了。因此，不应该草率地做出决定。\n\n## CONCLUSION 本章小结\n\nWhen faced with a framework, try not to marry it right away. See if there aren’t ways to date it for a while before you take the plunge. Keep the framework behind an architectural boundary if at all possible, for as long as possible. Perhaps you can find a way to get the milk without buying the cow.\n\n> 总而言之。当我们面临框架选择时，尽量不要草率地做出决定。在全身心投入之前，应该首先看看是否可以部分地采用以增加了解。另外，请尽可能长时间地将框架留在架构边界之外，越久越好。因为谁知道呢，也许你可以不用买奶牛也能喝到牛奶。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap33. CASE STUDY: VIDEO SALES 案例分析：视频销售网站\n\n![](../../images/books/架构整洁之道/CH-UN33.jpg)\n\nNow it’s time to put these rules and thoughts about architecture together into a case study. This case study will be short and simple, yet will depict both the process a good architect uses and the decisions that such an architect makes.\n\n> 现在是时候将所有的这些设计规则和架构理念整合起来了。下面，我们来做一次案财析，这个案例分析虽然很简短，但可以描述清楚一个优秀的系统架构师在设计过程和设计决策中应该如何行事。\n\n## THE PRODUCT 产品\n\nFor this case study, I’ve chosen a product with which I am rather intimately familiar: the software for a website that sells videos. Of course, it is reminiscent of cleancoders.com, the site where I sell my software tutorial videos.\n\n> 在这个案例分析中，我要讲的是一个我自己很熟悉的产品：线上收费视频网站。当然，这个有点像 `cleancoders.com`，我在这个网站上出售我的软件开发教程视频。\n\nThe basic idea is trivial. We have a batch of videos we want to sell. We sell them, on the web, to both individuals and businesses. Individuals can pay one price to stream the videos, and another, higher price to download those videos and own them permanently. Business licenses are streaming only, and are purchased in batches that allow quantity discounts.\n\n> 这个案例的设计很简单，就是我们打算向一些个人或者企业提供一批收费的线上教学视频。个人用户既可以选择在线支付之后直接在线观看视频，也可以选择付一笔更高的费用将视频下载到本地，永久地拥有它们。而企业用户就只能在线播放，但他们可以选择批量购买，以此来获得一定折扣。\n\nIndividuals typically act as both the viewers and the purchasers. Businesses, in contrast, often have people who buy the videos that other people will watch.\n\n> 个人用户通常既是购买者又是观看者。而企业用户则不同，他们购买视频通常是用来给其他人观看的。\n\nVideo authors need to supply their video files, written descriptions, and ancillary files with exams, problems, solutions, source code, and other materials.\n\n> 视频作者需要负责上传视频文件、写简介，并且提供视频附带的一系列习题、课后作业、答案、源代码以及其他各类资料。\n\nAdministrators need to add new video series, add and delete videos to and from the series, and establish prices for various licenses.\n\n> 管理员需要负责增加新的视频播放列表，往视频播放列表里添加和删除视频，并且为各种许可类型设置价格。\n\nOur first step in determining the initial architecture of the system is to identify the actors and use cases.\n\n> 系统架构设计中的第一步，是识别系统中的各种角色和用例。\n\n## USE CASE ANALYSIS 用例分析\n\nFigure 33.1 shows a typical use-case analysis.\n\n> 下面，我们通过图 33.1 来示范一次典型的用例分析。\n\n<Figures figure=\"33-1\">A typical use-case analysis</Figures>\n\nThe four main actors are evident. According to the Single Responsibility Principle, these four actors will be the four primary sources of change for the system. Every time some new feature is added, or some existing feature is changed, that step will be taken to serve one of these actors. Therefore we want to partition the system such that a change to one actor does not affect any of the other actors.\n\n> 如你所见，图中显然存在着四个角色。根据单一职责原则（SRP），这四个角色将成为系统变更的主要驱动力。每当添加新功能，或者修改现有功能时，我们所做的一切都是在为这些角色服务。所以我们希望能够对系统进行分区处理，避免其中一个角色的变更需求影响其他角色。\n\nThe use cases shown in Figure 33.1 are not a complete list. For example, you won’t find log-in or log-out use cases. The reason for this omission is simply to manage the size of the problem in this book. If I were to include all the different use cases, then this chapter would have to turn into a book in its own right.\n\n> 另外，图 33.1 中的用例并不是一个完整的列表。例如，这里没有分析用于执行登录、注销的用例。省略它们的原因很简单，为了控制本书篇幅。如果列出所有的用例，这一章就会变成一本单独的书了。\n\nNote the dashed use cases in the center of Figure 33.1. They are abstract1 use cases. An abstract use case is one that sets a general policy that another use case will flesh out. As you can see, the View Catalog as Viewer and View Catalog as Purchaser use cases both inherit from the View Catalog abstract use case.\n\n> 读者应该注意到图 33.1 中还有一些用虚线框起来的用例。我们称之为抽象用例，它们通常用来负责设置通用策略，然后交由其他具体用例来使用。譬如在该图“查看目录”这个用例同时被“购买者查看目录”和“观看者查看目录”这两个用例所继承并实现。\n\nOn the one hand, it was not strictly necessary for me to create that abstraction. I could have left the abstract use case out of the diagram without compromising any of the features of the overall product. On the other hand, these two use cases are so similar that I thought it wise to recognize the similarity and find a way to unify it early in the analysis.\n\n> 一方面来说，其实这种抽象并不是必需的。如果没有这一层拥象：整个产品并不会受到影响；但是另一方面来说，由于这两个用例十分相近，我认为以某种方式来将它们合并起来分析是很合理的。\n\n## COMPONENT ARCHITECTURE 组件架构\n\nNow that we know the actors and use cases, we can create a preliminary component architecture (Figure 33.2).\n\n> 既然我们弄清楚了系统中的各种角色和用例，接下来就可以构造一个初步的组件架构图了（如图 33.2 所示）。\n\nThe double lines in the drawing represent architectural boundaries as usual. You can see the typical partitioning of views, presenters, interactors, and controllers. You can also see that I’ve broken each of those categories up by their corresponding actors.\n\n> 在该图中，双实线代表了系统架构边界。可以看到这里将系统划分成视图、展示器、交互器以及控制器这几个组件，同时也按照对应的系统角色进行了分组。\n\nEach of the components in Figure 33.2 represents a potential .jar file or .dll file. Each of those components will contain the views, presenters, interactors, and controllers that have been allocated to it.\n\n> 图 33.2 中的每一个组件都对应着一个潜在的 .jar 文件或 .dll 文件。每一个组件都会包含归属于它的视图、展示器、交互器、控制器文件。\n\nNote the special components for the Catalog View and the Catalog Presenter. This is how I dealt with the abstract View Catalog use case. I assume that those views and presenters will be coded into abstract classes within those components, and that the inheriting components will contain view and presenter classes that will inherit from those abstract classes.\n\n> 值得注意的是，这里有两个特殊的组件：目录视图（Catalog View）和目录展示器（Catalog Presenter）。这就是我应对查看目录列表这个抽象用例的方法。我假设这些视图和展示器将会被编写为抽象类，而继承它们的组件将会包括它们的派生类。\n\n<Figures figure=\"33-2\">A preliminary component architecture</Figures>\n\nWould I really break the system up into all these components, and deliver them as .jar or .dll files? Yes and no. I would certainly break the compile and build environment up this way, so that I could build independent deliverables like that. I would also reserve the right to combine all those deliverables into a smaller number of deliverables if necessary. For example, given the partitioning in Figure 33.2, it would be easy to combine them into five .jar files—one for views, presenters, interactors, controllers, and utilities, respectively. I could then independently deploy the components that are most likely to change independently of each other.\n\n> 但问题是，我们真的需要将系统拆分成这么多组件，然后以 .jar 或 .dll 文件的形式一个个交付吗？是，又不全是。我们确实要按照组件将编译和构建环境分开，以便单独构建对应的组件。但我们仍然可以考虑将所有的交付单元组合起来交付，例如，根据图 33.2 中的分组，我们可以很简单地将它们交付为 5 个 .jar 文件——视图、展示器、交互器、控制器和工具类，这样就可以分别单独部署这些被修改的组件了。\n\nAnother possible grouping would be to put the views and presenters together into the same .jar file, and put the interactors, controllers, and utilities in their own .jar file. Still another, even more primitive, grouping would be to create two .jar files, with views and presenters in one file, and everything else in the other.\n\n> 除此之外，还有另一种分组方式，就是将视图和展示器放在同一个 .jar 文件中，而将交互器、控制器以及工具类各自放在独立的 .jar 文件中。还有一种更简单的方式，就是将视图和展示器放在一个 .jar 文件中，而将其他所有的组件合并为另一个 .jar 文件。\n\nKeeping these options open will allow us to adapt the way we deploy the system based on how the system changes over time.\n\n> 随着系统的演进，我们可以根据系统变更来调整部署方式。\n\n## DEPENDENCY MANAGEMENT 依赖关系管理\n\nThe flow of control in Figure 33.2 proceeds from right to left. Input occurs at the controllers, and that input is processed into a result by the interactors. The presenters then format the results, and the views display those presentations.\n\n> 如你所见，图 33.2 中的控制流是从右向左的。输入发生在控制器端，然后输入的数据经交互器处理后交由展示器格式化出结果，最后由视图来展示这个结果。\n\nNotice that the arrows do not all flow from the right to the left. In fact, most of them point from left to right. This is because the architecture is following the Dependency Rule. All dependencies cross the boundary lines in one direction, and they always point toward the components containing the higher-level policy.\n\n> 请注意，图中的箭头并不是一直从右向左的。事实上大部分的箭头都是从左向右的。这是因为该架构设计要遵守依赖关系原则。所有跨域边界的依赖关系都应该是同一个方向，而且都指向包含更高级策略的组件。\n\nAlso notice that the using relationships (open arrows) point with the flow of control, and that the inheritance relationships (closed arrows) point against the flow of control. This depicts our use of the Open–Closed Principle to make sure that the dependencies flow in the right direction, and that changes to low-level details do not ripple upward to affect high-level policies.\n\n> 另外，还注意一下图中的“使用”关系（开放箭头），它和控制流方向是一致的：而\"继承\"关系（闭合箭头）则与之相反，它反映的是我们对开闭原则的应用，通过调整依赖关系，可以保证底层细节的变更不会影响到高层策略组件。\n\n## CONCLUSION 本章小结\n\nThe architecture diagram in Figure 33.2 includes two dimensions of separation. The first is the separation of actors based on the Single Responsibility Principle; the second is the Dependency Rule. The goal of both is to separate components that change for different reasons, and at different rates. The different reasons correspond to the actors; the different rates correspond to the different levels of policy.\n\n> 图 33.2 中的架构实现的是两个维度上的隔离。第一个是根据单一职责原则对所使用的系统的各个角色进行了隔离，第二个则是对依赖关系原则的应用。这两个维度的隔离都是为了将不同变更原因和不同变更速率的组件分隔开来。譬如变更的原因不同是因为组件使用的角色不同，而变更速率则取决于组件所在的层级。\n\nOnce you have structured the code this way, you can mix and match how you want to actually deploy the system. You can group the components into deployable deliverables in any way that makes sense, and easily change that grouping when conditions change.\n\n> 按照这样的方式组织代码的结构，我们就可以在部署时做灵活的选择。可以随时将组件整合部署，也可以在要求变化的时候灵活地调整。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# Chap34. THE MISSING CHAPTER 拾遗\n\n![](../../images/books/架构整洁之道/CH-UN34.jpg)\n\nBy Simon Brown\n\nAll of the advice you’ve read so far will certainly help you design better software, composed of classes and components with well-defined boundaries, clear responsibilities, and controlled dependencies. But it turns out that the devil is in the implementation details, and it’s really easy to fall at the last hurdle if you don’t give that some thought, too.\n\n> 根据本书之前给出的所有建议，相信读者一定能够建构出具有良好边界设计的类和组件，以形成清晰的责任划分以及可控的依赖关系，设计出更好的软件了。但是困难之处往往在于细节之中，一旦疏忽，也有可能会对软件质量造成不良影响。\n\nLet’s imagine that we’re building an online book store, and one of the use cases we’ve been asked to implement is about customers being able to view the status of their orders. Although this is a Java example, the principles apply equally to other programming languages. Let’s put the Clean Architecture to one side for a moment and look at a number of approaches to design and code organization.\n\n> 下面我们再来看一个例子，假设正在构建一个在线书店，这个例子的任务是实现一个客户査看订单状态的用例，虽然这是一个 Java 程序的示例，但其所示范的原理适用于任何语言。现在，让我们暂时将整洁架构的概念放在一边，先来看一下如何具体安排代码设计和代码结构。\n\n## PACKAGE BY LAYER 按层封装\n\nThe first, and perhaps simplest, design approach is the traditional horizontal layered architecture, where we separate our code based on what it does from a technical perspective. This is often called “package by layer.” Figure 34.1 shows what this might look like as a UML class diagram.\n\n> 我们首先想到的，也可能是最简单的设计方式，就是传统的水平分层架构。在这个架构里，我们将代码从技术角度进行分类。这通常被称为“按层封装”。图 34.1 用 UML 类图展示了这种设计。\n\nIn this typical layered architecture, we have one layer for the web code, one layer for our “business logic,” and one layer for persistence. In other words, code is sliced horizontally into layers, which are used as a way to group similar types of things. In a “strict layered architecture,” layers should depend only on the next adjacent lower layer. In Java, layers are typically implemented as packages. As you can see in Figure 34.1, all of the dependencies between layers (packages) point downward. In this example, we have the following Java types:\n\n> 在这种常见的分层架构中，Web 代码分为一层，业务逻辑分为一层，持久化是另外一层。换句话说，我们对代码进行了水平分层，相同类型的代码在一层。在“严格的分层架构”中，每一层只能对相邻的下层有依赖关系。在 Java 中，分层的概念通常是用包来表示的。如图 34.1 所示，所有的分层（包）之间的依赖关系都是指向下的。这里包括了以下 Java 类。\n\n- OrdersController: A web controller, something like a Spring MVC controller, that handles requests from the web.\n- OrdersService: An interface that defines the “business logic” related to orders.\n- OrdersServiceImpl: The implementation of the orders service.1\n- OrdersRepository: An interface that defines how we get access to persistent order information.\n- JdbcOrdersRepository: An implementation of the repository interface.\n\n---\n\n> - OrdersController：Web 控制器，类似 Spring MVC 控制器，负责处理 Web 请求。\n> - OrderService：定义订单相关业务逻辑的接口。\n> - OrderServicelmpl：Order 服务的具体实现\n> - OrdersRepository：定义如何访问订单持久信息的接口。\n> - JdbcOrderRepository：持久信息访问接口的实现。\n\n<Figures figure=\"34-1\">Package by layer</Figures>\n\nIn “Presentation Domain Data Layering,”2 Martin Fowler says that adopting such a layered architecture is a good way to get started. He’s not alone. Many of the books, tutorials, training courses, and sample code you’ll find will also point you down the path of creating a layered architecture. It’s a very quick way to get something up and running without a huge amount of complexity. The problem, as Martin points out, is that once your software grows in scale and complexity, you will quickly find that having three large buckets of code isn’t sufficient, and you will need to think about modularizing further.\n\n> 在 presentation Domain Data Layering 这篇文章中，Martin Fowler 声称釆用这种分层架构是初期一个不错选择。他的观点并不缺乏拥戴者。很多书籍、教程和代码示范都在教育你采用分层架构。这种方式在在项目初期之所以会很合适，是因为它不会过于复杂。但就像 Martin 指出的那样，一旦软件规模扩展了，我们很快就会发现将代码分为三大块并不够，需要进一步进行模块化。\n\nAnother problem is that, as Uncle Bob has already said, a layered architecture doesn’t scream anything about the business domain. Put the code for two layered architectures, from two very different business domains, side by side and they will likely look eerily similar: web, services, and repositories. There’s also another huge problem with layered architectures, but we’ll get to that later.\n\n> 如 Bob 所说，这里还存在另外一个问题是，分层架构无法展现具体的业务领域信息。把两个不同业务领域的、但是都采用了分层架构的代码进行对比，你会发现它们的相似程度极高：都有 Web 层、服务层和数据仓库层。这是分层架构的另外一个问题，后文会具体讲述。\n\n## PACKAGE BY FEATURE 按功能封装\n\nAnother option for organizing your code is to adopt a “package by feature” style. This is a vertical slicing, based on related features, domain concepts, or aggregate roots (to use domain-driven design terminology). In the typical implementations that I’ve seen, all of the types are placed into a single Java package, which is named to reflect the concept that is being grouped.\n\n> 另外一种组织代码的形式是“按功能封装”，即垂直切分，根据相关的功能、业务概念或者聚合根（领域驱动设计原则中的术语）来切分。在常见的实现中，所有的类型都会放在一个相同的包中，以业务概念来命名。\n\nWith this approach, as shown in Figure 34.2, we have the same interfaces and classes as before, but they are all placed into a single Java package rather than being split among three packages. This is a very simple refactoring from the “package by layer” style, but the top-level organization of the code now screams something about the business domain. We can now see that this code base has something to do with orders rather than the web, services, and repositories. Another benefit is that it’s potentially easier to find all of the code that you need to modify in the event that the “view orders” use case changes. It’s all sitting in a single Java package rather than being spread out.3\n\n> 图 34.2 展示了这种方式，类和接口与之前类似，但是相比之前，这次它们都被放到了同一个 Java 包中。相 比 “按层封装”，这只是一个小变化，但是现在顶层代码结构至少与业务领域有点相关了。我们可以看到这段代码是与订单有关的，而不是只能看到 Web、服务及数据访问。另外一个好处是，如果需要修改 “查看订单”这个业务用例，比较容易找到相关代码，毕竟它们都在一个包中，而不是分散在各处。\n\nI often see software development teams realize that they have problems with horizontal layering (“package by layer”) and switch to vertical layering (“package by feature”) instead. In my opinion, both are suboptimal. If you’ve read this book so far, you might be thinking that we can do much better—and you’re right.\n\n> 软件研发团队常常一开始采用水平分层方式（即 “按层封装”），遇到困难后再切换到垂直分层方式（即 “按功能封装”）。我认为，两种方式都很不好。看完本书，你应该意识到还有更好的分类方式——没错。\n\n<Figures figure=\"34-2\">Package by feature</Figures>\n\n## PORTS AND ADAPTERS 端口和适配器\n\nAs Uncle Bob has said, approaches such as “ports and adapters,” the “hexagonal architecture,” “boundaries, controllers, entities,” and so on aim to create architectures where business/domain-focused code is independent and separate from the technical implementation details such as frameworks and databases. To summarize, you often see such code bases being composed of an “inside” (domain) and an “outside” (infrastructure), as suggested in Figure 34.3.\n\n> 如 Bob 大叔所说，通过采用“端口和适配器”“六边形架构”“边界、控制器、实体”等，我们可以创造出一个业务领域代码与具体实现细节（数据库、框架等）隔离的架构。总结下来，如图 34.3 所示，我们可以区分出代码中的内部代码（领域，Domain）与外部代码（基础设施，Infrastructure）。\n\n<Figures figure=\"34-3\">A code base with an inside and an outside</Figures>\n\nThe “inside” region contains all of the domain concepts, whereas the “outside” region contains the interactions with the outside world (e.g., UIs, databases, third-party integrations). The major rule here is that the “outside” depends on the “inside”—never the other way around. Figure 34.4 shows a version of how the “view orders” use case might be implemented.\n\n> 内部区域包含了所有的领域概念，而外部区域则包含了与外界交互的部分（例如 UI、数据库、第三方集成等）。这里主要的规则是，只有外部代码能依赖内部代码，反之则不能。图 34.4 展示了 “查看订单”这个业务用例是如何用这种方式实现的。\n\nThe `com.mycompany.myapp.domain` package here is the “inside,” and the other packages are the “outside.” Notice how the dependencies flow toward the “inside.” The keen-eyed reader will notice that the OrdersRepository from previous diagrams has been renamed to simply be Orders. This comes from the world of domain-driven design, where the advice is that the naming of everything on the “inside” should be stated in terms of the “ubiquitous domain language.” To put that another way, we talk about “orders” when we’re having a discussion about the domain, not the “orders repository.”\n\n> 这里 `com.mycompnay.myapp.domain` 包是内部代码，另外一个包是外部代码。注意这里的依赖关系是由外向内的。眼尖的读者可以注意到之前的 OrderRepository 类现在被改名为 Orders。这个概念基于领域驱动设计理念，其中要求内部代码都应该用独特的领域语言来描述。换句话说，我们在业务领域里面讨论的应该是 Orders，而不是“OrdersRepository”。\n\n<Figures figure=\"34-4\">View orders use case</Figures>\n\nIt’s also worth pointing out that this is a simplified version of what the UML class diagram might look like, because it’s missing things like interactors and objects to marshal the data across the dependency boundaries.\n\n> 值得注意的是，这里是 UML 类图的一个简化版，这里缺少了交互器，以及跨边界调用时对应的数据编码解码对象。\n\n## PACKAGE BY COMPONENT 按组件封装\n\nAlthough I agree wholeheartedly with the discussions about SOLID, REP, CCP, and CRP and most of the advice in this book, I come to a slightly different conclusion about how to organize code. So I’m going to present another option here, which I call “package by component.” To give you some background, I’ve spent most of my career building enterprise software, primarily in Java, across a number of different business domains. Those software systems have varied immensely, too. A large number have been web-based, but others have been client–server4, distributed, message-based, or something else. Although the technologies differed, the common theme was that the architecture for most of these software systems was based on a traditional layered architecture.\n\n> 虽然我对本书中的 SOLID、REP、CCP、CRP 以及其他大部分建议完全认同，我想提出对代码组织方式的一个不同看法——“按组件封装”。一些背景信息：在我的职业生涯中，我基于 Java 构建了大量不同领域的企业软件，这些软件系统要求各异。大部分系统都是基于 Web 的，也有一些是 CS 架构，或者是分布式架构的、基于消息的，或者其他的。虽然具体采用的技术不同，但大部分系统都是基于传统的分层架构的。\n\nI’ve already mentioned a couple of reasons why layered architectures should be considered bad, but that’s not the whole story. The purpose of a layered architecture is to separate code that has the same sort of function. Web stuff is separated from business logic, which is in turn separated from data access. As we saw from the UML class diagram, from an implementation perspective, a layer typically equates to a Java package. From a code accessibility perspective, for the OrdersController to be able to have a dependency on the OrdersService interface, the OrdersService interface needs to be marked as public, because they are in different packages. Likewise, the OrdersRepository interface needs to be marked as public so that it can be seen outside of the repository package, by the OrdersServiceImpl class.\n\n> 我已经给出一些分层架构不好的理由，但这还不是全部。分层架构设计的目的是将功能相似的代码进行分组。处理 Web 的代码应该与处理业务逻辑的代码分开，同时也与处理数据访问的代码分开。正如我们在 UML 类图中所见，从实现角度讲，层就是代表了 Java 包。从代码可访问性角度来讲，如果需要 OrdersController 依赖 OrderService 接口，那么这个接口必须设置为 public，因为它们在不同的包中。同样的，OrdersRepository 接口也需要设置为 public，这样才能被包外的类 OrdersServicelmple 使用。\n\nIn a strict layered architecture, the dependency arrows should always point downward, with layers depending only on the next adjacent lower layer. This comes back to creating a nice, clean, acyclic dependency graph, which is achieved by introducing some rules about how elements in a code base should depend on each other. The big problem here is that we can cheat by introducing some undesirable dependencies, yet still create a nice, acyclic dependency graph.\n\n> 在严格分层的架构中，依赖指向的箭头应该永远向下，每一层只能依赖相邻的下一层。通过引入一些代码互相依赖的规则，我们就形成了一个干净、漂亮的单向依赖图。这里有一个大问题——只要通过引入一些不应该有的依赖来作弊，依然可以形成漂亮的单向依赖图。\n\nSuppose that you hire someone new who joins your team, and you give the newcomer another orders-related use case to implement. Since the person is new, he wants to make a big impression and get this use case implemented as quickly as possible. After sitting down with a cup of coffee for a few minutes, the newcomer discovers an existing OrdersController class, so he decides that’s where the code for the new orders-related web page should go. But it needs some orders data from the database. The newcomer has an epiphany: “Oh, there’s an OrdersRepository interface already built, too. I can simply dependency-inject the implementation into my controller. Perfect!” After a few more minutes of hacking, the web page is working. But the resulting UML diagram looks like Figure 34.5.\n\n> 假设新员工加入了团队，你给新人安排了一个订单相关的业务用例的实现任务。由于这个人刚刚入职，他想好好表现，尽快完成这项功能。粗略看过代码之后，新人发现了 OrdersController 这个类，于是他将新的订单相关的 Web 代码都塞了进去。但是这段代码需更从数据库查找一些订单数据。这时候这个新人灵机一动：“代码己经有了一个 OrdersRepository 接口，只需要将它用依赖注入框架引入控制器就行，我真机智！”几分钟之后，功能已经正常了，但是 UML 结构图变成了图 34.5 这样。\n\nThe dependency arrows still point downward, but the OrdersController is now additionally bypassing the OrdersService for some use cases. This organization is often called a relaxed layered architecture, as layers are allowed to skip around their adjacent neighbor(s). In some situations, this is the intended outcome—if you’re trying to follow the CQRS5 pattern, for example. In many other cases, bypassing the business logic layer is undesirable, especially if that business logic is responsible for ensuring authorized access to individual records, for example.\n\n> 依赖关系箭头依然向下，但是现在 OrdersController 在某些情况下绕过了 OrderService 类。这种组织形式被称为宽松的分层采构，允许某些层跳过直接相邻的邻居。在有些情况下，这是意料之中的——例如，如果我们在遵循 CQRS 设计模式，这是合理的。但是更多的情况下，绕过业务逻辑层是不合理的，尤其是在业务逻辑层要控制权限的情况下。\n\nWhile the new use case works, it’s perhaps not implemented in the way that we were expecting. I see this happen a lot with teams that I visit as a consultant, and it’s usually revealed when teams start to visualize what their code base really looks like, often for the first time.\n\n> 虽然新的业务用例可以正常工作，但是它可能不是按照合理方式实现的。作为咨询师，我曾经见过很多团队出现这种情况，只有他们开始仔细观察自己的代码结构图时才会发现。\n\n<Figures figure=\"34-5\">Relaxed layered architecture</Figures>\n\nWhat we need here is a guideline—an architectural principle—that says something like, “Web controllers should never access repositories directly.” The question, of course, is enforcement. Many teams I’ve met simply say, “We enforce this principle through good discipline and code reviews, because we trust our developers.” This confidence is great to hear, but we all know what happens when budgets and deadlines start looming ever closer.\n\n> 这里我们有的其实只是一个规范——一个架构设计原则内容是“Web 控制器永远不应该直接访问数据层”。这里的核心问题当然是如何强制执行。我遇见的很多团队仅仅通过采用“自律”或者“代码评审”方式来执行，“我相信我的程序员”。有这种自信当然很好，但是我们都知道当预算缩减、工期临近的时候会发生什么事情。\n\nA far smaller number of teams tell me that they use static analysis tools (e.g., NDepend, Structure101, Checkstyle) to check and automatically enforce architecture violations at build time. You may have seen such rules yourself; they usually manifest themselves as regular expressions or wildcard strings that state “types in package `**/web` should not access types in `**/data`”; and they are executed after the compilation step.\n\n> 有一小部分团队告诉我，他们会采用静态分析工具（例如 Ndepend、Structure101、Checkstyle）来在构建阶段自动检查违反架构设计规则的代码。估计你见过这种代码，一般来说就是一段正则表达式，例如“包 `**/web` 下面的类型不允许访问 `**/data` 下面的类型”，这些检查在编译步骤之后执行。\n\nThis approach is a little crude, but it can do the trick, reporting violations of the architecture principles that you’ve defined as a team and (you hope) failing the build. The problem with both approaches is that they are fallible, and the feedback loop is longer than it should be. If left unchecked, this practice can turn a code base into a “big ball of mud.”6 I’d personally like to use the compiler to enforce my architecture if at all possible.\n\n> 这种方式虽然简单粗暴，但是确实能起效果，可以锁定违反了团队定义的系统架构设计原则的情况，并且（理想情况下）导致构建失败。这两种方法的共同问题是容易出错，同时反馈循环时间太长了。如果不精心维护，整个代码库可能很快就变成“一团泥巴”。我个人更倾向选择能够让编译器执法的做法。\n\nThis brings us to the “package by component” option. It’s a hybrid approach to everything we’ve seen so far, with the goal of bundling all of the responsibilities related to a single coarse-grained component into a single Java package. It’s about taking a service-centric view of a software system, which is something we’re seeing with micro-service architectures as well. In the same way that ports and adapters treat the web as just another delivery mechanism, “package by component” keeps the user interface separate from these coarse-grained components. Figure 34.6 shows what the “view orders” use case might look like.\n\n> 那么，看一下“按组件封装”的做法。这种做法混合了我们之前讲的所有的方法，目标是将一个粗粒度组件相关的所有类放入一个 Java 包中。这就像是以一种面向服务的视角来构建软件系统，与微服务架构类似。这里，就像端口和适配器模式将 Web 视为一种交付手段一样，“按组件封装”将 U1 与粗粒度组件分离。图 34.6 展示了“查看订单”这个用例的设计图。\n\nIn essence, this approach bundles up the “business logic” and persistence code into a single thing, which I’m calling a “component.” Uncle Bob presented his definition of “component” earlier in the book, saying:\n\n> 总的来说，这种方式将“业务逻辑”与“持久化代码”合并在一起，称为“组件”，Bob 大叔在本书中对“组件”的定义如下：\n\nComponents are the units of deployment. They are the smallest entities that can be deployed as part of a system. In Java, they are jar files.\n\n> 组件是部署单元。组件是系统中能够部署的最小单位，对应在 Java 里就是 jar 文件。\n\n<Figures figure=\"34-6\">View orders use case</Figures>\n\nMy definition of a component is slightly different: “A grouping of related functionality behind a nice clean interface, which resides inside an execution environment like an application.” This definition comes from my “C4 software architecture model,”7 which is a simple hierarchical way to think about the static structures of a software system in terms of containers, components, and classes (or code). It says that a software system is made up of one or more containers (e.g., web applications, mobile apps, stand-alone applications, databases, file systems), each of which contains one or more components, which in turn are implemented by one or more classes (or code). Whether each component resides in a separate jar file is an orthogonal concern.\n\n> 我对组件的定义稍有不同：“在一个执行环境（应川程序）中的、一个干净、良好的接口背后的一系列相关功能的集合”。这个定义来自我的“C4 软件架构模型\" 这个模里以一种层级模型讨论软件系统的静态结构，其中的概念包括容器、细件、类。这个模型认为，系统由一个或者多个容器组成（例 如 Web 应用、移动 App、独立应用、数据库、文件系统），每个容器包含一个或多个组件，每个组件由一个或多个类组成。每个组件具体存在于哪个 jar 文件中则是另外一个维度的事情。\n\nA key benefit of the “package by component” approach is that if you’re writing code that needs to do something with orders, there’s just one place to go—the OrdersComponent. Inside the component, the separation of concerns is still maintained, so the business logic is separate from data persistence, but that’s a component implementation detail that consumers don’t need to know about. This is akin to what you might end up with if you adopted a micro-services or Service-Oriented Architecture—a separate OrdersService that encapsulates everything related to handling orders. The key difference is the decoupling mode. You can think of well-defined components in a monolithic application as being a stepping stone to a micro-services architecture.\n\n> 这种“按组件封装”的方式的一个好处是，如果我们需要编写和订单有关的代码，只有一个位置需要修改 OrdersComponet。在这个组件中，仍然应该关注重点隔离原则，但这是组件内部|可题，使用者不需要关心。这就有点像采用微服务架构，或者是面向服务架构的结果——独立的 Orderservice 会将所有订单相关的东西封装起来。这里关键的区别是解耦的方式。我们可以认为，单体程序中的一个良好定义的组件，是微服务化架构的一个前提条件。\n\n## THE DEVIL IS IN THE IMPLEMENTATION DETAILS 具体实现细节中的陷阱\n\nOn the face of it, the four approaches do all look like different ways to organize code and, therefore, could be considered different architectural styles. This perception starts to unravel very quickly if you get the implementation details wrong, though.\n\n> 表面上看，四种代码组织方式各不相同，可以认为是不同的架构设计风格。可是，如果具体实现中不严加注意，很快就会出现偏差。\n\nSomething I see on a regular basis is an overly liberal use of the public access modifier in languages such as Java. It’s almost as if we, as developers, instinctively use the public keyword without thinking. It’s in our muscle memory. If you don’t believe me, take a look at the code samples for books, tutorials, and open source frameworks on GitHub. This tendency is apparent, regardless of which architectural style a code base is aiming to adopt—horizontal layers, vertical layers, ports and adapters, or something else. Marking all of your types as public means you’re not taking advantage of the facilities that your programming language provides with regard to encapsulation. In some cases, there’s literally nothing preventing somebody from writing some code to instantiate a concrete implementation class directly, violating the intended architecture style.\n\n> 我经常遇到的一个问题是，Java 中 public 访问控制修饰符的滥用。我们作为程序员，好像天生就喜欢使用严 public 关键词。这就好像是肌肉记忆一样。如果不信，请看一下各种书籍的代码示范、各种入门教程，以及 GitHub 上的开源框架。这个趋势是显而易见的，不管采用了哪种系统架构风格。将所有的类都设置为 public 意味着就无法利用编程语言提供的封装手段。这样一来，没有任何东西可以阻碍某人写一段直接初始化具体实现类的代码，哪怕它违反了架构设计的要求。\n\n## ORGANIZATION VERSUS ENCAPSULATION 组织形式与封装的区别\n\nLooking at this issue another way, if you make all types in your Java application public, the packages are simply an organization mechanism (a grouping, like folders), rather than being used for encapsulation. Since public types can be used from anywhere in a code base, you can effectively ignore the packages because they provide very little real value. The net result is that if you ignore the packages (because they don’t provide any means of encapsulation and hiding), it doesn’t really matter which architectural style you’re aspiring to create. If we look back at the example UML diagrams, the Java packages become an irrelevant detail if all of the types are marked as public. In essence, all four architectural approaches presented earlier in this chapter are exactly the same when we overuse this designation (Figure 34.7).\n\n> 从另外一个角度来看，如果我们将 Java 程序中的所有类型都设置为 public，那么包就仅仅是一种组织形式了（类似文件夹一样的分组方式），而不是一种封装方式，由于 public 类型可以在代码库的任何位置调用，我们事实上就可以忽略包的概念，因为它并不提供什么价值。最终，如果忽视包的概念（因为并不起到任何封装和隐藏的功能），那么想要采用的任何架构风格就都不重要了。我们回过头来看一下例子中的 UML 图，如果所有的类型都是 public，那么 Java 包就成了一个无关紧要的细节信息。于是，所有四种架构方式事实上并没有任何区别（参见图 34.7）。\n\nTake a close look at the arrows between each of the types in Figure 34.7: They’re all identical regardless of which architectural approach you’re trying to adopt. Conceptually the approaches are very different, but syntactically they are identical. Furthermore, you could argue that when you make all of the types public, what you really have are just four ways to describe a traditional horizontally layered architecture. This is a neat trick, and of course nobody would ever make all of their Java types public. Except when they do. And I’ve seen it.\n\n> 我们再详细看一下图 34.7 中各个类之间的箭头：不论采用哪种架构设计风格，它们的指向都是一致的。虽然概念不同，但是语法上都是一致的。更进一步说，如果所有的类都是 public 的，那么其实我们就是在用四种不同的方式描述一个传统的分层架构设计方式。你会说当然没有人会将所有的 Java 类都设置为 public，但是相信我，我见过。\n\nThe access modifiers in Java are not perfect,8 but ignoring them is just asking for trouble. The way Java types are placed into packages can actually make a huge difference to how accessible (or inaccessible) those types can be when Java’s access modifiers are applied appropriately. If I bring the packages back and mark (by graphically fading) those types where the access modifier can be made more restrictive, the picture becomes pretty interesting (Figure 34.8).\n\n> 虽然 Java 中的访问修饰符并不完美，但是忽略它们的存存就是在自找麻烦。Java 类与包的组织形式其实可以很大程度决定这个类的可访问性（或者不可访问性）。如果我们将包的概念引入这幅图，同时标记（虚化的形式展示）应用到访问控制符的地方，这个图就很有意思了（参见图 34.8）。\n\n<Figures figure=\"34-7\">All four architectural approaches are the same</Figures>\n\nMoving from left to right, in the “package by layer” approach, the OrdersService and OrdersRepository interfaces need to be public, because they have inbound dependencies from classes outside of their defining package. In contrast, the implementation classes (OrdersServiceImpl and JdbcOrdersRepository) can be made more restrictive (package protected). Nobody needs to know about them; they are an implementation detail.\n\n> 从左向右，在 “按层封装”方式中，OrderService 与 OrderRepository 需要 public 修饰符，因为包外的类需要依赖它们。然而，具体实现类（OrderServicelmpl 和 JdbcOrdersRepository）则可以设置更细致的访问权限（包范围内的 protected）。不需要有人依赖它们，它们是具体的实现细节。\n\nIn the “package by feature” approach, the OrdersController provides the sole entry point into the package, so everything else can be made package protected. The big caveat here is that nothing else in the code base, outside of this package, can access information related to orders unless they go through the controller. This may or may not be desirable.\n\n> 在“按功能封装”模式中，OrdersController 是整个包的入口，所以其他的类都可以设置为包范围内的 protected。这里的一个问题是，代码库中的其他代码都必须通过控制器才能访问订单信息——这可能是好处，也可能是坏处，视实际情况而定。\n\nIn the ports and adapters approach, the OrdersService and Orders interfaces have inbound dependencies from other packages, so they need to be made public. Again, the implementation classes can be made package protected and dependency injected at runtime.\n\n> 在端口与适配器模式中，OrderService 与 Orders 接口都有来自包外的依赖关系，所以需要 public 修饰符。同样，实现类可以设置为包范围内 protected，依赖在运行时注入。\n\n<Figures figure=\"34-8\">Grayed-out types are where the access modifier can be made more restrictive</Figures>\n\nFinally, in the “package by component” approach, the OrdersComponent interface has an inbound dependency from the controller, but everything else can be made package protected. The fewer public types you have, the smaller the number of potential dependencies. There’s now no way9 that code outside this package can use the OrdersRepository interface or implementation directly, so we can rely on the compiler to enforce this architectural principle. You can do the same thing in .NET with the internal keyword, although you would need to create a separate assembly for every component.\n\n> 最后、在“组件”封装模式中，OrdersComponet 接口有来自 Controller 的依赖关系，但是其他类都可以设置为包 protected。Public 类型越少，潜在的依赖关系就越少。现在包外代码就不能再直接使用 OrdersRepository 接口或者具对应的实现，我们就可以利用编译器来维护架构设计原则了。在 .Net 语言中，我们可以用 internal 关键词达到一样的目的，然而我们需要给每个组件创建一个单独的 assembly。\n\nJust to be absolutely clear, what I’ve described here relates to a monolithic application, where all of the code resides in a single source code tree. If you are building such an application (and many people are), I would certainly encourage you to lean on the compiler to enforce your architectural principles, rather than relying on self-discipline and post-compilation tooling.\n\n> 再澄清一点，这里描述的全都和单体程序有关，所有代码都存放在同一个代码树下。如果你在构建这种程序（大部分程序都是如此），那么我强烈建议利用编译器来维护架构设计原理，而不要依赖个人自律和编译过程之后的工具。\n\n## OTHER DECOUPLING MODES 其他的解耦合模式\n\nIn addition to the programming language you’re using, there are often other ways that you can decouple your source code dependencies. With Java, you have module frameworks like OSGi and the new Java 9 module system. With module systems, when used properly, you can make a distinction between types that are public and types that are published. For example, you could create an Orders module where all of the types are marked as public, but publish only a small subset of those types for external consumption. It’s been a long time coming, but I’m enthusiastic that the Java 9 module system will give us another tool to build better software, and spark people’s interest in design thinking once again.\n\n> 除编程语言自带的工具之外，通常还有其他方式可以进一步解耦源代码级别的依赖关系。在 Java 语言中，有模块化框架 OSGi，以及最新的 Java 9 模块系统。正确利用模块系统，我们可以进一步区分 public 类型和对外发布的类型。例如，我们可以创建一个 Orders 模块。将所有的类型标记为 public，但仅仅公布一小部分类供外部调用。虽然耗时很久，但是我十分期待 Java 9 的模块系统，它能提供构建更好软件的另一套工具，希望能够再次点燃人们思考设计的热情。\n\nAnother option is to decouple your dependencies at the source code level, by splitting code across different source code trees. If we take the ports and adapters example, we could have three source code trees:\n\n> 另外一个选择是将代码分散到不同的代码树中，以从源代码级别解耦依赖关系。以端口和适配器方式为例，我们会有三个代码树：\n\n- The source code for the business and domain (i.e., everything that is independent of technology and framework choices): OrdersService, OrdersServiceImpl, and Orders\n- The source code for the web: OrdersController\n- The source code for the data persistence: JdbcOrdersRepository\n\n---\n\n> - 业务代码（所有技术和框架无关的代码）：OrdersService、OrdersServiceImpl 以及 Orders。\n> - Web 源代码：OrdersController。\n> - 持久化源代码：JdbcOrdersRepository。\n\nThe latter two source code trees have a compile-time dependency on the business and domain code, which itself doesn’t know anything about the web or the data persistence code. From an implementation perspective, you can do this by configuring separate modules or projects in your build tool (e.g., Maven, Gradle, MSBuild). Ideally you would repeat this pattern, having a separate source code tree for each and every component in your application. This is very much an idealistic solution, though, because there are real-world performance, complexity, and maintenance issues associated with breaking up your source code in this way.\n\n> 后面两个源代码树对业务代码有编译期依赖关系，而业务代码则对 Web 和数据持久毫无所知。从实现角度来看，我们可以通过将这些代码在构建工具中组织成不同的模块或者项目（例如 Maven> Gradle> MSBUILD 等）来达到目的。理想情况下，我们可以用这种模式将所有组件都划分成不同的项目。然而，这有点太理想化了，因为拆分代码库经常会带来性能、复杂度和维护性方面的问题。\n\nA simpler approach that some people follow for their ports and adapters code is to have just two source code trees:\n\n> 有些人采用一个稍微简单的组织方式，仅使用两个代码树：\n\n- Domain code (the “inside”)\n- Infrastructure code (the “outside”)\n\n---\n\n> - 业务（Domain）代码（内部）\n> - 基础设施（Infrastructure）代码（外部）\n\nThis maps on nicely to the diagram (Figure 34.9) that many people use to summarize the ports and adapters architecture, and there is a compile-time dependency from the infrastructure to the domain.\n\n> 这与图 34.9 完美对应，很多人都用这个方式来简化对端口和适配器架构的描述。基础设施部分对业务代码有一个编译期的依赖关系。\n\n<Figures figure=\"34-9\">Domain and infrastructure code</Figures>\n\nThis approach to organizing source code will also work, but be aware of the potential trade-off. It’s what I call the “Périphérique anti-pattern of ports and adapters.” The city of Paris, France, has a ring road called the Boulevard Périphérique, which allows you to circumnavigate Paris without entering the complexities of the city. Having all of your infrastructure code in a single source code tree means that it’s potentially possible for infrastructure code in one area of your application (e.g., a web controller) to directly call code in another area of your application (e.g., a database repository), without navigating through the domain. This is especially true if you’ve forgotten to apply appropriate access modifiers to that code.\n\n> 这种代码组织方式是可行的，但是需要额外注意随之而来的问题。我称这个问题为“端口与适配器模式中的 Peripherique 反模式”。法国巴黎有一条环形公路，名字是 Peripherique 大道。这条大道允许车辆环绕巴黎而不需要进入社区。同样的，将所有的基础设施代码放在同一个源代码树中，就有可能使得应用中的一个区域的基础设施代码（Web 控制器）直接调用另外一个区域的代码（数据库访问），而不经过领域代码。如果没有设置正确的访问修饰符，就更是如此了。\n\n## CONCLUSION: THE MISSING ADVICE 本章小结：本书拾遗\n\nThe whole point of this chapter is to highlight that your best design intentions can be destroyed in a flash if you don’t consider the intricacies of the implementation strategy. Think about how to map your desired design on to code structures, how to organize that code, and which decoupling modes to apply during runtime and compile-time. Leave options open where applicable, but be pragmatic, and take into consideration the size of your team, their skill level, and the complexity of the solution in conjunction with your time and budgetary constraints. Also think about using your compiler to help you enforce your chosen architectural style, and watch out for coupling in other areas, such as data models. The devil is in the implementation details.\n\n> 这一章的中心思想就是，如果不考虑具体实现细节，再好的设计也无法长久。必须要将设计映射到对应的代码结构上，考虑如何组织代码树，以及在编译期和运行期采用哪种解耦合的模式。保持开放，但是一定要务实，同时要考虑到团队的大小、技术水平，以及对应的时间和预算限制。最好能利用编译器来维护所选的系统架构设计风格，小心防范来自其他地方的耦合模式，例如数据结构。所有的实现细节都是关键的！\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n# AFTERWORD 后序\n\nMy professional career as a software developer began in the 1990s, at a time when the dinosaurs of Big Architecture ruled the world. To get ahead, you had to learn about objects and components, about design patterns, and about the Unified Modeling Language (and its precursors).\n\n> 我的软件工程师生涯开始于 20 世纪 90 年代，那是一个恐龙级大型架构统治世界的时代。要想在那样的时代获得一席之地，我们必须学会对象及其组件、设计模式、统一建模语言（包括其前身）的相关知识。\n\nProjects—and boy, should we rue the day when we decided to call them that?—started with long design phases, where detailed blueprints for our systems were laid out by “senior” programmers for more “junior” programmers to follow. Which, of course, they didn’t. Ever.\n\n> 现在想起来，或许真的可以考虑把我们那段日子所做的事情叫作“童子军项目”。每个项目的开头都会有一段长长的设计阶段，以便等那些“高级”程序员为一些跟随他们的、较“低级”的程序员制订好系统的设计蓝图，当然，这些“高级”程序员似乎永远完不成这件事。\n\nAnd so it was that, after rising to the lofty ranks of “software architect”—and then “lead architect,” “chief architect,” “Lord Architect of the Privy Council,” and all the other highfalutin titles we gave ourselves back in the day—I seemed doomed to spend my days connecting boxes with arrows and coding with PowerPoint, and having barely any impact on the real code itself.\n\n> 于是乎，做这件事的人被升级到了“软件架构师”，接着是“首席架构师”“总架构师”“枢密院首席架构师”以及其他各种高不可言的头衔，最终，我们还是让一切回到了原点。而我似乎注定要把时间花在画那些带箭头的盒子和编写 PowerPoint 的事情上，而这些事对真实代码的影响近乎为零。\n\nIt struck me then that this was nonsense; every line of code contains at least one design decision, and therefore anyone who writes code has a much greater impact on the quality of the software than a PowerPoint jockey like me ever could.\n\n> 这让我无比受挫，每一行代码本身都至少包含了一条设计决策，任何一个写代码的家伙对软件质量的影响都远在我这个 PowerPoint 专业户之上。\n\nAnd then, thankfully, the Agile Software Development revolution arrived and put architects like me out of our misery. I’m a programmer. I like programming. And the best way I’ve found to have a positive impact on code is to write it.\n\n> 幸运的是，接下来发生的敏捷软件开发革命终于让我们这些架构师脱离了苦海。毕竟我是一名程序员，喜欢的是编程。而且我也发现影响软件质量最好的方法还是后序编写代码。\n\nThe dinosaurs of Big Architecture—typically to be found wandering the primeval plains of Big Process—were wiped out by the asteroid of Extreme Programming. And it came as a blessed relief.\n\n> 这些大型架构像恐龙一样在大进程式的原始平原上游荡，然后被一颗叫作“敏捷开发”的小行星灭绝了，真是老天开眼啊！\n\nDevelopment teams were set free to focus on what matters and to concentrate their efforts on things that add value. Instead of waiting weeks or months for a Big Architecture document so they could dutifully ignore it and write the code they were going to write anyway, teams could just agree to a test with their customer, have a quick design session to get their bearings, and then write the code they were going to write anyway.\n\n> 现在！开发团队可以自由地专注于真正重要的内容，并思考如何为他们所做的事情添加更多价值了。也就是说，他们现在再也不需要浪费几周或几个月的时间等待那些大型架构的设计文档了，他们可以名正言顺地忽略这些设计，直接按照自己的想法编写代码。然后，开发团队只需要安排客户直接参与测试，并在快速设计会议上得到用户的支持，然后他们就可以继续写代码了。\n\nThe Big Architecture dinosaurs were gone, and small, nimble Just-Enough-Design-Up-Front-with-Plenty-of-Refactoring mammals replaced us. Software architecture became responsive.\n\n> 大型架构像恐龙一样消失了，前期设计够用、后期进行大量重构的设计思想如小巧玲珑的哺乳动物一样代替了它们，软件架构迎来了响应式设计的时代。\n\nWell, that was the theory, anyway.\n\n> 好吧，无论如何，以上这些都属于理论。\n\nThe problem with leaving architecture to programmers is that programmers have to be able to think like architects. It turns out that not all of the stuff we learned during the Big Architecture era was of no value. The way that software is structured can have a profound impact on our ability to keep adapting and evolving it, even in the short term.\n\n> 把架构设计工作交给程序员的问题就是，程序员必须学会像架构师一样思考问题。事实证明，我们在大型架构时代学到的东西也并非一文不值。其设计软件结构的方法依然在我们保持软件的适应和扩展能力方面有着深远的影响，即使在短期开发中也是如此。\n\nEvery design decision needs to leave the door open for future changes. Like playing pool, each shot isn’t just about sinking that ball; it’s also about lining up the next shot. Writing working code that doesn’t block future code is a non-trivial skillset. It takes years to master.\n\n> 我们的每一项设计决策都必须为未来的变化敞开大门。就像打台球一样，我们的每一杆击球都不只是为了要把球打进洞里，它也事关下一杆击球时所在的位置。让我们现在编写的代码不对未来的代码产生阻碍是一项非常重要的技能，通常需要花费多年的时间才能掌握。\n\nAnd so, the era of Big Architecture gave way to a new era of Fragile Architecture: designs that grew quickly to deliver value sooner, but that made sustaining that pace of innovation very difficult.\n\n> 因此，在大型架构时代让位给易碎型架构（Fragile Architecture）的新时代之后，虽然设计创造的价值得到了快速发展，但这也让我们想要持续创新变得举步维艰。\n\nIt’s all very well talking about “embracing change,” but if it costs \\$500 to change a line of code, change ain’t happening.\n\n> 这里所有关于“拥抱变革\"的讨论都很美好，但如果每修改一行代码的代价是 500 美元的话，这些变革恐怕根本就不会发生。\n\nBob Martin’s original papers on OO design principles had a big impact on me as a young software developer. I looked at my code with a fresh perspective, and noticed problems that—until then—never seemed like problems to me.\n\n> 当我还是一名年轻的软件开发者的时候，Bob Martin 那篇关于面向对象设计原则的论文对我产生了很大的影响，他让我以一种全新的视觉审视了自己的代码，并发现了其中的问题，在那之前，这些问题对我来说似乎从来都不是问题。\n\nNow you’ve seen how it’s possible to write code that delivers value today without blocking future value tomorrow; the onus is on you to put in the practice so you can apply these principles to your own code.\n\n> 现在，你们也看到了如何才能写出既能提供当前价值，又不会阻碍未来价值的代码，期待你们也能亲自实践这些设计原则，并将其应用到自己的代码中。\n\nLike riding a bicycle, you can’t master software design just by reading about it. To get the best from a book like this, you need to get practical. Analyze your code and look for the kinds of problems Bob highlights, then practice refactoring the code to fix these problems. If you’re new to the refactoring discipline, then this will be a doubly valuable experience.\n\n> 就像学习骑自行车一样，单纯靠阅读是无法掌握软件设计方法的。为了让我们从这本书中的获益最大化，亲自实践是必不对少的。我们需要亲自分析自己的代码，查看其中是否存在 Bob 所强调的各种问题，然后在重构代码的实践中修复它们。如果你在重构方面是个新手，那么你将从本书收获双重的宝贵学习经验。\n\nLearn how you can incorporate design principles and Clean Architecture into your development processes, so that new code is less likely to cause pain. For example, if you’re doing TDD, make a point of having a little design review after passing each test, and clean up as you go. (It’s way cheaper than fixing bad designs later.) Perhaps, before you commit code, ask a colleague to review it with you. And look into the possibility of adding a code “quality gate” to your build pipeline as a last line of defense against unclean architecture. (And if you don’t have a build pipeline, maybe it’s time to create one?)\n\n> 我们得学会将书中的这些设计原则以及整洁架构融入自己的开发过程中，这可以大大减少新代码给我们带来的麻烦。例如，如果我们现在正在进行一次测试驱动的开发（TDD），就可以在每一次测试之后做一些设计审查，并及时整理我们的设计（这比事后再修复这些不良设计要省时省力得多）。或者，在提交代码之前，我们也可以邀请同事一起审查代码。另外，我们也可以研究在构建软件的管道中引入一些代码的“质量把关”机制，以作为防止架构设计不够清晰分明的最后一道防线。（如果你还没有设置构建软件的管道，现在是否可以考虑设置一个了？）\n\nMost important of all is to talk about Clean Architecture. Talk about it with your team. Talk about it with the wider developer community. Quality is everybody’s business, and it’s important to reach a consensus about the difference between good and bad architecture.\n\n> 这一切的重中之重就是要讨论架构的整洁性，我们要在自己的团队中讨论它，在各种开发者社区中讨论它。保证软件质量是我们每个人的责任，在区分架构的好坏标准上达成共识是一件非常重要的事。\n\nBe mindful that most software developers are not very architecture-aware, just as I wasn’t 25 years ago. More experienced developers clued me into it. Once you’ve wrapped your head around Clean Architecture, take the time to wrap someone else’s head around it. Pay it forward.\n\n> 我们必须意识到，大部分的软件开发者是没有太多架构意识的。就像 25 年前的我一样，是更有经验的开发者让我了解了架构。一旦我们一头扎进了整洁架构中，就会花时间围绕着它思考问题，并玩转它。\n\nWhile the technology landscape for developers evolves continuously, foundational principles like the ones described here rarely change. I have little doubt that this is a book that’s going to stay on your shelf for many years after your copy of Lean JSON Cloud NoSQL for Dummies has ended up in a yard sale. I hope it does for your Design Fu what Bob’s original papers did for mine.\n\n> 虽然开发者所在的技术环境一直在不断地发展，但本书所讨论的这些基本设计原则几乎不会发生变化。我一点都不怀疑在你们把 Lean JSON Cloud NoSQL for Dummies 当废纸卖掉很多年之后，这本书会还留在你们的书架上。我希望这本书会 对你们有很大的帮助，就像 Bob 那篇原创论文对我的帮助一样。\n\nThe real journey starts here.\n\n> 愿你们真正的编程设计之旅从这里开始！\n\n—Jason Gorman\n\nJanuary 26, 2017\n\n> ——Jason Gorman\n>\n> 2017 年 1 月 26 日\n","tags":["clean architecture"],"categories":["读书"]},{"title":"认识ProtocolBuffers","url":"/posts/673cef84.html","content":"\n## 什么是Protocol Buffers\n\n> Protocol buffers are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.\n>\n> ——Google\n\npb是google推出的一个语言无关、平台无关、可扩展的数据序列化机制，它用来序列化类似xml的结构化数据。\n\nPB有着许多优点：\n\n1. 强类型约束\n2. 序列化结果是二进制数据\n3. 性能好\n\n比如JSON数据这种结构化数据：\n\n```javascript\n{\n  \"name\": \"zxfan\",\n  \"id\": 123213,\n  \"email\": \"xxx@xx.com\"\n}\n```\n\n可以注意到JSON的缺点：没有类型约束。我们可以尝试使用PB对这块数据进行定义\n\n```protobuf\n// person.proto\nmessage Person {\n  required string name = 1;\n  required int32 id = 2;\n  optional string email = 3;\n}\n```\n\n`message`用于定义数据结构，Person有三个字段。两个字符串类型（name和email）。一个32位整型（email）。\n\n## PB2的语法\n\n`protocol buffers`有`proto2`和`proto3`两个版本，默认是`proto2`。\n\n### 定义一个message\n\n```protobuf\nmessage SearchRequest {\n  required string query = 1;\n  optional int32 page_number = 2;\n  optional int32 result_per_page = 3;\n}\n```\n\n`message`用于定义一个message结构，message里每个字段（field）的由几部分组成：\n\n```text\n[field rule] [field type] [field name] = [field number]\n```\n\n### Field Rule\n\n- `required`：指定字段是必须的\n- `optionsal`：指定字段是可选\n- `repeated`：指定字段是可重复的，类似数组\n\noptional的字段是可以添加默认值的，如：\n\n```protobuf\noptional int32 result_per_page = 3 [default = 10];\n```\n\n### Field Type\n\n定义字段类型，字段类型可以是**标量类型**也可以是一个**message**\n\n#### 标量类型\n\n所支持的标量类型，请查阅[官网文档](https://developers.google.cn/protocol-buffers/docs/proto#scalar)\n\n#### Message作为Field类型\n\n如下例：\n\n```protobuf\nmessage SearchResponse {\n  repeated Result result = 1;\n}\n\nmessage Result {\n  required string url = 1;\n  optional string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n#### 枚举类型\n\n```protobuf\nenum Corpus {\n  UNIVERSAL = 0;\n  WEB = 1;\n  IMAGES = 2;\n  LOCAL = 3;\n  NEWS = 4;\n  PRODUCTS = 5;\n  VIDEO = 6;\n}\n\nmessage SearchRequest {\n  required string query = 1;\n  optional int32 page_number = 2;\n  optional int32 result_per_page = 3 [default = 10];\n  optional Corpus corpus = 4 [default = UNIVERSAL];\n}\n```\n\n\n\n### Field Name\n\n定义字段名称\n\n### Field Number\n\n定义字段编号。pb被编码成二进制数据，这个编号就是用来标识字段的。\n\n- 字段编号必须唯一，不能两个字段使用同一个数字。（只要确保同一个message中不重复就行）\n- 编号1～15会被编码成1个字节，而16～2047会被编码成2个字节。所以要尽可能多得使用1～15。\n- 最小编号1，最大编号2^29 - 1。\n\n### Reserved\n\n```protobuf\nmessage Foo {\n  reserved 2, 15, 9 to 11; // 保留 field number\n  reserved \"foo\", \"bar\"; // 保留 field name\n}\n```\n\n`reserved`意味着指定的`field number`或`field name`不能被使用。\n\n这在一些场景下十分有用——如果你删除了某个message的field，那么对应的field number就可以被其他field使用了。但是如果其他人使用的是旧版的proto文件，这是就会发生问题，因为PB是通过number来鉴别field的。\n\n所以，当我们删除某个字段时，考虑一下这个number能否被复用。如果不能，那就使用`reserved`避免使用到该number。\n\n`enum`也是支持`reserved`的\n\n```protobuf\nenum Foo {\n  reserved 2, 15, 9 to 11, 40 to max;\n  reserved \"FOO\", \"BAR\";\n}\n```\n\n### 嵌套\n\n`message`能够嵌套`message`和`enum`\n\n```protobuf\nmessage SearchResponse {\n  message Result {\n    required string url = 1;\n    optional string title = 2;\n    repeated string snippets = 3;\n  }\n  enum EnumLike {\n    UNKNOWN = 0;\n    STARTED = 1;\n  }\n  repeated Result result = 1;\n  required EnumLike like = 2;\n}\n```\n\n### import\n\n注意：这个特性不支持`Java`语言\n\n我们通常讲不通的message拆分到不通的`.proto`文件中。我们可以使用`import`来复用`.proto`的内容\n\n```protobuf\nimport \"other_proto.proto\";\n\n// 这就可以使用other_proto.proto的内容了\n```\n\n还有一个`import public`语句。举个例子：有`a.protp` `b.proto` `c.proto` `d .proto`四个`.proto`文件，其中`b.proto`内容如下：\n\n```protobuf\nimport public \"a.proto\";\nimport \"d.proto\"\n// ...\n```\n\n然后`c.proto`再导入`b.proto`文件，这样c就可以使用a和b中的定义的内容\n\n```protobuf\nimport \"b.proto\";\n\n// 能够使用a.proto和b.proto定义的内容\n// 但不包括d.proto，因为b使用的是不加public的import\n```\n\n所以加上`public`后，就具有传递行了。\n\n特别注意：我们在使用pb命令行工具时，可用通过添加参数`-I/--proto_path`，用于指定寻找文件的位置。如果没有指定默认取当前工作路径（就是命令执行的目录）。\n\n### Extensions\n\nPB提供一套扩展机制，可以对现有message进行扩展（类似类继承）\n\n```protobuf\nmessage Foo {\n  // ...\n  extensions 100 to 199; \n  // 100 to max\n}\n```\n\n`extensions`关键字表明100~199的编号是为扩展保留的。\n\n```protobuf\nextend Foo {\n  optional int32 bar = 126;\n}\n```\n\n`extend`关节字后加上message name，表示对该message进行扩展。新加字段只能使用100～199作为编号。\n\n### Oneof\n\n### Maps\n\n### Packages\n\n// TODO\n\n## JavaScript如何使用PB\n\n// TODO\n\n因为是语言无关的，可以在[官网](https://developers.google.cn/protocol-buffers)找到相对应的语言指导\n\n```javascript\nconst protobuf =  require('protocol-buffers');\nconst fs = require('fs')\n\n// 创建schema\nconst schema = protobuf(fs.redFileSync(__dirname + './person.proto', 'utf-8'));\n\n// 编码\nconst buf = schema.Column.encode({\n  id: 1,\n  name: \"zxfan\",\n  email: \"zxfan@xx.com\"\n});\n\n// 解码\nconst data = schema.Column.decode(buf)\n```\n\n编码会将原数据编码成二进制","categories":["experience"]},{"title":"Crypto","url":"/posts/6f842db3.html","content":"\n## 哈希\n\n哈希算法又称为散列算法。将一个任意长度的的数组作为输入，能够获得固定长度的输出。\n\n```javascript\nconst crypto = require(\"crypto\");\n\nconsole.log(crypto.getHashes());\n\n/*\n输出\n[\n  'RSA-MD4',\n  'RSA-MD5',\n  'RSA-MDC2',\n  'RSA-RIPEMD160',\n  'RSA-SHA1',\n  'RSA-SHA1-2',\n  'RSA-SHA224',\n  ...\n  ...\n]\n*/\n```\n\n以`md5`为例：\n\n```javascript\nconst crypto = require(\"crypto\");\n\nconst text = \"hello crypto!\";\n\nconst md5 = crypto.createHash(\"md5\");\nconst result = md5.update(text).digest(\"hex\");\n\nconsole.log(result);\n```\n\n- `createHash`：创建hash，参数为hash算法，具体见`crypto.getHashes()`\n- `update`：对字符串进行hash\n- `digest`：获取信息摘要\n  - 不传参数，返回Buffer\n  - 参数为字符编码，`hex`返回16进制\n\nmd5是不可逆的，破解md5也只能使用暴力的“碰撞破解”。所以一般会对文本进行多次md5哈希：`md5.update(text).update(text).update(text)`\n\n> 哈希算法通常用作信息摘要算法，比如双发通信时，发送方将资源（数据，用户）的信息摘要进行加密，接收方再去验证比对\n\n## HMAC\n\n`Hmac`被称为加盐算法，即 `Hmac = hash + 密钥`。比如`sha-1`算法\n\n```javascript\nconst crypto = require(\"crypto\");\n\nconst text = \"hello crypto!\";\n\nconst result = crypto.createHmac(\"sha1\", \"miyao\").update(text).digest(\"hex\");\n\nconsole.log(result); // 09ef939a42b909a48d8ea3803692ec88eedc4c04\n```\n\n`createHmac`第二个参数密钥\n\n> 密钥可以通过`openssl`来创建\n>\n> `openssl genrsa -out rsa_private.key 1024`\n\n## 对称加密\n\n对称加密指：利用同一个密钥来加密/解密数据。这有两个关键点：\n\n- 有加密也有解密，所以加密算法是可逆的\n- 同一个密钥\n\n以`aes192`为例：\n\n```javascript\nconst crypto = require(\"crypto\");\n\nconst text = \"hello crypto!\";\nconst key = crypto.scryptSync(\"woshimiyao\", \"yanzhi\", 24); // 密钥\n\n// 加密\nfunction encrypt(data, iv) {\n  const cipher = crypto.createCipheriv(\"aes192\", key, iv);\n\n  return cipher.update(data, \"utf-8\", \"hex\").final(\"hex\");\n}\n\n// 解密\nfunction decrypt(data, iv) {\n  const decipher = crypto.createDecipheriv(\"aes192\", key, iv);\n\n  return decipher.update(data, \"hex\", \"utf-8\").final(\"utf-8\");\n}\n\nconst iv = Buffer.alloc(16, 0); // 初始化向量\nconst e = encrypt(text, iv);\nconst d = decrypt(e, iv);\nconsole.log(e, d); // 3e07418b2c1ed2b128943b005610f166 hello crypto!\n```\n\n## 非对称加密\n\n非对称加密：利用两个密钥，一个用于加密另一个用于解密。这也有两个关键点：\n\n- 有加密也有解密，所以加密算法是可逆的\n- 两个密钥：\n  - 公钥：用于加密\n  - 私钥：用于解密\n\n## 常见加密算法\n\n","tags":["Nodejs","crypto"],"categories":["experience"]},{"title":"字节跳动面试","url":"/posts/33f3fd9d.html","content":"## 一面\n\n1. 自我介绍\n\n2. 网络模型：osi七层模型，每层干什么的？\n\n3. http协议的理解。想到啥说啥。就是你随便说，面试官会顺着问\n   1. 无状态\n   2. 应用层协议，基于tcp\n   3. 发展历史：从0.9到3.0\n   4. 缓存\n   5. http状态吗：从1xx一直说到5xx\n\n4. https？说了一下tls协商\n\n5. es6相关，说一些用过哪些？面试官会顺着问。\n   1. var/let/const ， 面试官顺着问了它们的区别\n   2. 字符串有哪些方法。这个问题应该是问错了，他想问得是数组：map filter reduce sort…\n   3. 模块规范 esm cjs 区别\n   4. promise，然后就开始手写。估计他最初是想让我实现数组相关的方法，但是发现自己问错了就跳过了。\n6. 3道题\n   1. Promise.all\n   2. 快排、归并，dfs选一个写\n   3. 最小银币找零问题：现有[1,2,5,9,10]几种硬币，当有18面值的硬币时，如何找零使得硬币数量最少；答案是2——18 = 9+9\n\n7. 感受：一面还是非常基础的。问了挺多的网络相关的内容\n\n## 二面\n\n1. 自我介绍？没让自我介绍直接开始。\n\n2. 看简历：\n   1. 问你是怎么优化（webpack）构建性能的？\n      1. 缓存：如何根据js代码变化去修改缓存的？\n      2. thread-loader 怎么选取进程数量的？\n      3. 如何去做chunk拆分，怎么考量的？\n   2. cli脚手架 怎么设计的？\n3. vue的computed如何进行依赖收集？说了computed的实现机制。\n4. vue3相对于vue2做了哪些改进？讲了响应式和compiler的优化（静态提升、pathFlag、BlockTree）\n\n5. 手写题目：类似vue中的渲染函数（render），让你生成dom元素（返回一个dom对象）\n\n   ```javascript\n   const vnode = el(\"div\", { class: \"container\" }, [\n     el(\"span\", {}, [\"hello world\"]),\n   ]);\n   vnode.render();\n   ```\n\n6. 场景题：\n\n   一个多语言应用，大概14种语言。假如每个语言都放在一个js文件中（中文的一个文件，英文的一个文件）。目前存在两个问题\n\n   - 应用启动时，会加载这14种语言（js文件），但实际上只需要1种语言，问如何优化？\n   - 随着开发，有一些语言的值不在使用了，但还是加载到内存中去了，如何优化？\n\n7. 感受：二面连自我介绍都省了，哈哈！！感觉面试官爱从编译的角度问问题，估计这和他的具体工作相关吧。总体感觉这位面试官还是不错的，问得都是比较实际的问题。\n\n## 三面\n\n三面聊得特别广，也挺深的。\n\n1. 之前性能优化怎么做的，这个聊了很久\n\n2. cdn为什么会快？\n\n3. 从url到页面渲染的过程\n\n   1. 知道http如何判断响应返回的吗？\n   2. script 加载为什么会阻塞dom解析，既然有defer和async，为什么浏览器不默认defer/async?\n\n4. js中函数是一等公民。js中函数可以返回一个函数（闭包），知道这个特性实现难点在哪吗？\n\n5. 你的项目（自己的开源项目）有做过设计吗？看过设计相关的书吗？\n\n   1. 设计模式\n   2. 函数式编程\n\n6. 你项目写了虚拟列表优化，怎么做的\n\n   1. 滚动得快的话，出现白屏怎么优化？\n   2. 如果高度不固定，怎么实现？\n\n7. 为什么会学习electron？\n\n   1. electron的进程模型\n   2. 浏览器的进程模型\n\n8. 手写题：\n\n   场景：根据ip判断ip所在范围，要求：尽可能高效\n\n   ```javascript\n   // 假如在这两个范围内的 是中国的ip\n   const db = [\n     [\"0.0.0.0\", \"10.0.0.0\"],\n     [\"11.0.0.0\", \"200.0.0.0\"],\n   ]\n   \n   // ip: string，判断ip是否是中国ip\n   function isInChain(ip) {}\n   ```\n\n感觉三面的面试官的职责可能不仅仅是前端，喜欢问一些特别底层的问题。\n\n> 三轮技术面试都没有怎么考算法，就一面考了一道动态规划。飞书的面试官还是比较注重实际的开发能力的。\n\n","tags":["前端","interview"],"categories":["self"]},{"title":"clear 清除浮动","url":"/posts/d8bddba6.html","content":"\n## 场景\n\nclear用于解决，由于float造成的浮动塌陷问题。\n\n## 只能清除前面的浮动\n\n```html\n<div class=\"box\">\n  <div class=\"a\">a</div>\n  <div class=\"b\">b</div>\n  <div class=\"c\">c</div>\n</div>\n\n<style>\n  .box {\n    background: red;\n  }\n\n  .a,\n  .b,\n  .c {\n    float: left;\n  }\n\n  .b {\n    clear: left\n  }\n</style>\n```\n\n无论对`b`设置`clear: left/right/both`。都只能清除`a`的浮动（a将独占一行），然而无法清除b的浮动。这是因为浏览器的解析顺序的缘故。\n\n那么`clear: right`有什么用？当`float:right`时不就能清除右侧浮动了么！","tags":["css"],"categories":["CSS"]},{"title":"前端性能优化","url":"/posts/616f4683.html","content":"\n## 性能优化\n\n性能优化是很大的话题，可以从两个角度入手\n\n- 优化资源体积\n- 优化请求速度\n\n## 优化资源体积\n\n### 资源懒加载\n\n资源懒加载就是指，当前这个页面只去加载本页面的资源。其它资源不去加载\n\n#### 按照路由懒加载\n\n如果使用`webpack`这种构建工具，可以使用动态`import`函数来按照路由实现拆分chunk\n\n#### 拆分node_modules\n\n如果一个项目使用到了诸如：`element-ui` `vue` `pdfjs` `videojs`这些插件；`webpack`默认会将所有`node_modules`打包成一个`chunk`。但是某一个页面只用到了vue没有用到其它库，这是就会导致这个页面加载了许多无用的资源\n\n所以我们要根据使用情况来拆分`node_modules`。具体做法就是通过`webpack`的`splitChunk`功能来实现。\n\n> 把这些库都拆分出去了，不就影响到下个页面的性能的吗？\n>\n> 利用`preftch`解决\n>\n> - import函数可以使用魔法注释 `/*.webpackPrefetch: true */` `/*.webpackPreload: true */`\n\n#### 库按需加载\n\n比如`element-ui`，它内置了大量组件。我们应该去按需引用他们。\n\n使用`babel-plugin-import`来实现组件库（js和css）的按需加载\n\n### 资源压缩\n\n#### 客户端压缩\n\n客户端压缩资源文件，比如`js` `css` `img`等\n\n- js：使用`terser-webpack-plugin`压缩脚本代码\n- css：使用`optimize-css-webpack-plugin`\n- Img: 图片可以使用 `image-webpack-loader`压缩\n\n#### 服务端压缩\n\n服务端开启`g-zip`压缩\n\n比如nginx，直接配置`gzip: on`即可\n\n## 优化请求速度\n\n从请求速度角度入手。首先，需要理清楚页面显示之前都发生了些什么。\n\n### 浏览器缓存\n\n输入url，后首先不是DNS，而是检查浏览器缓存。浏览器缓存可以分成四种\n\n#### Service Worker\n\n`service worder`就是服务端与客户端之间的代理人。客户端对资源的请求会被`service worker`拦截下来\n\n```javascript\n// worker.js\n/* 监听安装事件，install 事件一般是被用来设置你的浏览器的离线缓存逻辑 */\nthis.addEventListener('install', function (event) {\n\n  /* 通过这个方法可以防止缓存未完成，就关闭serviceWorker */\n  event.waitUntil(\n    /* 创建一个名叫V1的缓存版本 */\n    caches.open('v1').then(function (cache) {\n      /* 指定要缓存的内容，地址为相对于跟域名的访问路径 */\n      return cache.addAll([\n        './index.html' // 资源URL\n      ]);\n    })\n  );\n});\n\n/* 注册fetch事件，拦截全站的请求 */\nthis.addEventListener('fetch', function(event) {\n  \n  /* 在缓存中匹配对应请求资源直接返回 */\n  event.respondWith(caches.match(event.request));\n});\n```\n\n`service worker`需要注册, `navigator.serviceWorker.register`\n\n```javascript\n// main.js\n/* 判断当前浏览器是否支持serviceWorker */\nif ('serviceWorker' in navigator) {\n  /* 当页面加载完成就创建一个serviceWorker */\n  window.addEventListener('load', function () {\n    /* 创建并指定对应的执行内容 */\n    /* scope 参数是可选的，可以用来指定你想让 service worker 控制的内容的子目录。 在这个例子里，我们指定了 '/'，表示 根网域下的所有内容。这也是默认值。 */\n    navigator.serviceWorker.register('./serviceWorker.js', {scope: './'})\n      .then(function (registration) {\n\n      console.log('ServiceWorker registration successful with scope: ', registration.scope);\n    })\n      .catch(function (err) {\n\n      console.log('ServiceWorker registration failed: ', err);\n    });\n  });\n}\n```\n\n> service worker是基于web worker\n\n#### memory cache & disk cache\n\n- 内存缓存，这部分资源存放到内存中的\n\n- 磁盘缓存，这部分资源是存放到磁盘中的。也就是我们常说的**强缓存**和**协商缓存**\n\n`chrome`会自动将磁盘缓存存放到内存中，下次请求时，就会自动从内存中去。内存IO的性能肯定优于磁盘IO。当浏览器关闭后，存放到内存的缓存就会自动清空，而磁盘缓存一致存在\n\n#### push cache\n\n`HTTP2`拥有**服务端推送的功能**。\n\n### DNS prefetch\n\n开启DNS 预取，在加载HTML时，开始解析域名获取IP。\n\n```html\n<!-- 会自动加上响应头，告诉浏览器开始dns预解析 -->\n<meta http-equiv=\"x-dns-prefetch-control\" content=\"on\" />\n\n<!-- 指定要解析的域名 -->\n<link rel=\"dns-prefetch\" href=\"//www.zhix.net\" />\n```\n\n### CDN\n\n将一些图片或者不变的大资源，采用CDN上云的方式。从而加快请求速度\n\n### 并发限制\n\n现代浏览器对同一个域的请求是有并发限制的。比如`chrome`最多并发6个请求。我们有两种方案来解决：\n\n- 拆分不同的域名：那我们可以将资源拆分到不同的域下，从而绕开限制。\n- 使用HTTP2：`http2`可以实现多路复用，一个域名只需要建立一个tcp连接\n\n","tags":["网络","Nodejs"],"categories":["experience"]},{"title":"Vuex@4.x","url":"/posts/340f0a10.html","content":"\n## Vuex注册流程\n\n首先通过`createStore`方法创建一个store对象。然后使用`app.use(store)`。`store`对象是一个vue插件。所以必须实现install方法\n\n```javascript\n{\n  install (app, injectKey) {\n    app.provide(injectKey || storeKey, this)\n    app.config.globalProperties.$store = this\n  }\n}\n\n// 在组件里使用vuex\n// 1: this.$store\n// 2: inject: [injectKey] \n```\n\n创建store对象的流程：\n\n1. 初始化所有module\n2. resetStoreState\n   - 注册getter\n   - 响应式state\n\n## 如何注册module\n\n`installModule`会初始化root模块，也会初始化所有子模块\n\n```javascript\nfunction installModule (store, rootState, path, module, hot) {\n  const isRoot = !path.length\n  const namespace = store._modules.getNamespace(path)\n\n  // register in namespace map\n  if (module.namespaced) {\n    store._modulesNamespaceMap[namespace] = module\n  }\n\n  // set state\n  if (!isRoot && !hot) {\n    const parentState = getNestedState(rootState, path.slice(0, -1))\n    const moduleName = path[path.length - 1]\n  }\n\n  const local = module.context = makeLocalContext(store, namespace, path)\n\n  // 注册所有mutation\n  module.forEachMutation((mutation, key) => {\n    const namespacedType = namespace + key\n    registerMutation(store, namespacedType, mutation, local)\n  })\n\t\n  // 注册所有action\n  module.forEachAction((action, key) => {\n    const type = action.root ? key : namespace + key\n    const handler = action.handler || action\n    registerAction(store, type, handler, local)\n  })\n\n  // 注册所有getter\n  module.forEachGetter((getter, key) => {\n    const namespacedType = namespace + key\n    registerGetter(store, namespacedType, getter, local)\n  })\n\n  // 注册所有子模块\n  module.forEachChild((child, key) => {\n    installModule(store, rootState, path.concat(key), child, hot)\n  })\n}\n```\n\n### 注册getters\n\n```javascript\nfunction registerGetter (store, type, rawGetter, local) {\n  if (store._wrappedGetters[type]) {\n    if (__DEV__) {\n      console.error(`[vuex] duplicate getter key: ${type}`)\n    }\n    return\n  }\n  \n  // 把所有getter 注册到 _wrappedGetters对象上\n  store._wrappedGetters[type] = function wrappedGetter (store) {\n    // rawGetter就是开发者提供的getter\n    return rawGetter(\n      local.state, // local state\n      local.getters, // local getters\n      store.state, // root state\n      store.getters // root getters\n    )\n  }\n}\n```\n\n### 注册actions\n\n```javascript\nfunction registerAction (store, type, handler, local) {\n  const entry = store._actions[type] || (store._actions[type] = [])\n  \n  // 利用闭包实现柯里化\n  // 下次执行函数就不需要传参数了\n  entry.push(function wrappedActionHandler (payload) {\n    let res = handler.call(store, {\n      dispatch: local.dispatch,\n      commit: local.commit,\n      getters: local.getters,\n      state: local.state,\n      rootGetters: store.getters,\n      rootState: store.state\n    }, payload)\n    \n    // 会用Promise包一层 action\n    if (!isPromise(res)) {\n      res = Promise.resolve(res)\n    }\n    if (store._devtoolHook) {\n      return res.catch(err => {\n        store._devtoolHook.emit('vuex:error', err)\n        throw err\n      })\n    } else {\n      return res\n    }\n  })\n}\n```\n\n### 注册mutations\n\n```javascript\nfunction registerMutation (store, type, handler, local) {\n  const entry = store._mutations[type] || (store._mutations[type] = [])\n  \n  // 对各个模块 注册mutation\n  entry.push(function wrappedMutationHandler (payload) {\n    handler.call(store, local.state, payload)\n  })\n}\n```\n\n## 如何初始化store中的数据\n\n需要响应式的数据有getters和state\n\nstate的响应式是通过`reactive`对象来实现的\n\n```javascript\nfunction resetStoreState (store, state, hot) {\n  const oldState = store._state\n\n  // bind store public getters\n  store.getters = {}\n  // reset local getters cache\n  store._makeLocalGettersCache = Object.create(null)\n  const wrappedGetters = store._wrappedGetters\n  const computedObj = {}\n  forEachValue(wrappedGetters, (fn, key) => {\n\n    computedObj[key] = partial(fn, store)\n    Object.defineProperty(store.getters, key, {\n      get: () => computedObj[key](),\n      enumerable: true // for local getters\n    })\n  })\n\t\n  // 使用reactive响应式state\n  store._state = reactive({\n    data: state\n  })\n\n  // enable strict mode for new state\n  if (store.strict) {\n    enableStrictMode(store)\n  }\n\n  if (oldState) {\n    if (hot) {\n      // dispatch changes in all subscribed watchers\n      // to force getter re-evaluation for hot reloading.\n      store._withCommit(() => {\n        oldState.data = null\n      })\n    }\n  }\n}\n```\n\n## 如何实现只有mutation才能修改state\n\n说明：只有**严格模式**且**开发模式**下，vuex才会阻止非mutation修改state\n\n```javascript\n// 严格模式会调用 enableStrictMode\nif (store.strict) {\n  enableStrictMode(store)\n}\n\n// 使用watch监听state，如果state发生变化\n// 提示\nfunction enableStrictMode (store) {\n  watch(() => store._state.data, () => {\n    if (__DEV__) {\n      \n      // assert如果条件为 false会抛一场\n      // 由于是sync\n      // 所以会阻止修改\n      assert(store._committing, `do not mutate vuex store state outside mutation handlers.`)\n    }\n  }, { deep: true, flush: 'sync' })\n}\n```\n\n所以这个`store._committing`只要是`false`就会阻止修改state。\n\n那什么时候这个值为true呢，那肯定是commit的时候\n\n```javascript\nthis._withCommit(() => {\n  entry.forEach(function commitIterator (handler) {\n    handler(payload)\n  })\n})\n\n// _withCommit方法会修改_committing的状态\n// 执行完mutation又会 改回来\n_withCommit (fn) {\n  const committing = this._committing\n  this._committing = true\n  fn()\n  this._committing = committing\n}\n```\n\n","tags":["vue"],"categories":["源码"]},{"title":"Electron的隔离上下文","url":"/posts/b9b99d96.html","content":"\n## ContextIsolation\n\n处于安全考虑，`Electron12`默认开启了上下文隔离（context isolation），它会将**上下文环境**划分两个运行环境——**主环境**和**隔离环境**\n\n主环境：渲染进程所运行的环境，无法访问到Electron API\n\n隔离环境：preload脚本所运行的环境，能够访问到Electron API\n\n`ContextIsolation`是默认开启的\n\n```typescript\nnew BrowserWindow({\n  webPreference: {\n    contextIsolation: true // 默认就是true\n    preload: 'path to your preload js file', // 设置preload脚本\n  }\n})\n```\n\n## ContextBridge\n\n通过使用[ContextBridge](https://www.electronjs.org/docs/api/context-bridge#contextbridgeexposeinmainworldapikey-api-experimental)，可以通过隔离环境将`Electron API`暴露给主环境\n\n```typescript\n// 隔离环境\nconst { contextBridge, ipcRenderer } = require('electron')\n\ncontextBridge.exposeInMainWorld(\n  'electron',\n  {\n    doThing: () => ipcRenderer.send('do-a-thing')\n  }\n)\n```\n\n主环境直接在window对象上使用`window.electron.doThing()`","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"vue-router@4.x","url":"/posts/22412f62.html","content":"\n## 问题\n\n### vue-router是如何实现修改url而不会使页面刷新？\n\n`vue-router`通过`history`这个`BOM`对象来修改url的\n\n- `history.pushState`：向当前浏览器会话的历史堆栈中添加一个state\n- `history.replaceState`：替换历史堆栈栈顶的state\n\n这两个API不会导致页面刷新\n\n### vue-router如何监听url变化？\n\n`history.pushState`和`history.replaceState`是手动执行的，不需要监听\n\n需要监听浏览器后退——`window.addEventListener(\"popstate\", () => {})`\n\n> 旧版本的`vue-router`。对hash路由做了一层兼容性判断：如果浏览器支持`history.pushState`就监听`popstate`事件，否则监听`hashchange`\n\n### vue-router的路由组件如何响应url变化\n\n在执行`vue-router`的`install`方法时，将`currentRoute`全局注入（provide），然后在`router-view`组件内`inject`。\n\n在创建router时传入了`routes`参数，以定义应用的路由列表。`routes`是一个树结构。每一次路由变化时，都会在routes中寻找一个匹配当前跳转url的路由列表（数组）并赋值给`currentRoute.matched`。\n\n在`router-view`中时这样获取的：\n\n```typescript\nconst matchedRouteRef = computed<RouteLocationMatched | undefined>(\n  () => routeToDisplay.value.matched[depth]\n)\n```\n\n`router-view`是一个嵌套结构，`depth`表示深度。`depth`是这样来的：\n\n```typescript\nconst depth = inject(viewDepthKey, 0) // 初始默认为0\nprovide(viewDepthKey, depth + 1) // +1 provide给子组件\n```\n\n这样就可以获取匹配到的路由，然后就是获取路由对应的组件，并渲染。\n\n### 导航守卫原理\n\n每次发生路由跳转时，回去执行导航守卫，源码位于`vue-router-next/src/router.ts`下的`navigate`方法。该方法主要做了：\n\n1. 收集`beforeRouteLeave`导航守卫\n2. 执行所有收集到的导航\n3. 收集并执行全局守卫`beforeEach`\n4. 收集并执行`beforeRouteUpdate`\n5. 收集并执行`beforeEnter`\n6. 收集并执行`beforeRouteEnter`\n7. 收集并执行`beforeResolve`\n8. 最后执行`afterEach`\n\n> 整个过程是Promise链式调用。若其中一步reject，后面就不会执行了。","tags":["vue"],"categories":["源码"]},{"title":"网络知识梳理","url":"/posts/8c9e2fd.html","content":"\n## HTTP演进\n\n### HTTP/0.9\n\n第一版HTTP协议，只能传输文本，请求报文内容只有 1 行。\n\n- 客户端：请求报文：`GET/index.html`\n- 服务端：返回一个以 ASCII 字符流编码的 HTML 文档。\n\n### HTTP/1.0\n\nHTTP 可以用来传输脚本、样式、图片、音频和视频等不同类型的文件\n\n增加了头部的设定，`Accept`和`Content-Type`\n\n### HTTP/1.1\n\n解决了`HTTP/1.0`的连接问题，支持TCP连接复用\n\n- `HTTP/1.0`：每次请求都会建立连接、传输数据和断开连接三个阶段\n- `HTTP/1.1`：第二次请求会复用第一次请求的TCP连接\n\n长连接可以在请求头中加上`Connection: keep-alive`。`HTTP/1.1`默认开启`keep-alive`，不加这个请求头也可以使用长连接的。\n\n### HTTP/2\n\n`HTTP/2`增强了并发能力\n\n- **二进制传输**：`http/1.1`传输的是文本，`http/2`传输的是二进制流\n- **多路复用**：`http/2`有两个概念——**帧**和**流**。`http/2`将数据报文分成一个个二进制**帧（Frame）**，在一个TCP连接中，不同的帧组合在一起发送（**二进制分帧**）形成**流（Stream）**。在接收方根据帧首部信息在组合起来。`HTTP/1.1`只能一个个请求报文排队发送（容易发生**队头阻塞**）。\n- **header压缩**：http请求有这繁多冗长的首部，`http/2`会对首部进行压缩\n- **服务端推送**：能够主动给客户端推送资源\n  - `http/1.1`加载网页的顺序：请求html，解析html，再请求js、css等文件\n  - `http/2`：当服务端收到html请求时，服务端就主动吧html、css、js以及图片等资源发送给客户端\n\n### HTTP/3\n\n`HTTP/1.x`、`HTTPS`以及`HTTP/2.0`都离不开底层的`TCP`协议。\n\n`HTTP/2.0`采用多路复用，多个数据包使用一个`TCP`连接。`TCP`是可靠连接，但发生丢包时，会进行重传。所以网络状态差的情况下，某些数据包频繁重传，从而导致拥塞，后面的HTTP包都穿不出去。这叫做**头部阻塞（Head of line Blocking）**\n\n`HTTP/3.0`就开始考虑放弃`TCP`转向`UDP`协议。起初`Google`搞出来个`QUIC`协议，后来`IETF`标准化了`QUIC`协议形成`HTTP/3`。其底层采用`UDP`，基于`UDP`实现做了众多增强：\n\n- 0RTT：`TPC`建立连接每次都需要三次握手，就存在数据包的三次往返即**3RTT**。而`QUIC`首次建立连接只需要`1RTT`。其后的连接可以直接复用，只需要**0RTT**\n- 连接迁移：当`源IP`、`源端口`、`目的IP`、`目的端口`其中一个发生变化就需要重新建立TCP连接。只要**Connection ID**没有变化。`HTTP/3`可以继续复用连接\n- 头部阻塞：由于使用`UDP`，发生丢包时，也不会立即重传，阻塞连接。\n- 拥塞控制\n- 前向纠错\n- 更多特性 请参考[文章](https://zhuanlan.zhihu.com/p/143464334)\n\nchrome只支持 `Google QUIC`。对`IETF QUIC`的支持处于`WIP`状态\n\n## HTTPS\n\nHTTP(超文本传输协议)，有着一个致命的缺陷，那就是内容是**明文传输**的，没有经过任何加密，而这些明文数据会经过**WiFi、路由器、运营商、机房**等多个物理设备节点，如果在这中间任意一个节点被监听，传输的内容就会完全暴露，这一攻击手法叫做MITM（Man In The Middle）**中间人攻击**。\n\nHTTPS = HTTP + TLS/SSL。HTTPS就是在HTTP（应用层）与TCP（传输层）之间加上了一层`TLS/SSL`协议\n\n### 对称加密和非对称加密\n\n区别：\n\n- 加解密方式不同：\n  - 对称加密使用同一个密钥加解密\n  - 非对称加密使用不同的密钥加解密\n- 性能：对称加密比非对称加密快\n\n### CA(Certification Authority)\n\nCA是为了保证密钥的正确性。具体来说就是把密钥放入一个证书中，该证书包含服务端的信息，比如颁发者、域名、有效期，为了保证证书是可信的，需要由一个可信的第三方来对证书进行签名。这个第三方一般是证书的颁发机构，也称 CA（Certification Authority，认证中心）。\n\n### HTTPS工作流程\n\n![https](../../images/network/HTTP-process.webp)\n\n1. 客户端发送HTTPS请求（默认端口443）\n2. 服务端有一套`CA数字证书`，证书含有一个`公钥public`。服务端接收到请求，会将这个证书发送给客户端。服务端还有一个`私钥private`，私钥是一直保存再服务端不公开的。\n3. 客户端收到证书，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续。\n4. 客户端先生成一段`随机key`，再利用证书中的`公钥public`加密这段`随机key`，并将这个`随机key密文`发送给服务端。\n5. 服务端收到这个`随机key密文`文后，通过`私钥private`来解密，获取客户端真正的`随机key`\n6. 服务端使用`随机key`来加密需要传输的HTTP数据，并发送给客户端\n7. 客户端再用`随机key`来解密服务端传输过来的密文，获取真正的数据\n8. 后续HTTPS请求使用之前交换好的`随机Key`进行对称加解密。\n\n>  由于随机key明文没有再网络上传输，所以\"中间人\"并不知道用于加密和解密的随机key，因此是安全的\n\n## TCP\n\n`SYN`报文：请求连接\n\n`ACK`报文：应答\n\n`FIN`报文：断开连接\n\n#### 三次握手\n\n三次握手就是建立TCP连接的过程，流程如下图：\n\n![三次握手](../../images/network/三次握手.png)\n\n一共分三步：\n\n1. 客户端发送SYN消息给服务端（告知服务端要建立连接）\n2. 服务端同时发送两个消息（SYN和ACK）给客户端\n   - ACK表示收到了客户端的SYN\n   - SYN表示服务端也要连接客户端\n3. 客户端发送ACK给服务端（表示接受服务端的SYN）\n\n>  **为什么要三次握手？**\n>\n> TCP是可靠传输，三次握手目的是确认双方的接收和发送能力。经过三次握手，服务端和客户端都确认了双方的接收和发送能力。\n\n#### 四次挥手\n\n四次挥手是TCP断开连接的过程，流程如下图\n\n![四次挥手.png](../../images/network/四次挥手.png)\n\n一共分为四步：（客户端和服务端都可以断开请求，以服务端为例）\n\n1. 服务端发送FIN请求，表示服务端要断开连接\n2. 客户端发送ACK请求，表示收到了服务端的请求\n3. 客户单发送FIN请求，表示客户端也要断开连接\n4. 服务端发送ACK请求，表示收到了客户端的请求\n\n> 为什么2，3步骤不能一起发送\n>\n> ACK只是对FIN的应答，断开连接要处理的问题比较多，比如说服务端/客户端可能还有发送出去的消息没有得到 ACK；也有可能服务端自己有资源要释放。\n\n## webscoket\n\n`websocket`的建立也是通过`http`实现的\n\n首先，客户端先发送一个HTTP请求，请求头携带以下信息\n\n```http\nGET ws://websocket.example.com/ HTTP/1.1\nHost: websocket.example.com\nUpgrade: websocket\nConnection: Upgrade\nOrigin: http://example.com\nSec-WebSocket-Key:pAloKxsGSHtpIHrJdWLvzQ==\nSec-WebSocket-Version:13\n```\n\n- `Connection: Upgrade`告知服务端，浏览器想要升级协议\n- `Upgrade: websocket`：升级到websocket协议\n- `Sec-WebSocket-Key`浏览器的随机key，用于娇艳\n- `Sec-WebSocket-Version`：websocket版本\n\n服务端收到请求，就开始升级协议，返回101。服务端收到。响应大概是这样的\n\n```http\nHTTP/1.1 101 Switching Protocols\nUpgrade: websocket\nConnection: Upgrade\nSec-WebSocket-Accept: nRu4KAPUPjjWYrnzxDVeqOxCvlM=\n```\n\n`Sec-WebSocket-Accept`是根据响应头中的key进行加密而来的\n\n客户端收到这个响应后，会校验这个`accept`。就是以同样的方式加密key，看key和accept是否相同。\n\n到这里，websocket的连接就建立完成了。随后的请求都是以websocket协议发送。\n\n## 网络分层结构\n\n### TCP/IP 四层模型\n\n`TCP/IP`是互联网相关的各类协议族的总称\n`TCP/IP`具有分层结构，分为：应用层、传输层、网络层和数据链路层\n\n#### 应用层\n\n应用层决定了向用户提供应用服务时通信的活动。\n相关协议：`FTP`、`DNS`以及`HTTP`\n\n#### 传输层\n\n传输层提供处于网络连接中的两台计算机之间的数据传输\n相关协议：`TCP`和`UDP`\n\n#### 网络层\n\n网络层规定了数据包通过怎样的传输线路到达对方计算机\n相关协议：`IP`\n\n#### 数据链路层\n\n数据链路是用来处理连接网络的**硬件部分**\n例如：`NIC(网卡)`、`光纤`等物理可见部分\n\n### OSI七层模型\n\n- 应用层\n- 表示层：负责数据格式的转换\n- 会话层：负责建立和断开通信连接\n- 传输层\n- 网络层\n- 数据链路层\n- 物理层\n\n![网络分层结构](../../images/network/网络分层结构.webp)\n\n#### 数据链路层\n\n数据链路层主要有3种功能：\n\n- 封装成帧：将物理层上交的比特流封装成帧\n- 透明传输：封装成帧的时候，会给每个帧加上帧开始符（SOH）和帧结束符（EOT）。是指该层上传输的数据的内容、格式及编码没有限制，也没有必要解释信息结构的意义\n- 差错检测\n  - 比特差错\n  - 帧 丢失/重复/失序\n\n对于网络层，由于链路层的存在，而不需要关心物理层具体采用了那种传输介质和通信设备。\n\n> 网络层、数据链路层和物理层要关联理解。\n>\n> 假如A与B通信（在不同的网段中），实际上AB之间还有很多的物理设备（交换机、路由器）。物理设备之间是通过传输介质相连接，比如光纤、同轴电缆（这属于物理层）。\n>\n> 消息从A到B，需要经过一个个的网段，每个网段内都是通过mac地址来寻找下一个站点（数据链路层）。在公网上使用IP来寻找目的主机（网络层）\n\n#### 传输单元\n\n物理层的 数据传输单元是数据位（bit）\n数据链路层的数据传输单元是数据帧（frame）\n网络层的数据传输单元是数据包（packet）\n传输层的 数据传输单元是数据段（segment）\n其他更高层次的数据传输单元是数据（data）\n\n### TCP和UDP\n\n|              | UDP                                        | TCP                                    |\n| :----------- | :----------------------------------------- | -------------------------------------- |\n| 是否连接     | 无连接                                     | 面向连接                               |\n| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制       | 可靠传输，使用流量控制和拥塞控制       |\n| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信                       |\n| 传输方式     | 面向报文                                   | 面向字节流                             |\n| 首部开销     | 首部开销小，仅8字节                        | 首部最小20字节，最大60字节             |\n| 适用场景     | 适用于实时应用（IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 |\n\n","tags":["NetWork","HTTP"],"categories":["NetWork"]},{"title":"JavaScript原型污染","url":"/posts/54b3fc67.html","content":"\n## 原型污染\n\n> 原型污染就是，通过某种手段达到修改JavaScript原型的目的\n\n比如\n\n```javascript\nvar a = {}\n```\n\n定义了一个对象a，a有一个`constructor`属性指向a的构造器（`Object`）\n\n```javascript\na.constructor === Object // true\n```\n\nObject很常用，比如：`Object.prototype.toString`\n\n```javascript\nObject.prototype.toString.call(a) // \"[object Object]\" 获取类型\n```\n\n但是问题来了，通过a对象可以访问并修改Object对象\n\n```javascript\na.constructor.prototype.toString = () => console.log(\"attack\")\n\n// 再使用 toString\nObject.prototype.toString.call(a) // \"attack\"\n```\n\n这就发生了**原型污染**\n\n> lodash发生过一次严重的原型污染bug，场景是两个对象合并`merge(a, b)`， \n\n## 预防\n\n### 过滤危险属性\n\n两个对象合并，把`constructor`属性和`__proto__`这样的敏感过滤掉。\n\n### Object.freeze\n\n`Object.freeze`可以冻结一个对象，这个对象不能被修改。\n\n原理就是修改对象的`descriptor`中的`writable:false`\n\n```javascript\nObject.freeze(Object.prototype);\n\nObject.prototype.toString = \"attack\"\n\nconsoel.log(Object.prototype.toString) // ƒ toString() { [native code] }\n```\n\n### Object.create(null)\n\n创建一个原型对象为null的对象，这样就不存在污染原型的情况\n\n### Map代替对象字面量\n\n`map.set(\"__proto__\", xx)`并不会修改原型对象\n\n## 提醒\n\n深合并和深拷贝算法注意**原型污染**","tags":["JavaScript","Promise"],"categories":["JavaScript"]},{"title":"Webpack构建流程源码解析","url":"/posts/aef11e42.html","content":"\nwebpack的构建分为3个阶段：\n\n- 准备阶段：生成 `compiler`和`compilation`对象\n- 编译阶段：递归生成模块依赖图\n- 产出阶段：优化modules，生成chunks。最终输出文件\n\n本文讨论的是`webpack@5.34.0`\n\n## 准备阶段\n\n### 创建compiler\n\n对于每一个wepback的构建配置，都会创建一个`compiler`对象，记录着整个 Webpack 的生命周期\n\n```javascript\nimport webpack from \"webpack\"\n\nconst compiler = webpack(options)\n// webpack(options, () => {})\n```\n\n调用webpack函数会返回`compiler`对象，其内部大致逻辑如下：\n\n```javascript\nconst webpack = (options, callback) => {\n  // 1. 创建compiler\n  let compiler;\n  if (Array.isArray(options)) compiler = createMultiCompiler(options, options);\n  else compiler = createCompiler(options);\n  \n  // 2.\n  // 有callback参数就会自动执行compiler.run\n  // options中watch为true就会自动调用compiler.watch\n  \n  // 3. 返回compiler\n  return compiler\n}\n```\n\n> 示例代码并非是webpack中的源码。只是将源码中的核心逻辑提炼出来的伪代码，这样更方便理解webpack的主流程。下同。\n\n`createCompiler`和`createMultiCompiler`才是真正创建`compiler`的逻辑\n\n```javascript\nconst createCompiler = rawOptions => {\n\t// 1. normalize options\n  // 就是对传入的options做些初始化，添加默认参数之类的工作\n  \n  // 2. 他来了，创建compiler对象\n\tconst compiler = new Compiler(options.context);\n\tcompiler.options = options;\n  \n  // 2. 新建NodeEvniromentPlugin，这是wepback启用的第一个plugin\n  // 主要作用是 \n  // - 创建日志（方便webpack输出构建日志）\n  // - 设置compiler的文件系统 inputFileSystem...\n\tnew NodeEnvironmentPlugin({\n\t\tinfrastructureLogging: options.infrastructureLogging\n\t}).apply(compiler);\n  \n  // 3. 执行所有plugin\n  // - 函数plugin，执行函数\n  // - class plugin，执行其apply方法\n\tif (Array.isArray(options.plugins)) {\n\t\tfor (const plugin of options.plugins) {\n\t\t\tif (typeof plugin === \"function\") {\n\t\t\t\tplugin.call(compiler, compiler);\n\t\t\t} else {\n\t\t\t\tplugin.apply(compiler);\n\t\t\t}\n\t\t}\n\t}\n  \n  applyWebpackOptionsDefaults(options);\n\tcompiler.hooks.environment.call(); // hook\n\tcompiler.hooks.afterEnvironment.call(); // hook\n  \n  // 5.添加默认内置plugin\n  // 根据options的设置来配置响应内置plugin\n\tnew WebpackOptionsApply().process(options, compiler); \n\tcompiler.hooks.initialize.call();\n  \n  return compiler\n}\n\nconst createMultiCompiler = (childOptions, options) => {\n  // 给每一个option创建一个compiler\n\tconst compilers = childOptions.map(options => createCompiler(options));\n  // 创建MultiCompiler对象\n\tconst compiler = new MultiCompiler(compilers, options);\n\t\n  // ...\n  \n\treturn compiler;\n};\n```\n\n这里注意一点：在`compiler`对象创建后：\n\n1. 逐一执行`options.plugins`中所有的plugin。\n2. 根据options的内容，添加webpack内置的plugin。比如`EntryOptionPlugin`。针对不同环境(node electron browser)会设置不同的plugin。\n\n> webpack有大量的内置plugin，这都是在`WebpackOptionsApply`中的`process`来设置的。可以说webpack的所有功能(resolve optimization module解析...)都是由相应的plugin完成的。\n\n获得`compiler`对象后，下一步就时进行构建，这是通过`compiler.run`方法实现的。\n\n`run`方法主要做了2件事：\n\n- 执行compiler的hook `beforeRun` `run` `readRecords`。在创建compiler对象时会执行所有plugin。如果在这三个hook绑定的了事件，在此时会被执行。（这三个hook时串行执行的，代码是嵌套的）\n- 执行`compiler.compile`方法进行构建\n\n```javascript\nthis.hooks.beforeRun.callAsync(this, err => {\n  if (err) return finalCallback(err);\n\n  this.hooks.run.callAsync(this, err => {\n    if (err) return finalCallback(err);\n\n    this.readRecords(err => {\n      if (err) return finalCallback(err);\n\n      this.compile(onCompiled);\n    });\n  });\n});\n```\n\n### 创建Compilation\n\n`compilation`对象属于`compiler`。每一次构建，`compiler`都会创建一个`compilation`对象\n\n`compiler.compile`方法会真正地创建`compilation`对象\n\n```javascript\n// ./lib/Compiler.js\n// compile\nconst params = this.newCompilationParams();\nthis.hooks.beforeCompile.callAsync(params, err => {\n  if (err) return callback(err);\n\n  this.hooks.compile.call(params);\n\t\n  // 创建compilation对象\n  const compilation = this.newCompilation(params);\n\n  // ...\n  // 执行compiler的各种hook\n  // 以及执行compilation的 finish 和 seal方法\n});\n```\n\n代码很长，主要流程如下:\n\n1. `compiler.hooks.beforeCompile` \n2. 创建`compilation`对象。这里调用了`compiler.newCompilation`方法，该方法做了以下几件事\n   1. 创建`compilation`，会先清理上一次构建的`compilation`对象\n   2. `compiler.hooks.thisCompilation`\n   3. `compiler.hooks.compilation`\n3. `compiler.hooks.make` \n4.  `compiler.hooks.finishMake`\n5. `compilation.finish`\n6. `compilation.seal`\n7. `compiler.hooks.afterCompile`\n\n这些hooks都是串行执行的。`afterCompile`这个hook的执行表示一次构建已经完成。那么从compilation对象创建完成到`afterCompile`触发之前，包含了**编译阶段**和**产出阶段**\n\n## 编译阶段\n\n`compiler.hooks.make`这个hook被触发执行，就代表了编译开始。\n\n在`compiler`创建时(`new WebpackOptionsApply().process(options, compiler); `)，这里给compiler添加了许多并绑定了许多内置plugin。其中有一个`EntryOptionsPlugin`，他是用于解析入口(entry)配置。根据entry字段类型再选择不同的plugin\n\n- entry为function：`DynamicEntryPlugin`\n- entry不为function：`EntryPlugin`\n\n编译阶段的开始就是从`entry`文件开始解析`module`。\n\n以`EntryPlugin`为例，其apply方法：\n\n```javascript\ncompiler.hooks.make.tapAsync(\"EntryPlugin\", (compilation, callback) => {\n  const { entry, options, context } = this;\n\n  const dep = EntryPlugin.createDependency(entry, options);\n  compilation.addEntry(context, dep, options, err => {\n    callback(err);\n  });\n});\n```\n\n`EntryPlugin`在`compile.make`这个hook上注册了一个事件。`compiler.hooks.make`这个hook被触发执行时，hook上注册的事件全都会被执行。\n\n`EntryPlugin`会调用`compilation.addEntry`方法。\n\n接下看就看`compilation`的表演：\n\n1. addEntry添加入口文件\n2. 将资源文件转成`NormalModule`对象（简称module对象），一个文件(js css img)都是一个module\n3. 调用`module.build`方法\n4. 调用`runLoaders`，找到相应的loader处理该module\n5. 对于js module，会通过`acorn`转成`AST`。分析模块依赖关系，如果有依赖模块 调用`compilation.addEntry`（第1步）\n6. 最终获取所有module\n\n> 编译阶段是一个递归的过程\n>\n> 每一个module build完成都会触发`compilation.hooks.succeedModule`，并传入当前module对象\n\n## 产出阶段\n\n调用`compilation.seal`方法，封存文件就是处理文件生成chunk。\n\n### Seal\n\n首先触发`compilation.hooks.optimizeDependencies`这个hook上的所有事件。对module做一些优化操作（比如`tree-shaking`）\n\n根据入口生成chunk，有几个入口就会有几个chunk。\n\n然后就是递归分析chunk，如果有动态导入(`import()`)就会单独拆分出chunk\n\n> 这个过程还有一堆hooks，这些可以在这些hooks上做些优化操作。比如`optimizeModules`和`optimizeChunks`\n\n生成chunck的`hash`\n\n生成chunk的`sourceMap`\n\n### Assets\n\n`createChunkAssets`生成assets ，会将生成的Assets存放到`compilation.assets`数组中\n\n`emitAsset`将文件输出\n\n## Watch模式\n\n当调用`compiler.watch`，会启用watch模式。当文件发生更改是，会自动重新构建.\n\n```javascript\n{\n  watch(watchOptions, handler) {\n\t\t// ...\n\t\tthis.watching = new Watching(this, watchOptions, handler);\n    \n\t\treturn this.watching;\n\t}\n}\n```\n\nwatch方法创建了一个`Watching`实例。\n\n```javascript\nclass Watch {\n  contstructor() {\n    // ...\n    this._invalidate()\n  }\n  _invalidate() {\n    // 防止重复构建\n    this._go()\n  }\n  _go() {\n    // 构建逻辑\n    compiler.compile() // 调用compiler的compile方法进行构建\n  }\n  _done() {\n    // 构建完成了\n    // 获取构建完后的依赖\n    this.watch() // 监听这些依赖\n  }\n  watch() {\n    // 监听文件变化\n    this.compiler.watchFileSystem.watch()\n    \n    // 文件发生变化 监听的回调会被调用\n    this._invalidate() // 进行下一轮构建\n  }\n}\n```\n\n监听文件是通过`this.compiler.watchFileSystem.watch()`方法来实现的。这个`watchFileSystem`是在创建`compiler`对象时，初始化的。\n\n创建`compiler`时，执行了`NodeEvniromentPlugin`。这个plugin会设置文件系统。将`watchFleSystem`设置成`NodeWatchFileSystem`，而其内部又会创建一个`watchpack`对象来监听文件变化。\n\n```javascript\nclass NodeEnvironmentPlugin {\n\tapply(compiler) {\n\t\t//...\n\t\tcompiler.inputFileSystem = new CachedInputFileSystem(fs, 60000);\n\t\t// ...\n\t\tcompiler.watchFileSystem = new NodeWatchFileSystem(\n\t\t\tcompiler.inputFileSystem\n\t\t);\n    // ...\n\t}\n}\n\n```\n\n> 值得一提的是，当文件短时间变化多次，会触发多次构建吗？\n>\n> 其实是不会的，`watchpack`添加了防抖机制。只会触发最后一次。\n\n## 总结\n\n一张图总结流程\n\n![webpack构建流程](../../images/framework/webpack构建流程.svg)","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"vue2-生命周期","url":"/posts/bdeefbce.html","content":"\n## Vue2生命周期图\n\n![生命周期](../../images/Vue/vue2从创建到渲染.svg)\n\n## 组件创建到页面渲染\n\n### 初始化\n\n`new Vue()`的执行，会创建一个组件实例（根组件）`vm`，然后进行各种初始化工作\n\n1. 合并 options，也就是初始化组件的options选项\n2. 初始化vm（组件实例）上的各个属性\n3. 初始化绑定在当前组件上的listener(v-on)\n4. 初始化render函数，在vm上绑定createElement方法\n5. **`beforeCreated`**钩子调用\n6. 将inject定义为响应式\n7. .初始化, 定义响应式数据 `props`  `methods` `data` ` computed` `watch`\n8. 初始化vm._provide属性\n9. **`creted`**钩子调用\n\n### 渲染\n\n如果`new Vue`传入了`el`属性，就会自动调用`vm.$mount`方法，渲染实例\n\n1. 调用`mountComponent`\n2. 新建Watcher，传入`updateComponent`逻辑\n3. Watcher调用`updateComponent`逻辑\n4. 进入`patch`逻辑\n\n## 响应式\n\nvue2的响应式涉及到三种角色——`reactiveObj(响应式对象)` `Watcher`  `Dep`\n\n- 响应式对象通过`Object.defineProperty`拦截getter和setter\n- Watcher用于触发组件更新\n- 每个响应式对象都有一个dep对象，它有一个subs的Watcher数组，用于记录依赖该响应式对象的所有watcher\n\n当组件开始渲染时：\n\n- 会创建一个`Watcher`对象。将组件更新的逻辑（`updateComponent`）记录到Watcher\n- 将Dep.target设置为 创建的 `Watcher`对象\n\n随即执行render方法，会触发响应式对象的getter。将`Dep.target`添加到`dep.subs`中，即依赖收集\n\n在修改响应式对象，会触发setter。\n\n- 执行`dep.notify`，触发`dpe.subs`中所有`watcher`的`update`方法\n- `watcher.update()`会触发`updateComponent`，从而使得组件更新","tags":["vue"],"categories":["源码"]},{"title":"Webpack之SplitChunks","url":"/posts/110bf707.html","content":"\n## SplitChunks\n\n`splitChunks`可以指定`webpack`打包的拆分规则。\n\n```javascript\nmodule.exports = {\n  // ...\n  optimization: {\n    splitChunks: {\n      chunks: \"async\", // 三选一： \"initial\" | \"all\" | \"async\" (默认)\n      minSize: 30000, // 最小尺寸，30K，development 下是10k，越大那么单个文件越大，chunk 数就会变少（针对于提取公共 chunk的时候，不管再大也不会把动态加载的模块合并到初始化模块中）当这个值很大的时候就不会做公共部分的抽取了\n      maxSize: 0, // 文件的最大尺寸，0为不限制，优先级：maxInitialRequest/maxAsyncRequests < maxSize < minSize\n      minChunks: 1, // 默认1，被提取的一个模块至少需要在几个 chunk 中被引用，这个值越大，抽取出来的文件就越小\n      maxAsyncRequests: 5, // 在做一次按需加载的时候最多有多少个异步请求，为 1 的时候就不会抽取公共 chunk 了\n      maxInitialRequests: 3, // 针对一个 entry 做初始化模块分隔的时候的最大文件数，优先级高于 cacheGroup，所以为 1 的时候就不会抽取 initial common 了\n      automaticNameDelimiter: \"~\", // 打包文件名分隔符\n      name: true, // 拆分出来文件的名字，默认为 true，表示自动生成文件名，如果设置为固定的字符串那么所有的 chunk 都会被合并成一个\n      cacheGroups: {\n        vendors: {\n          test: /[\\\\/]node_modules[\\\\/]/, // 正则规则，如果符合就提取 chunk\n          priority: -10, // 缓存组优先级，当一个模块可能属于多个 chunkGroup，这里是优先级\n        },\n        default: {\n          minChunks: 2,\n          priority: -20, // 优先级\n          reuseExistingChunk: true, // 如果该chunk包含的modules都已经另一个被分割的chunk中存在，那么直接引用已存在的chunk，不会再重新产生一个\n        },\n      },\n    },\n  },\n};\n```\n\n使用动态导入`import()`或者`requre.ensure()`，就会根据\n\n## SplitChunks参数\n\n### chunks\n\n有三个值——`async` `all` `initial`\n\n#### async(默认)\n\n只会将异步模块（`import()`导入的模块）提出出来\n\n#### initial\n\n提取同步模块和异步模块。如果一个模块在moduleA中是同步导入，在moduleB中是异步导入。那么由于导入方式不同，这个模块会被抽离出不同的文件。\n\n#### all\n\n提取同步模块和异步模块，无论是同步import还是异步import。都会抽离到一个文件中。`all`会最大程度复用文件。\n\n### maxInitialRequests和maxAsyncRequests\n\n浏览器对相同域名的并法请求是有限制的。比如chrome 限制6个相同域名的请求。如果同一时间发送10个请求。则另外4个就会被阻塞\n\n所以，`splitChunks`把文件拆得太碎，反而会影响加载时间。\n\n`maxInitialRequests`设置为`3`，表示浏览器初始最多发送3个请求。它会将入口文件拆成<3份。\n\n`maxAsyncRequests`是用来限制异步模块并行最大请求数的。\n\n> 前者是限定入口的文件的拆分，后者是限定异步模块的拆分\n\n### minSize和maxSize\n\n`minSize`：满足拆分的最小体积（单位字节）。大于这个大小并满足拆分规则就会被拆分\n\n`maxSize`：默认为0表示不作限制。如果非0。待拆分模块大小大于`maxSize`时就会拆分\n\n> 规则优先级：maxInitialRequest/maxAsyncRequests < maxSize < minSize\n\n### cacheGroups\n\n这是`splitChunks`最重要的部分。它定义了拆分规则。\n\n```javascript\ncacheGroups: {\n  vendors: {\n    test: /[\\\\/]node_modules[\\\\/]/, // 正则规则，如果符合就提取 chunk\n    priority: -10, // 缓存组优先级，当一个模块可能属于多个 chunkGroup，这里是优先级\n  },\n}\n```\n\n`test`表示匹配规则，可以是一个正则。`/[\\\\/]node_modules[\\\\/]`表示匹配`/node_modules/`或着`\\node_modules\\`\n\n`priority`：缓存组优先级，当一个模块可能属于多个 chunkGroup时，取优先级高的\n\n`reuseExistingChunk`: true表示复用其他chunk内已拥有的模块 当chunks引用了已经存在的被抽离的chunks时不会新创建一个chunk而是复用chunk。\n\n其它属性：`chunks` `maxInitialRequests` `maxAsyncRequests` `minSize`.......\n\n> cacheGroups下找不到`chunks`等属性，就会去splitChunks中的配置。\n\n","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"web-vitals源码解读","url":"/posts/473044000000.html","content":"\n## web-vitals简介\n\n[web-vitals](https://www.npmjs.com/package/web-vitals#overview)是`google`开源的一个测量web性能指标的工具。体积才**1KB**，它可以用来测量`CLS`、`FID`、`LCP`、`FCP`、`TTFB`。\n\n可通过npm来安装`npm install web-vitals`\n\n使用也十分简单\n\n```typescript\nimport {getLCP, getFID, getCLS} from 'web-vitals';\n\ngetCLS(console.log);\ngetFID(console.log);\ngetLCP(console.log);\n```\n\n## 源码结构\n\n`web-vitals`整个项目不是很复杂，目录结构如下\n\n```text\n├─.git\n├─docs\n├─src # 源码\n├─test # 测试代码\n├─.eslintrc \n├─.gitignore\n├─base.d.ts\n├─base.js\n├─CHANGELOG.md\n├─LICENSE # 开源协议\n├─package-lock.json\n├─package.json\n├─README.md\n├─rollup.config.js # rollup构建配置\n├─tsconfig.json # ts配置\n├─wdio.conf.js # e2e测试配置\n```\n\n## 代码规范\n\n### Eslint\n\n`web-vitals`通过配置eslint来约定代码规范。通常，`eslint`配置文件位于根目录下。这样对于整个项目都通用一套`eslint`配置。这往往是不满足需求的。可能src目录需要一套eslint配置，而test目录有需要另一套eslint配置。`web-vitals`是通过`eslintrc`下的**overrides**字段配置的\n\n```json\n{\n  \"parser\": \"babel-eslint\",\n  \"env\": {\n    \"browser\": true,\n    \"es6\": true,\n    \"node\": true,\n    \"mocha\": true\n  },\n  \"parserOptions\": {\n    \"sourceType\": \"module\"\n  },\n  \"overrides\": [\n    {\n      \"files\": \"wdio.conf.js\",\n      \"extends\": [\n        \"eslint:recommended\", \"google\"\n      ],\n      \"rules\": {\n        \"max-len\": \"off\"\n      }\n    },\n    {\n      \"files\": [\"test/e2e/*.js\"],\n      \"globals\": {\n        \"$\": false,\n        \"browser\": false\n      },\n      \"extends\": [\n        \"eslint:recommended\", \"google\"\n      ],\n      \"rules\": {\n        \"no-invalid-this\": \"off\",\n        \"max-len\": [2, {\n          \"ignorePattern\": \"^\\\\s*import|= require\\\\(|^\\\\s*it\\\\(|^\\\\s*describe\\\\(\",\n          \"ignoreUrls\": true\n        }],\n      }\n    },\n    {\n      \"files\": \"src/**/*.ts\",\n      \"parser\": \"@typescript-eslint/parser\",\n      \"extends\": [\n        \"plugin:@typescript-eslint/recommended\"\n      ],\n      \"rules\": {\n        \"@typescript-eslint/no-non-null-assertion\": \"off\",\n        \"@typescript-eslint/no-use-before-define\": \"off\",\n        \"@typescript-eslint/explicit-function-return-type\": \"off\",\n        \"@typescript-eslint/explicit-module-boundary-types\": \"off\",\n        \"@typescript-eslint/ban-ts-comment\": \"off\",\n        \"@typescript-eslint/camelcase\": \"off\",\n        \"node/no-missing-import\": \"off\",\n        \"node/no-unsupported-features/es-syntax\": \"off\",\n        \"node/no-missing-require\": \"off\",\n        \"node/shebang\": \"off\",\n        \"no-dupe-class-members\": \"off\"\n      },\n      \"parserOptions\": {\n        \"ecmaVersion\": 2018,\n        \"sourceType\": \"module\"\n      }\n    }\n  ]\n}\n```\n\n`overrides`字段对应的值是一个数组，该数组中的每个元素都是一条新的eslint规则，并覆盖全局配置\n\n### husky\n\n[`husky`](https://typicode.github.io/husky/)是一个`git`钩子工具，`package.json`文件下有个`husky`字段\n\n```json\n{\n    \"scripts\": {\n        \"lint\": \"eslint \\\"*.js\\\" \\\"src/**/*.ts\\\" \\\"test/**/*.js\\\"\",\n        \"lint:fix\": \"eslint --fix \\\"*.js\\\" \\\"src/**/*.ts\\\" \\\"test/**/*.js\\\"\",\n    },\n    \"husky\": {\n        \"hooks\": {\n            \"pre-commit\": \"npm run lint\"\n        }\n    },\n}\n```\n\n它的作用是，在每次`git commit`时，触发钩子并执行`npm run lint`，也就是进行Eslint检查。如果没有通过eslint，就会commit失败。\n\n### @rollup/plugin-eslint\n\n`web-vitals`的`rollup`并没有配置[@rollup/plugin-eslint](https://github.com/rollup/plugins/tree/master/packages/eslint)。如果加上这个插件，会在构建时进行eslint检查，如果没有通过eslint，就会构建失败并给出相应的修复提示。\n\n## 构建配置\n\n`web-vitals`是通过`rollup`进行构建打包的。其配置也十分简单\n\n```javascript\n// rollup.config.js\nimport replace from '@rollup/plugin-replace';\nimport {terser} from 'rollup-plugin-terser';\nimport babel from 'rollup-plugin-babel';\n\nconst configurePlugins = ({module, polyfill = false}) => {\n  return [\n    babel({\n      presets: [['@babel/preset-env', {\n        targets: {\n          browsers: ['ie 11'],\n        },\n      }]],\n    }),\n    terser({\n      module,\n      mangle: true,\n      compress: true,\n    }),\n    replace({\n      'self.__WEB_VITALS_POLYFILL__': polyfill,\n    })\n  ]\n}\n\nconst configs = [\n  {\n    input: 'dist/modules/index.js',\n    output: {\n      format: 'esm',\n      file: './dist/web-vitals.js',\n    },\n    plugins: configurePlugins({module: true, polyfill: false}),\n  },\n  {\n    input: 'dist/modules/index.js',\n    output: {\n      format: 'umd',\n      file: `./dist/web-vitals.umd.js`,\n      name: 'webVitals',\n    },\n    plugins: configurePlugins({module: false, polyfill: false}),\n  },\n  {\n    input: 'dist/modules/index.js',\n    output: {\n      format: 'esm',\n      file: './dist/web-vitals.base.js',\n    },\n    plugins: configurePlugins({module: true, polyfill: true}),\n  },\n  {\n    input: 'dist/modules/index.js',\n    output: {\n      format: 'umd',\n      file: `./dist/web-vitals.base.umd.js`,\n      name: 'webVitals',\n      extend: true,\n    },\n    plugins: configurePlugins({module: false, polyfill: true}),\n  },\n  {\n    input: 'dist/modules/polyfill.js',\n    output: {\n      format: 'iife',\n      file: './dist/polyfill.js',\n      name: 'webVitals',\n      strict: false,\n    },\n    plugins: configurePlugins({module: false}),\n  },\n];\n\nexport default configs;\n\n```\n\n### 不同的产出文件\n\n导出的`config`是一个数组。每个数组元素是一份rollup配置\n\n| 产出文件名             | module | polyfill |\n| ---------------------- | ------ | -------- |\n| web-vitals.js          | esm    | 不含     |\n| web-vitals.umd.js      | umd    | 不含     |\n| web-vitals.base.js     | esm    | 含       |\n| web-vitals.base.umd.js | umd    | 含       |\n| polyfill.js            | iife   | -        |\n\n- `esm`：即 ES Module，在代码中直接`import`使用\n\n- `iife`：立即执行函数，就是`(function() {})(window)`这种形式\n\n- `umd`：本质上也是iife，但是它将待执行的函数作为iife的参数传入\n\n  ```javascript\n  var a = 2;\n  (function IIFE( def ) {\n    def( window );\n  })(function def( global ) {\n    var a = 3;\n    console.log( a ); // 3 \n    console.log( global.a ); // 2\n  });\n  ```\n\n`iife`和`umd`都是直接在浏览器中使用了\n\n###  tree-shaking\n\nrolup使用了`@rollup/plugin-replace`，用于替换一些常量\n\n```javascript\nreplace({\n    'self.__WEB_VITALS_POLYFILL__': polyfill,\n})\n```\n\n这会将代码中所有出现的`self.__WEB_VITALS_POLYFILL__`的地方替换成`polyfill`变量的对应的值（`true`或`false`）。在代码中出现大量的`self.__WEB_VITALS_POLYFILL__`\n\n```typescript\n// src/lib/getFirstHidden.ts \n\n// function getFirstHidden\nif (self.__WEB_VITALS_POLYFILL__) {\n    firstHiddenTime = self.webVitals.firstHiddenTime;\n    if (firstHiddenTime === Infinity) {\n        trackChanges();\n    }\n} else {\n    firstHiddenTime = initHiddenTime();\n    trackChanges();\n}\n```\n\n如果`self.__WEB_VITALS_POLYFILL__`是true，rollup在构建时，就会吧else的逻辑删掉。反之，会把if的逻辑给删掉。这样就实现了Tree Shaking——删除多余代码。\n\n### TypeScript\n\n`web-vitals`的源码是使用TS编写的，最终需要生成js文件。\n\n`web-vitals`的构建过程：\n\n- 先通过tsc生成**js文件**和**类型声明文件**。\n- 再通过**rollup**进行对**js文件**打包构建\n\n类型声明需要再`package.json`中`typings`字段指定声明文件的位置\n\n```json\n{\n    \"main\": \"dist/web-vitals.umd.js\",\n    \"module\": \"dist/web-vitals.js\",\n    \"typings\": \"dist/modules/index.d.ts\",\n    \"files\": [\n        \"base.js\",\n        \"base.d.ts\",\n        \"dist\",\n        \"src\"\n    ],\n}\n```\n\n- `main`:  定义了 npm 包的入口文件，browser 环境和 node 环境均可使用\n- `module`:  定义 npm 包的 ESM 规范的入口文件，browser 环境和 node 环境均可使用\n- 好有个`browser` : 定义 npm 包在 browser 环境下的入口文件\n\n- `files`：当`npm publish`是，指定需要上传的文件。\n\n## 开源协议\n\n`web-vitals`采用`Apache-2.0`开源协议。该协议允许开发者修改代码，并且商业发布。但是对于改动部分必须提供一份声明。\n\n## 测试\n\n`web-vitals`的测试需要真实的浏览器环境，即需要**端到端测试（e2e test）**。项目通过[wdio（webDriver.IO）]([Getting Started | WebdriverIO](https://webdriver.io/docs/gettingstarted))来实现的。\n\n```json\n{\n    \"scripts\": {\n        \"test\": \"npm-run-all build -p -r test:*\",\n        \"test:e2e\": \"wdio wdio.conf.js\",\n        \"test:server\": \"node test/server.js\",\n    }\n}\n```\n\n### 测试流程\n\n当执行`npm run test`时\n\n- 先构建打包项目\n- 启动一个HTTP服务，用于处理浏览器的资源请求\n- 启动wdio测试\n\n当执行test/e2e目录下的测试用例时，例如`getLCP-test.js`\n\n```javascript\nit('reports the correct value on hidden (reportAllChanges === false)', async function() {\n    // 浏览器不支持就跳过这条用例\n    if (!browserSupportsLCP) this.skip();\n\t\n    // 打开 /test/lcp这个网页，这是测试网页\n    await browser.url('/test/lcp');\n\n    // 等待所有图片加载完成\n    await imagesPainted();\n\n    // 跳转到空白页，触发上一个页面的 hide状态\n    await browser.url('about:blank');\n\t\n    // 检测是beacon.log中是否有数据，参数为数据条数\n    await beaconCountIs(1);\n    \n    // 对 beacon数据进行断言\n    assertStandardReportsAreCorrect(await getBeacons());\n});\n```\n\n当输入`browser.url('/test/lcp')`其实访问的地址是`http://localhost:9090/test/lcp`(在wdio.config.js中配置的)。这条请求会发送给本地的HTTP服务上。\n\n```javascript\n// src/test/server.js\n\napp.get('/test/:view', function(req, res) {\n  const data = {\n    ...req.query,\n    modulePath: `/dist/web-vitals${\n        req.query.polyfill ? `.base` : ``}.js`,\n    webVitalsPolyfill: fs.readFileSync('./dist/polyfill.js', 'utf-8'),\n  }\n  res.send(nunjucks.render(`${req.params.view}.njk`, data));\n});\n```\n\n`nunjucks`是一个模板引擎。data数据会插入到模板引擎内。当访问`/test/lcp`时，会将解析`lcp.njk`并将html返回给浏览器。\n\n```html\n<!-- src/test/view/lcp.njk -->\n{% extends 'layout.njk' %}\n\n{% block content %}\n  <h1>LCP Test</h1>\n  <p>\n    {% if not imgDelay %}\n      {% set imgDelay = 500 %}\n    {% endif %}\n    <img {% if imgHidden %}hidden{% endif %} src=\"/test/img/square.png?delay={{ imgDelay }}\">\n  </p>\n  <p>Text below the image</p>\n\n  <p><a id=\"navigate-away\" href=\"https://example.com\">Navigate away</a></p>\n\n  <!-- Include a tall element to ensure scrolling is possible. -->\n  <div style=\"height: 100vh\"></div>\n\n  <footer>Text below the full-height element.</footer>\n\n  <script type=\"module\">\n    import {getLCP} from '{{ modulePath }}';\n\n    getLCP((lcp) => {\n      // Log for easier manual testing.\n      console.log(lcp);\n\n      // Elements can't be serialized, so we convert first.\n      lcp = {\n        ...lcp,\n        entries: lcp.entries.map((e) => ({\n          element: e.element.nodeName.toLowerCase(),\n          size: e.size,\n          startTime: e.startTime,\n        })),\n      };\n\n      // 发送统计数据\n      navigator.sendBeacon(`/collect`, JSON.stringify(lcp));\n    }, self.__reportAllChanges);\n  </script>\n{% endblock %}\n```\n\nhtml中的最后一步调用了` navigator.sendBeacon(\"/collect\", JSON.stringify(lcp));`，`/collect`这个请求也是发到本地的HTTP服务。服务端会将数据写入到`src/test/beacons.log`中。\n\n### sendBeacon\n\n`navigator.sendBeacon`是专门用来发送异步统计数据的API。\n\n有一种需求：当页面跳转或关闭时，我们需要将当前页面的一些统计数据发送到服务端。往往这些数据不能提前发送。如果使用异步`XMLHttpRequest`的话，浏览器可能会忽略这个请求。如果使用同步`XMLHttpRequest`的话，会影响下个页面的加载速度。\n\n使用`navigator.sendBeacon`，会发送一个异步请求，并且不会被浏览器忽略。\n\n```javascript\ndocument.addEventListener('visibilitychange', function logData() {\n  if (document.visibilityState === 'hidden') {\n    navigator.sendBeacon('/log', analyticsData);\n  }\n});\n```\n\n> 判断页面关闭与否，建议使用`visibilitychange`事件\n>\n> safari需要使用`pagehide`事件\n\n## 代码实现\n\n### PerformanceObserver\n\n性能观察者(PerformanceObserver)用于获取性能数据。\n\n`new PerformanceObserver(callback);` 接受一个callback作为参数\n\n`observer`方法用于注册性能条目类型，type指所要观测的性能条目类型，取值情况通过`PerformanceObserver.supportedEntryTypes`属性查看。\n\n`[\"element\", \"event\", \"first-input\", \"largest-contentful-paint\", \"layout-shift\", \"longtask\", \"mark\", \"measure\", \"navigation\", \"paint\", \"resource\"]`\n\n其中:\n\n- `largest-contentful-paint`：LCP\n- `layout-shift`：CLS\n- `first-input`：FID\n\n```javascript\n// 获取lcp时间\nconst callback = (entryList) => {\n  for (const entry of entryList.getEntries()) {\n    console.log('LCP candidate:', entry.startTime, entry);\n  }\n}\n\nconst observer = new PerformanceObserver(callback)\n\nobserver.observe({type: 'largest-contentful-paint', buffered: true});\n```\n\n### LCP、FID、CLS\n\n`web-vitals`中的`LCP`、`FID`和`CLS`都是通过`PerformanceObserver`来实现的。\n\n以LCP为例：\n\n`getLCP`函数位于`src/getLCP.ts`文件中。\n\n```typescript\nexport const getLCP = (onReport: ReportHandler, reportAllChanges?: boolean) => {\n  \n  // 1 获取 第一次页面处于hidden状态的时间\n  const firstHidden = getFirstHidden();\n  let metric = initMetric('LCP');\n  let report: ReturnType<typeof bindReporter>;\n\t\n                         \n  // 2. PerformanceObserver\n  const entryHandler = (entry: PerformanceEntry) => {\n    const value = entry.startTime;\n\n    // 过滤掉切换pagehide后的 性能数据\n    if (value < firstHidden.timeStamp) {\n      metric.value = value;\n      metric.entries.push(entry);\n    }\n\n    report();\n  };\n\n  const po = observe('largest-contentful-paint', entryHandler);\n\n  if (po) {\n    report = bindReporter(onReport, metric, reportAllChanges);\n\n    const stopListening = () => {\n      if (!finalMetrics.has(metric)) {\n        po.takeRecords().map(entryHandler as PerformanceEntryHandler);\n        po.disconnect();\n        finalMetrics.add(metric);\n        report();\n      }\n    }\n\n    // 当用户点击页面时，立即触发 report\n    ['keydown', 'click'].forEach((type) => {\n      addEventListener(type, stopListening, {once: true, capture: true});\n    });\n\n    onHidden(stopListening, true);\n\t\t\n    // 当pageshow时，报告metric\n    onBFCacheRestore((event) => {\n      metric = initMetric('LCP');\n      report = bindReporter(onReport, metric, reportAllChanges);\n      requestAnimationFrame(() => {\n        requestAnimationFrame(() => {\n          metric.value = performance.now() - event.timeStamp;\n          finalMetrics.add(metric);\n          report();\n        });\n      });\n    });\n  }\n};\n```\n\n### TTFB\n\nTTFB时间直接取`performance.responseStart`","tags":["web-vitals"],"categories":["源码"]},{"title":"知识串联：JavaScript执行机制","url":"/posts/1b8392cc.html","content":"\n这篇文章将梳理JavaScript的执行机制，并且串联众多知识点：作用域、作用域链、闭包、变量提升、函数提升、`this`指向\n\n## JavaScript 执行的阶段\n\n在 V8 引擎中 JavaScript 代码的运行过程主要分成三个阶段。\n\n- 语法分析阶段。 该阶段会对代码进行语法分析，检查是否有语法错误（SyntaxError），如果发现语法错误，会在控制台抛出异常并终止执行。\n\n- 编译阶段。 该阶段会进行全局执行上下文（Execution Context）的创建，这个过程也被称为预解析阶段。\n\n- 执行阶段。 将编译阶段中创建的执行上下文压入执行栈，并成为正在运行的执行上下文，代码执行结束后，将其出栈。在执行过程中，又可能会产生新的执行上下文（比如调用了函数）。再将新的执行上下文入栈，执行完出栈\n\n## 三种执行上下文\n\n执行上下文是对执行环境的抽象，它代表JavaScript执行时当前的执行环境，用于。JavaScript中一共有三种执行上下文\n\n- 全局执行上下文：有且仅有一个\n- 函数执行上下文\n- `eval`执行上下文：不讨论\n\n如下代码:\n\n```javascript\nconst name = \"zxfan\"\n\nfunction sayName() {\n  console.log(name)\n}\n\nsayName()\n```\n\n编译时，首先创建一个全局执行上下文`GlobalContext`，并将其放入执行栈\n\n执行时，执行栈栈顶的执行上下文为当前正在执行的执行上下文，当执行到`sayName`函数时，又会创建一个函数执行上下文`FunctionContext`，并将其入栈。当函数执行上下文执行完毕，出栈。全局上下文也执行完毕，出栈。\n\n> 全局执行上下文是编译时被创建的\n>\n> 函数执行上下文是执行时被创建的\n\n## 执行栈\n\n执行栈是用来存放执行上下文的。\n\n以函数为例，函数执行的时候创建函数执行上下文，并将其入栈，当函数执行完成后再出栈。全局执行上下文第一个入栈最后一个出栈。\n\n## 执行上下文做了什么？\n\n执行上下文被创建时，做了三件事：\n\n- 确定`this`的指向\n- 创建环境记录\n  - 创建词法环境(LexicalEnvironment)\n  - 创建变量环境(VariableEnvironment)\n\n### this的指向\n\nthis的取值取决于具体的场景：\n\n- 全局执行上下文中：this取全局对象（浏览器是window对象，nodejs是global对象）\n- 函数执行上下文中：\n  - 构造函数中：指向创建的实例对象\n  - 对象方法：this指向这个对象\n  - 箭头函数：外层执行上下文的this\n  - `call` `apply` `bind`：可以指定this\n  - 其它情况：this为undefined（严格模式下）\n\n### 环境记录(Environment Record)\n\n基于JavaScript这种嵌套的代码结构，环境记录用来记录特定的**标识符**和代码中所定义的**变量和函数**之间的关系。\n\n换句话说，环境记录就是记录一堆标识符，这些标识符指向具体代码中的数据。\n\n```java\nconst name = \"zxfan\"\nvar age = 18\n\nfunction sayName() {\n  console.log(name)\n}\n```\n\n其环境记录\n\n```json\nEnvironment Record {\n\tname: <uninitialized> // 代码执行完后 name: <\"zxfan\">\n  age: <18> // var 具有变量提升，所以这里不是uninitialized\n\tsayName: <function> // function有函数提升，所以这里不是uninitialized\n}\n```\n\n环境记录分类三种类型（声明环境记录又分为两种）：\n\n- 声明环境记录： 包含`var` `let` `const` `class` `function`  `import`声明的变量的标识符。\n  - 函数环境记录： `function`\n  - 模块环境记录：`import`\n- 对象环境记录：为对象创建一个环境记录，它有一个**关联的绑定对象[[BindingObject]]**。比如全局执行上下文会创建一个对象环境记录，其关联绑定的对象是全局对象（window或global）\n- 全局环境记录：最外层环境记录，包含声明环境记录和对象环境记录\n\n**词法环境和变量环境本质上都是环境记录**，这么做是为了单独区分`var`\n\n#### 词法环境（作用域）\n\n词法环境可以理解为**作用域**，从词法环境的角度能更好地理解作用域。词法环境有两个成员：\n\n- 环境记录（Environment Record）：用于记录自身词法环境中的变量对象。\n- 外部词法环境引用（Outer Lexical Environment）：记录外层词法环境的引用。\n\n##### 环境记录\n\n词法环境的环境记录，会保存**函数声明**和**变量声明**(`let`和`const`声明的变量)，如\n\n```javascript\nfunction sayFullName() {\n  const firstName = \"Donald\"\n  const lastName = \"Trump\"\n  console.log(firstName, lastName)\n}\nsayFullName()\n```\n\n`sayFullNmae`的词法环境\n\n```json\nLexicalEnciroment {\n\tEnviroment Record {\n\t\tfirstName: <uninitialize>\n\t\tlastName: <uninitialize>\n\t\targuments: <{}>\n\t}\n\touter: <Global or outer function environment reference>  \n}\n```\n\n注意：`let`和`const`定义的变量初始都是`uninitialize`。当代码执行后才会赋值。\n\n##### 外部词法环境引用（作用域链）\n\n任何一个词法环境（全局词法环境除外）都有一个指向外层词法环境的引用。这构成了词法环境链即**作用域链**。当访问一个变量时，先会在当前词法环境中寻找，找不到就去外部词法环境中寻找。就这样，一直找到全局词法环境。\n\n#### 变量环境\n\n变量环境和词法环境的结构一致，区别是其环境记录所记录的数据不同。\n\n语法环境的环境记录，是记录`var`声明。\n\n\n\n> 环境记录 词法环境 作用域 其实都是一个概念，这么区分是为了针对不同场景方便理解。\n\n## 常见问题\n\n### 解释作用域与作用域链\n\nJS的作用域时词法作用域，有词法结构决定。js代码编译时创建全局执行上下文，执行上下文又会创建当前环境的环境记录（分为词法环境和变量环境）。当执行js代码时（比如调用一个函数），又会创建函数执行上下文。随之函数环境的环境就又会创建。\n\n每个环境记录都有个outer引用，指向外层环境记录。外层再指向外层，一直到最外层。这便构成了作用域链。\n\n### 闭包\n\n解释闭包就是解释**作用域**和**垃圾回收机制**\n\n[闭包](https://en.wikipedia.org/wiki/Closure_(computer_programming)) 是指内部函数总是可以访问其所在的外部函数中声明的变量和参数，即使在其外部函数被返回（寿命终结）了之后。\n\n正常情况下，代码执行完毕，其相应的执行上下文出栈，相应的内存空间会被回收。然而，闭包情况下，内层词法环境（作用域）可以访问到，所以外层词法环境不会被回收，仍然可以访问到，但仅限在内层词法环境访问。\n\n### 变量提升和函数提升\n\n环境记录创建时，会记录当前环境下所有变量，遇到：\n\n- var变量声明：此时会给变量分配内存，并将其初始化为undefined（该过程只进行定义声明，执行阶段才执行赋值语句）。\n\n- 函数声明：此时会在内存里创建函数对象，并且直接初始化为该函数对象。\n\n### this指向\n\nthis指向是在执行上下文创建时才确定的，具体指向谁取决于具体场景。上文已讨论。\n\n","tags":["JavaScript"],"categories":["JavaScript"]},{"title":"XSS攻击与防御","url":"/posts/df6ed6ff.html","content":"\n`xss(cross-site script)`指**网站对用户输入数据未做有效过滤，攻击者可以将恶意脚本注入网站页面中，达到执行恶意代码的目的**\n\n攻击者只需要诱使受害者打开特定的网址，就可以在受害者的浏览器中执行被注入的恶意代码，从而窃取用户身份，执行一些敏感操作\n\n## XSS攻击类型\n\nXSS攻击可以分成三种类型：\n\n- 反射型XSS\n\n- 存储型XSS\n- DOM型XSS\n\n### 反射型\n\n反射型指的是**将攻击代码存放在URL参数中**，例如`http://localhost/home?name=<script>alert(1)</script>`。\n\n如果服务端直接去url中的name参数，并当作html返回给客户端。攻击代码就会执行。\n\n### 存储型\n\n存储型是指**将恶意代码存储到服务器上**，只要诱使受害者访问被插入恶意代码的页面即可触发。存储型 XSS 经常出现在一些可以发表评论的地方，如帖子、博客\n\n当用户在评论中输入一段攻击代码，网站又没有过滤。这段代码会存储到数据库中。当其它用户访问评论时，这段攻击代码被当作html内容输出就会引发攻击代码的执行\n\n### DOM型\n\n**前两种都是服务端的XSS，DOM型是客户端的XSS**\n\nJavaScript 能够操作DOM。通过JavaScript控制获取**源数据（内含攻击代码）**，又未进行处理。直接**当作HTML输出（innerHTML）或脚本执行**\n\n就会发生DOM型XSS攻击\n\n常见的源数据有：`document` `location` `localStorage` `sessionStorage`等\n\n常见的触发攻击的点：`document.write` `eval` `innerHTML` `a的href属性`等\n\n## XSS常见的攻击方式\n\n### 窃取cookie\n\n许多网站都使用`cookie`来存放用户登陆信息。\n\n攻击者利用`xss`漏洞来注入脚本。`document.cookie`就可以获取到cookie。然后再将获取到的cookie上报。之后就可以本地修改 Cookie 来登录受害者的账号\n\n### 蠕虫攻击\n\n以微博XSS蠕虫攻击为例：\n\n- 利用 XSS 漏洞插入恶意 JS 代码；\n\n- 利用 XMLHttpRequest 发送请求去发表微博、关注用户、获取关注者列表并向其发送私信；\n\n- 微博消息和私信都包含有恶意攻击链接，等于实现了攻击代码的自我复制和传播。\n\n### 获取用户键盘记录\n\n```javascript\nkeys = \"\"\ndocument.onkeypress = function(){\n  keys += String.fromCharCode(window.event.keyCode);\n}\n```\n\n### 获取剪贴板内容\n\n```javascript\ndocument.addEventListener('paste', function (evt) {\n  clipdata = evt.clipboardData || window.clipboardData;\n  console.log(clipdata.getData('text/plain'));\n});\n```\n\n### 钓鱼欺骗用户输入账号、密码\n\n弹个弹窗，让用户输入账号密码\n\n## XSS漏洞挖掘\n\n#### 收集用例\n\n人工测试的主要思路就是在一切可输入数据的地方输入“XSS payload”（测试用例），这些地方包括所有的 GET、POST、Cookie、HTTP 头。提交数据之后，看网站的输出是否解析了前面输入的 XSS payload。\n\n我常用的 XSS payload 有以下几个。搜索“XSS cheat sheet”，也可以找到很多这种测试用例。\n\n[Cross-site scripting (XSS) cheat sheet](https://portswigger.net/web-security/cross-site-scripting/cheat-sheet)\n\n[XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet)\n\n[HTML5 Security Cheatsheet](http://html5sec.org/)\n\n#### 测试\n\n这一步可以手动测试也可以采用自动测试工具。\n\n手动：可以先一次性批量输入测试，如果无效，再输入一些特殊字符看过滤情况，根据返回数据作相应的调整测试。\n\n自动：[XSStrike](https://github.com/s0md3v/XSStrike)，它内置了很多测试用例，也可以添加自定义测试用例\n\n## XSS防御\n\n### 做好检查\n\n#### 输入检查\n\n检查攻击者所有可能的输入的地方\n\n- `URL`参数\n- （富）文本框\n- 接口返回的数据\n\n> 服务端也需要进行检查，前端是可以绕过去的\n\n#### 输出检查\n\n从前端角度来看，有两个地方可能导致恶意代码执行——`HTML`和`JavaScript`\n\n- HTML：`innerHTML` `outerHTML` `document.write()` `v-html` `danderousSetInnerHTML`\n\n  将原数据当作HTML输出，极容易导致XSS攻击。尽量避免这么做，使用`textContent`来代替。如果必须输出（如评论内容），需要进行**转义**。通常使用**白名单**的方式进行转义。\n\n  > [xss](https://www.npmjs.com/package/xss)是npm上的一个不错的HTML转义库\n\n- JavaScript：\n\n  - 内联事件监听器：`location` `onclick` `onerror` `onload` `onmousemove`等等等\n  - a标签的href属性使用伪协议：`<a href=\"javascript:alert('attack')\" />`\n  - `eval` `setTimeout` `setInterval`都能够把字符串当作js执行\n\n  这些api的不恰当使用会导致XSS攻击，所以使用时要格外注意。好在它们大多都有可替代方案。\n\n### HttpOnly禁止cookie访问\n\n如果给某个 cookie 设置了 `HttpOnly` 属性，则无法通过 JS 脚本 读取到该 cookie 的信息，但还是能通过 Application 中手动修改 cookie，所以只是在一定程度上可以防止 XSS 攻击，不是绝对的安全\n\n```text\nSet-Cookie: Name=Value; expires=Wednesday, 01-May-2014 12:45:10 GMT; HttpOnly\n```\n\n> cookie由服务端创建返回给浏览器的（响应头：`Set-Cookie`）。之后的请求会自动携带cookie。默认情况下，它随着seesion的结束而结束。\n>\n> 能不使用cookie就别使用了\n\n### CSP 内容安全策略\n\n内容安全策略（Content Security Policy，CSP）也是减少 XSS 攻击的一种方式 ，是浏览器提供一种防御机制。它采用的是白名单机制，告诉浏览器可以加载和执行哪些外部资源，这样就能防止被一些第三方恶意脚本注入执行。\n\n开启 CSP 有两种方式：\n\n1. 通过 HTTP 头信息的 Content-Security-Policy 的字段：(在返回html文件的请求的响应头上加)\n\n   ```text\n   Content-Security-Policy: script-src 'self'; object-src 'none';style-src cdn.example.org third-party.org; child-src https:（2）通过网页的<meta>标签设置：\n   ```\n\n2. 通过网页的`<meta>`标签设置\n\n   ```html\n   <meta\n     http-equiv=\"Content-Security-Policy\"\n     content=\"script-src 'self'; object-src 'none'; style-src cdn.example.org third-party.org; child-src https:\"\n   />\n   ```\n\n如何指定csp：**指令 策略**\n\n指令字段含义：\n\n| 指令          | 策略示例             | 含义                                                     |\n| ------------- | -------------------- | -------------------------------------------------------- |\n| `default-src` | `'self' www.aaa.com` | 默认资源加载策略，没有指定策略的指令使用本策略           |\n| `script-src`  | `'selft' js.a.com`   | 针对js文件的策略                                         |\n| `style-src`   | `'selft' css.a.com`  | 针对css文件的策略                                        |\n| `img-src`     | `'selft' img.a.com`  | 针对img图片资源的策略                                    |\n| `connect-src` | `'selft'`            | 针对ajax、websocket的策略，不允许会返回400               |\n| `font-src`    | `font.a.com`         | 针对字体的加载策略                                       |\n| `media-src`   | `media.a.com`        | 针对video和audio引入资源的策略                           |\n| `frame-src`   | `'self'`             | 针对frame的加载策略                                      |\n| `sandbox`     | `allow-forms`        | 对请求资源启用`sandbox`                                  |\n| `report-uri`  | `/report-uri`        | 告知浏览器，当请求资源不被策略允许时，往那个接口提交信息 |\n\n指令值字段含义：\n\n- `none` 表示不执行任何匹配。\n-  `self`表示与当前来源（而不是其子域）匹配。\n-  `unsafe-inline`表示允许使用内联 JavaScript 和 CSS。\n-  `unsafe-eval` 表示允许使用类似 eval 的 text-to-JavaScript 机制。\n- `www.aasd.com`允许加载指定域名的资源\n\n","tags":["FrontEnd","安全"],"categories":["experience"]},{"title":"排序问题梳理","url":"/posts/88f2a5b3.html","content":"\n## 归并排序\n\n### 数组的归并排序\n\n[912. 排序数组](https://leetcode-cn.com/problems/sort-an-array/)\n\n归并排序类似二叉树的后序遍历，思想也一致：利用子树的信息推算出整棵树的信息\n\n记忆：\n\n1. 将list划分成两部分，\n2. 后序遍历\n3. 合并两个有序list\n\n```typescript\nfunction sortArray(nums: number[], low = 0, high = nums.length - 1): number[] {\n  // 后序遍历\n  if (low < high) {\n    // 1. 划分\n    const mid = low + ((high - low) >> 1);\n    \n    // 2.后续遍历\n    sortArray(nums, low, mid);\n    sortArray(nums, mid + 1, high);\n    \n    // 3. 合并两个有序list\n    merge(nums, low, mid, high);\n  }\n\n  return nums;\n}\n\n// 合并两个有序数组\n// 数组A： nums[low ... mid]\n// 数组B：nums[mid+1 ... high]\nfunction merge(nums: number[], low: number, mid: number, high: number) {\n  const store: number[] = [];\n\n  // 两个数组的起始索引\n  let i = low;\n  let j = mid + 1;\n\n  while (i <= mid && j <= high) {\n    if (nums[i] < nums[j]) store.push(nums[i++]);\n    else store.push(nums[j++]);\n  }\n\n  while (i <= mid) store.push(nums[i++]);\n  while (j <= high) store.push(nums[j++]);\n\n  store.forEach((num) => (nums[low++] = num));\n}\n```\n\n时间复杂度 O(nlgn)，空间复杂度 O(n)\n\n### 链表的归并排序\n\n[148. 排序链表](https://leetcode-cn.com/problems/sort-list/)\n\n思路都一样，同样的三步\n\n```typescript\nfunction sortList(head: ListNode | null): ListNode | null {\n  if (head === null || head.next === null) return head;\n  const dummy = new ListNode();\n\n  // 1.划分\n  const [back, front] = divide(head);\n\n  // 2.后续遍历\n  const left = sortList(back);\n  const right = sortList(front);\n\n  // 3.合并两个有序链表\n  dummy.next = merge(left, right);\n\n  return dummy.next;\n}\n\n// 将链表划分成两部分\nfunction divide(head: ListNode) {\n  let back = head;\n  let front = head;\n\n  while (front.next) {\n    front = front.next;\n    if (front.next === null) break;\n    front = front.next;\n    back = back;\n  }\n  const result = [head, back.next!];\n  back.next = null;\n  return result;\n}\n\n// 合并两个有序列表 l1 l2\nfunction merge(l1: ListNode | null, l2: ListNode | null) {\n  const dummy = new ListNode();\n  let tail = dummy;\n  while (l1 && l2) {\n    if (l1.val < l2.val) {\n      tail.next = l1;\n      l1 = l1.next;\n    } else {\n      tail.next = l2;\n      l2 = l2.next;\n    }\n    tail = tail.next;\n  }\n  if (l1) tail.next = l1;\n  if (l2) tail.next = l2;\n\n  return dummy.next;\n}\n```\n\n### 数组中的逆序对\n\n[剑指 Offer 51. 数组中的逆序对](https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/)\n\n这道题也是利用归并排序中的**分治思想**。现将数组不断划分，然后合并两个有序数组`a[low...mid]`和`a[mid+1...high]`，循环比较`a[i]`和`a[j]`的大小\n\n- 如果`a[j]`小，即`a[i...mid]`所有元素都比`a[j]`大，也就是说它们构成了逆序对。逆序对的数量加上`mid-i+1`\n- 如果`a[i]`小，无需处理\n\n### 右侧较小元素个数\n\n[315. 计算右侧小于当前元素的个数](https://leetcode-cn.com/problems/count-of-smaller-numbers-after-self/)\n\n## 快速排序\n\n```typescript\nfunction sortArray(nums: number[], low = 0, high = nums.length - 1): number[] {\n  if (low < high) {\n    const index = partition(nums, low, high);\n    sortArray(nums, low, index - 1);\n    sortArray(nums, index + 1, high);\n  }\n  return nums;\n}\n\n// 划分操作\nfunction partition(nums: number[], low: number, high: number) {\n  const target = nums[low];\n  while (low < high) {\n    while (low < high && nums[high] >= target) high--;\n    nums[low] = nums[high];\n    while (low < high && nums[low] <= target) low++;\n    nums[high] = nums[low];\n  }\n  nums[low] = target;\n  return low;\n}\n```","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"队列问题梳理","url":"/posts/631e9859.html","content":"\n## BFS 广度优先遍历\n\nBFS、广度优先、层序遍历都是一回事。需要通过队列来实现\n\n###  队列实现BFS\n\n```typescript\n/**\n * Definition for a binary tree node.\n * class TreeNode {\n *     val: number\n *     left: TreeNode | null\n *     right: TreeNode | null\n *     constructor(val?: number, left?: TreeNode | null, right?: TreeNode | null) {\n *         this.val = (val===undefined ? 0 : val)\n *         this.left = (left===undefined ? null : left)\n *         this.right = (right===undefined ? null : right)\n *     }\n * }\n */\n\nfunction levelOrder(root: TreeNode | null): number[][] {\n  const queue: TreeNode[] = [root]\n  const ans = []\n\n  if (root === null) return ans\n  while (queue.length > 0) {\n    const node = queue.shift()\n    ans.push(node.val)\n    if (node.left) queue.push(node.left)\n    if (node.right) queue.push(node.right)\n  }\n\n  return ans\n};\n```\n\n### 按层次输出层序遍历\n\n在层序遍历的过程中还要记住当前处在拿一层\n\n- 用一个last指针指向每一层最后一个节点\n- 或者，前序遍历。逐个给每一层添加元素。前序遍历是先遍历第一个第一个元素，然后第二层第一个元素....\n\n[102. 二叉树的层序遍历](https://leetcode-cn.com/problems/binary-tree-level-order-traversal/)\n\n往往，考题不会只靠队列这一个点。层序遍历只是解决问题的一个手段\n\n### 填充右侧节点\n\n[117. 填充每个节点的下一个右侧节点指针 II](https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node-ii/)\n\n考点：层序遍历+last指针记住层次\n\n层次遍历到当前节点时：\n\n- 当前节点是last：不修改next指针\n- 不是last：将当前节点的next指向队列中第一个元素\n\n## 循环队列\n\n### 实现\n\n[622. 设计循环队列](https://leetcode-cn.com/problems/design-circular-queue/)\n\n循环队列有两种实现方式\n\n#### fornt+rear+used\n\n![循环队列](../../images/algorithm/循环队列1.png)\n\nfront和rear分别指向队头和队尾，used记录队列的元素个数，当：\n\n- 队列为空：front = rear且used=0\n- 队列满了：front=rear且used=队列长度\n- 其它情况：front != rear，used=队列元素个数\n\n#### 浪费一个空间\n\n![循环队列2](../../images/algorithm/循环队列2.png)\n\nfront和rear分别指向队头和队尾，当：\n\n- 队列为空：front = rear\n- 队列满了：(rear + 1) % capacity == front\n- 其它情况：front != rear\n\n### 🌟在js中实现循环队列\n\n无需指针，直接调用数组对象的`push`和`shift`方法模拟队列。\n\n循环队列的出现是因为其它语言的数组是定长的，在声明时就要指定长度，所以需要充分利用空间。而JavaScript中的数组，无需声明是指定长度。所以并不需要循环队列这种数据结构。\n\n理论上`shift`删除队列首元素，会导致后面所有元素向前移动一位。但是在`v8`的优化下，这种方式比`front`+`rear`两个指针要快\n\n```typescript\nclass MyCircularQueue {\n  private size: number;\n  private queue: number[] = [];\n\n  constructor(k: number) {\n    this.size = k;\n  }\n\n  enQueue(value: number): boolean {\n    if (this.isFull()) return false;\n    this.queue.push(value);\n    return true;\n  }\n\n  deQueue(): boolean {\n    if (this.isEmpty()) return false;\n    this.queue.shift();\n    return true;\n  }\n\n  Front(): number {\n    if (this.isEmpty()) return -1;\n    return this.queue[0];\n  }\n\n  Rear(): number {\n    if (this.isEmpty()) return -1;\n    return this.queue[this.queue.length - 1];\n  }\n\n  isEmpty(): boolean {\n    return this.queue.length === 0;\n  }\n\n  isFull(): boolean {\n    return this.queue.length === this.size;\n  }\n}\n```\n\n## 单调队列\n\n单调队列：\n\n- 基于双端队列：两端都可以入队和出队\n- 队列元素满足**单调递增**或者**单调递减**\n\n### 滑动窗口最大值\n\n[239. 滑动窗口最大值](https://leetcode-cn.com/problems/sliding-window-maximum/)\n\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"vue3-任务调度","url":"/posts/d2a05aba.html","content":"\n在vue3中，修改一个响应式对象，像是这样：\n\n```typescript\n<template>\n  <span class=\"my-name\">name: {{ name }}</span>\n</template>\n\n<script lang=\"ts\" setup>\nimport { ref, watchEffect } from 'vue'\n\nconst name = ref(\"zxfan\")\n\nname.value += ' yes!'\n\n</script>\n```\n\n当执行`name.value += ' yes!'`，`vue3`并不会立即触发当前组件的更新。而是将更新任务放到任务队列中。这一点与vue2一致。\n\n## 任务队列\n\n调度相关的源码位于`runtime-core/src/schduler.ts`中\n\n在任务调度过程中，任务会被放入三类任务队列中：\n\n- preFlushCbs：要在执行queue之前执行的队列\n\n- queue：任务队列\n- postFlush：要在执行queue之后执行的队列\n\n每一次flush的过程（或者说一个`Tick`），都是按照**清空preFlushCbs队列->清空queue队列->清空postFlush队列**的顺序\n\n> flush 指刷新任务队列，或者说 执行完任务队列中所有的任务\n\n## 入队queue的时机\n\n`queue`存放的都是组件渲染任务\n\n### 组件更新\n\n先提一下vue中的响应式：\n\n```typescript\nimport {effect, ref} from '@vue/reactivity'\n\nconst age = ref(20)\n\neffect(() => {\n  console.log(age.value) // 会输出两次，分别是 20 和 21\n})\n\nage.value = 21\n```\n\n`effect`的回调函数会被响应式得重写触发执行。\n\n那么回到本文最开始的例子中，当执行`name.value += ' yes!'`。响应式数据变化了，触发（`trigger`）其关联到的`effect`重新执行。那么需要重新执行的`effect`在哪里声明的呢？\n\n```typescript\n// runtie-core/src/renderer.ts\nconst setupRenderEffect: SetupRenderEffectFn = (\n  instance,\n  initialVNode,\n  container,\n  anchor,\n  parentSuspense,\n  isSVG,\n  optimized\n) => {\n  // create reactive effect for rendering\n  instance.update = effect(function componentEffect() {\n    // 省略。。。创建或更新 VNode\n  }, __DEV__ ? createDevEffectOptions(instance) : prodEffectOptions)\n}\n```\n\n`setupRenderEffect`给组件套上了个`effect`。这个函数是组件实例创建的时候调用的。\n\n当修改组件内的响应式数据时，会触发该`effect`重新执行。\n\n当然不会直接就执行了，注意到了吗，effect还有第二个参数。第二个参数的类型如下：\n\n```typescript\nexport interface ReactiveEffectOptions {\n  lazy?: boolean // 该effect是否\n  scheduler?: (job: ReactiveEffect) => void // 调度\n  onTrack?: (event: DebuggerEvent) => void\n  onTrigger?: (event: DebuggerEvent) => void\n  onStop?: () => void\n  allowRecurse?: boolean\n}\n```\n\n其它先不关注，我们只看`scheduler`属性。\n\n如果有这个属性，就不会直接执行`effect`，而是调用这个`scheduler`函数，并且将`effect`作为参数传给它\n\n```typescript\nexport function trigger(\n  target: object,\n  type: TriggerOpTypes,\n  key?: unknown,\n  newValue?: unknown,\n  oldValue?: unknown,\n  oldTarget?: Map<unknown, unknown> | Set<unknown>\n) {\n  \n  // 省略...\n  \n  const run = (effect: ReactiveEffect) => {\n\n    // 有scheduler 调用 scheduler\n    if (effect.options.scheduler) {\n      effect.options.scheduler(effect)\n    } else {\n      // 否则直接执行 effect\n      effect()\n    }\n  }\n\n  effects.forEach(run)\n}\n```\n\n那么在给组件实例套上`effect`的时候，传给`effect`的第二个参数是什么呢？\n\n```typescript\n// runtie-core/src/renderer.ts\n\nconst prodEffectOptions = {\n  scheduler: queueJob,\n  // #1801, #2043 component render effects should allow recursive updates\n  allowRecurse: true\n}\n\nfunction createDevEffectOptions(\n  instance: ComponentInternalInstance\n): ReactiveEffectOptions {\n  return {\n    scheduler: queueJob,\n    allowRecurse: true,\n    onTrack: instance.rtc ? e => invokeArrayFns(instance.rtc!, e) : void 0,\n    onTrigger: instance.rtg ? e => invokeArrayFns(instance.rtg!, e) : void 0\n  }\n}\n```\n\n`__DEV__ ? createDevEffectOptions(instance) : prodEffectOptions)`根据不同的环境传递的参数有一些差异性。但是我们只关注scheduler，`scheduler`的值都是`queueJob`这个函数\n\n`queueJob`的作用就是将`effect`放入`queue`任务队列。\n\n稍后在讨论`queueJob`具体都做了些什么，先总结一下组件更新的调度流程\n\n1. 组件实例创建时，套上了effect方法\n\n2. 修改响应式数据，触发effect重新执行（先调用trigger函数）\n\n3. effect的第二个参数中有`scheduler`属性，所以不会直接执行effect方法，而是将调用`scheduler`方法即`queueJob`\n4. 将组件更新effect放入`queue`队列中\n\n### 调用forceUpdate\n\n在`vue2`中可以使用`this.$forceUpdate`强制组件重新渲染。这一API在vue3 Options API中保留了下来\n\n```typescript\n// runtime-core/src/componentPublicInstance.ts\n\nconst publicPropertiesMap: PublicPropertiesMap = extend(Object.create(null), {\n  // 省略...\n  \n  $forceUpdate: i => () => queueJob(i.update),\n  \n  // 省略...\n} as PublicPropertiesMap)\n```\n\n可以观察到，`forceUpdate`就是直接调用`queueJob`，并将`effect`(i.update就是effect)传入。\n\n### hmr\n\n开发环境下，热更新也会触发组件重新渲染。也是调用`queueJob`将更新任务加入任务队列\n\n## 入队preFlushCbs和postFlushCbs的时机\n\n`preFlushCbs`存放的是组件渲染前需要完成的任务\n\n`postFlushCbs`存放的是组件渲染完成后要完成的任务\n\n### watchEffect和watch\n\n以`watchEffect`为例，看一下它的类型声明：\n\n```typescript\nfunction watchEffect(\n  effect: (onInvalidate: InvalidateCbRegistrator) => void,\n  options?: WatchEffectOptions\n): StopHandle\n\ninterface WatchEffectOptions {\n  flush?: 'pre' | 'post' | 'sync' // 默认：'pre'\n  onTrack?: (event: DebuggerEvent) => void\n  onTrigger?: (event: DebuggerEvent) => void\n}\n```\n\n`watchEffect`的第二个参数中有个`flush`属性，有三种取值\n\n- `pre`（默认）：在组件渲染前异步调用，会将任务放入`preFlushCbs`队列中\n- `post`：在组件渲染后异步调用，会将任务放入`postFlushCbs`队列中\n- `sync`：同步调用\n\n分析源码，来看一下具体放入队列的操作：\n\n```typescript\nexport function watchEffect(\n  effect: WatchEffect,\n  options?: WatchOptionsBase\n): WatchStopHandle {\n  // 调用doWatch方法\n  return doWatch(effect, null, options)\n}\n\n\nfunction doWatch(\n  source: WatchSource | WatchSource[] | WatchEffect | object,\n  cb: WatchCallback | null,\n  { immediate, deep, flush, onTrack, onTrigger }: WatchOptions = EMPTY_OBJ,\n  instance = currentInstance\n): WatchStopHandle {\n  \n  // 省略...\n    \n  const job: SchedulerJob = () => {\n    // 省略\n    // 会执行传入的回调 cb\n  }\n\n  // 赋值scheduler\n  let scheduler: ReactiveEffectOptions['scheduler']\n  if (flush === 'sync') {\n    scheduler = job\n  } else if (flush === 'post') {\n    scheduler = () => queuePostRenderEffect(job, instance && instance.suspense)\n  } else {\n    // default: 'pre'\n    scheduler = () => {\n      if (!instance || instance.isMounted) {\n        queuePreFlushCb(job)\n      } else {\n        // 第一次执行，组件未渲染的话，同步执行\n        job()\n      }\n    }\n  }\n\n  // 创建effect\n  const runner = effect(getter, {\n    lazy: true, // true的话， effect第一次不会自动执行，而是直接返回effect\n    onTrack,\n    onTrigger,\n    scheduler\n  })\n  \n  // 省略...\n}\n```\n\n总结一下：\n\n1. 响应式都是通过`effect`来实现的\n2. 先赋值`sheduler`，有三种情况\n   - `flush: sync`：直接赋值`job`，也就是直接触发effect执行\n   - `flush: post`：赋值一个函数，函数会执行`queuePostRenderEffect`，即将`job`放入`postFlushCbs`队列\n   - `flush: pre`：赋值一个函数，函数会执行`queuePreRenderEffect`，即将`job`放入`preFlushCbs`队列\n\n3. 创建`effect`，以实现响应式 并将`scheduler`传入。当响应式数据发生变化，就会调用`scheduler`函数\n\n\n\n除此之外，在Vnode创建、更新和销毁的过程中，许多环节需要在组件更新完之后再去执行相应操作。vue调用了`queuePostFlushCb`。\n\n## 任务调度\n\n现在来具体看一下这些**任务**进入任务队列中都做了什么：\n\n### queueJob\n\n```typescript\n// runtime-core/src/schduler.ts\nexport function queueJob(job: SchedulerJob) {\n  // 判断队列中是否已有该job，没有才会添加到任务队列中\n  if (\n    (!queue.length ||\n      !queue.includes(\n        job,\n        isFlushing && job.allowRecurse ? flushIndex + 1 : flushIndex\n      )) &&\n    job !== currentPreFlushParentJob\n  ) {\n    // 找的任务在任务队列中合适的位置\n    const pos = findInsertionIndex(job)\n    if (pos > -1) {\n      queue.splice(pos, 0, job)\n    } else {\n      queue.push(job)\n    }\n    // 清空任务队列\n    queueFlush()\n  }\n}\n```\n\n先进行重复判断。**这是确保任务队列中不会出现多个相同组件的effect，防止组件重复渲染**。\n\n最终调用`queueFlush`来执行清空任务队列（执行完所有任务）\n\n### queuePreFlushCb\n\n```typescript\n// runtime-core/src/schduler.ts\nfunction queueCb(\n  cb: SchedulerCbs,\n  activeQueue: SchedulerCb[] | null,\n  pendingQueue: SchedulerCb[],\n  index: number\n) {\n  if (!isArray(cb)) {\n    if (\n      !activeQueue ||\n      !activeQueue.includes(\n        cb,\n        (cb as SchedulerJob).allowRecurse ? index + 1 : index\n      )\n    ) {\n      pendingQueue.push(cb)\n    }\n  } else {\n    pendingQueue.push(...cb)\n  }\n  \n  // 清空任务队列\n  queueFlush()\n}\n\nexport function queuePreFlushCb(cb: SchedulerCb) {\n  queueCb(cb, activePreFlushCbs, pendingPreFlushCbs, preFlushIndex)\n}\n\nexport function queuePostFlushCb(cb: SchedulerCbs) {\n  queueCb(cb, activePostFlushCbs, pendingPostFlushCbs, postFlushIndex)\n}\n```\n\n`queuePreFlushCb`和`queuePostFlushCb`都会再去调用`queueCb`函数，这个函数做两件事\n\n1. 将任务放入响应的任务队列（当然 先判断重复）\n2. 执行`queueFlush`，来清空任务队列\n\n### queueFlush\n\n```typescript\n// runtime-core/src/schduler.ts\nconst resolvedPromise: Promise<any> = Promise.resolve()\nfunction queueFlush() {\n  if (!isFlushing && !isFlushPending) {\n    isFlushPending = true\n    currentFlushPromise = resolvedPromise.then(flushJobs)\n  }\n}\n\nfunction flushJobs(seen?: CountMap) {\n  // 省略...\n  \n  // 1. 清空preFlushCb队列\n  flushPreFlushCbs(seen)\n  \n\t// 省略...\n  \n  try {\n    // 2. 清空queue队列\n    for (flushIndex = 0; flushIndex < queue.length; flushIndex++) {\n      const job = queue[flushIndex]\n      if (job) {\n        // 执行job，也就是前面传入的effect\n        callWithErrorHandling(job, null, ErrorCodes.SCHEDULER)\n      }\n    }\n  } finally {\n\n    // 省略...\n    \n    // 3. 清空postFlushCbs队列\n    flushPostFlushCbs(seen)\n\t\t// 省略...\n  }\n}\n```\n\n清空队列主要流程：\n\n1. 异步执行`flushJob`，这里使用了`resolvedPromise.then(flushJobs)`。将清空队列的操作变成了异步。\n2. 清空preFlushCb队列\n3. 清空queue队列\n4. 清空postFlushCbs队列\n\n这里的“清空”是执行队列中所有任务的意思\n\n## nextTick原理？\n\n先看一段demo：\n\n```vue\n<template>\n  <span class=\"my-name\">name: {{name}}</span>\n</template>\n\n<script lang=\"ts\" setup>\nimport { nextTick, onMounted, ref } from 'vue'\n\nconst name = ref(\"zxfan\")\n\nonMounted(() => {\n  name.value += ' yes!'\n  const dom = document.querySelector(\".my-name\")\n  \n  console.log(dom?.innerHTML); // 输出：name: zxfan\n  nextTick(() => {\n    console.log(dom?.innerHTML); // 输出：name: zxfan yes!\n  })\n})\n</script>\n```\n\n由于修改响应式数据，不会立即触发组件重渲染，所以第一个`console.log`输出的内容是上一次渲染的内容。而`nexTick`注册的回调会等到在渲染完毕后执行。\n\n我们看一下`nextTick`是如何实现的\n\n```typescript\n// runtime-core/src/schduler.ts\nexport function nextTick(\n  this: ComponentPublicInstance | void,\n  fn?: () => void\n): Promise<void> {\n  const p = currentFlushPromise || resolvedPromise\n  return fn ? p.then(this ? fn.bind(this) : fn) : p\n}\n```\n\n注意到，它是等promise执行完毕后在去执行回调函数。那么这个promise是什么呢？\n\n- `currentFlushPromise`：这个promise我们刚刚遇到过，是在`queueFlush`中赋值的。这个promise会在本轮任务队列全部清空后才会变成`fullfilled`。这是再去调用nextTick的回调，就能获取到最新的dom\n- `resolvedPromise`：说明现在任务队列为空，那就包装一层promise并返回\n\n\n\n要理解nextTick，还需要结合浏览器的**事件循环**来分析，我们先明确几个知识点：\n\n1. 浏览器的事件循环将事件放到两个队列——**宏任务队列**和**微任务队列\n2. 每一次事件循环，会优先先清空微任务队列\n3. promise属于微任务\n\n以下面的demo为例，解释一下从修改响应式数据到`nextTick`中回调执行的过程\n\n```typescript\nname.value += ' yes!'\nnextTick(() => {\n  console.log(dom?.innerHTML); // 输出：name: zxfan yes!\n})\n```\n\n1. 当执行`name.value += ' yes!'`时，响应式数据发生了改变。\n   - 触发Proxy的setter，将**更新组件任务的effect**放入vue任务队列中（调用queueJob）\n   - 调用queueFlush，这里调用了`promise.resolve`，所以将**flushJobs**放入微任务队列\n   - 此时微任务队列= [flushJobs]\n2. 接着执行`nextTick`。等待`currentFlushPromise`执行完毕\n3. 开始清空微任务队列。先执行flushJobs，执行**更新组件任务的effect**，这个过程会操作DOM，一旦操作DOM。浏览器会进行线程切换。由**JS线程**切换到**渲染线程**，浏览器去更新DOM。当DOM更新完毕，在切换回**JS线程**。回到JS线程后，`currentFlushPromise`状态变成`fullfilled`。将nextTick的回调`cb`放入微任务队列。此时微任务队列= [cb]\n4. 继续清空微任务队列，执行cb。此时如果在cb中访问dom，就是渲染完成后的dom内容。\n\n## 总结\n\n![vue任务调度.png](../../images/Vue/vue任务调度.png)\n\n## Vue2中的表现\n\n### 任务调度\n\nvu2的任务调度原理也是类似。\n\n1. 组件的响应式数据发生改变，会触发setter方法。\n2. 触发`dep.notify()`。\n3. 遍历dep对象上的`watcher`，逐一调用其`update`方法，（Watcher对象是在渲染组件时创建的，用来更新组件）\n4. update再调用`queueWatcher`，将更新任务加入任务队列\n5. 调用`nextTick(flushSchedulerQueue)`，用来清空任务队列。`nextTick`是为了让组件更新变成异步。\n\n### nextTick\n\nvue2中的nextTick比vue3多了些内容。\n\nnextTick也模拟了一个回调任务队列`callbacks`（注意这不是调度的任务队列）\n\n```typescript\nexport function nextTick (cb?: Function, ctx?: Object) {\n  let _resolve\n  \n  // 将回调加入队列中\n  callbacks.push(() => {\n    if (cb) {\n      try {\n        cb.call(ctx)\n      } catch (e) {\n        handleError(e, ctx, 'nextTick')\n      }\n    } else if (_resolve) {\n      _resolve(ctx)\n    }\n  })\n  \n  // 如果队列没有正在执行（flush），就去清空队列\n  if (!pending) {\n    pending = true\n    timerFunc() // 清空队列\n  }\n  // $flow-disable-line\n  if (!cb && typeof Promise !== 'undefined') {\n    return new Promise(resolve => {\n      _resolve = resolve\n    })\n  }\n}\n```\n\nnextTick调用了`timeFunc`来清空队列\n\n```typescript\nfunction flushCallbacks () {\n  // 省略... 就是清空callbakcs任务队列\n}\n\nlet timerFunc\n\n\n// 1 支持promise，就用promise来模拟异步\nif (typeof Promise !== 'undefined' && isNative(Promise)) {\n  const p = Promise.resolve()\n  timerFunc = () => {\n    p.then(flushCallbacks)\n   \n    if (isIOS) setTimeout(noop)\n  }\n  isUsingMicroTask = true\n} \n// 2. 不支持promise 就用MutationObserver来模拟异步\nelse if (!isIE && typeof MutationObserver !== 'undefined' && (\n  isNative(MutationObserver) ||\n  // PhantomJS and iOS 7.x\n  MutationObserver.toString() === '[object MutationObserverConstructor]'\n)) {\n  // Use MutationObserver where native Promise is not available,\n  // e.g. PhantomJS, iOS7, Android 4.4\n  // (#6466 MutationObserver is unreliable in IE11)\n  let counter = 1\n  const observer = new MutationObserver(flushCallbacks)\n  const textNode = document.createTextNode(String(counter))\n  observer.observe(textNode, {\n    characterData: true\n  })\n  timerFunc = () => {\n    counter = (counter + 1) % 2\n    textNode.data = String(counter)\n  }\n  isUsingMicroTask = true\n} \n\n// 3.用setImmediate来模拟异步\nelse if (typeof setImmediate !== 'undefined' && isNative(setImmediate)) {\n\n  timerFunc = () => {\n    setImmediate(flushCallbacks)\n  }\n} else {\n  // Fallback to setTimeout.\n  timerFunc = () => {\n    setTimeout(flushCallbacks, 0)\n  }\n}\n```\n\n为了更多的兼容浏览器，timerFunc模拟异步判断了三种情况\n\n1. 支持Promise，就直接用Promise来模拟异步。Promise属于微任务\n2. 不支持Promise，支持MutationObserver。MutationObserver也属于微任务\n   - 创建一个空的文本节点，监听这个文本节点的字符变化。变化了就调用`flushCallbacks`来清空回调任务队列\n   - 调用`timerFunc`，会修改文本节点的内容，从而触发`flushCallbacks`函数的执行\n3. `MutationObserver`和`Promise`都不支持，就用`setImmediate`来模拟异步，后者属于宏任务\n4. 最后方案就是使用setTimeout来模拟异步\n\n可见`vue2`为了兼容性，下足了功夫。而`vue3`直接就使用了`Promise`\n\n","tags":["vue"],"categories":["源码"]},{"title":"栈问题梳理","url":"/posts/1f4ac2fb.html","content":"\n## 普通栈\n\n栈的特性：`先进后出`\n\n数组模拟：\n\n- 进栈：`arr.push()`\n- 出栈：`arr.pop()`\n\n### 匹配消除\n\n栈可以用来解决**匹配**问题\n\n### [20. 有效的括号](https://leetcode-cn.com/problems/valid-parentheses/)\n\n括号匹配，`({[`与`]})`匹配\n\n创建一个栈`stack`，并遍历字符串。当遇到`({[`时入栈，当遇到`]})`时，取栈顶元素比较\n\n- 相匹配，栈顶元素出栈，继续循环\n- 不匹配，直接返回`false`\n\n时间复杂度O(n)，空间复杂度O(n)\n\n> 如果栈中的元素都一样，就不需要用栈，用一个计数器count即可\n\n### 大鱼吃小鱼\n\n*题目】在水中有许多鱼，可以认为这些鱼停放在 x 轴上。再给定两个数组 Size，Dir，Size[i] 表示第 i 条鱼的大小，Dir[i] 表示鱼的方向 （0 表示向左游，1 表示向右游）。这两个数组分别表示鱼的大小和游动的方向，并且两个数组的长度相等。鱼的行为符合以下几个条件:*\n\n*所有的鱼都同时开始游动，每次按照鱼的方向，都游动一个单位距离；*\n\n*当方向相对时，大鱼会吃掉小鱼；*\n\n*鱼的大小都不一样。*\n\n*输入：Size = [4, 2, 5, 3, 1], Dir = [1, 1, 0, 0, 0]*\n\n*输出：3*\n\n这道题跟上一条题原理一样都是**匹配消除**，上一道题是根据元素的内容（括号）来判断匹配消除。而本道题是根据元素的**大小**的**“方向”**两个条件来判断\n\n```typescript\nconst LEFT = 0;\nconst RIGHT = 1;\n\nfunction eatFish(size: number[], dir: number[]) {\n  const stack: number[] = [];\n  for (let i = 0; i < size.length; i++) {\n    // 还没有鱼\n    if (stack.length <= 0) {\n      stack.push(i);\n      continue;\n    }\n\n    \n    let insert = true; \n    \n    // 栈顶的鱼比 当前的鱼小, 就一直循环得吃\n    while (stack.length > 0) {\n      let last = stack[stack.length - 1];\n      const canMeet = dir[last] === RIGHT && dir[i] == LEFT;\n\n      if (canMeet && size[last] < size[i]) stack.pop();\n      \n      // 大鱼把栈中的所有鱼都吃完了，需要在最后将这条大鱼放入栈中\n      else if (canMeet) {\n        insert = false;\n        break;\n      } else {\n        insert = true;\n        break;\n      }\n    }\n    // 栈中的鱼都吃完了\n    if (insert) stack.push(i);\n  }\n  return stack;\n}\n```\n\n## 单调栈\n\n单调栈分为两种：\n\n- 递增栈\n- 递减栈\n\n### 相邻最小索引\n\n【题目】一个整数数组 A，找到每个元素：右边第一个比我小的下标位置，没有则用 -1 表示。\n\n输入：[5, 2]\n\n输出：[1, -1]\n\n解释：因为元素 5 的右边离我最近且比我小的位置应该是 A[1]，最后一个元素 2 右边没有比 2 小的元素，所以应该输出 -1。\n\n```typescript\n/**\n * 解析：\n *  遍历数组元素，构造递增栈\n *  当前元素比栈顶小，则栈顶元素需要出栈，并记录栈顶元素右侧第一个小的下标为当前元素下标\n */\nfunction findRightSmall(arr: number[]) {\n  const result: number[] = arr.map((i) => -1);\n  const stack: number[] = [];\n\n  for (let i = 0; i < arr.length; i++) {\n    const cur = arr[i];\n\n    while (stack.length > 0 && arr[stack[stack.length - 1]] > cur) {\n      result[stack[stack.length - 1]] = i;\n      stack.pop();\n    }\n\n    stack.push(i);\n  }\n\n  return result;\n}\n\n// 改变一下问题\n// 求左边第一个比我下的下标为止，没有则用-1表示\n\n/**\n * 解析\n *  还是遍历数组元素，构造递增栈\n *  当前元素小于等于栈顶元素是需要出栈\n *  当不需要栈顶元素出栈，说明当前元素比栈顶元素大。即栈顶元素是当前元素左侧第一个小的元素，记录一下\n * \n * 记录之前还要排除掉相等的情况，即从栈顶往下找，一直找到一个不相同的元素\n */\nfunction findLeftSmall(arr: number[]) {\n  const result: number[] = arr.map((i) => -1);\n  const stack: number[] = [];\n\n  for (let i = 0; i < arr.length; i++) {\n    const cur = arr[i];\n\n    while (stack.length > 0 && arr[stack[stack.length - 1]] > cur) stack.pop();\n\n    let top = stack.length - 1;\n    while (arr[stack[top]] === cur) top--;\n    if (top >= 0) result[i] = stack[top];\n\n    stack.push(i);\n  }\n\n  return result;\n}\n\n```\n\n### 字典序最小的 k 个数的子序列\n\n【题目】给定一个正整数数组和 k，要求依次取出 k 个数，输出其中数组的一个子序列，需要满足：1. 长度为 k；2.字典序最小。\n\n输入：nums = [3,5,2,6], k = 2\n输出：[2,6]\n\n解释：在所有可能的解：{[3,5], [3,2], [3,6], [5,2], [5,6], [2,6]} 中，[2,6] 字典序最小。\n\n所谓字典序就是，给定两个数组：x = [x1,x2,x3,x4]，y = [y1,y2,y3,y4]，如果 0 ≤ p < i，xp == yp 且 xi < yi，那么我们认为 x 的字典序小于 y。\n\n```typescript\nfunction findSmallSeq(seg: number[], k: number) {\n  const stack: number[] = [];\n\n  for (let i = 0; i < seg.length; i++) {\n    const cur = seg[i];\n    if (stack.length <= 0) stack.push(cur);\n\n    while (\n      stack.length > 0 &&\n      stack[stack.length - 1] > cur &&\n      stack.length + seg.length - i > k\n    )\n      stack.pop();\n\n    if(stack.length < k) stack.push(cur)\n  }\n\n  return stack;\n}\n\n```\n\n## 单调栈的运用\n\n[84. 柱状图中最大的矩形](https://leetcode-cn.com/problems/largest-rectangle-in-histogram/)\n\n[42. 接雨水](https://leetcode-cn.com/problems/trapping-rain-water/)\n\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"vue3-vnode","url":"/posts/f9d1a0d8.html","content":"\n`VNode`是vue十分重要的核心概念，下图整理了VNode的创建、销毁、更新patch等流程。\n\n![VNode](../../images/Vue/VNode.svg)\n\n","tags":["vue"],"categories":["源码"]},{"title":"二分法梳理","url":"/posts/d7f42810.html","content":"\n## 二分查找的原则\n\n1. 开闭原则：首先要确定查找的区间。i一般都取0；j可以取length也可以取length-1\n   - `j = length`：意味着左闭右开区间即`[i, j)`\n   - `j = length - 1`：意味着左闭右闭区间`[i, j]`\n2. 循环终止条件\n   - `while(i < j)`：当采用**左闭右开区间**时使用这个。终止搜索区间为`[i, i)`(长度为0)；终止条件`i === j`。\n   - `while(i <= j)`：当采用**左闭右闭区间**时使用这个。终止搜索区间为`[i, i]`（长度为1，还有个i）；终止条件`i = j + 1`。\n3. `(i + j) >> 1`：这样默认是取下限；`(i + j + 1) >> 1`：这样默认是取上限\n4. `i`和`j`怎么变？\n   - `i = mid + 1`和`j = mid`：当采用**左闭右开区间**时使用这个，mid是取不到的，所以j可以等于mid\n   - `i = mid + 1`和`j = mid - 1` ：当采用**左闭右闭区间**时使用这个，因为是右闭，所以j要等于`mid - 1`\n\n> 确定开闭原则是十分重要\n\n## 两个模版\n\n【题目】给定一个有序数组，返回指定元素在数组的最左/右边的位置\n\n输入：A = [1, 2, 2, 2, 2, 3, 3], target = 2；\n\n### 元素在数组最左的位置（lowBound模版）\n\n我们选左闭右开区间 `[i, j)`\n\n也就是找到数组中第一次出现指定元素2的位置。\n\n当遍历到一个元素 nums[mid]，会分两种情况\n\n1. `nums[mid] >= target`：此时区间`[i, mid)`是我们要继续搜索的。当前元素就是元素2，因为我们是要找第一个2，所以还需要往左边找，防止mid\n2. `nums[mid] < target`：此时区间`[mid + 1, j)`是我们要继续搜索的，说明target在mid的右侧\n\n```javascript\nfunction findLeft(nums: number[], target: number) {\n  let i = 0\n  let j = nums.length\n\n  while (i < j) {\n    const mid = (i + j) >> 1\n    if (nums[mid] < target) i = mid + 1\n    else j = mid\n  }\n  return i\n}\n```\n\n### 元素在数组最右的位置（upperBound模版）\n\n同理，当遍历到一个元素 nums[mid]，有三种情况。有两种情况处理结果一样：\n\n- `nums[mid] > target`：此时区间`[i, mid - 1]`是我们要继续搜索的，说明target在mid的左侧\n- `nums[mid] <= target`：此时区间`[mid, high]`是我们要继续搜索的，说明target在mid的右侧\n\n```javascript\nfunction findRight(nums: number[], target: number) {\n  let i = 0\n  let j = nums.length\n\n  while (i < j) {\n    const mid = (i + j) >> 1\n    if (nums[mid] > target) j = mid\n    else i = mid + 1\n  }\n  return i - 1\n}\n```\n\n> 为什么`return i - 1`?\n>\n> 应为当 num[mid] === target时，`i = mid + 1`。所以最后nums[i]一定不等于target，只有nums[i-1]才可能等于target（如果存在target元素）\n\n### 练习：[35. 搜索插入位置](https://leetcode-cn.com/problems/search-insert-position/)\n\n## 二分解题思路\n\n二分的前提：搜索范围有规律（例如：有序）\n\n提问破题法。\n\n1. 要什么，什么就是 x。x表示搜索空间\n2. 获取C[f(1), f(2), ... f(x)...]，\n   1. 满足**约束条件**的 f(x) = 0。f(x) 表示通过 x 得到的值。约束条件看题意\n   2. 不满足约束条件的 f(x) 设置为 -1 或者 1。\n3. 最优解 0 在 C[] 的最左边还是最右边，决定使用 lowerBound 还是 upperBound。\n\n### [852. 山脉数组的峰顶索引](https://leetcode-cn.com/problems/peak-index-in-a-mountain-array/)\n\n1. 确定搜索空间`[1,len-1)`左闭右开\n2. C[] && f(x)\n   - arr[x]比左边小比右边大（处于递增）：return -1\n   - arr[x]比两边都大：return 0\n   - arr[x]比左边大比右边小（处于递减）：return 1\n3. 所找元素唯一（不存在重复），选择使用 lowerBound 还是 upperBound都可以， 当f(x)\n   - 等于-1：`i = m + 1`\n   - 等于0或等于1: `j = m`\n\n### 给定一个有序数组，找出数组中下标与值相等的那些数。\n\n```javascript\n/**\n * @param {number[]} nums\n * @return {number}\n */\nvar getNumberSameAsIndex= function(nums) {\n    let i = 0\n    let j = nums.length\n    while(i < j) {\n        const m = (i + j) >> 1\n        if(m === nums[i]) return m\n        else if (m < nums[i]) j = m\n        else i = m + 1\n    }\n    return m\n};\n```\n\n### 给定一个有序数组，找出数组中下标与值相等的数的范围。\n\n先使用lowerBound找一个left\n\n再使用upperBound找一个right\n\n`[left, right]`就是答案\n\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"二叉树遍历问题梳理","url":"/posts/4ed68d4d.html","content":"\n## 二叉树\n\n二叉树的定义\n\n```typescript\nclass TreeNode {\n  public value: number;\n  public left?: TreeNode;\n  public right?: TreeNode;\n}\n```\n\n有四种遍历方式:\n\n- 前序遍历\n- 中序遍历\n- 后序遍历\n- 层次遍历\n\n## 前序遍历——给子树传递信息\n\n[LeetCode 114.二叉树的前序遍历](https://leetcode-cn.com/problems/binary-tree-preorder-traversal/)\n\n解法：\n\n- 递归\n- 栈\n- Morris\n\n常见的解法：**递归法**\n\n```typescript\nfunction preOrder(node: TreeNode): void {\n  if (!node) return\n\t\n  // 访问节点\n  console.log(node.value)\n\t// 遍历左子树\n  preOrder(node.left)\n\t// 遍历右子树\n  preOrder(node.right)\n}\n```\n\n**使用栈**：栈模拟递归，先依次将节点以及节点的左子节点放入栈中，如果没有左子节点，就去栈顶元算的右子节点依次循环。当栈为空说明遍历完了，时间复杂度O(n)，空间复杂度O(h)，h为树的高度。\n\n**Morris 遍历**可以实现空间复杂度O(1)，无需递归。\n\n### “影子”二叉树\n\n星座二叉树是一种思考方式，根据题意，将所给二叉树构造成另一颗二叉树\n\n#### [LeetCode 98. 验证二叉搜索树](https://leetcode-cn.com/problems/validate-binary-search-tree/)\n\n[解析]：可以构造影子二叉树，影子二叉树的节点都是一个区间`[min, max]`，我们需要做的就是判断原二叉树的节点是否在其对应的影子二叉树节点所表示的区间范围累\n\n先前序遍历二叉树，根节点判断是否在`[-Infinity, Infinity]`区间，左子树判断是否在`[-Infinity, root.val]`之间，右子树判断是否在`[root.val, Infinity]`之间\n\n前序遍历可以**递归**或**栈**，也可以用`Morris`\n\n使用栈的话，就需要自己构造出影子二叉树，在递归的过程中不断给min和max赋值。\n\n```typescript\nclass ShadowNode {\n  node: TreeNode;\n  min: number;\n  max: number;\n\n  constructor(node: TreeNode, min: number, max: number) {\n    this.node = node\n    this.min = min\n    this.max = max\n  }\n}\n```\n\n#### [LeetCode 100. 相同的树](https://leetcode-cn.com/problems/same-tree/)\n\n[题解]：题目给了两棵树`p`和`q`，他们俩互为影子二叉树，两棵树同时前序遍历，判断对应节点是否相同 \n\n#### [LeetCode 572. 另一个树的子树](https://leetcode-cn.com/problems/subtree-of-another-tree/)\n\n[题解]：题目给了两棵树`s`和`t`，前序遍历`s`，当`s.val === t.val`是，t可能是s的子树，这时再去判断s和t是否是相同的树(上一题)\n\n### 利用回溯（回归）\n\n#### [113. 路径总和 II](https://leetcode-cn.com/problems/path-sum-ii/)\n\n计算符合所给target值的全部路径。\n\n[题解]： 前序遍历二叉树，在遍历的过程中使用`path`数组记录路径，`sum`变量记录路径和。当遍历到叶子节点时（左右子树为空）。判断`sum === target`，相等将path放入`result(二维数组)`中。\n\n没有遍历到叶子节点继续回溯\n\n到叶子节点后，要将`path.pop`。即把叶子结点从路径最后扔掉! \n\n> 扩展：求从根节点到所有叶子节点的路径\n\n## 中序遍历——有序性\n\n#### [94. 二叉树的中序遍历](https://leetcode-cn.com/problems/binary-tree-inorder-traversal/)\n\n中序遍历：\n\n- 递归\n- 栈\n- Morris\n\n使用栈解决中序遍历：算法和前序遍历差不多，就是读取数据的实际不同，前序是在每一次深入左子树前读；而中序是每次切换右子树时读\n\n### 中序有序性\n\n#### [98. 验证二叉搜索树](https://leetcode-cn.com/problems/validate-binary-search-tree/)\n\n使用中序遍历解决这道题比前序遍历要简单，因为一个特性：**中序遍历二叉搜索树，一定有序**。只要在遍历过程中判断当前节点的值是否大于上一个节点的值，如果不满足可以直接判断不是二叉搜索树。\n\n#### [501. 二叉搜索树中的众数](https://leetcode-cn.com/problems/find-mode-in-binary-search-tree/)\n\n求二叉搜索树出现次数最多的数（可能不止一个）。采用**中序遍历**，因为一定有序。所以问题就转化成：**给定有序数组，求出现次数最多的数**。\n\n最简单的就是Map统计每个数据的出现次数，空间复杂度O(n)\n\n空间O(1)解决方法：四个变量:\n\n- max：数组，存放出现次数最多的元素\n- maxCount：出现次数最多的元素的次数\n- last：上一个遍历到的数据\n- lastCount：上一个遍历到的数据出现的次数\n\n当当前节点值不等于last，就需要判断`lastCount`和`maxCount`的大小，来决定是否将lastCount放入数组\n\n边界情况：当遍历结束后，还要再判断一下。\n\n#### [783. 二叉搜索树节点最小距离](https://leetcode-cn.com/problems/minimum-distance-between-bst-nodes/)\n\n还是利用**中序遍历二叉搜索树的有序性**。当前节点和上一个节点的值相减取最小值即可。\n\n#### [99. 恢复二叉搜索树](https://leetcode-cn.com/problems/recover-binary-search-tree/)\n\n还有利用**中序遍历二叉搜索树的有序性**，问题就转化为：还原升序数组被调换的两个数。\n\n三个指针\n\n- first：指向第一个被调换的节点\n- second：指向第二个被调换的节点\n- lastNode：上一个遍历的节点\n\n每次遍历，判断当前节点与lastNode的大小。动态调整first和second的指向。遍历有两种情况\n\n- 只会遇到一次`root.val < lastNode.val`：被调换的两个节点相邻在一起，这时`first`和`second`分别指向`root`和`lastNode`\n- 会遇到第二次，第二次只需要调整`second`，指向`root`\n\n### 二叉搜索树（BST）的增删查\n\n#### [450. 删除二叉搜索树中的节点](https://leetcode-cn.com/problems/delete-node-in-a-bst/)\n\n```typescript\n/**\n * Definition for a binary tree node.\n * class TreeNode {\n *     val: number\n *     left: TreeNode | null\n *     right: TreeNode | null\n *     constructor(val?: number, left?: TreeNode | null, right?: TreeNode | null) {\n *         this.val = (val===undefined ? 0 : val)\n *         this.left = (left===undefined ? null : left)\n *         this.right = (right===undefined ? null : right)\n *     }\n * }\n */\n\nfunction deleteNode(root: TreeNode | null, key: number): TreeNode | null {\n  // case1 空树\n  if (root === null) return root\n\n  // case2 要删除的元素在左子树\n  if (key < root.val) root.left = deleteNode(root.left, key)\n\n  // case3 要删除的元素在右子树\n  else if (key > root.val) root.right = deleteNode(root.right, key)\n\n  // case4 当前节点即为 需要删除的元素 ，又分为四种情况：\n  else {\n    // 1.叶子节点\n    if (root.left === null && root.right === null) return null\n    // 2.有左子树\n    else if (root.left !== null) {\n      // 找左子树最大值\n      let node = root.left\n      while (node.right) node = node.right\n      swapNodeVal(root, node)\n      root.left = deleteNode(root.left, node.val)\n    }\n    // 3.有右子树\n    else if (root.right !== null) { \n      // 找右子树最小值\n      let node = root.right\n      while (node.left) node = node.left\n      swapNodeVal(root, node)\n      root.right = deleteNode(root.right, node.val)\n    }\n    // 4.既有左子树 又有右子树。这种情况包含在情况2中\n    // 所以最终答案有两种\n  }\n  return root\n};\n\nfunction swapNodeVal(a: TreeNode, b: TreeNode) {\n  const val = a.val\n  a.val = b.val\n  b.val = val\n}\n```\n\n#### [701. 二叉搜索树中的插入操作](https://leetcode-cn.com/problems/insert-into-a-binary-search-tree/)\n\n插入操作和删除相似，但是就没有那么多边界情况\n\n```typescript\nfunction insertIntoBST(root: TreeNode | null, val: number): TreeNode | null {\n  if (root === null) return new TreeNode(val)\n\n  if (root.val < val) root.right = insertIntoBST(root.right, val)\n  else if (root.val > val) root.left = insertIntoBST(root.left, val)\n\n  return root\n};\n```\n\n#### [700. 二叉搜索树中的搜索](https://leetcode-cn.com/problems/search-in-a-binary-search-tree/)\n\n搜索也类似\n\n```typescript\nfunction searchBST(root: TreeNode | null, val: number): TreeNode | null {\n  if (root === null) return root\n\n  if (root.val < val) return searchBST(root.right, val)\n  else if (root.val > val) return searchBST(root.left, val)\n  else return root\n};\n```\n\n## 后序遍历——给父节点传递信息\n\n如果一个节点既有左子树又有右子树，那么该节点会在回溯时被访问（即该节点被遍历到两次）\n\n后续遍历：\n\n- 递归\n- 栈\n- Morris\n\n#### [145. 二叉树的后序遍历](https://leetcode-cn.com/problems/binary-tree-postorder-traversal/)\n\n使用**栈**来递归遍历二叉树，比前序和中序要稍微复杂一些，一些节点是在第二次遍历到时才访问\n\n使用一个变量`pre`始终指向上一个访问的节点\n\n遍历到节点时有两个分支\n\n- 当前节点没有右节点或者右节点等于`pre`时，访问该节点，不再深入有节点（因为是回溯回来的）\n- 反之，继续访问右节点\n\n```typescript\nfunction postorderTraversal(root: TreeNode | null): number[] {\n  const stack: TreeNode[] = []\n  const result: number[] = []\n  let pre: TreeNode | null\n  while (true) {\n    while (root) {\n      stack.push(root)\n      root = root.left\n    }\n    if (stack.length <= 0) break\n    root = stack[stack.length - 1] // 取栈顶元素\n    \n    // 右子树为空，或者右子树等于上一个被访问的节点（回溯回来的）时，访问\n    if (root.right === null || root.right === pre) {\n      result.push(root.val)\n      stack.pop() // 出栈\n      pre = root\n      root = null // root = null 说明不再遍历该节点的子树\n    } \n    // 否则继续后序遍历\n    else root = root.right\n  }\n\n  return result\n};\n```\n\n#### [剑指 Offer 68 - II. 二叉树的最近公共祖先](https://leetcode-cn.com/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/)\n\n##### 后序遍历\n\n后续遍历的精髓：**先深入左右子树搜取信息，回溯时再判断**（回溯时就知道了子节点的信息）\n\n现深入左右子树，回溯时，判断每个节点左右子树等于p和q的次数`l`与`r`\n\n- 如果`l`和`r`均为1，说明当前节点就是`p`和`q`的最近公共祖先\n\n- 如何`l`和`r`有一个为1且当前节点等于p或q，也说明当前节点就是`p`和`q`的最近公共祖先\n\n- 回溯时，返回以当前节点为根节点的树中p和q的数量\n\n注意这道题的前提条件：p、q唯一且不相等\n\n##### 前序遍历\n\n这道题还可以用**前序遍历**来解决，前序遍历时遍历到该节点就去访问，此时只知道当前节点和遍历过的节点信息并不知道子节点信息。\n\n- 在遍历到该节点是，判断一下该节点是不是等于`p`或`q`\n  - 如果是，就直接返回子节点就不需要在遍历了\n  - 如果不是，继续遍历左子树和右子树找`p`和`q`的点\n- 当左右子树找完了\n  - 左右子树都找到了`p`和`q`，说明该节点就是最近公共祖先\n  - 如果只找到一个，或者没有找到（没找到的话返回null），返回不等于null的节点（继续往下找），都等于null说明不存在最近公共祖先\n\n> 扩展：多个节点的最近公共祖先呢？\n\n## 思考题\n\n### [105. 从前序与中序遍历序列构造二叉树](https://leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/)\n\n前序遍历 `preorder = [3,9,20,15,7]`\n中序遍历`inorder =  [9,3,15,20,7]`\n\n特性：\n\n- 前序遍历的第一个元素一定为根节点，后面的元素分别是左子树和右子树\n- 中序遍历某一个元素如果为根节点，则左边的都是其左子树的节点，右边都是其右子树的节点\n\n根据特性可以总结出以下解体思路\n\n1. 先构造一个map，存放`inorder`的`value->index`，这是为了查找索引时方便（空间换时间）\n2. 递归遍历`preorder`，\n   - 取第一个元素出来，当作根节点\n   - 在分别设置改根节点的左子树和右子树\n\n```typescript\nfunction buildTree(preorder: number[], inorder: number[]): TreeNode | null {\n  const map = new Map<number, number>()\n  inorder.map((v, i) => map.set(v, i))\n\n  function build(s: number, e: number) {\n    if (s > e) return null\n\n    const val = preorder.shift()\n    const root = new TreeNode(val)\n    const index = map.get(val) // 查找索引\n\n    // 设置左右子树\n    root.left = build(s, index - 1)\n    root.right = build(index + 1, e)\n    return root\n  }\n\n  return build(0, preorder.length - 1)\n};\n```\n\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"链表问题梳理","url":"/posts/4ed68d4d.html","content":"\n解决链表问题的“三板斧”：**假头、新链表、双指针**。\n\n## 假头节点\n\n假头通常也叫作 Dummy Head。就是在链表前面，加上一个额外的结点。此时，存放了 N 个数据的带假头的链表，算上假头一共有 N+1 个结点。添加假头后，可以省略掉很多空指针的判断，链表的各种操作会变得更加简洁。\n\n`LeetCode[707] 设计链表`\n掌握几种常见的链表操作\n\n- get: 查找制定索引的链表元素\n- addAtHead: 头部插入元素\n- addAtTail: 尾部插入元素\n- addAtIndex: 指定索引插入\n- deleteAtIndex: 指定索引删除\n\n## 新链表\n\n做链表的**反转**、**交换**等操作时，不建议直接在原来的链表上进行操作。一种可取的思路是，把这些操作想象成要生成新的链表。\n\n### 反转\n\n列表反转(`LeetCode 201`)：可以新建一个有头节点的新链表，遍历旧链表。将每个元素采用**头部插入**的方法放到新链表中\n\n### 删除元素\n\n根据**一些条件**判断来删除元素\n\n- 移除链表指定元素(`LeetCode 203`)：同样创建一个新链表。遍历旧链表，相同元素跳过，不同元素加入新链表\n- 删除链表重复元素：判断当前遍历的元素与新链表中最后的元素是否相等。\n- 删除链表所有重复过的元素：\n\n### 合并\n\n- 合并两个有序链表(`LeetCode 21`)\n- 合并K个升序链表(`LeetCode 23`)\n\n这两道题页都是生成 dummy 新链表，然后**选择结点**往新链表尾部追加数据\n\n- 升序： 选择最小的\n- 降序：选择最大的\n\n**考点**：在选择最小或最大时，可以使用堆（优先队列）来优化\n\n### 交换\n\n交换链表中的结点(`LeetCode 24`)：两两反转即奇偶位置元素交换\n\n- 先拆分：按照奇偶拆成两个链表\n- 再合并：奇数位对应原来偶数位，偶数位对应原来奇数位\n\nK 个一组翻转链表(`LeetCode 25`)：每k的元素一组交换(k=2就等价于上一题)\n\n- 准备两个链表——temp和result\n- 遍历链表，将节点插入temp，满k个就反转并插入result中\n- 最终将剩余的节点（不满k个）插入result\n\n逆向k个一组：上一题翻着来\n\n- 先将链表反转\n- 再沿用上题的方法\n\n## 双指针\n\n链表的双指针有两种：\n\n1. 间隔指针：前面的指针先走一步，然后后面的指针再一起走；前面的指针先走 k 步，后面的指针再一起走。\n2. 快慢指针：两个指针的速度一快一慢前进，比如一个每次走一步，一个每次走两步。\n\n`LeetCode[19]` 删除链表倒数第K个节点\n\n- 采用间隔指针back,front   front先走k布\n- back，front再一起走直到front到最后一个节点\n- 边界情况：删除的是第一个节点\n\n将链表从中间拆分成两半\n\n- 采用快慢指针back,front\n- front每次走2步，back每次走1步\n- 边界\n  - 奇数个节点时，front正好是最后一个节点\n  - 偶数个节点时，front为空，应返回back的前驱\n\n`LeetCode[143]` 重排链表\n\n- 先把链表平分\n- 把后半部分逆置\n- 再把逆置的后半部分插入到前半部分的偶数位上\n\n`LeetCode[141]` 环形链表\n\n- 采用快慢指针back,front\n- front每次走2步，back每次走1步\n- 如果有环，back和front必定相遇\n\n找出环形链表成环的节点\n\n- 记住一个结论：快慢指针分别从头节点和相遇节点出发，最终一定会再成环节点相遇\n- 先都从头节点出发，找到相遇节点\n- 分别从头节点和相遇节点出发，最后相遇的节点即成环节点\n\n`LeetCode[148]` 链表排序：给定一个单向链表，如何给这个链表排序，要求复杂度达到 O(nlogn)。\n\n- 采用归并排序的思想来解\n- 递推过程：两两分解——用快慢将链表不断二分\n- 回归过程：两两合并——利用新建头尖点来不断合并两个有序链表\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"js中的数值类型","url":"/posts/9a6a2aee.html","content":"\n## IEEE 754\n\n`JavaScript`的数值类型遵循`IEEE 754`规范。`JavaScript`中的数字都是以是64-bits的双精度数的形式存储的。所以能表示有2^64种情况。\n\n### 浮点数公式\n\njs中的任何一个二进制浮点数可以由以下公式来表示：\n$$\nV = (-1)^{S} * M * 2^{E}\n$$\n\n- V：表示二进制浮点数\n- S：符号位，1位。为0正数，1为负数\n- M：有效数字，52位。\n- E：指数位，11位\n\n`M`是一个介于1和2之间的数即(`1.xxxxxxxxxxx`, 11个`x`)。第一个`1`是默认填上的所以M有`2^53 - 1`中可能。\n\n`E`的取值有`2^11`中可能，由于`E`需要能够表示负数，所以要减去一个中间数(`1023`)\n\n十进制7，二进制为111：\n$$\n7(111) = (-1)^{0} * 1.11 * 2^{2}\n= 1.11 * 100 = 111\n$$\n注意：这里是2进制的运算`2^2 = 100`\n\n`E`为2（10），这里已经减去1023。`2+1023=1025`，即十一位二进制对应的值为`1025`\n\n### E的几种情况\n\n同时指数E还可以**根据规定分为三种情况讨论**\n\n1. **E不全为0或不全为1** 这个阶段就是正常的浮点数表示，通过计算E然后减去1024即为指数\n2. **E全为0** 浮点数的指数E等于0-1023 = -1023，当指数为-1023时，**有效数字M不再加上第一位的1**，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字\n3. **E全为1** 此时如果有效数字M全为0，那么就表示+∞或者-∞，取决于第一位符号位。**但是如果有效数字M不全为0，则表示这不是一个数(NaN)**\n\n## JavaScript中的IEEE 754\n\n### 最大安全整数\n\n$$\nNumber.MAX\\_SAFE\\_INTEGER = 2^{53} - 1\n$$\n\n有效数字只有52位，`2^53`和`2^53+1`以及后面的数在js中都相等。所以js能够表示的最大安全整数是`2^53 - 1`。\n\n### 0.1 + 0.2 !== 0.3 ?\n\n计算机进行数值运算是，是将十进制转成二进制补码再进行计算\n\n```text\n0.1D = (-1)^0 * 1.1001..(1001循环13次)1010B * 2^-4\n0.2D = (-1)^0 * 1.1001..(1001循环13次)1010B * 2^-3\n0.3D = (-1)^0 * 1.0011..(0011循环13次)0011B * 2^-2\n```\n\n当0.1，0.2转化为二进制的时候，有效数字都是52位(4 * 12 + 4)，因为在64位精确度中，只能保持52位有效数字，如果没有52位有效数字的约束，其实在第53位中，0.1转二进制本来是1，但是有了52位约束之后，根据二进制的取舍（**0舍1入**） ，最后五位数就从1001 **1(第53位)** 变成了 1010。\n\n我们可以手动计算一下0.1的二进制加上0.2的二进制：\n$$\n0.1 + 0.2 = (-1)^{0} * 1.0011...(0011 循环13次)0011 * 2^{-2}\n$$\n那么相加结果转换为十进制其实等于`0.30000000000000004`，这就是为什么0.1 + 0.2 != 0.3 的原因了。\n\n\n\n","tags":["javascript","Number"],"categories":["JavaScript"]},{"title":"js位运算和权限","url":"/posts/8d54c840.html","content":"\n## 位运算\n\n### 与 &\n\n都为1则为1，否则为0\n\nA：0011010\nB：0101100\nC：0001000\n\n### 或\t |\n\n有1即为1，否则为0\n\nA：0011010\nB：0101100\nC：0111110\n\n### 非 ^\n\n不同为1，相同为0\n\nA：0011010\nB：0101100\nC：0110110\n\n## 权限控制\n\n现在有`读`、`写`和`执行`三种权限\n\n```test\n读\t写 执行 十进制 权限\n0\t 0  1     1\t\t只有执行\n0\t 1  0     2\t\t只有写\n1\t 0\t0\t\t\t4\t\t只有读\n```\n\n读写执行对应的值分别是`1`、`2`和`4`\n\n`011`即`3`对应的权限为**写和执行**，其它以此类推。\n\n### 添加权限\n\n使用`|`来添加权限\n\n用户的权限为1(`001`，只有执行)，现在需要加上读(4, `100`)\n\n```text\n1 | 4:\n0 0 1 => 1\n1 0 0 => 4\n1 0 1 => 5\n```\n\n结果为5(`101`)对应执行和读的权限\n\n### 删除权限\n\n使用`^`来删除权限\n\n用户的权限为7(`111`)，需要删除写(2, `010`)的权限\n\n```text\n7 ^ 2:\n1 1 1 => 7\n0 1 0 => 2\n1 0 1\t=> 5\n```\n\n结果为5(`101`)，对应执行和读的权限\n\n### 判断权限\n\n当拿到用户权限时，使用`&`来判断用户的权限\n\n用户的权限是6（`110`，读和写）\n\n`110` & `001` = `000`， 表示**没有**执行权限 \n\n`110` & `010` = `010`， 表示**有**写的权限\n\n`110` & `100` = `100`， 表示**有**读的权限 \n\n只有&后的结果等于所需判断的权限，就表示有该权限\n\n## 权限数的限制\n\n每增加一位权限，就需要多一位二进制位。\n\nJavaScript 将数字存储为 64 位浮点数，但所有按位运算都以 32 位二进制数执行。\n\n- 在执行位运算之前，JavaScript 将数字转换为 32位有符号整数。\n\n- 执行按位操作后，结果将转换回 64 位 JavaScript 数。\n\n所以，js中最多能配置32种权限(`1` `1 << 1`....`1 << 31`)。`1 << 32`等于`1`\n\n使用`BigInt`能够表示更多的权限。\n\n`1n << 33n => 8589934592n`","tags":["javascript","位运算"],"categories":["JavaScript"]},{"title":"Rust学习笔记-Struct","url":"/posts/a574aaab.html","content":"\n本系列文章是笔者学习`Rust`时所做的笔记，供日后翻阅复习。\n\n## 定义Struct\n\n使用`struct`来定义一个结构体，结构体是`key-value`集合。`key`是字段名, `value`是类型。\n\n```rust\nstruct User {\n  username: String,\n  email: String,\n  sign_in_count: u64,\n  active: bool,\n}\n```\n\n> `Strut`的存在 类似其他语言的`class`\n\n## 实例化Struct\n\n实例化时，需要提供初始参数。\n\n```rust\nlet user = User {\n  email: String::from(\"someone@example.com\"),\n  username: String::from(\"someusername123\"),\n  active: true,\n  sign_in_count: 1,\n};\n```\n\n默认，user是`immutable`，如果需要`mutable`，在定义时加上`mut`\n\n```rust\nlet mut user = User {\n  email: String::from(\"someone@example.com\"),\n  username: String::from(\"someusername123\"),\n  active: true,\n  sign_in_count: 1,\n};\n\nuser.username = String::from(\"zxfan\")\n```\n\n如果加上`mut`那么，整个实例都是可变的。`rust`不允许指定字段是可变的。\n\n### 工厂模式实例化\n\n采用工厂模式来实例化Struct\n\n```rust\nfn build_user(email: String, username: String) -> User {\n  User {\n    email,\n    username,\n    active: true,\n    sign_in_count: 1,\n  }\n}\n```\n\n`email: email`可以省略为`email`。这一特性和`JavaScript`一样。\n\n### 结构体更新语法\n\n[Struct Update Syntax](https://doc.rust-lang.org/book/ch05-01-defining-structs.html#creating-instances-from-other-instances-with-struct-update-syntax)允许创建使用一个实例来创建另一个实例\n\n```rust\nlet user1 = User {\n  email: String::from(\"someone@example.com\"),\n  username: String::from(\"someusername123\"),\n  active: true,\n  sign_in_count: 1,\n};\n\nlet user2 = User {\n  email: String::from(\"another@example.com\"),\n  username: String::from(\"anotherusername567\"),\n  ..user1\n};\n\n// owner 发生 move\n// user1 无法访问\n```\n\n通过`..`语法指定`user2`的剩余字段取`user1`的值。注意：`..`会发生`owner`的move，user1就无法再访问了\n\n## Tupple Struct\n\n没有字段名，以元组的方式定义struct\n\n```rust\nstruct Color(i32, i32, i32);\nstruct Point(i32, i32, i32);\n\nlet black = Color(0, 0, 0);\nlet origin = Point(0, 0, 0);\n\nbalck.0 // 访问\n```\n\n通过`.`来访问其元素\n\n> 默认情况下，`struct`字段值不能是引用(`References `)。\n>\n> 在指定有`lifetime`的情况下，可以在结构体中使用引用。生命周期能够确保只有struct有效，那么其strutct内的应用也有效\n\n## 使用派生特性添加使用功能\n\n当使用`println!`直接输出一个结构体，会报错！\n\n```rust\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n\nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n\n    println!(\"rect1 is {}\", rect1);\n}\n\n/*\n  --> src/main.rs:12:29\n   |\n12 |     println!(\"rect1 is {}\", rect1);\n   |                             ^^^^^ `Rectangle` cannot be formatted with the default formatter\n   |\n   = help: the trait `std::fmt::Display` is not implemented for `Rectangle`\n   = note: in format strings you may be able to use `{:?}` (or {:#?} for pretty-print) instead\n   = note: required by `std::fmt::Display::fmt`\n   = note: this error originates in a macro (in Nightly builds, run with -Z macro-backtrace for more info)\n*/\n```\n\n**`Rectangle` cannot be formatted with the default formatter**。利用派生特性可以解决struct输出的问题。\n\n`#[derive(Debug)]`：将`Debug`特性派生到自定义类型（结构体）中\n\n```rust\n// #声明注解\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n\nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n\t\t\n  \t// 在输出时，加上{:?}\n    println!(\"rect1 is {:?}\", rect1);\n}\n```\n\n两种输出：\n\n- `{:?}`: 输出`rect1 is Rectangle { width: 30, height: 50 }`\n\n- `{:#?}`: 格式化输出\n\n  ```tex\n  rect1 is Rectangle {\n      width: 30,\n      height: 50,\n  }\n  ```\n\n## 结构体方法\n\n`struct`类似其它语言的`class`。类有成员方法。`stuct`也有类型概念。使用`impl`（implement）关键字来给`struct`添加成员方法\n\n```rust\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n\nimpl Rectangle {\n    fn area(&self) -> u32 {\n        self.width * self.height\n    }\n}\n\nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n\n    println!(\n        \"The area of the rectangle is {} square pixels.\",\n        rect1.area()\n    );\n}\n\n```\n\n结构体方法的第一个参数必定为`self`，它是`struct`实例。加上`&`是因为只需要引用。\n\n使用时直接用`.`调用，无需考虑像`C/C++`那样有`.`和`->`两种调用方式。因为`Rust`能够自动引用和解引用。\n\n> 一个impl能够声明多个方法，一个struct也能有多个impl\n\n## 关联函数\n\n`impl`能够声明不以`self`作为参数的函数，被称为`关联函数`。可以理解成其他语言的**静态方法**\n\n```rust\nimpl Rectangle {\n    fn square(size: u32) -> Rectangle {\n        Rectangle { width: size, height: size }\n    }\n}\n\n// 调用\nlet sq = Rectangle::square(3)\n```\n\n使用`::`来调用关联函数。\n\n","tags":["Rust","语言学习"],"categories":["Rust"]},{"title":"前端性能指标","url":"/posts/d43bedc2.html","content":"\n## 性能指标\n\n`google`的**Core Web Vitals**主要由三个性能指标组成\n\n- `LCP(Largest Contentful Paint)`：最大内容绘制\n\n- `FID(First Input Delay)`：首次输入延迟\n\n- `CLS(Cumlative Layout Shift)`：累积布局偏移\n\n除此之外，还有一些常见性能指标：\n\n- `FCP(First Contentful Paint)`：首次内容绘制\n\n- `TTFB(Time to First Byte)`：首字节时间\n\n## Web Vitals\n\n`Web Vitals`是`google`发起的倡议，为web性能提供统一的衡量标准。它有三部分组成——`LCP`、`FID`和`CLS`。\n\n![web vitals](../../images/Performance/web-vitals.png)\n\n- **Largest Contentful Paint (LCP)**: 用于衡量加载性能。考虑到用户体验，LCP应该在**2.5s**内\n- **First Input Delay (FID)**: 用来衡量网站的交互性。考虑到用户体验，FID应该小于**100ms**\n- **Cumulative Layout Shift (CLS)**: 用来衡量网站的视觉稳定性。考虑到用户体验，CLS应该小于**0.1**\n\n衡量一个网站的性能：如果一个网站有**75%**的页面能达到`GOOD`标准，那么该网站就满足`GOOD`级别的性能。\n\n这三个性能数据都可以通过\n\n- `Google`开源的[web-vitals](https://www.npmjs.com/package/web-vitals)\n- `lighthouse`\n\n来测量。\n\n## [Largest Contentful Paint(LCP)](https://web.dev/lcp/)\n\n最大内容绘制时间是指网页最大图像/文本块的绘制时间。当一个页面的**最大丰富内容元素**绘制完成了，就几乎可以认为是该页面渲染完成。LCP认为的**最大丰富内容元素**有：\n\n- `img`元素\n- `svg`里的`image`元素\n- `video`元素\n- `css`中`url()`加载的图片\n- 包含文本元素的块级元素\n\n### 分阶段加载\n\n页面的加载是分阶段的，页面上的最大元素可能会发生变化。\n\n当页面首帧绘制完毕后，浏览器会实例一个化[`PerformanceEntry`](https://developer.mozilla.org/en-US/docs/Web/API/PerformanceEntry)对象，并且将其`entryType`属性设置为`largest-contentful-paint`。用于标识首帧元素的绘制\n\n当页面出现新的最大元素时，又会再创建一个`PerformancenEntry`对象。如何有任何元素大于大于上一个最大元素，就会创建一个`PerformanceEntry`对象\n\n![lcp vs fcp](../../images/Performance/lcpvsfcp.png)\n\nFCP是值首次内容绘制时间，指的是页面出现第一个绘制完成元素的时间。所以FCP比LCP要快。\n\n### 影响LCP的因素\n\n- 服务端响应慢\n- css和js阻塞渲染\n- 资源加载时间\n- 客户端渲染\n\n## [First Input Delay](https://web.dev/fid/)\n\n首次输入延迟（FID）度量标准有助于衡量用户对网站的交互性和响应性的第一印象。\n\nFID衡量的是从用户首次与页面进行交互（即当他们单击链接，点击按钮或使用自定义的JavaScript事件）到浏览器实际上能够开始处理事件处理程序的时间\n\n> FID仅在事件处理中测量“延迟”。它不会测量事件处理时间本身。\n\n![fid](../../images/Performance/fid.svg)\n\n当用户**第一次与页面交互**（例如点击页面）。但是这时**JS线程**正在执行，它会阻塞渲染线程的执行，所以此时，页面是没有给用户反馈的。这段时间就是**FID**\n\n要再强调**首次**，FID只衡量第一次的交互。第一个输入延迟将是用户对您网站的响应度的第一印象，而第一印象对于塑造我们对网站质量和可靠性的整体印象至关重要。\n\n再次强调FID只测量**输入延迟**，记录首次交互到事件开始的事件，并不记录事件执行的事件。\n\n## [Cumlative Layout Shift](https://web.dev/cls/)\n\n累积布局偏移会测量在页面整个生命周期中发生的每个*意外的布局移位*的所有个别*布偏移分数*的总和\n\n**布局偏移**是指页面上的课件元素下一阵偏移到其它位置。\n\n### 布局偏移分数\n\n`Layout Shift Score`计算，是通过视窗口中两个渲染帧之间元素的运动，取该运动中两个度量的乘积：**冲击分数（Impact Fraction）**和**距离分数（Distance Fraction）**\n\n$layout shift score = impact fraction * distance fraction$\n\n### Impact Fraction\n\n![impact fraction](../../images/Performance/impact_fraction.png)\n\n在上图中，有一个元素在一帧中占据了视口的一半。然后，在下一帧中，元素下移视口高度的25％。红色的虚线矩形表示两个帧中元素的可见区域的并集，在这种情况下，其为总视口的75％，因此其*影响分数*为`0.75`。\n\n### Distance Fraction\n\n![distance_fraction.png](../../images/Performance/distance_fraction.png)\n\n在上面的示例中，最大视口尺寸是高度，不稳定元素已移动了视口高度的25％，这使得*距离分数*为0.25。\n\n因此，在此示例中，*碰撞分数*为`0.75`，*距离分数*为`0.25`，因此*布局偏移分数*为`0.75 * 0.25 = 0.1875`。\n\n### [如何改善CLS ](https://web.dev/cls/#how-to-improve-cls)\n\n对于大多数网站，可以遵循一些指导原则来避免所有意外的布局变化：\n\n- **务必确保图片和视频元素有正确的尺寸**，通过`padding-top`实现**宽高等比例**，容器内容使用**绝对定位**\n- **除非响应用户交互，否则切勿在现有内容上方插入内容。**这样可以确保可以预期发生任何版式移位。\n- **与将动画（animation）触发布局更改的属性动画相比，转换（transform）动画更可取。**对过渡进行动画处理，以提供状态与状态之间的上下文和连续性。\n\n## First Contentful Paint\n\n**首次内容绘制**衡量页面开始加载到页面首个元素渲染完成的事件。通常可以用来代表网页的白屏时间。通常`LCP`时间是大于或等于`FCP`时间\n\n## Time To First Bytes\n\n**首字节时间**是指客户端（浏览器）接收到服务端发来的第一个字节所经历的时间。包括**DNS解析**、**TCP三次握手**、**TLS协商**以及**服务端处理请求**\n\n## 其它性能数据\n\n通过`performance`对象，能获取到详细的网页性能数据\n\n`performance.timing`对象结构：\n\n```typescript\ninterface PerformanceTiming {\n    readonly connectEnd: number;\n    readonly connectStart: number;\n    readonly domComplete: number;\n    readonly domContentLoadedEventEnd: number;\n    readonly domContentLoadedEventStart: number;\n    readonly domInteractive: number;\n    readonly domLoading: number;\n    readonly domainLookupEnd: number;\n    readonly domainLookupStart: number;\n    readonly fetchStart: number;\n    readonly loadEventEnd: number;\n    readonly loadEventStart: number;\n    readonly navigationStart: number;\n    readonly redirectEnd: number;\n    readonly redirectStart: number;\n    readonly requestStart: number;\n    readonly responseEnd: number;\n    readonly responseStart: number;\n    readonly secureConnectionStart: number;\n    readonly unloadEventEnd: number;\n    readonly unloadEventStart: number;\n    toJSON(): any;\n}\n```\n\n\ntiming对象提供了各种与浏览器处理相关的时间数据。具体如下表\n\n| 名称                       | 作用（这里所有时间戳都代表UNIX毫秒时间戳）                   |\n| -------------------------- | ------------------------------------------------------------ |\n| connectEnd                 | 浏览器与服务器之间的连接建立时的时间戳，连接建立指的是所有握手和认证过程全部结束 |\n| connectStart               | HTTP请求开始向服务器发送时的时间戳，如果是持久连接，则等同于fetchStart。 |\n| domComplete                | 当前网页DOM结构生成时，也就是Document.readyState属性变为“complete”,并且相应的readystatechange事件触发时的时间戳。 |\n| domContentLoadedEventEnd   | 当前网页DOMContentLoaded事件发生时，也就是DOM结构解析完毕、所有脚本运行完成时的时间戳。 |\n| domContentLoadedEventStart | 当前网页DOMContentLoaded事件发生时，也就是DOM结构解析完毕、所有脚本开始运行时的时间戳。 |\n| domInteractive             | 当前网页DOM结构结束解析、开始加载内嵌资源时，也就是Document.readyState属性变为“interactive”、并且相应的readystatechange事件触发时的时间戳。 |\n| domLoading                 | 当前网页DOM结构开始解析时,也就是Document.readyState属性变为“loading”、并且相应的readystatechange事件触发时的时间戳。 |\n| domainLookupEnd            | 域名查询结束时的时间戳。如果使用持久连接，或者从本地缓存获取信息的，等同于fetchStart |\n| domainLookupStart          | 域名查询开始时的时间戳。如果使用持久连接，或者从本地缓存获取信息的，等同于fetchStart |\n| fetchStart                 | 浏览器准备通过HTTP请求去获取页面的时间戳。在检查应用缓存之前发生。 |\n| loadEventEnd               | 当前网页load事件的回调函数结束时的时间戳。如果该事件还没有发生，返回0。 |\n| loadEventStart             | 当前网页load事件的回调函数开始时的时间戳。如果该事件还没有发生，返回0。 |\n| navigationStart            | 当前浏览器窗口的前一个网页关闭，发生unload事件时的时间戳。如果没有前一个网页，就等于fetchStart |\n| redirectEnd                | 最后一次重定向完成，也就是Http响应的最后一个字节返回时的时间戳。如果没有重定向，或者上次重定向不是同源的。则为0 |\n| redirectStart              | 第一次重定向开始时的时间戳，如果没有重定向，或者上次重定向不是同源的。则为0 |\n| requestStart               | 浏览器向服务器发出HTTP请求时（或开始读取本地缓存时）的时间戳。 |\n| responseEnd                | 浏览器从服务器收到（或从本地缓存读取）最后一个字节时（如果在此之前HTTP连接已经关闭，则返回关闭时）的时间戳 |\n| responseStart              | 浏览器从服务器收到（或从本地缓存读取）第一个字节时的时间戳。 |\n| secureConnectionStart      | 浏览器与服务器开始安全链接的握手时的时间戳。如果当前网页不要求安全连接，则返回0。 |\n| unloadEventEnd             | 如果前一个网页与当前网页属于同一个域下，则表示前一个网页的unload回调结束时的时间戳。如果没有前一个网页，或者之前的网页跳转不是属于同一个域内，则返回值为0。 |\n| unloadEventStart           | 如果前一个网页与当前网页属于同一个域下，则表示前一个网页的unload事件发生时的时间戳。如果没有前一个网页，或者之前的网页跳转不是属于同一个域内，则返回值为0。 |\n\n**常用指标计算公式如下**\n\n1. DNS解析耗时: domainLookupEnd - domainLookupStart\n2. TCP连接耗时: connectEnd - connectStart\n3. SSL安全连接耗时: connectEnd - secureConnectionStart\n4. 网络请求耗时(TTFB): responseStart - requestStart\n5. 数据传输耗时: responseEnd - responseStart\n6. DOM解析耗时: domInteractive - responseEnd\n7. 资源加载耗时: loadEventStart - domContentLoadedEventEnd\n8. 首包时间: responseStart - domainLookupStart\n9. 首次渲染时间 / 白屏时间: responseEnd - fetchStart\n10. 首次可交互时间: domInteractive - fetchStart\n11. DOM Ready时间: domContentLoadEventEnd - fetchStart\n12. 页面完全加载时间: loadEventStart - fetchStart\n\n","tags":["网络","Nodejs"],"categories":["experience"]},{"title":"vue3-依赖注入","url":"/posts/dafb6b4a.html","content":"\n## 如何使用\n\n在`setup`中使用：\n\n```typescript\n// 生产组件\nimport { defineComponent, provide, inject, ref } from \"vue\";\n\ndefineComponent({\n  setup() {\n    const name = ref(\"name\");\n    provide(\"name\", name);\n  },\n});\n\n// 消费组件\ndefineComponent({\n  setup() {\n    const name = inject(\"name\"); // 会保留响应式\n    return { name };\n  },\n});\n\n```\n\n全局`provide`\n\n```typescript\nimport { createApp } from \"vue\";\n\nconst app = createApp()\n\napp.provide(name, 'ZXFAN')\n```\n\n## 处理过程\n\n在**父组件**的`setup`中使用`provide`函数，会在放在组件实例上的`provides`对象上。**注意：每个组件实例上的`provides`对象的原型对象都是其父组件的`provides`对象**，根组件的原型对象为null。这样在查找时，就会自动在原型链上寻找。\n\n在**子组件**的`setup`中使用`inject`函数，会在组件实例上找，实例上没有就去**原型链**（父组件的`provides`对象）去找。\n\n全局`provide`即`app.provide(xx, xx)`的形式，会将注入的内容存放在上下文对象的`providers`上\n\n## `provides`原型链的形成\n\n具有嵌套的组件的provides对象构成了原型链，这是为了方便做查找操作\n\n原型链的最顶是null，这是在创建应用上下文对象时初始化的。\n\n```typescript\n// runtime-core/src/apiCreateApp.ts\n\nexport function createAppContext(): AppContext {\n  return {\n    app: null as any,\n    config: {\n      isNativeTag: NO,\n      performance: false,\n      globalProperties: {},\n      optionMergeStrategies: {},\n      isCustomElement: NO,\n      errorHandler: undefined,\n      warnHandler: undefined\n    },\n    mixins: [],\n    components: {},\n    directives: {},\n    provides: Object.create(null)\n  }\n}\n```\n\n`Object.create(null)`会创建并返回一个空对象，并且将这个空对象的原型对象设置为参数`null`。\n\n然后是组件实例创建时，会自动初始化`provides`对象。\n\n```typescript\nexport function createComponentInstance(\n  vnode: VNode,\n  parent: ComponentInternalInstance | null,\n  suspense: SuspenseBoundary | null\n) {\n  // ...\n\n  const instance: ComponentInternalInstance = {\n    // ...\n    provides: parent ? parent.provides : Object.create(appContext.provides),\n    // ...\n  }\n  //...\n\n  return instance\n}\n```\n\n显示判断**是否存在父组件**，若存在直接取父组件的**provides对象**\n若没有父组件，则说明是**根组件**，则取**上下文对象**的**provides对象**\n\n## provide函数\n\n```typescript\n// runtime-core/src/apiInject.ts\n\nexport function provide<T>(key: InjectionKey<T> | string | number, value: T) {\n  if (!currentInstance) {\n    if (__DEV__) {\n      warn(`provide() can only be used inside setup().`)\n    }\n  } else {\n    let provides = currentInstance.provides\n    // 默认，实例会继承其父组件的原型对象\n    // 当组件本身需要provide，它会创建自己的provides对象，并将父组件的provides对象设为其原型对象\n    // 这样在使用inject函数注入时，就能利用原型链自动向父组件查找。\n    const parentProvides =\n      currentInstance.parent && currentInstance.parent.provides\n    if (parentProvides === provides) {\n      provides = currentInstance.provides = Object.create(parentProvides)\n    }\n    // TS doesn't allow symbol as index type\n    provides[key as string] = value\n  }\n}\n```\n\n当`parentProvides === provides`为`true`时，说明这是当前组件第一次调用`provide`函数。因为如果一个组件不需要provide，那么实例的`provides`就指向其父组件的`provides`对象。这样就缩短了原型链的长度。\n\n## inject函数\n\n```typescript\nexport function inject(\n  key: InjectionKey<any> | string,\n  defaultValue?: unknown,\n  treatDefaultAsFactory = false\n) {\n  // fallback to `currentRenderingInstance` so that this can be called in\n  // a functional component\n  const instance = currentInstance || currentRenderingInstance\n  if (instance) {\n    // #2400\n    // to support `app.use` plugins,\n    // fallback to appContext's `provides` if the intance is at root\n    const provides =\n      instance.parent == null\n        ? instance.vnode.appContext && instance.vnode.appContext.provides\n        : instance.parent.provides\n\n    if (provides && (key as string | symbol) in provides) {\n      // TS doesn't allow symbol as index type\n      return provides[key as string]\n    } else if (arguments.length > 1) {\n      return treatDefaultAsFactory && isFunction(defaultValue)\n        ? defaultValue()\n        : defaultValue\n    } else if (__DEV__) {\n      warn(`injection \"${String(key)}\" not found.`)\n    }\n  } else if (__DEV__) {\n    warn(`inject() can only be used inside setup() or functional components.`)\n  }\n}\n```\n\ninject就是去`provides`对象找对应`key`的过程。\n注意：这里判断`instance.parent == null`是来判断当前组件是不是根组件。","tags":["vue"],"categories":["源码"]},{"title":"vue3-指令","url":"/posts/c445157e.html","content":"\n## 如何使用\n\n在根实例上**注册全局指令**\n\n```typescript\nimport { createApp } from \"vue\"\nimport App from 'app.vue'\n\nconst app = createApp(App)\n\napp.derectives(\"focus\", {\n  // ...\n})\n```\n\n通过选项来**注册局部指令**\n\n```typescript\nimport { defineComponent } from \"vue\"\n\ndefineComponent({\n  // ...\n  directives: {\n    focus: {\n      // ...\n    }\n  }\n  //...\n})\n```\n\n在template中使用：\n\n```vue\n<template>\n\t<input v-focus />\n</template>\n```\n\n在render函数中使用\n\n```typescript\nimport { defineComponent, h, withDirectives, vShow } from \"vue\"\n\ndefineComponent({\n  // ...\n  data: {\n    value: true\n  },\n  render() {\n   \treturn withDirectives(h(\"input\"), [vShow, this.value])\n  }\n  //...\n})\n```\n\n`withDirectives`的函数签名：\n\n- 第一个参数是VNode\n- 第二个参数是指令（可以是自定义指令）\n\n```typescript\nfunction withDirectives<T extends VNode<RendererNode, RendererElement, {\n    [key: string]: any;\n}>>(vnode: T, directives: DirectiveArguments): T\n```\n\n## 指令生命周期\n\n指令有两种类型——对象和函数\n\n```typescript\nexport type Directive<T = any, V = any> =\n  | ObjectDirective<T, V>\n  | FunctionDirective<T, V>\n\n\nexport interface ObjectDirective<T = any, V = any> {\n  created?: DirectiveHook<T, null, V>\n  beforeMount?: DirectiveHook<T, null, V>\n  mounted?: DirectiveHook<T, null, V>\n  beforeUpdate?: DirectiveHook<T, VNode<any, T>, V>\n  updated?: DirectiveHook<T, VNode<any, T>, V>\n  beforeUnmount?: DirectiveHook<T, null, V>\n  unmounted?: DirectiveHook<T, null, V>\n  getSSRProps?: SSRDirectiveHook\n}\n\nexport type FunctionDirective<T = any, V = any> = DirectiveHook<T, any, V>\n```\n\n对象就是声明指令的每个生命周期\n\n函数，只会生命`mounted`和`update`\n\n> 一个指令定义对象可以提供如下几个钩子函数 (均为可选)：\n>\n> - `created`：在绑定元素的 attribute 或事件监听器被应用之前调用。在指令需要附加须要在普通的 `v-on` 事件监听器前调用的事件监听器时，这很有用。\n> - `beforeMount`：当指令第一次绑定到元素并且在挂载父组件之前调用。\n> - `mounted`：在绑定元素的父组件被挂载后调用。\n> - `beforeUpdate`：在更新包含组件的 VNode 之前调用。\n>\n> - `updated`：在包含组件的 VNode **及其子组件的 VNode** 更新后调用。\n> - `beforeUnmount`：在卸载绑定元素的父组件之前调用\n> - `unmounted`：当指令与元素解除绑定且父组件已卸载时，只调用一次。\n\n## 处理过程\n\n全局注册指令，会在**上下文对象**上的**directives（Array类型）**中添加指令\n\n局部指令注册，会将指令存放在**组件实例**\n\n在`template`中使用指令，构建工具将其转换成`render函数`。\n\n运行时，先去app上下文或者组件实例上寻找指令。然后将指令绑定到`VNode`。每个`VNode`都会有一个`dirs`数组，用来存放绑定到该`VNode`的全部指令。\n\n最后在各个阶段执行指令相应的生命周期函数\n\n## 注册流程\n\n### 全局注册\n\n```typescript\nimport { createApp } from \"vue\"\nimport App from 'app.vue'\n\nconst app = createApp(App)\n\napp.derectives(\"focus\", {\n  // ...\n})\n```\n\n指令全局注册是通过`createApp`函数返回的app对象上的**directives方法**来注册的\n\n观察一下**createApp函数**\n\n```typescript\n// runtime-core/src/apiCreateApp.ts\n\nexport function createAppAPI<HostElement>(\n  render: RootRenderFunction,\n  hydrate?: RootHydrateFunction\n): CreateAppFunction<HostElement> {\n  return function createApp(rootComponent, rootProps = null) {\n\n    const context = createAppContext()\n    const installedPlugins = new Set()\n\n    let isMounted = false\n\n    const app: App = (context.app = {\n      // 省略其它代码...\n      directive(name: string, directive?: Directive) {\n        if (__DEV__) {\n          validateDirectiveName(name)\n        }\n\n        if (!directive) {\n          return context.directives[name] as any\n        }\n        if (__DEV__ && context.directives[name]) {\n          warn(`Directive \"${name}\" has already been registered in target app.`)\n        }\n        context.directives[name] = directive\n        return app\n      }\n      // 省略其它代码...\n    })\n\n    return app\n  }\n}\n```\n\ndirective函数做了三件事\n\n- 通过`validateDirectiveName`函数吗，判断是否是内置指令(`v-if`、`v-show`等)。如果是，在开发环境下会报一个警告\n- 如果只传了`name`，认为是取指令操作并返回对应name的指令。如果传了`directive`则认为是注册指令操作\n- 注册指令：在`context.directives`对象上保存指令\n\n> `context`是一个上下文对象。通过`createAppContext`函数创建的\n\n### 局部注册\n\n选择局部注册的方式，指令写在`directives选项`中。单文件组件会通过构建工具生成**组件实例**，也等价于**defineComponent**。在生成`VNode`时，将组件实例绑定到`VNode`的`type`属性上。\n\n局部注册的指令存放在组件实例上。后续会通过`VNode.type.directives`来访问指令\n\n## 绑定与执行\n\n在template模版上使用指令，如：\n\n```vue\n<template>\n\t<input v-focus />\n</template>\n```\n\n构建工具编译生成**render函数**：\n\n```javascript\nimport { resolveDirective as _resolveDirective, createVNode as _createVNode, withDirectives as _withDirectives, openBlock as _openBlock, createBlock as _createBlock } from \"vue\"\n\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  const _directive_focus = _resolveDirective(\"focus\")\n\n  return _withDirectives((_openBlock(), _createBlock(\"input\", null, null, 512 /* NEED_PATCH */)), [\n    [_directive_focus]\n  ])\n}\n\n```\n\n可以看出，render内调用了两个方法：\n\n- `_resolveDirective`：接受指令名称作为参数。该函数的作用是去app上下文或者组件实例上寻找指令\n- `_withDirectives`：将指令绑定到VNode上。\n\n### 解析指令\n\n解析指令找到需要使用的指令，也就是`resolveDirective`的过程。分析源码，发现`resolveDirective`调用`resolveAsset`。\n\n```typescript\n// runtime-core/helpers/resolveAssets.ts\n\nconst COMPONENTS = 'components'\nconst DIRECTIVES = 'directives'\n\nexport function resolveDirective(name: string): Directive | undefined {\n  return resolveAsset(DIRECTIVES, name)\n}\n\nfunction resolveAsset(\n  type: typeof COMPONENTS | typeof DIRECTIVES,\n  name: string,\n  warnMissing = true\n) {\n  const instance = currentRenderingInstance || currentInstance\n  if (instance) {\n    const Component = instance.type\n\n    // 省略 组件处理...\n\n    const res =\n      // 局部注册\n      // check instance[type] first for components with mixin or extends.\n      resolve(instance[type] || (Component as ComponentOptions)[type], name) ||\n      // 全局注册\n      resolve(instance.appContext[type], name)\n    \n    return res\n  }\n}\n\nfunction resolve(registry: Record<string, any> | undefined, name: string) {\n  return (\n    registry &&\n    (registry[name] ||\n      registry[camelize(name)] ||\n      registry[capitalize(camelize(name))])\n  )\n}\n```\n\n`instance`是组件实例，`instance.type`等于`VNode.type`即组件实例（也就是注册局部指令的地方）。`instance.appContext`是全局上下文（也就是注册全局指令的地方）\n\n解析组件的过程：\n\n- 先寻找局部注册的指令，在组件实例`instance`上寻找，找不到去组件实例（`instance.type`）去找。\n- 如果找不到局部注册指令，就寻找全局注册指令。直接在上下文对象`intance.appContext`上找\n\n> 可以发现，局部注册的指令会覆盖全局注册指令。\n\n### 绑定指令\n\n绑定指令到VNode是通过`withDirectives`函数实现的\n\n```typescript\n// runtime-cor/src/directives.ts\n\nexport type DirectiveArguments = Array<\n  | [Directive]\n  | [Directive, any]\n  | [Directive, any, string]\n  | [Directive, any, string, DirectiveModifiers]\n>\n\n/**\n * Adds directives to a VNode.\n */\nexport function withDirectives<T extends VNode>(\n  vnode: T,\n  directives: DirectiveArguments\n): T {\n  const internalInstance = currentRenderingInstance\n  if (internalInstance === null) {\n    __DEV__ && warn(`withDirectives can only be used inside render functions.`)\n    return vnode\n  }\n  const instance = internalInstance.proxy\n  const bindings: DirectiveBinding[] = vnode.dirs || (vnode.dirs = [])\n  for (let i = 0; i < directives.length; i++) {\n    let [dir, value, arg, modifiers = EMPTY_OBJ] = directives[i]\n    if (isFunction(dir)) {\n      dir = {\n        mounted: dir,\n        updated: dir\n      } as ObjectDirective\n    }\n    bindings.push({\n      dir,\n      instance,\n      value,\n      oldValue: void 0,\n      arg,\n      modifiers\n    })\n  }\n  return vnode\n}\n```\n\n`withDirectives`函数遍历了`directives`数组，并将其元素绑定到`VNode.dirs`上。\n\n**特别注意**：如果指令是一个函数，只会给`mounted`和`updated`赋值，并且执行逻辑是一样的。\n\n指令对象的结构：\n\n- `instance`：使用指令的组件实例。\n- `value`：传递给指令的值。例如，在 `v-my-directive=\"1 + 1\"` 中，该值为 `2`。\n- `oldValue`：先前的值，仅在 `beforeUpdate` 和 `updated` 中可用。值是否已更改都可用。\n- `arg`：参数传递给指令 (如果有)。例如在 `v-my-directive:foo` 中，arg 为 `\"foo\"`。\n- `modifiers`：包含修饰符 (如果有) 的对象。例如在 `v-my-directive.foo.bar` 中，修饰符对象为 `{foo: true，bar: true}`。\n- `dir`：一个对象，在注册指令时作为参数传递。例如，在以下指令中\n\n### 执行指令\n\n指令绑定到`VNode`后，就会在相应的时候调用指令\n\n观察指令的类型签名，有两种——对象指令，和函数指令。其中对象指令声明了很多`hook(钩子函数)`，这些是指令的生命周期。\n\n比如，在`mountElement`函数中就有很多触发指令的代码，例如：\n\n```typescript\n// runtime-core/src/render.ts\n\n// function mountElement\n\nif (dirs) {\n  invokeDirectiveHook(vnode, null, parentComponent, 'created')\n}\n```\n\n`invokeDirectiveHook`是用来触发指令，它和`withDirectives`都位于`runtime-core/src/directives.ts`文件中。\n\n```typescript\nexport function invokeDirectiveHook(\n  vnode: VNode,\n  prevVNode: VNode | null,\n  instance: ComponentInternalInstance | null,\n  name: keyof ObjectDirective\n) {\n  const bindings = vnode.dirs!\n  const oldBindings = prevVNode && prevVNode.dirs!\n  for (let i = 0; i < bindings.length; i++) {\n    const binding = bindings[i]\n    if (oldBindings) {\n      binding.oldValue = oldBindings[i].value\n    }\n    const hook = binding.dir[name] as DirectiveHook | undefined\n    if (hook) {\n      callWithAsyncErrorHandling(hook, instance, ErrorCodes.DIRECTIVE_HOOK, [\n        vnode.el,\n        binding,\n        vnode,\n        prevVNode\n      ])\n    }\n  }\n}\n```\n\n每个生命周期钩子的执行都会传入4个参数\n\n- `el`： vnode对应的element元素\n- `binding`：当前vnode绑定的所有指令对象\n- `vnode`：虚拟节点\n- `prevVNode`：上一个虚拟节点，仅在 `beforeUpdate` 和 `updated` 钩子中可用\n\n## v-model指令\n\nvue内置了众多指令，其中`v-model`用来实现**双向绑定**。\n\n### v-model不是单指一个指令\n\n当在template中使用v-model:\n\n```vue\n<input v-model=\"username\"/>\n<input type=\"radio\" v-model=\"gender\"/>\n<input type=\"checkbox\" v-model=\"gender\"/>\n\n<!-- 自定义组件 -->\n<my-component v-model=\"isShow\"/>\n```\n\n被构建工具编译后的渲染函数\n\n```javascript\nimport { vModelText as _vModelText, createVNode as _createVNode, withDirectives as _withDirectives, vModelRadio as _vModelRadio, vModelCheckbox as _vModelCheckbox, resolveComponent as _resolveComponent, Fragment as _Fragment, openBlock as _openBlock, createBlock as _createBlock } from \"vue\"\n\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  const _component_my_component = _resolveComponent(\"my-component\")\n\n  return (_openBlock(), _createBlock(_Fragment, null, [\n    _withDirectives(_createVNode(\"input\", {\n      \"onUpdate:modelValue\": $event => (_ctx.username = $event)\n    }, null, 8 /* PROPS */, [\"onUpdate:modelValue\"]), [\n      [_vModelText, _ctx.username]\n    ]),\n    _withDirectives(_createVNode(\"input\", {\n      type: \"radio\",\n      \"onUpdate:modelValue\": $event => (_ctx.gender = $event)\n    }, null, 8 /* PROPS */, [\"onUpdate:modelValue\"]), [\n      [_vModelRadio, _ctx.gender]\n    ]),\n    _withDirectives(_createVNode(\"input\", {\n      type: \"checkbox\",\n      \"onUpdate:modelValue\": $event => (_ctx.gender = $event)\n    }, null, 8 /* PROPS */, [\"onUpdate:modelValue\"]), [\n      [_vModelCheckbox, _ctx.gender]\n    ]),\n    _createVNode(_component_my_component, {\n      modelValue: _ctx.isShow,\n      \"onUpdate:modelValue\": $event => (_ctx.isShow = $event)\n    }, null, 8 /* PROPS */, [\"modelValue\", \"onUpdate:modelValue\"])\n  ], 64 /* STABLE_FRAGMENT */))\n}\n\n// Check the console for the AST\n```\n\n可以观察到，渲染函数使用`withDirectives`分别给三个`input`元素绑定了三个指令`vModelText`、`vModelRadio`、`vModelCheckbox`。然而并未给**组件**绑定指令。\n\n### 不同元素的v-model行为不一样\n\n针对不同元素，实现双向绑定的方式不同。默认情况下:\n\n- 针对组件，传递`modelValue`，并监听`update:modelValue`事件\n- 针对文本输入框，`vModelText`会将值绑定到`value`属性，并监听`input`或`chang`(有lazy修饰符)事件\n- 针对单选按钮和复选框，`vModelRadio`和`vModelCheckobx`都会将值绑定到`checked`属性，并监听其`change`事件\n- 针对下拉框，`vModelSelect`会遍历所有`option`并对比option的value属性与v-model的值是否一致，若一致给该`option`添加`selected=true`。并监听`change`事件响应更改。\n\n这些`v-model`指令的源码位于`runtime-dom/src/directives/vModel.ts`，看一下`vModelText`的源码\n\n```typescript\n// v-model和其它指令一样会绑定到VNode上\n// 如果不使用v-model，这部分代码会被tree-shaking\nexport const vModelText: ModelDirective<\n  HTMLInputElement | HTMLTextAreaElement\n> = {\n  created(el, { modifiers: { lazy, trim, number } }, vnode) {\n    el._assign = getModelAssigner(vnode)\n    const castToNumber = number || el.type === 'number'\n    addEventListener(el, lazy ? 'change' : 'input', e => {\n      if ((e.target as any).composing) return\n      let domValue: string | number = el.value\n      if (trim) {\n        domValue = domValue.trim()\n      } else if (castToNumber) {\n        domValue = toNumber(domValue)\n      }\n      el._assign(domValue)\n    })\n    if (trim) {\n      addEventListener(el, 'change', () => {\n        el.value = el.value.trim()\n      })\n    }\n    if (!lazy) {\n      addEventListener(el, 'compositionstart', onCompositionStart)\n      addEventListener(el, 'compositionend', onCompositionEnd)\n      // Safari < 10.2 & UIWebView doesn't fire compositionend when\n      // switching focus before confirming composition choice\n      // this also fixes the issue where some browsers e.g. iOS Chrome\n      // fires \"change\" instead of \"input\" on autocomplete.\n      addEventListener(el, 'change', onCompositionEnd)\n    }\n  },\n  // set value on mounted so it's after min/max for type=\"range\"\n  mounted(el, { value }) {\n    el.value = value == null ? '' : value\n  },\n  beforeUpdate(el, { value, modifiers: { trim, number } }, vnode) {\n    el._assign = getModelAssigner(vnode)\n    // avoid clearing unresolved text. #2302\n    if ((el as any).composing) return\n    if (document.activeElement === el) {\n      if (trim && el.value.trim() === value) {\n        return\n      }\n      if ((number || el.type === 'number') && toNumber(el.value) === value) {\n        return\n      }\n    }\n    const newValue = value == null ? '' : value\n    if (el.value !== newValue) {\n      el.value = newValue\n    }\n  }\n}\n```\n\n`vModelTest`声明了三个生命周期函数——`created`、`mounted`和`beforeUpdate`\n\n- `created`\n  - 根据`lazy`来判断绑定`input`和`change`事件。在该事件下触发`VNode`上的`onUpdate:modelValue`事件来更新数据\n  - 如果绑定`trim`修饰符，每次`input`后修改`value`属性\n  - 如果没有`lazy`修饰符，会做组合键输入优化，这对中文输入很有效。在`compositionend`上触发`input`元素的`input`事件\n- `mounted`：将`v-model`的值绑定到`input`的`value`属性上\n- `beforeUpdate`：主要是对标签的一些属性进行更新\n\n","tags":["vue"],"categories":["源码"]},{"title":"手撕Promise","url":"/posts/d884e9d5.html","content":"\n## Promise快速回顾\n\n`Promise`是一个用来处理异步任务的强大的API。\n\n### 三种状态\n\n`Promise`有**三种状态**:\n\n- `pending`: 等待状态\n- `fulfilled`: 完成状态（终态）\n- `rejected`: 拒绝状态（终态）\n\n> `promise`的状态只会改变一次，从`pending`->`fullfilled`或者从`pending`->`rejected`。状态是不可逆的。\n\n### Promise原型方法\n\n一个`Promise`对象的原型有**三个方法**，它们都接受一个回调函数作为参数\n\n- `Promise.prototype.then(onFulfilled, onRejected)`：当`pending`->`fullfilled`时触发`then`的`onFulfilled`\n- `Promise.prototype.catch(onRejected)`：当`pending`->`rejected`时出发`catch`\n- `Promise.prototype.finally(onFinally)`：当状态为终态时，最后一定会触发`finally`\n\n> `then`和`catch`的回调函数一定会返回一个Promise\n>\n> - 当直接reutrn a; 相当于 return Promise.resolve(a)\n>\n> - 当直接throw err; 相当于 return Promise.reject(err)\n>\n> - 当直接return pormise；那么就返回这个promise对象\n\n### Promise的方法\n\n- [`Promise.all(iterable)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/all)\n\n  - all接受一个可迭代对象（例如数组）。每个迭代元素可以是Promise也可以不是Promise\n  - 如果迭代元素是Promise会被依次执行。\n  - 如果所有Promise成功执行，则状态修改成`fulfilled`，并将可迭代对象的所有promise返回值的数组作为成功回调的返回值，顺序跟iterable的顺序保持一致。\n  - 如果这个新的promise对象触发了失败状态（rejected），它会把iterable里第一个触发失败的promise对象的错误信息作为它的失败错误信息\n\n  > 无论最终状态是`fulfilled`还是`rejected`，`iterable`中所有Promise都会被执行。因为Promise被定义时就会执行。\n\n- [`Promise.allSettled(iterable)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/allSettled)\n\n  与`Promise.all`十分类似，区别在于：\n\n  - 当发生`rejected`时，`promise.all`直接把第一个失败的promise对象的错误信息返回而`promise.allSettled`会等所有promise全部执行后在返回\n  - 结果数组不是promise执行结果的集合，而是状态集合 [fulfilled, rejected, fulfilled]\n\n- [`Promise.any(iterable)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/any)\n\n  接收一个Promise对象的集合，当其中的一个 promise 成功，就返回那个成功的promise的值。\n\n- [`Promise.race(iterable)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/race)\n\n  当iterable参数里的任意一个子promise被成功或失败后，以这个promise返回\n\n- [`Promise.reject(reason)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/reject)\n\n  返回一个状态为失败的Promise对象，并将给定的失败信息传递给对应的处理方法\n\n- [`Promise.resolve(value)`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/resolve)\n\n  返回一个状态由给定value决定的Promise对象。\n\n  - 如果该值是thenable(即，带有then方法的对象)，返回的Promise对象的最终状态由then方法执行决定；\n  - 否则的话(该value为空，基本类型或者不带then方法的对象),返回的Promise对象状态为fulfilled，并且将该value传递给对应的then方法。\n\n  > 通常而言，如果不知道一个值是否是Promise对象，使用Promise.resolve(value) 来返回一个Promise对象,这样就能将该value以Promise对象形式使用。\n\n## 手写Promise\n\n我们要写一个符合[`Promise/A+`](https://promisesaplus.com/)规范的Promise\n\n### 基础结构\n\n先看一个如何使用的Demo\n\n```typescript\nnew FakePromise<any>((resolve, reject) => {\n  setTimeout(() => {\n    console.log(\"进入setTimeout\")\n    resolve()\n  }, 1000)\n  console.log(\"FakePromise\")\n}).then((res) => {\n  console.log(res)\n  throw \"发生错误了\"\n}).catch(err => {\n  console.log(err)\n})\n```\n\n根据api，先写出基础结构\n\n```typescript\ninterface IPromiseCallback {\n  (resolve: Function, reject: Function): void;\n}\n\n// Promise的三种状态\nconst PENDING = \"pending\";\nconst FULFILLED = \"fulfilled\";\nconst REJECTED = \"rejected\";\n\nclass FakePromise<T> {\n  private state: string; // 保存promise状态\n  private value!: T;\t// resolve的值\n  private reason: any; // reject的值\n\n  constructor(executor: IPromiseCallback) {\n    this.state = PENDING;\n\n    const resolve = (value: T) => {\n      \n    };\n    const reject = (reason?: any) => {\n      \n    };\n\n    try {\n      executor(resolve, reject);\n    } catch (err) {\n      reject(err);\n    }\n  }\n\n  then(onFulfilled: Function, onRejected: Function) {}\n  catch(onRejected: Function) {}\n}\n```\n\n当执行`new FakePromise`时，立即修改状态（Pending）。**然后执行回调**（可以看出Promise一旦被创建就会立即执行），并传入两个参数`resolve`和`reject`\n\n`FakePromise`的回调中会调用`resolve`或者`reject`函数，接下来完善`resolve`和`reject`\n\n```typescript\n// ...\n\nconst resolve = (value: T) => {\n\tsetTimeout(() => {\n    if (this.state !== PENDING) return;\n    this.value = value;\n    this.state = FULFILLED\n  })\n};\nconst reject = (reason?: any) => {\n  setTimeout(() => {\n    if (this.state !== PENDING) return;\n    this.reason = reason;\n    this.state = REJECTED\n  })\n};\n\n// ...\n```\n\n此处目前做了三个工作：\n\n- `resolve`和`reject`应该都是异步的，所以这里用`setTimout`来模拟。\n- 保存value和reason的值\n- 更改promise的状态\n\n### then\n\n由于`resolve`的执行是异步的，此时应该先调用同步的`then`\n\n```typescript\nclass FakePromise<T> {\n  //...\n  \n  private onFulfilledFns: Function[] = [];\n  private onRejectedFns: Function[] = [];\n  \n  // ...\n  \n  then(onFulfilled?: (res: T) => any, onRejected?: Function) {\n    onFulfilled = typeof onFulfilled === \"function\" ? onFulfilled : (x) => x;\n    onRejected =\n      typeof onRejected === \"function\"\n        ? onRejected\n        : (x: any) => {\n            throw x;\n          };\n    const promise = new FakePromise((resolve, reject) => {\n      switch (this.state) {\n        case FULFILLED:\n          setTimeout(() => {\n            try {\n              resolve(onFulfilled!(this.value))\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n        case REJECTED:\n          setTimeout(() => {\n            try {\n              resolve(onRejected(this.reason));\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n        case PENDING:\n          // store and wait\n          this.onFulfilledFns.push(() => {\n            try {\n              resolve(onFulfilled(this.value));\n            } catch (err) {\n              reject(err);\n            }\n          });\n          this.onRejectedFns.push(() => {\n            try {\n              resolve(onRejected(this.reason));\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n      }\n    });\n    return promise;\n  }\n  // ...\n}\n```\n\n`then`函数：\n\n- 第一步，对两个参数进行处理，如果不是函数就赋一个默认值（函数）\n- 然后定义了一个`FakePromise`并最终将其返回，因为then就是应该返回一个`Promise`，这样才能挂载多个then从而链式调用\n- 分别对每个状态进行处理，无论什么状态都是异步的\n  - `fulfilled`：直接调用`onFulfilled`，传入value并捕获起异常\n  - `rejected`：直接调用`onRejected`，传入reason并捕获起异常\n  - `pending`：说明当执行`then`时，（异步）promise还在执行。那我们就需要把回调存下来，存到`onFulfilledFns`和`onRejectedFns`中，注意它们必须是数组，因一个为`FakePromise`可以有多个`then`。等到（异步）promise执行完毕（`resolve`或者`rejected`）时再去调用。\n\n`pending`状态的回调已经保存下来了。我们需要再`resolve`和`reject`中去处理\n\n```typescript\n// ...\n\nconst resolve = (value: T) => {\n\tsetTimeout(() => {\n    if (this.state !== PENDING) return;\n    this.value = value;\n    this.state = FULFILLED\n    this.onFulfilledFns.forEach((fn) => fn()); // 添加这一行\n  })\n};\nconst reject = (reason?: any) => {\n  setTimeout(() => {\n    if (this.state !== PENDING) return;\n    this.reason = reason;\n    this.state = REJECTED\n    this.onRejectedFns.forEach((fn) => fn()); // 添加这一行\n  })\n};\n\n// ...\n```\n\n就是遍历数组，执行每一个函数。\n\n`then`的两个回调参数——`onFulfilled`和`onRejected`。的返回值有很多情况。我们目前没有对这些情况判断而是直接`resolve(x)`或者`reject(x)`（见上方代码）\n\n`Promise/A+`规范规定:\n\n- 情况 1： x 等于 promise（当前的promise对象）\n\n  抛出一个 TypeError 错误，拒绝 promise。\n\n- 情况 2：x 为 Promise 的实例\n\n  如果 x 处于等待状态，那么 promise 继续等待至 x 执行或拒绝，否则根据 x 的状态执行/拒绝 promise。\n\n- 情况 3：x 为对象或函数\n\n  该情况的核心是取出 x.then 并调用，在调用的时候将 this 指向 x。将 then 回调函数中得到结果 y 传入新的 Promise 解决过程中，形成一个递归调用。其中，如果执行报错，则以对应的错误为原因拒绝 promise。\n\n  这一步是处理拥有 then() 函数的对象或函数，这类对象或函数我们称之为“**thenable**”。注意，它只是拥有 then() 函数，并不是 Promise 实例。\n\n- 情况 4：如果 x 不为对象或函数\n\n  以 x 作为值，执行 promise。\n\n接下来根据`Promise/A+`规范来实现`resolvePromise`函数\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  private resolvePromise(\n    promise: FakePromise<any>,\n    x: any,\n    resolve: Function,\n    reject: Function\n  ) {\n      // 情况1: x等于当前promise对象，直接抛出TypeError\n      if (promise === x) {\n        return reject(new TypeError(\"x can not be equal to promise\"));\n      } \n      \n      // 情况2：x是 FakePromise的实例\n      // 取决于x的状态\n      else if (x instanceof FakePromise) {\n        if (x.state === FULFILLED) {\n          resolve(x.value);\n        } else if (x.state === REJECTED) {\n          reject(x.reason);\n        } else {\n          // PENDING\n          x.then((y) => {\n            this.resolvePromise(promise, y, resolve, reject);\n          }, reject);\n        }\n      } \n      \n      // 情况3: x是对象或者函数\n      else if (\n        x !== null &&\n        (typeof x === \"object\" || typeof x === \"function\")\n      ) {\n        // excute记录是否执行过，防止重复执行\n        let executed: boolean = false;\n        try {\n          // 取出 对象或函数（也是对象）的then属性\n          const then = x.then;\n          \n          // then是函数，执行\n          if (typeof then === \"function\") {\n            // 然后执行\n            then.call(\n              x,\n              (y: any) => {\n                if (executed) return;\n                executed = true;\n                this.resolvePromise(promise, y, resolve, reject);\n              },\n              (e: any) => {\n                if (executed) return;\n                executed = true;\n                reject(e);\n              }\n            );\n          }\n          \n          // then不是函数，直接resolve\n          else {\n            resolve(x);\n          }\n        } catch (e) {\n          if (executed) return;\n          executed = true;\n          reject(e);\n        }\n      } \n      \n      \n      // 情况4: 其他情况，直接resolve\n      else {\n        resolve(x);\n      }\n  }\n  \n  // ...\n}\n```\n\n然后修改`then`函数\n\n```typescript\nclass FakePromise<T> {\n  //...\n  \n  private onFulfilledFns: Function[] = [];\n  private onRejectedFns: Function[] = [];\n  \n  // ...\n  \n  then(onFulfilled?: (res: T) => any, onRejected?: Function) {\n    onFulfilled = typeof onFulfilled === \"function\" ? onFulfilled : (x) => x;\n    onRejected =\n      typeof onRejected === \"function\"\n        ? onRejected\n        : (x: any) => {\n            throw x;\n          };\n    const promise = new FakePromise((resolve, reject) => {\n      switch (this.state) {\n        case FULFILLED:\n          setTimeout(() => {\n            try {\n              this.resolvePromise(\n                promise,\n                onFulfilled!(this.value),\n                resolve,\n                reject\n              );\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n        case REJECTED:\n          setTimeout(() => {\n            try {\n              this.resolvePromise(\n                promise,\n                onRejected!(this.reason),\n                resolve,\n                reject\n              );\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n        case PENDING:\n          // store and wait\n          this.onFulfilledFns.push(() => {\n            try {\n              this.resolvePromise(\n                promise,\n                onFulfilled!(this.value),\n                resolve,\n                reject\n              );\n            } catch (err) {\n              reject(err);\n            }\n          });\n          this.onRejectedFns.push(() => {\n            try {\n              this.resolvePromise(\n                promise,\n                onRejected!(this.reason),\n                resolve,\n                reject\n              );\n            } catch (err) {\n              reject(err);\n            }\n          });\n          break;\n      }\n    });\n    return promise;\n  }\n}\n```\n\n把之前所有`resolve`和`reject`的地方改成调用`resolvePromise`函数，该函数接受四个参数：当前then返回的promise对象，`onFulfilled`或`onRejected`的执行结果，resolve还有reject函数\n\n### catch\n\n`catch`和`then`的第二个参数一样，用于捕获异常。\n\n当then第二个参数没传，它会被默认赋值一个异常处理函数`(x: any) => { throw x }`，这里直接抛出异常。\n\n```typescript\nnew FakePromise((resolve, reject) => {\n  // p0\n  setTimeout((() => {\n    reject('hi')\n  }, 1000))\n}).then(() => {\n  // p1\n  console.log('p1')\n  return 'p1 done'\n}).then(() => {\n  // p2\n  console.log('p2')\n  return 'p2 done'\n}).catch(err => {\n  console.log(err)\n})\n```\n\n在`p0`中reject。由于`p0`的`then`没有传`onRejected`。所以当执行then函数时，会默认赋一个抛出异常的函数。这个异常被`p1`的`try catch`捕获到了，进而`p1`也`reject`了。进而执行`p1`的**onRejected**，不过也没传，继续抛异常再reject。继续执行p2的**onRejected**。`p2`没有调用then函数了但是调用了**catch**函数。所以此时catch函数只要将其回调绑定到`then`函数的第二个参数（onRejected）上就可以被执行了。\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  catch(onRejected: Function) {\n    return this.then(undefined, onRejected);\n  }\n  \n  // ...\n}\n```\n\n调用`catch`会给当前Promise对象添加一个`then`函数并且传递了`onRejected`。\n\n> 当**promise**链中有一个环节reject了。他就会一直向下寻找**onRejected**，直到找到为止。\n>\n> 如果catch执行之后返回一个**fulfilled**的**promise**，**catch**之后的**then**继续执行\n>\n> 如果**catch**执行之后返回一个**rejected**的**promise**，继续往后寻找**onRejected**\n\n### finally\n\n无论promise最终状态是`fulfilled`还是`rejected`。`finally`都会执行。那我们在`Promise`链的最后去执行finally即可\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  finally(onFinally: Function) {\n    this.then(\n      (value: T) => {\n        onFinally();\n        return value;\n      },\n      (reason: any) => {\n        onFinally();\n        throw reason;\n      }\n    );\n  }\n  \n  // ...\n}\n```\n\n### Promise.resolve\n\n`resolve`用来讲一个普通的变量包装成`fulfilled`的`promise`对象，处理过程需要符合`Promise/A+`规范，也就是那四种情况。\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  static resolve(value: any) {\n    const promise = new FakePromise((resolve, reject) => {\n      setTimeout(() => {\n        this.prototype.resolvePromise(promise, value, resolve, reject);\n      });\n    });\n    return promise;\n  }\n  \n  // ...\n}\n```\n\n### Promise.reject\n\n`reject`用来将一个普通的变量包装成`rejected`的`promise`对象，处理过程需要符合`Promise/A+`规范，也就是那四种情况。\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  static reject(value: any) {\n    const promise = new FakePromise((resolve, reject) => {\n      reject(value);\n    });\n    return promise;\n  }\n  \n  // ...\n}\n```\n\n### Promise.all\n\n直接上代码\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  static all(it: Array<any>) {\n    const result: Array<any> = [];\n    let count = 0;\n    return new FakePromise<Array<any>>((resolve, reject) => {\n      it.forEach((cb, index) => {\n        FakePromise.resolve(cb).then((res) => {\n          count++;\n          result[index] = res;\n          if (count === it.length) resolve(result);\n        }, reject);\n      });\n    });\n  }\n  \n  // ...\n}\n```\n\n参数`it`应该是一个可迭代对象，为了简化就用数组来模拟。循环中使用`FakePromise.resolve`来将`cb`包装成`Promise`对象。当发生错误直接调用reject，。如果没有错误，当count等于it的长度（即it所有元素处理完毕）时，将结果`result`给`resolve`出去。\n\n### Promise.race\n\n`race`就更简单了，当第一个`promise`执行后就直接`resolve`\n\n```typescript\nclass FakePromise<T> {\n  // ...\n  \n  static race(it: Array<any>) {\n    return new FakePromise<any>((resolve, reject) => {\n      it.forEach((cb) => {\n        FakePromise.resolve(cb).then(res => {\n          resolve(res)\n        }, reject);\n      });\n    });\n  }\n  \n  // ...\n}\n```\n\n> 十分重要：无论`all`还是`race`。传入的所有`promise`都会执行。只是有些`promise`可能不会添加`then`或者`catch`来处理\n\n[源码](https://github.com/zxffan/playground/blob/main/fake_promise/index.ts)\n\n## async和await\n\n### 谁的语法糖？\n\n`async`和`await`是 ES2017 标准推出的用于处理异步操作的关键字。它是`Generator`函数（生成器函数）的语法糖\n\n`Generator`函数是 ES6 提出的除 Promise 之外的另一种异步解决方案。\n\n```typescript\nfunction* gen() {\n  console.log(\"first\");\n  yield 1;\n  console.log(\"second\");\n  yield 2;\n  console.log(\"third\");\n}\n\nconst iterator = gen() // 返回一个迭代器对象\n\niterator.next() // 返回 { value: 1, done: false }\niterator.next() // 返回 { value: 2, done: false }\niterator.next() // 返回 { value: undefined, done: true }\n```\n\n### async和await原理\n\n`async/await` 做的事情就是将` Generator函数`转换成` Promise`\n\n```typescript\nfunction generatorToPromise(generator: GeneratorFunction) {\n  return function () {\n    const iterator = generator.apply(this, Array.of(arguments));\n    return new Promise((resolve, reject) => {\n      function step(action: keyof typeof iterator, arg?: any): any {\n        try {\n          const { value, done } = iterator[action](arg);\n          if (done) {\n            resolve(value);\n          } else {\n            return Promise.resolve(value).then(\n              (val) => step(\"next\", value),\n              (err) => step(\"throw\", err)\n            );\n          }\n        } catch (err) {\n          return reject(err);\n        }\n      }\n\n      return step(\"next\");\n    });\n  };\n}\n```\n\n","tags":["JavaScript","Promise"],"categories":["JavaScript"]},{"title":"vue3-Emit分析","url":"/posts/9c1e6144.html","content":"\n## 如何使用\n\n`template`中绑定自定义事件\n\n```vue\n<template>\n\t<child-component @show-info=\"showInfo\" @delete.once=\"deleteItem\"/>\n</template>\n```\n\n在`child-component`子组件中使用emit\n\n`this.emit(\"show-info\")`\n\n## 处理过程\n\nvue会将所有`v-on`指令绑定的事件全部存放到**组件实例**的**props**中，并对其改名, `show-info`会变成`onShowInfo`。这部分工作由构建工具完成。\n\n如果没有使用`template`，而使用渲染函数，需要手动写成`onShowInfo`的形式\n\n当在子组件中使用emit时，也是会先修改名称再去props中寻找相应事件并执行。\n\n## Emit函数\n\nemit函数用来触发事件，其源码位于`rumtime-core/src/componentEmits.ts`下\n\n```typescript\n// ...\n\nexport function emit(\n  instance: ComponentInternalInstance,\n  event: string,\n  ...rawArgs: any[]\n) {\n  const props = instance.vnode.props || EMPTY_OBJ\n\n  let args = rawArgs\n\n  // ----------------------\n  // 此处是处理 update:xxx 事件的(v-model)\n  const isModelListener = event.startsWith('update:')\n  const modelArg = isModelListener && event.slice(7)\n  if (modelArg && modelArg in props) {\n    const modifiersKey = `${\n      modelArg === 'modelValue' ? 'model' : modelArg\n    }Modifiers`\n    const { number, trim } = props[modifiersKey] || EMPTY_OBJ\n    if (trim) {\n      args = rawArgs.map(a => a.trim())\n    } else if (number) {\n      args = rawArgs.map(toNumber)\n    }\n  }\n  // ----------------------\n\n  // 如果 event是  custom-event\n  let handlerName = toHandlerKey(camelize(event))\n  // handlerName 变成 onCustomEvent\n  let handler = props[handlerName]\n\n  // 如果v-model update:xxx的事件，处理则不同\n  if (!handler && isModelListener) {\n    // 如果 event是 update:modelValue\n    handlerName = toHandlerKey(hyphenate(event))\n    // handlerName 变成 update:model-value\n    handler = props[handlerName]\n  }\n\n  if (handler) {\n    // 执行 函数\n    callWithAsyncErrorHandling(\n      handler,\n      instance,\n      ErrorCodes.COMPONENT_EVENT_HANDLER,\n      args\n    )\n  }\n\t\n  // 寻找有没有 once修饰符的事件，\n  // 如果有判断是否执行过，用emmited记录\n  // 如果有则直接返回，没有记录emited并执行\n  const onceHandler = props[handlerName + `Once`]\n  if (onceHandler) {\n    if (!instance.emitted) {\n      ;(instance.emitted = {} as Record<string, boolean>)[handlerName] = true\n    } else if (instance.emitted[handlerName]) {\n      return\n    }\n    callWithAsyncErrorHandling(\n      onceHandler,\n      instance,\n      ErrorCodes.COMPONENT_EVENT_HANDLER,\n      args\n    )\n  }\n}\n\n//...\n```\n\n源码中有3种处理：v-model的update:xxx、自定义事件、once事件\n\n- v-model的**update:xxx**：\n- 自定义事件：先修改event，再去props里寻找对应事件，调用\n- once：在`instance.emited`中记录调用次数，并在事件名称后加上**Once**\n\n`emit`函数会在组件实例创建是被挂载在组件实例上\n\n```typescript\n// runtime-core/src/components\n\nexport function createComponentInstance(\n  vnode: VNode,\n  parent: ComponentInternalInstance | null,\n  suspense: SuspenseBoundary | null\n) {\n  // ...\n  instance.emit = emit.bind(null, instance)\n  // ...\n}\n```\n\n## v-on事件处理\n\n通过[vue-template-explore](https://vue-next-template-explorer.netlify.app/)来观察一下如何处理自定义事件\n\n`<child-component @show-info=\"showInfo\" @delete.once=\"deleteItem\">Hello</child-component>`\n\n```javascript\nimport { createTextVNode as _createTextVNode, resolveComponent as _resolveComponent, withCtx as _withCtx, createVNode as _createVNode, openBlock as _openBlock, createBlock as _createBlock } from \"vue\"\n\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  const _component_child_component = _resolveComponent(\"child-component\")\n\n  return (_openBlock(), _createBlock(_component_child_component, {\n    onShowInfo: _ctx.showInfo,\n    onDeleteOnce: _ctx.deleteItem\n  }, {\n    default: _withCtx(() => [\n      _createTextVNode(\"Hello\")\n    ]),\n    _: 1 /* STABLE */\n  }, 8 /* PROPS */, [\"onShowInfo\", \"onDeleteOnce\"]))\n}\n\n// Check the console for the AST\n```\n\n`createBlock`函数位于`runtime-core/src/vnode.ts`中。用来创建区块根节点。它的第二个参数就是props。可以观察到`show-info`变成了`onShowInfo`，`delete`变成了`onDeleteOnce`。\n\n下面是`createBlock`的函数签名。\n\n```typescript\nfunction createBlock(\n\ttype: VNodeTypes | ClassComponent, \n  props?: Record<string, any> | null | undefined,\n  children?: any,\n  patchFlag?: number | undefined, \n  dynamicProps?: string[] | undefined\n): VNode\n```\n\n## 与vue2的区别\n\nvue2的emit是挂载在`vue.prototype`上的方法\n\nvue3的emit是挂载在实例上的方法","tags":["vue"],"categories":["源码"]},{"title":"Nodejs搭建vue服务端渲染","url":"/posts/af3ae610.html","content":"\n## 何为服务端渲染\n\n与**服务端渲染**相对应的是**客户端渲染**。区别他们的方法就是判断网页（具有完整HTML结构）是由服务端生成的还是由客户端生成。以vue为例：\n\n- 客户端渲染：用户输入网址，服务端返回一个html文件（没有完整的HTML结构，通常只有`<div id=\"app\"></div>`）。浏览器解析HTML，遇到许多script外链，进而请求这些脚本。然后再执行这些脚本，最终在生成相应dom节点。\n- 服务端渲染：用户输入网址，服务端收到请求后。在服务端执行相关脚本，生成相应的dom节点。最后将渲染后的具有完整HTML结构的html文件直接发送给客户端浏览器。这时，浏览器就可以展示页面了，之后再解析HTML文件，请求外链脚本。比较重要的是客户端需要激活服务端生成的那些节点。\n\n由此，服务端渲染相对于客户端有以下好处：\n\n1. 比客户端更快的首屏速度，快了请求下载脚本和执行脚本的时间\n2. 更好的SEO，服务器返回的是一个完整的HTML页面。\n\n## 技术选型\n\n**服务端渲染**必须有一个服务端来担任渲染网页的职责。nodejs是最好的选择。\n\n- 中间件系统：Koa\n- Vue相关：vue、vuex、vue-router、vue-server-renderer\n- 构建：webpak相关\n- 开发语言：TypeScript\n\n## 实现蓝图\n\n![ssr蓝图](../../images/nodejs/vue_ssr_blueprint.jpg)\n\n首先项目是由webpack打包构建的，项目有两个入口文件`server entry`和`client entry`。一个用于服务端一个用于客户端。把服务端和客户端的公共逻辑（例如创建vue、vuex、vue-router实例）抽离出来放入`app.js`。\n\nwebpack构建后会生成两份`bundle`——`server bundle`和`client bundle(manifest)`。这两个文件会传递给`vue-server-renderer`用来创建`render`（渲染器），从而在服务端渲染出html。\n\n[源码地址](https://github.com/zxffan/vue2-ssr)\n\n## vue-server-renderer\n\n这是vue官方提供的一个服务端渲染工具。vue的ssr实现是基于它的。\n\n配置webpack生成所需要的bundle和manifest\n\n```typescript\nimport VueSSRServerPlugin from \"vue-server-renderer/server-plugin\";\nimport VueSSRClientPlugin from \"vue-server-renderer/client-plugin\";\n// client\nexport default {\n  // ...省略\n  plugins: [new VueSSRClientPlugin()],\n  // ...省略\n}\n\n// server\nexport default {\n  // ...省略\n  plugins: [new VueSSRServerPlugin()],\n  // ...省略\n}\n```\n\n`vue-server-renderer`提供两个**plugin**——`server plugin`和`client plugin`。前者会在打包过程中生成**bundle**文件，后者会生成**manifest**文件\n\n使用例子：\n\n```typescript\nimport { createBundleRenderer } from \"vue-server-renderer\";\n// 这两个文件是webpack打包后自动生成的\nconst bundle = require(\"../dist/vue-ssr-server-bundle.json\");\nconst clientManifest = require(\"../dist/vue-ssr-client-manifest.json\");\n\n// 传入clientManifest和bundle\nconst renderer = createBundleRenderer(\n  bundle,\n  {\n    clientManifest,\n    template: readFileSync(ab(\"./src/index.html\"))?.toString(),\n    runInNewContext: false,\n    basedir: ab(\"./dist\"),\n  }\n);\n\n// 使用\n// async function\nconst html = await renderer.renderToString(context)\n// html 即 渲染后的html结构\n```\n\n一旦bundle和manifest配置完毕，`vue-server-render`会自动帮我们做很多工作，例如客户端激活。\n\n还有需要在html模版文件中的body标签哪加上**<!--vue-ssr-outlet-->**，这样`vue-server-renderer`就会将生成的vue实例挂载在对应位置。\n\n## 集成vue-router\n\n从两个角度来说：\n\n一是服务端，当一个路由请求发送到服务端，这是路由匹配发生在服务端\n\n```typescript\n// server entry\nimport { createApp } from \"./app\";\n\ninterface IServerContext {\n  url: string;\n  state: any,\n  meta: any\n}\n\nexport default function (ctx: IServerContext) {\n  const { app, router, store } = createApp(); // 此处创建vue实例\n  return new Promise<typeof app>((resolve, reject) => {\n    router.push(ctx.url); // 匹配路由\n\t\t\n    // 在onReady做一些处理操作\n    router.onReady(() => {\n      // 获得所有以已经匹配的组件\n      const matchedComponents = router.getMatchedComponents();\n      if (matchedComponents.length <= 0) {\n        return reject({ code: 404 });\n      }// 没有说明 没有匹配此路由的组件，返回404\n\t\t\t\n      // 我们约定存在 asyncData选项\n      // 它返回Promise，并且在服务端执行\n      // 当 asyncData执行完毕后才会生成html返回给客户端\n      Promise.all(\n        matchedComponents.map((com: any) => {\n          if (com.asyncData !== undefined) {\n            return com.asyncData({ store, router: router.currentRoute });\n          }\n        })\n      ).then(() => {\n        resolve(app);\n      });\n    }, reject);\n  });\n}\n```\n\n二是客户端，当在客户端使用router跳转时，也需要去先执行asyncData，待其执行完毕后在返回页面。\n\n```typescript\n// client entry\n// ...\n\n// 处理路由 update的情况\nVue.mixin({\n  beforeRouteUpdate(to, from, next) {\n    Promise.all(\n      to.matched.map((c) => {\n        const options = c.components.$options;\n        const asyncData = (options as any).asyncData;\n        if (asyncData) {\n          return asyncData({\n            store: store,\n            route: to,\n          });\n        }\n      })\n    ).finally(next);\n  },\n});\n\nrouter.onReady(() => {\n  router.beforeResolve((to, from, next) => {\n    const matched = router.getMatchedComponents(to);\n    const prevMatched = router.getMatchedComponents(from);\n\t\t\n    // 对比 两条路由下的组件有否有不同，若都相同就就直接跳转\n    let diffed = false;\n    const activated = matched.filter((c, i) => {\n      return diffed || (diffed = prevMatched[i] !== c);\n    });\n\n    if (activated.length <= 0) next();\n\n    // 这里可以显示加载器\n    const render = createLoading();\n\n    render\n      .mount()\n      .then(() =>\n        Promise.all(\n          activated.map((c: any) => {\n            if (c.asyncData) return c.asyncData({ store, router: to });\n          })\n        )\n      )\n      .then((res) => {\n        // TODO 将结果 合并到data选项\n      })\n      .finally(() => {\n        // 这里可以关闭加载器\n        render.hide();\n        next();\n      });\n  });\n  app.$mount(\"#app\");\n});\n```\n\n上面这种路由策略，是必须先asyncData执行完毕，再展示画面，这通常会有一个全屏的loading页。\n\n还有一种策略是，直接显示页面，当aysncData执行完毕再将其填充组件，这样对于每一个组件都应该有一个loading状态。\n\n## 集成vuex\n\n服务端收到路由请求，先匹配路由，执行asyncData，其可能会修改store的值。待所有路由组件的asyncData执行完毕后。会在返回给客户端的html中插入一段**script**\n\n```html\n<script>\nwindow.__INITIAL_STATE__ = {\n  // state的值\n}\n</script>\n```\n\n客户端需要将**\\_\\_INITIAL_STATE\\_\\_**的值插入store实例中。\n\n```typescript\n// client entry\nconst initalState = (window as any).__INITIAL_STATE__;\nif (initalState) {\n  store.replaceState(initalState);\n}\n```\n\n在服务端中需要加上一段\n\n```typescript\nexport default function (ctx: IServerContext) {\n  const { app, router, store } = createApp();\n  return new Promise<typeof app>((resolve, reject) => {\n    router.push(ctx.url);\n    ctx.meta = app.$meta()\n\n    router.onReady(() => {\n      const matchedComponents = router.getMatchedComponents();\n      if (matchedComponents.length <= 0) {\n        return reject({ code: 404 });\n      }\n\n      Promise.all(\n        matchedComponents.map((com: any) => {\n          if (com.asyncData !== undefined) {\n            return com.asyncData({ store, router: router.currentRoute });\n          }\n        })\n      ).then(() => {\n        // 在上下文加上 state\n        ctx.state = store.state\n        resolve(app);\n      });\n    }, reject);\n  });\n}\n```\n\n在服务端入口文件中导出的这个function，会在使用`render.renderToString(context)`是自动调用，其ctx对于传入的context参数。这个context也会被`vue-server-render`使用到。\n\n## 开发环境的构建\n\n生产环境直接打包启用服务即可。\n\n在开发环境下，需要实现热更新。当用户代码发生修改时，重新打包，并通过socket通知浏览器更新相应内容。\n\n客户端的热更新：由于我们使用的是koa，所以这里使用`koa-webpack`插件，它集成了两个插件：\n`webpack-dev-middleware`：打包项目到内存中，并允许客户端访问到\n`webpack-hot-client`：实现热更新\n\n```typescript\n// 获取webpack配置\nconst clientConfig = createClientConfig();\n// 生成compiler\nconst clientCompiler = webpack(clientConfig);\nkoaWebpack({\n  compiler: clientCompiler,\n  devMiddleware: {\n    publicPath: clientConfig.output?.publicPath,\n  },\n}).then((middleware) => app.use(middleware)); // 注册中间件\n```\n\n服务端的热更新，直接用webpack watch模式来打包。但是注意需要修改文件输出的文件系统，我们需要将打包后的文件放在内存中而不是磁盘上。\n\n```typescript\n// * 处理服务端 更新获取bundle\nconst serverConfig = createServerConf();\nconst serverCompiler = webpack(serverConfig);\n\n// 使用 memory-fs 来修改 webpack默认的文件系统\nconst mfs = new MemoryFs();\nserverCompiler.outputFileSystem = mfs;\n\n// watch模式 打包\nserverCompiler.watch({}, (err, stats) => {\n  if (err) throw err;\n  const result = stats.toJson();\n  if (result.errors.length) return;\n\n  // TODO 打包成功\n});\n```\n\n## css支持\n\ncss的支持只需要有正确的webpack loader配置即可。\n\n需要注意的是，使用`vue-style-loader`来代替`style-loader`。前者支持服务端渲染。\n\n还有一个坑是，`css-loader`的默认配置与`vue-style-loader`冲突，需要关闭`esModule`\n\n```typescript\nexport default {\n  // 省略\n  module: {\n    rules: [\n      {\n        test: /\\.css$/,\n        use: [\n          isDev ? \"vue-style-loader\" : extractLoader,\n          {\n            loader: \"css-loader\",\n            options: {\n              esModule: false, // 关闭 esModule\n            },\n          },\n        ],\n      },\n    ],\n  },\n  // 省略\n};\n```\n\n还可以加上`postcss-loader`、`sass-loader`等\n\n## HEAD支持\n\n为了更好得支持`SEO`。提供了自定义head的能力。我们通过[vue-meta](https://vue-meta.nuxtjs.org/guide/ssr.html)来实现。\n\n先注册插件\n\n```typescript\nimport Vue from 'vue'\nimport VueMeta from 'vue-meta'\n\nVue.use(VueMeta)\n```\n\n在服务端入口文件\n\n```typescript\nexport default function (ctx: IServerContext) {\n  const { app, router, store } = createApp();\n  return new Promise<typeof app>((resolve, reject) => {\n    router.push(ctx.url);\n    // 加上这句\n    ctx.meta = app.$meta()\n\n    // 省略...\n}\n```\n\n最后修改html模版文件\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n  <meta charset=\"UTF-8\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  {{{ meta.inject().title ? meta.inject().title.text() : '' }}}\n  {{{ meta.inject().meta ? meta.inject().meta.text() : '' }}}\n</head>\n\n<body>\n  <!--vue-ssr-outlet-->\n</body>\n\n</html>\n```\n\n使用：在metaInfo选项中配置\n\n```typescript\nexport default {\n  metaInfo: {\n    title: \"Home页面\",\n    meta: [{ charset: \"utf-8\" }, { name: \"description\", content: \"foo\" }],\n  },\n}\n```\n\n## 客户端激活\n\n客户端激活的工作已经由`vue-server-renderer`完成了。我们分析一下它是如何实现的。\n\n在服务端，由`vue-server-renderer`生成html。会在相应的html上打上标记，例如`<div id=\"app\" data-server-rendered=\"true\">`。客户端识别到`data-server-rendered`属性，就会知道这部分html是由服务端如渲染而来的，随后客户端就会激活这些静态的HTML\n\n## 缓存\n\n每次请求，服务端都需要创建组件实例，这会有一定的性能损耗。对于**非用户特定的页面**（对不同的用户展示相同内容的页面），我们可以进行缓存\n\n### 缓存页面\n\n以页面为单位，缓存html文本\n\n```typescript\nimport LRU from \"lru-cache\";\n\nconst pageCache = new LRU({\n  max: 100,\n  maxAge: 1000, // 重要提示：条目在 1 秒后过期。\n});\n\nasync function renderPage(ctx: Context) {\n  console.log(\"路由匹配:\", ctx.url);\n  try {\n    // 判断 是否命中缓存\n    const cacheable = isCacheable(ctx.url);\n    if (cacheable && pageCache.get(ctx.url)) {\n      ctx.status = 200;\n      ctx.body = pageCache.get(ctx.url);\n      return;\n    }\n    const context: any = {\n      url: ctx.url,\n    };\n    const html = await renderer.renderToString(context);\n\n    ctx.res.setHeader(\"Content-Type\", \"text/html\");\n    ctx.status = 200;\n    ctx.body = html;\n\t\t\n    // 设置缓存\n    if (cacheable) {\n      pageCache.set(ctx.url, html);\n    }\n  } catch (err) {\n    // 省略\n  }\n}\n\nfunction isCacheable(url: string) {\n  return [\"/about\", \"/profiles\"].indexOf(url) >= 0;\n}\n```\n\n### 缓存组件\n\n一组件为单位来缓存。`vue-server-renderer` 内置支持组件级别缓存。只需要在创建`renderer`时传递`cache`参数。\n\n```typescript\nimport LRU from \"lru-cache\";\n\nconst renderer = createRenderer({\n  cache: LRU({\n    max: 10000,\n    maxAge: 1000\n  })\n})\n```\n\n在组件内，设置`serverCacheKey`选项来启用缓存。\n\n```typescript\nexport default {\n  name: 'item', // 必填选项\n  props: ['item'],\n  serverCacheKey: props => props.item.id,\n  render (h) {\n    return h('div', this.item.id)\n  }\n}\n```\n\n注意：\n\n- `serverCacheKey`的返回值表示缓存，当前发生变化缓存失效。若返回常量表示组件将被永久缓存\n- `name`唯一\n\n通常来说，组件缓存比较适用于一种场景。`v-for`渲染大组件列表。通常数据都会有个id和最后更新时间。通过这两个属性可以决定缓存是否有效\n\n```typescript\nexport default {\n  serverCacheKey: props => props.item.id + '::' + props.item.last_updated\n}\n```\n\n","tags":["vue2","ssr","Nodejs"],"categories":["Server"]},{"title":"Nodejs搭建服务端","url":"/posts/9e0c0ca5.html","content":"\n## 服务端\n\n服务端顾名思义就是提供服务的一方。\n\n先回顾一下四层模型：`应用层（最顶层）`-> `传输层` -> `网络层` -> `数据链路层（最底层）`\n\n其中传输层使用的是`TCP/UDP`协议\n应用层使用的协议有`http`、`ftp`等\n\n任何一种网络服务都必须遵从一种协议。\n\n`nodejs`内置了若干模块，实现了常见的网络协议，并向用户提供了便利的接口。\n\n> 四层模型只是理论模型\n\n## Net模块\n\n[`net`](https://nodejs.org/dist/latest-v14.x/docs/api/net.html)模块在[认识RPC](/posts/91c0fa71.html#搭建多路复用的RPC通道)中提到过，当时是用来搭建RPC通道。\n\n它可以建立基于流的TCP服务端和客户端。\n简单的说，就是建立两端——服务端和客户端，两者之间通过TCP连接。数据以流的方式传输（`Buffer`）\n\n```typescript\n// server.ts\nimport { createServer } from \"net\";\n\nconst server = createServer((socket) => {\n  //\n  socket.on(\"data\", (buffer) => {\n    console.log(\"server: receive data from server: \", buffer.toString());\n  });\n\n  socket.write(\"hello client!\");\n});\n\nserver.listen(8081);\n\n// ---------------------------------------------\n\n// client.ts\nimport { createConnection } from \"net\";\n\nconst socket = createConnection({\n  host: \"localhost\",\n  port: 8081,\n});\n\nsocket.on(\"data\", (buffer) => {\n  console.log(\"client: receive data from server: \", buffer.toString());\n\n  socket.write(\"hello server!\")\n});\n\nsocket.on(\"close\", () => {\n  console.log(\"client: close connection\");\n});\n```\n\n服务端通过`createServer`创建一个TCP服务，其回调函数接受`socket`作为参数。\n客户端通过`createConnection`来连接服务端，其返回`socket`\n\n`sokect`是服务端和客户端用来通信的工具\n\n```typescript\n// 通过on来监听data事件\n// 有消息发送过来 就会触发该事件\n// 参数为buffer，使用toString toJSON等方法来获取原始值，参考nodejs buffer模块\nsocket.on(\"data\", buffer => {\n  // TODO\n  // buffer.toString()\n  // buffer.toJSON()\n})\n\n// socket.write(data[, encoding][, callback])\n// write方法用来发送数据\nsocket.write(\"hello\")\n```\n\n`buffer`的编解码可以使用[`Protocol Buffers`](https://github.com/protocolbuffers/protobuf)\n\n## HTTP模块\n\n[`http`模块](https://nodejs.org/dist/latest-v14.x/docs/api/http.html)实现了`HTTP协议`。`HTTP协议`是基于`TCP协议`的，所以`nodejs`的`http`模块是基于`net`模块的。\n\n传统的web网站主要使用的就是http协议\n\n```typescript\nimport { createServer } from \"http\";\nimport { readFileSync } from \"fs\";\n\nconst buffer = readFileSync(\"./index.html\");\n\nconst server = createServer((req, res) => {\n  res.end(buffer);\n});\n\nserver.listen(\"8080\");\n```\n\n在浏览器输入`localhost:8080`就可以访问`index.html`。一个极简的http服务就搭建成了。\n\n`http`模块也提供了客户端方法——`request`\n\n```typescript\nimport { request } from 'http'\n\nconst postData = querystring.stringify({\n  'msg': 'Hello World!'\n});\n\nconst options = {\n  hostname: 'www.google.com',\n  port: 80,\n  path: '/upload',\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/x-www-form-urlencoded',\n    'Content-Length': Buffer.byteLength(postData)\n  }\n};\n\nconst req = http.request(options, (res) => {\n  console.log(`STATUS: ${res.statusCode}`);\n  console.log(`HEADERS: ${JSON.stringify(res.headers)}`);\n  res.setEncoding('utf8');\n  res.on('data', (chunk) => {\n    console.log(`BODY: ${chunk}`);\n  });\n  res.on('end', () => {\n    console.log('No more data in response.');\n  });\n});\n\nreq.on('error', (e) => {\n  console.error(`problem with request: ${e.message}`);\n});\n\n// Write data to request body\nreq.write(postData);\nreq.end();\n```\n\n## HTTPS模块\n\n在`HTTP`和`TCP`之间有加了一层`TLS/SSL`，以解决明文传输的安全问题\n\n`HTTPS`在`HTTP`基础上添加了`TLS/SSL`加密功能。在`nodejs`中`TLS/SSL`也是一个独立的模块。`HTTPS`模块基于`HTTP`模块和`TLS/SSL`模块。\n\n对于开发者，使用`HTTPS`就是多了一步——**配置私钥和证书**。\n\n### 生成私钥和证书\n\n首选确认正确安装`openssl`。将通过命令行来生成私钥和证书\n\n第一步，生成私钥key , `ryans-key.pem`\n\n```bash\nopenssl genrsa -out ryans-key.pem 2048\n```\n\n第二步，根据私钥，生成证书注册请求（Certificate Signing Request， CSR）, `ryans-csr.pem`，会提问一堆问题（密码记住）\n\n```bash\nopenssl req -new -sha256 -key ryans-key.pem -out ryans-csr.pem\n```\n\n第三步，把CSR发给CA机构签名，我们这一步采用自签名的方式，获得证书`ryans-cert.pem`\n\n```bash\nopenssl x509 -req -in ryans-csr.pem -signkey ryans-key.pem -out ryans-cert.pem\n```\n\n至此，我们获得了私钥和`cer证书`。\n\n我们还可以进一步获取`pfx证书`,`ryans.pfx`\n\n```bash\nopenssl pkcs12 -export -in ryans-cert.pem -inkey ryans-key.pem -out ryans.pfx\n```\n\n### https模块使用\n\n```typescript\nimport { createServer } from \"https\";\nimport { fstat, readFileSync } from \"fs\";\n\nconst options = {\n  key: readFileSync(\"./certs/ryans-key.pem\"),\n  cert: readFileSync(\"./certs/ryans-cert.pem\"),\n};\n\nconst html = readFileSync('../index.html')\n\nconst server = createServer(options, (req, res) => {\n  res.end(html)\n});\n\nserver.listen(443) // https默认是443端口\n```\n\n使用Chrome来测试，首先需要允许`localhost`使用无效证书（没有经过CA签名）。`chrome://flags/#allow-insecure-localhost`，设为`Enabled`即可\n\n在浏览器中输入`https://localhost:443`。就可以看到页面了\n\n还可以使用pfx证书，pfx证书相对于cer证书：\n\n- cer证书只包含公钥\n- pfx证书包含公钥和私钥\n\n```typescript\nimport { createServer } from \"https\";\nimport { fstat, readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync('./certs/ryans.pfx'),\n  passphrase: '' // pfx证书的密码\n};\n\nconst html = readFileSync('../index.html')\n\nconst server = createServer(options, (req, res) => {\n  res.end(html)\n});\n\nserver.listen(443)\n```\n\n`https`模块也有`https.request`方法用来发起https请求\n\n## HTTP/2\n\n### HTTP/2 特点\n\n`http`通常指`http/1.1`。`http/2`相较于`http/1.1`做了很多提升:\n\n- **`TLS/SSL`加密**：和https一样。所以也需要配置证书和私钥\n- **二进制传输**：`http/1.1`传输的是文本，`http/2`传输的是二进制流\n- **多路复用**：`http/2`有两个概念——**帧**和**流**。`http/2`将数据报文分成一个个二进制**帧（Frame）**，在一个TCP连接中，不同的帧组合在一起发送（**二进制分帧**）形成**流（Stream）**。在接收方根据帧首部信息在组合起来。`HTTP/1.1`只能一个个请求报文排队发送。\n- **header压缩**：http请求有这繁多冗长的首部，`http/2`会对首部进行压缩\n- **服务端推送**：能够主动给客户端推送资源\n  - `http/1.1`加载网页的顺序：请求html，解析html，再请求js、css等文件\n  - `http/2`：当服务端收到html请求时，服务端就主动吧html、css、js以及图片等资源发送给客户端\n\n> 前4个都是`http/2`自动实现的。服务端推送需要开发者手动配置。\n\n### Nodejs实现\n\n`nodejs`内置了`http2`模块，实现了`http/2`协议。\n\n```typescript\nimport { createSecureServer } from \"http2\";\nimport { readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync(\"./certs/ryans.pfx\"),\n  passphrase: \"\",\n};\n\nconst html = readFileSync(\"../index.html\");\n\nconst server = createSecureServer(options);\n\nserver.on(\"stream\", (stream, headers) => {\n  stream.respond({\n    \"content-type\": \"text/html; charset=utf-8\",\n    \":status\": 200,\n  });\n  stream.end(html);\n});\n\nserver.listen(443);\n```\n\n`http2`模块有两个创建服务的方法——`createServer`和`createSecureServer`。前者是不带TLS/SSL加密的，后者带加密。目前主流浏览器只支持带`TLS/SSL`加密的`HTTP/2`\n\n监听`http2Server`的`stream`事件，当请求发来就来触发该事件（http2数据是以二进制流的形式传输）\n\n`http2Stream`是一个双工流。既可以发送数据也可以接受数据。`ServerHttp2Stream`是其实现，其：\n\n- `http2stream.pushStream(headers[, options], callback)`：实现服务端主动推送\n- `http2stream.respond([headers[, options]])`：发送回应，可以在这设置响应头\n- `stream`是一个流，使用`stream.write()`向其写入内容或`stream.end(content)`结束这个流\n\n### 服务端推送(Server Push)\n\n这是http/2的一大特点。nodejs中实现通过`pushStream`方法即可实现\n\n```typescript\nimport { createSecureServer } from \"http2\";\nimport { readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync(\"./certs/ryans.pfx\"),\n  passphrase: \"\",\n};\n\nconst html = readFileSync(\"../index.html\");\nconst png = readFileSync(\"../hello.jpg\");\n\nconst server = createSecureServer(options);\n\nserver.on(\"stream\", (stream, headers) => {\n  stream.respond({\n    \"content-type\": \"text/html; charset=utf-8\",\n    \":status\": 200,\n  });\n  stream.pushStream({ \":path\": \"/hello.jpg\" }, (err, pushStream, headers) => {\n    if (err) throw err;\n    pushStream.respond({ \":status\": 200 });\n    pushStream.end(png);\n  });\n  stream.end(html);\n});\n\nserver.listen(443);\n\n```\n\n上例在用户请求`https://localhost`时，将index.html和`https://localhost/hello.jpg`一起发送给客户端。\n\n### 客户端\n\n`http2`模块也提供了客户端实现。\n\n```typescript\nimport { connect } from \"http2\";\nimport { readFileSync } from \"fs\";\n\nconst client = connect(\"https://www.zxffan.com:443\", {\n  ca: readFileSync(\"./certs/ryans-cert.pem\"),\n});\n\nconst req = client.request({ \":path\": \"/\" });\n\nreq.on(\"response\", (headers, flags) => {\n  for (const name in headers) {\n    console.log(`${name}: ${headers[name]}`);\n  }\n});\n\nreq.setEncoding(\"utf8\");\nlet data = \"\";\nreq.on(\"data\", (chunk) => {\n  data += chunk;\n});\nreq.on(\"end\", () => {\n  console.log(`\\n${data}`);\n  client.close();\n});\nreq.end();\n```\n\n客户端需要配置ca证书\n\n## Express\n\n`Express`是`ndoejs`的第三方库，它对网络模块做了增强。来个例子：\n\n```typescript\nimport express from \"express\";\nimport { createServer } from 'http'\n\nconst app = express();\nconst server = createServer(app)\n\napp.get(\"/\", (req, res) => {\n  // TODO\n  res.send('hello express!')\n});\n\napp.use((req, res, next) => {\n  console.log('Time: %d', Date.now())\n  next()\n})\n\nserver.listen(3000);\n```\n\n将app传给`createServer`。这样`express`就拦截了所有请求，在收到请求到响应之间就可以添加很多**中间件**。\n\n- 中间件系统，`app.use`来注册一个中间件，所有请求回按照中间件注册顺序依次调用。\n\n- 路由系统，`express`新增了路由，`app.get`、`app.post`。路由本质上也是中间件\n\n### 中间件——洋葱模型\n\n```typescript\nimport express from \"express\";\nimport { createServer } from \"http\";\n\nconst app = express();\nconst server = createServer(app);\n\napp.use(\n  function m1(req, res, next)  {\n    console.log('m1 start');\n    next()\n    console.log('m1 end')\n  },\n  function m2(req, res, next)  {\n    console.log('m2 start');\n    next()\n    console.log('m2 end')\n  },\n  function m3(req, res, next)  {\n    console.log('m3 start');\n    next()\n    console.log('m3 end')\n  },\n);\n\napp.get(\"/\", (req, res) => {\n  // TODO\n  res.send(\"hello express!\");\n});\n\nserver.listen(3000);\n```\n\n上例注册了3个中间件——`m1`,`m2`和`m3`\n\n输出顺序：\n\n```text\nm1 start\nm2 start\nm3 start\nm3 end\nm2 end\nm1 end\n```\n\n中间件就像一个洋葱，`m1`是外表皮，`m2`是中间表皮，`m2`是内表皮。从洋葱的一层穿透到另一个，经过顺序必然是：`m1->m2->m3->m3->m2->m1`。、\n\n![洋葱模型](../../images/nodejs/中间件洋葱模型.png)\n\n但是`express`的洋葱模型又个问题——异步支持不好。如果m2中进行一个异步操作（RPC，查数据库等），其它中间件不会等待操作结果。`Koa`的出现弥补了这个缺点。\n\n### https和http2\n\nhttps\n\n```typescript\nimport express from \"express\";\nimport { createServer } from \"https\";\nimport { readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync(\"./certs/ryans.pfx\"),\n  passphrase: \"\",\n};\n\nconst app = express();\nconst server = createServer(options, app);\n\nconst html = readFileSync(\"../index.html\", \"utf-8\");\n\napp.get(\"/\", (req, res) => {\n  // TODO\n  res.send(html);\n});\n\nserver.listen(3000);\n```\n\n使用方法和`http`模块类似。\n\n至于`http2`模块，`express`目前还无法与其兼容。参见官方[issue](https://github.com/expressjs/express/issues/2761#issuecomment-142610897)\n如果想在`http2`模块中使用`express`的路由，可以使用[`router`](https://github.com/pillarjs/router)，它是从express独立出来的并且兼容`http2`，参考[issue](https://github.com/expressjs/express/issues/2761#issuecomment-142612001)\n搜索资料，发现可以使用`spdy`这个库来结合express实现`http2`\n\n## Koa\n\n`Koa`是`express`原班人马打造的。`koa`就是一个**中间件系统**。他的中间件支持两种函数——普通函数和**异步函数**\n\n```typescript\nimport Koa from \"koa\";\nimport { createServer } from \"http\";\n\nconst app = new Koa();\nconst server = createServer(app.callback());\n\napp.use(async (ctx, next) => {\n  await next();\n  ctx.body = 'hello koa!'\n});\n\nserver.listen(3000);\n```\n\n我这里的写法都是通过原生`http`模块，这是为了体现`koa`、`express`只不过是一套中间件层。底层的网络服务还是nodejs提供的。\n\n也可以简写\n\n```typescript\nimport Koa from \"koa\";\n\nconst app = new Koa();\n\napp.use(async (ctx, next) => {\n  await next();\n  ctx.body = 'hello koa!'\n});\n\napp.listen(3000);\n```\n\nkoa中间件支持nodejs的`async`和`await`语法，从而优雅的实现异步。\n\n### https\n\n使用https，也就是更换底层网络协议。\n\n```typescript\nimport Koa from \"koa\";\nimport { createServer } from \"https\";\nimport { readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync(\"./certs/ryans.pfx\"),\n  passphrase: \"\",\n};\n\nconst app = new Koa();\nconst server = createServer(options, app.callback());\n\nconst html = readFileSync(\"../index.html\", \"utf-8\");\n\napp.use(async (ctx, next) => {\n  await next();\n  ctx.body = html;\n});\n\nserver.listen(3000);\n```\n\n### http/2\n\n`Koa`是兼容`http2`模块的：\n\n```typescript\nimport Koa from \"koa\";\nimport { createSecureServer } from \"http2\";\nimport { readFileSync } from \"fs\";\n\nconst options = {\n  pfx: readFileSync(\"./certs/ryans.pfx\"),\n  passphrase: \"\",\n};\n\nconst html = readFileSync(\"../index.html\", \"utf-8\");\n\nconst app = new Koa();\nconst server = createSecureServer(options, app.callback());\n\napp.use(async (ctx, next) => {\n  await next();\n  ctx.\n  ctx.body = html;\n});\n\nserver.listen(443);\n```\n\nkoa如何使用服务端推送，目前还没有查到😂。\n\n查了下官方issue，开发者只提到兼容HTTP/2。没提`server push`，不过有人建议通过`ctx.stream`的形式获得流，进而使用`stream.pushStream()`\n\n## HTTP/3\n\n`HTTP/1.x`、`HTTPS`以及`HTTP/2.0`都离不开底层的`TCP`协议。\n\n`HTTP/2.0`采用多路复用，多个数据包使用一个`TCP`连接。`TCP`是可靠连接，但发生丢包时，会进行重传。所以网络状态差的情况下，某些数据包频繁重传，从而导致拥塞，后面的HTTP包都穿不出去。这叫做**头部阻塞（Head of line Blocking）**\n\n`HTTP/3.0`就开始考虑放弃`TCP`转向`UDP`协议。起初`Google`搞出来个`QUIC`协议，后来`IETF`标准化了`QUIC`协议形成`HTTP/3`。其底层采用`UDP`，基于`UDP`实现做了众多增强：\n\n- 0RTT：`TPC`建立连接每次都需要三次握手，就存在数据包的三次往返即**3RTT**。而`QUIC`首次建立连接只需要`1RTT`。其后的连接可以直接复用，只需要**0RTT**\n- 连接迁移：当`源IP`、`源端口`、`目的IP`、`目的端口`其中一个发生变化就需要重新建立TCP连接。只要**Connection ID**没有变化。`HTTP/3`可以继续复用连接\n- 头部阻塞：由于使用`UDP`，发生丢包时，也不会立即重传，阻塞连接。\n- 拥塞控制\n- 前向纠错\n- 更多特性 请参考[文章](https://zhuanlan.zhihu.com/p/143464334)\n\nnodejs目前未支持`HTTP/3`。\n\nchrome只支持 `Google QUIC`。对`IETF QUIC`的支持处于`WIP`状态\n\n","tags":["Nodejs","服务"],"categories":["Server"]},{"title":"Nginx","url":"/posts/d0156050.html","content":"\n> nginx [engine x] is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server\n>\n> nginx是一个HTTP服务器、反向代理服务器、邮件代理服务器、通用TCP/UDP代理服务器\n\n总而言之，`nginx`能够在你的机器上跑起HTTP服务，我们可以在这个服务上部署传统的Web系统。\n\n## Nginx配置\n\n安装什么的就不提了。nginx的配置框架如下\n\n```nginx\n\n#user  nobody;\nworker_processes  1; #配置工作进程数目\n\n#配置全局错误日志及类型 [debug|info|notice|warn|error|crit(致命错误)] 默认error\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#配置进程pid文件\n#pid        logs/nginx.pid;\n\n\n#配置工作模式和连接数\nevents {\n  #配置每个worker的最大连接数\n  #nginx最大连接数 = worker_process * worder_connections\n  worker_connections  1024;\n}\n\n#配置http\nhttp {\n  #include 用来引入其他文件的配置\n  #当收到静态资源请求时，会根据资源的后缀名去mime.types里找对应的mime类型，再根据mime来设置响应头中的Content-Type\n  include       mime.types;\n  default_type  application/octet-stream; #设置默认响应类型\n\n  #设置日志格式\n  #log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n  #                  '$status $body_bytes_sent \"$http_referer\" '\n  #                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n  #access_log  logs/access.log  main;\n\n  #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，\n  #对于普通应用，必须设为 on,\n  #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，\n  #以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n  sendfile        on;\n  #tcp_nopush     on; #累计一定量的数据包一起发送\n  #tcp_nodelay\t\ton; #默认延后0.2s后发送整合数据包（避免频繁发送小数据包）。on则关闭这个特性\n\n  #连接超时时间\n  #keepalive_timeout  0;\n  keepalive_timeout  65;\n\n  #开启gzip压缩\n  gzip  on;\n\n  server {\n    listen       8080; #配置监听端口\n    server_name  localhost; #配置服务名\n\n    #编码\n    #charset koi8-r;\n\n    #设置日志存放路径，格式为 main（在http中定义的）\n    access_log  logs/host.access.log  main;\n\n    #默认的匹配规则\n    location / {\n      root   html;\n      index  index.html index.htm;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n      root   html;\n    }\n\n    # 代理所有url中含有api的请求，并转发到 http://127.0.0.1\n    location /api/ {\n      proxy_pass   http://127.0.0.1:8080;\n    }\n\n    # 拒接所有ht文件请求\n    location ~ /\\.ht {\n      deny  all;\n    }\n  }\n\n  include servers/*;\n}\n\n```\n\n## 虚拟主机\n\n**虚拟主机技术**可以将一台物理服务器划分成多个**虚拟主机**。可以在每个虚拟主机部署网站。\n\n### 基于端口\n\n`server`下的`listen`字段可以设置所需监听的端口\n\n```nginx\nserver {\n  listen 8080;\n  root /project1/\n  \n  location / {\n    index index.html\n  }\n}\n```\n\n`localhost:8080`即可访问到虚拟主机（server）上部署的网站\n\n### 基于虚拟主机名\n\n`server_name`：配置虚拟主机的名称。可以配置成访问的域名\n\n```nginx\n# A\nserver {\n  listen  80;\n  server_name www.test1.com;\n  # ...\n}\n\n# B\nserver {\n  listen  80;\n  server_name www.test2.com;\n  # ...\n}\n```\n\n虚拟主机A和B监听同一个端口，但是通过配置不同的`server_name`来区分\n\n- `http://www.test1.com/index.html`将访问到虚拟主机A\n- `http://www.test2.com/index.html`将访问到虚拟主机B\n\n## location匹配规则\n\n`location [=|~|~*|^~] /uri/ { … }`\n\n- `=` 开头表示精确匹配\n\n- `^~` 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。\n\n- `~` 开头表示区分大小写的正则匹配\n\n- `~*` 开头表示不区分大小写的正则匹配\n\n- `!~`和`!~*`分别为区分大小写不匹配及不区分大小写不匹配 的正则\n\n- `/` 通用匹配，任何请求都会匹配到。\n\n## root和alias\n\n`rooot`和`alias`都是用来指定文件路径的\n\n```nginx\nlocation ^~ /public/ {\n\troot /www/root/html;\n}\n```\n\n当访问`/public/index.html`时会在`/www/root/html/public/index.html`路径下寻找文件\n\n```nginx\nlocation ^~ /public/ {\n\talias /www/root/html/;\n}\n```\n\n当访问`/public/index.html`时会在`/www/root/html/index.html`路径下寻找文件\n\n所以，区别就是在查找文件时，root会加上location配置路径，而alias不会\n\n## 初始页\n\n```nginx\nserver {\n  listen 80;\n  server_name www.test.com;\n  \n  location / {\n    root /website/project1;\n    index index.html welcome.html\n  }\n}\n```\n\n当访问`www.test.com`时，会在`/website/project1/`目录下寻找`index.html`文件，有则返回否则继续寻找`welcome.html`\n\n## 错误页\n\n对于一些错误页面（404，500等），可以通过以下配置来访问\n\n```nginx\nerror_page 404 =200 /404.html;\nlocation = /404.html {\n    root /website;\n}\n\nerror_page 500 502 503 =200 /50x.html;\nlocation = /50x.html {\n    root /website;\n} \n```\n\n当请求发生404时（访问到不存在的页面），会跳转到`/404.html`。为了防止找不到，加了个`location`指定文件所在位置（`/website/404.html`）。\n\n对于单页面应用，通常只有一个`index.html`。在配置404等错误时，需要返回`index.html`\n\n```nginx\nerror_page 404 =200 /404.html;\nlocation = /404.html {\n  root /website;\n  try_files $uri $uri/ /index.html;\n}\n```\n\n解释：发生404时，重定向到`/404.html`。匹配到`/404.html`的`location`。然后遇到`try_files`指令\n\n**`try_files $uri $uri/ /index.html;`**\n\n访问`/public/somepage.html`时，会前去找`$uri`(就是`/public/somepage.html`)，找不到寻找`$uri/`。找不到最后返回`/index.html`\n\n## 代理\n\n反向代理和正向代理都需要通过`proxy_pass`指令来实现。\n\n需要代理的场景一般有三种角色：\n\n- 客户端：一般指浏览器\n- 代理服务器：指nginx\n- 服务端：真正需要访问的服务器\n\n```nginx\nserver {\n  listen 80;\n  root /websites/demo;\n  \n  location / {\n    try_files $uri $uri/ /index.html;\n    index index.html;\n  }\n  \n  location ^~ /api {\n    proxy_pass http://localhost:8081/ #末尾加/ 转发就不会包含/api(location的路径配置)\n  }\n}\n```\n\n客户端访问`/api/get-user-info`。请求到达代理服务器，匹配到`/api`转发给`http://localhost:8081/get-user-info`。\n\n反向代理和正向代理本质上都是请求和响应的转发。根据代理的目的来划分它们。\n\n代理一般都是指**正向代理**，目的是**帮助内网的客户端访问外网**。比如通过科学上网访问google，它在国外假设一台没有被禁的代理服务器。国内访问这台代理服务器，代理服务器再去访问google。\n\n**反向代理**正好相反。它是**帮助外网的客户端访问内网**。比如访问baidu。客户端（浏览器）访问百度，会访问到baidu的代理服务器，通过代理服务器来访问baidu的内网服务器。\n\nnginx的反向代理常常被提到。因为它的性能真的很好。最重要的是反向代理可以来做**负载均衡**。\n\n## 负载均衡\n\n还以访问百度为例，当代理服务器收到客户端的请求时，代理服务器根据负载均衡规则（算法）来选择百度的内网服务器（百度的服务器肯定不止一台）来转发请求。\n\n### 配置\n\n```nginx\nhttp {\n  upstream backend {\n    server 127.0.0.1:3000 weight=3; # weight权重 越大访问的机率越高\n    server 127.0.0.1:5000 weight=1; \n  }\n  \n  server {\n    listen 80;\n    root /websites/demo\n    location / {\n      proxy_pass http://backend;\n    }\n  }\n}\n```\n\n所有请求都会代理转发到`upstream`中配置的服务器。按照权重分配\n\n### 策略\n\n#### 1.轮询（默认）\n\n```nginx\nupstream backserver { \n  server 127.0.0.1:3000; \n  server 127.0.0.1:5000; \n} \n```\n\n每个请求都会按照时间循序依次分配到所配置的后端服务器，如果服务器宕机则自动剔除\n\n#### 2.权重\n\n```nginx\nupstream backend {\n  server 127.0.0.1:3000 weight=3; # weight权重 越大访问的机率越高\n  server 127.0.0.1:5000 weight=1; \n}\n```\n\n指定轮询机率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n\n#### 3.IP哈希\n\n服务端可能需要访问session，如果每一次处理请求的服务端不同，是无法获取正确的session的。IP哈希是指每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，从而解决session的问题。\n\n```nginx\nupstream backserver { \n  ip_hash;\n  server 127.0.0.1:3000; \n  server 127.0.0.1:5000; \n} \n```\n\n#### 4.fair\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。 \n\n```nginx\nupstream backserver {\n  server 127.0.0.1:3000; \n  server 127.0.0.1:5000;\n  fair;\n} \n```\n\n#### 5.URL哈希\n\n根据请求URL的hash来分配，相同hash分配至同一台服务器\n\n```nginx\nupstream backserver {\n  server 127.0.0.1:3000; \n  server 127.0.0.1:5000;\n  hash $request_uri;\n  hash_method crc32;\n}\n```\n\n### 其它配置\n\n```nginx\nupstream backserver {\n  server 127.0.0.1:3000 down; # down表示服务宕机，不参与分配 \n  server 127.0.0.1:5000;\n  server 127.0.0.1:6000;\n  server 127.0.0.1:7000 backup; # backup表示这是备用服务，只有当其它服务全部down，才会启用备用服务\n}\n```\n\n\n\n## 设置头信息\n\n设置响应头有两个指令——`add_header`和`proxy_set_header`。\n\n- `add_header key value [always]`：**设置响应头给浏览器**，对20x和30x的响应码有效，加上`always`强制生效\n- `proxy_set_header key value`：**设置请求头给上游服务器**\n\n```nginx\n# nginx 设置cors跨域\nadd_header 'Access-Control-Allow-Origin' '*';\nadd_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';\nadd_header 'Access-Control-Allow-Headers' 'Content-Type';\nlocation ^~ /api {\n  if ($request_method = 'OPTIONS') {\n    return 200;\n  }\n  proxy_set_header Host $http_host;\n  proxy_pass http://127.0.0.1:8081/;\n}\n```\n\n## 变量参数\n\nnginx内置了很多变量，使用形式`$变量名`\n\n```nginx\n$args                    #请求中的参数值\n$query_string            #同 $args\n$arg_NAME                #GET请求中NAME的值\n$is_args                 #如果请求中有参数，值为\"?\"，否则为空字符串\n$uri                     #请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如\"/foo/bar.html\"。\n$document_uri            #同 $uri\n$document_root           #当前请求的文档根目录或别名\n$host                    #优先级：HTTP请求行的主机名>\"HOST\"请求头字段>符合请求的服务器名.请求中的主机头字段，如果请求中的主机头不可用，则为服务器处理请求的服务器名称\n$hostname                #主机名\n$https                   #如果开启了SSL安全模式，值为\"on\"，否则为空字符串。\n$binary_remote_addr      #客户端地址的二进制形式，固定长度为4个字节\n$body_bytes_sent         #传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的\"%B\"参数保持兼容\n$bytes_sent              #传输给客户端的字节数\n$connection              #TCP连接的序列号\n$connection_requests     #TCP连接当前的请求数量\n$content_length          #\"Content-Length\" 请求头字段\n$content_type            #\"Content-Type\" 请求头字段\n$cookie_name             #cookie名称\n$limit_rate              #用于设置响应的速度限制\n$msec                    #当前的Unix时间戳\n$nginx_version           #nginx版本\n$pid                     #工作进程的PID\n$pipe                    #如果请求来自管道通信，值为\"p\"，否则为\".\"\n$proxy_protocol_addr     #获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串\n$realpath_root           #当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径\n$remote_addr             #客户端地址\n$remote_port             #客户端端口\n$remote_user             #用于HTTP基础认证服务的用户名\n$request                 #代表客户端的请求地址\n$request_body            #客户端的请求主体：此变量可在location中使用，将请求主体通过proxy_pass，fastcgi_pass，uwsgi_pass和scgi_pass传递给下一级的代理服务器\n$request_body_file       #将客户端请求主体保存在临时文件中。文件处理结束后，此文件需删除。如果需要之一开启此功能，需要设置client_body_in_file_only。如果将次文件传 递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off，uwsgi_pass_request_body off，or scgi_pass_request_body off\n$request_completion      #如果请求成功，值为\"OK\"，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空\n$request_filename        #当前连接请求的文件路径，由root或alias指令与URI请求生成\n$request_length          #请求的长度 (包括请求的地址，http请求头和请求主体)\n$request_method          #HTTP请求方法，通常为\"GET\"或\"POST\"\n$request_time            #处理客户端请求使用的时间,单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。\n$request_uri             #这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如：\"/cnphp/test.php?arg=freemouse\"\n$scheme                  #请求使用的Web协议，\"http\" 或 \"https\"\n$server_addr             #服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中\n$server_name             #服务器名\n$server_port             #服务器端口\n$server_protocol         #服务器的HTTP版本，通常为 \"HTTP/1.0\" 或 \"HTTP/1.1\"\n$status                  #HTTP响应代码\n$time_iso8601            #服务器时间的ISO 8610格式\n$time_local              #服务器时间（LOG Format 格式）\n$cookie_NAME             #客户端请求Header头中的cookie变量，前缀\"$cookie_\"加上cookie名称的变量，该变量的值即为cookie名称的值\n$http_NAME               #匹配任意请求头字段；变量名中的后半部分NAME可以替换成任意请求头字段，如在配置文件中需要获取http请求头：\"Accept-Language\"，$http_accept_language即可\n$http_cookie　　　　　　　 #请求的所有cookie\n$http_host               #请求地址，即浏览器中你输入的地址（IP或域名）\n$http_referer            #url跳转来源,用来记录从那个页面链接访问过来的\n$http_user_agent         #用户终端浏览器等信息\n$http_x_forwarded_for    #客户端的IP和代理服务器的IP，以逗号隔开；可伪造\n$http_x_forwarded_proto  #请求的协议\n$sent_http_NAME          #可以设置任意http响应头字段；变量名中的后半部分NAME可以替换成任意响应头字段，如需要设置响应头Content-length，$sent_http_content_length即可\n$sent_http_cache_control\n$sent_http_connection\n$sent_http_content_type\n$sent_http_keep_alive\n$sent_http_last_modified\n$sent_http_location\n```\n\n## https\n\n在nginx中使用https，配置一下证书就可以\n\n```nginx\n# HTTPS server\n#\nserver {\n  listen       443 ssl;\n  server_name  localhost;\n\n  ssl_certificate      cert.pem; # 公钥，会被发送给每一个访问的客户端\n  ssl_certificate_key  cert.key; # 私钥，用来解密客户端发送的数据\n\n  ssl_session_cache    shared:SSL:1m; # 设置ssl/tls会话缓存的类型和大小\n  ssl_session_timeout  5m; # ssl参数的过期时间\n\n  ssl_ciphers  HIGH:!aNULL:!MD5; # 选择加密套件\n  ssl_prefer_server_ciphers  on; # on代表 设置协商加密算法时，优先使用服务端的加密套件，而不是客户端的加密套件\n\n  location / {\n    root   html;\n    index  index.html index.htm;\n  }\n}\n```\n\n## HTTP/2\n\n在https的例子上，做一处改动：在listen后加上http2即可\n\n```nginx\nlisten       443 ssl http2;\n```\n\n## Nginx日志切割\n\n如果把所有日志都打在一个日志文件中，当文件很大时，读写就会变慢从而影响nginx性能\n\n可以通过shell脚本按大小来切割日志文件。\n\n在nginx中，也可以按照时间来切割文件\n\n```nginx\nif ($time_iso8601 ~ \"^(\\d{4})-(\\d{2})-(\\d{2})\") {\n  set $year $1;\n  set $month $2;\n  set $day $3;\n}\naccess_log /var/log/nginx/$year-$month-$dayaccess.log json;\n```\n\n上例是把同一天的日志放在一个日志文件中。\n\n## 实现重定向\n\n重定向分为两种\n\n- 301：永久重定向\n- 302：临时重定向\n\n```nginx\nserver {\n  listen 8080;\n  \n  if($host != 'www.aaa.com') {\n    rewrite ^/(.*)$ 'http://www.bbb.com' permanent\n  }\n}\n```\n\n使用`rewirte`命令可以实现重定向功能\n\n```nginx\nrewrite 正则 重定向地址 flag\n```\n\nflag有一下值\n\n| 标记符号  | 说明                                               |\n| --------- | -------------------------------------------------- |\n| last      | 本条规则匹配完成后继续向下匹配新的location URI规则 |\n| break     | 本条规则匹配完成后终止，不在匹配任何规则           |\n| redirect  | 返回302临时重定向                                  |\n| permanent | 返回301永久重定向                                  |\n\n","tags":["Server","Nginx","Web"],"categories":["Server"]},{"title":"JavaScript沙箱","url":"/posts/72bec40a.html","content":"\n> **沙盒**（英语：sandbox，又译为**沙箱**）是一种安全机制，为运行中的程序提供的隔离环境。通常是作为一些来源不可信、具破坏力或无法判定程序意图的程序提供实验之用 **by wikipedia**\n\n简单的说，沙箱就是一个隔离的环境。沙箱里外互不影响。\n\n## Node的沙箱环境\n\n`nodejs`内置了一个`vm`模块，他可以让我们直接在 V8 虚拟机上下文中编译和运行代码，使用方法如下：\n\n```javascript\nconst vm = require(\"vm\");\n\n// 创建需要运行的脚本\nconst script = new vm.Script(\"a + b\");\n\n// 创建上下文 context\nconst context = vm.createContext({a: 1, b: 2});\n\n// 在上下文context下运行脚本\nconst result = script.runInContext(context)\n\nconsole.log(result) // 输出：3\n\n\n// 或者直接\nvm.runInContext(\"a + b\", context) // 输出：3\n```\n\n在nodejs中创建一个沙箱还是挺容易的。\n\n但是值得注意的是，`vm`模块并非绝对安全，由它创建的的沙箱内部通过一些手段还是可以访问到外部环境的。所以`nodejs`官方文档明确标注： **`vm` 模块不是安全的机制。 不要使用它来运行不受信任的代码**。\n\n也有一些社区模块：\n比如`vm2`，它内部使用`vm`模块，并且使用Proxy来阻止沙箱脚本逃逸。\n\n[`Safeify`](https://www.npmjs.com/package/safeify)是一个基于`vm2`的第三方库，它创建了个进程池，把代码放入进程池中执行。进程间通过IPC通讯。\n\n## 浏览器的沙箱环境\n\n浏览器环境没有`vm`这个API，实现将有所不同。\n\n### eval\n\n这是一个令人诟病的api，`eval(\"window\")`是能够访问到`window`对象的，所以它并不能隔离。\n\n### new Function()\n\n```javascript\nfn = new Function(...args, 'functionBody');\n```\n\n`new Function`依然能够访问到全局作用域。\n\n### with\n\n这个冷门的API，可能大多数JS开发者都没听说过\n\n```javascript\nfunction createRuntimeSandbox(src) {\n  src = 'with (context) {' + src + '}'\n  return new Function('context', src)\n}\n\nconst func = createRuntimeSandbox(\"console.log(window)\")\nfunc({window: 123}) // 输出 123\n```\n\n`with`关键字会使用`in`运算符来判断是否在`context`中。如果context存在就去context取。反之去全局作用域中取。\n\n### Proxy\n\n在with的例子上做些改动\n\n```javascript\nfunction createRuntimeSandbox(src) {\n  src = 'with (context) {' + src + '}'\n  const func = new Function('context', src)\n  return context => {\n    const fakeContext = {}\n    const proxy = new Proxy(fakeContext, {\n      has() { return true }, // 确保 xx in fakeContext 永远为true，不去全局作用域找\n      get(target, param) {\n        return target[param] || context[param]\n      }\n    })\n    return func(proxy)\n  }\n}\n\nconst func = createRuntimeSandbox(\"console.log(name);name='hello';console.log(name)\")\n\nconst context = { name: \"zxffan\", console }\nfunc(context) // 输出：zxffan hello\nconsole.log(context.name) // 输出：zxffan\n```\n\n上例使用了`proxy`，将上下文（context）做了代理。在沙箱里修改context的name属性不会影响到沙箱外。\n\n还有个问题，`proxy`只代理了`context`，如果context里又包含对象，那么在沙箱里是可以修改的。写一个通用的代理方法来解决\n\n```javascript\nfunction createProxySandbox(context, handler = {}) {\n  const fakeContext = {};\n  return new Proxy(fakeContext, Object.assign({\n    get(target, param) {\n      return Reflect.get(target, param) || Reflect.get(context, param)\n    }\n  }, handler))\n}\n\nfunction createRuntimeSandbox(src) {\n  src = 'with (context) {' + src + '}'\n  const func = new Function('context', src)\n  return context => {\n    const proxy = createProxySandbox(context, { has() { return true } })\n    return func(proxy)\n  }\n}\n\n\nconst func = createRuntimeSandbox(\"window.aa='zxffan';console.log(window.aa)\")\n\nconst fakeWindow = createProxySandbox(window)\nfakeWindow.window = fakeWindow\n\nfunc(fakeWindow) // 输出：zxffan\nconsole.log(window.aa) // 输出：undefined\n```\n\n这样使用，可以自定义需要暴露给沙箱的全局对象。\n\n`createProxySandbox`相当于代理提供的对象，并返回一个代理后的对象。对代理后的对象的修改不影响原对象，这本身就是一个**数据沙箱**。\n\n`createRuntimeSandbox`提供了一个指定上下文的JS执行环境。该环境确保不会直接访问和修改沙箱外的作用域的数据，这相当于一个**运行时沙箱**。\n\n## 总结\n\n沙箱的作用是隔离上下文环境，保证不会造成JS污染。\n\n应用场景：\n\n- 在微前端场景下，可以利用沙箱来保证各个微应用之间以及微应用和主应用之间不会造成JS污染。\n- 通常也可以将不受信（存在安全隐患）的代码放在沙箱中运行，以阻止其破坏主程序。\n\n推荐使用`with`、`new Function`以及`Proxy`构成的沙箱实现\n\n","tags":["javascript"],"categories":["JavaScript"]},{"title":"云计算的发展","url":"/posts/8aa364dc.html","content":"\n最近对`serverless`提起了兴趣，于是提笔写几篇学习笔记。\n\n## 时代历程\n\n总的来说云计算的发展经过了**物理机时代**、**虚拟机时代**、**容器时代**以及当下的**Serverless**。\n\n### 物理机时代\n\n发布一个网站，需要购买一台物理机服务器。然后手动安装操作系统和许多的软件环境。那时服务器发生故障时，服务迁移是一件很痛苦的事。而且购买物理机的成本也很高。\n\n### 虚拟机时代\n\n2001年后虚拟化技术日渐成熟。**虚拟化技术**可以将一台**物理机**分割成多台**虚拟机**供多名用户使用，充分利用硬件资源。比如阿里云的ECS，我上学的时候就买了一台虚拟机。相对于直接购买一台物理机，虚拟机可以大大降低成本。\n\n### 容器时代\n\n容器技术。目前比较流行的如`Docker`。在服务器上安装容器，将软件服务部署在容器中。这样，在做迁移的时候可以将容器内的软件环境打包成镜像。再拷贝到另一台服务器上部署。大大降低了迁移成本\n\n有了容器，在服务器上部署的就不再是应用而是一个个容器。当容器多了就比较难以管理。`Kubernetes(K8S)`是Google的用来进行容器编排的开源工具。有了K8S就可以实现网站的自动弹性伸缩。但是这一切的配置都需要专业的运维知识。\n\n### Serverless\n\n`Serverless`是指构建和运行不需要服务器管理的一种模式。目前Serverless实现方式主要是基于`FaaS`和`BaaS`\n\n- FaaS(函数即服务)：将应用切割成一个个独立的函数，每个函数有自己独立的业务，这些函数再组成复杂的应用。\n- Baas(后端即服务)：将数据库、文件存储等后端能力封装成服务，并以接口的形式提供。在FaaS中可以调用各种后端服务。\n\n一个Serverless的网站架构大致如下：\n\n![serverless架构](../../images/serverless/serverless网站架构.png)\n\n## XaaS\n\n梳理一些一些名词：IaaS、PaaS、SaaS、FaaS与BaaS\n\n- IaaS（基础设施即服务）：虚拟化技术成熟后，出现众多云厂商和产品。例如AWS 的 EC2、阿里云 ECS。这些都属于IaaS。\n- PaaS（平台即服务）：随着业务形态发展，云厂商发现可以抽象出一些通用的平台，比如中间件、数据库等，于是就把这些功能做成服务，也放在云上去卖，这些属于PaaS。\n- SaaS（软件即服务）：SaaS很常见。比如邮箱服务，软件环境部署在开发者服务器中。用户只需要一个账户，打开浏览器即可使用。\n- FaaS与BaaS上文讨论过。\n\n## Serverless\n\n### 什么是Serverless\n\n**广义的 Serverless** 是指：**构建和运行软件时不需要关心服务器的一种架构思想**\n\n**狭义的 Serverless** 是 **FaaS 和 BaaS 的组合**，这是当前主流的实现\n\nServerless的主要特点\n\n- 服务无关：开发者无需关心服务器资源（配置，磁盘大小等），只需要提供一份代码。\n- 弹性伸缩：资源的分配完全由云服务来计算，会根据请求量自动调整资源占用\n- 按量计费：在 Serverless 架构中，计费方式按实际使用量计费（比如函数调用次数、运行时长）。\n\n###  PaaS、Kubernetes 、云原生等技术是不是 Serverless？\n\n按照`Serverless`的特点来看，它们都不是\n`PaaS`是按照服务收费并非按量收费\n`K8S`是一种容器编排技术，它可以实现弹性伸缩。但是具体的编排规则需要专业运维来设置，不符合服务无关\n云原生是指原生为云设计的一种架构模式。`Serverless`是云原生的一种实现，`K8S`是另一种实现\n\n## Serverless的缺点\n\n1. 依赖第三方：使用`Serverless`就必须使用云厂商提供的`Serverless`的产品。这样就与云厂商绑定。一旦选定一个云厂商，在想做迁移就十分复杂。这是因为当前国内`Serverless`实现没有一个公共的标准。\n2. 底层硬件多样性：同一个云函数可能运行在不同硬件资源下。如果你的服务依赖于具体的硬件资源（比如只有某个CPU/GPU能够使用），这就要云厂商提供相应服务。\n3. 性能瓶颈：`Serverless`的云函数不是一直运行的，只有需要的时候才会执行。每次执行前会初始化函数执行环境，这需要一定时间。而这个时间需要云厂商自己去优化。\n4. 通信效率低：`Serverful`中函数掉函数都是在内存中进行的。而`Serverless`中函数都是独立的，之间调用（HTTP，RPC）肯定效率没有内存高\n5. 开发调试复杂：目前`Serverless`还处于发展阶段，各厂商的标准不一，开发和调试工具不完善。\n\n","tags":["Serverless","云计算"],"categories":["Server"]},{"title":"js实现选中与复制粘贴","url":"/posts/82fa4d6c.html","content":"\n## 选中\n\n### 两个对象\n\n1. [selection]( https://developer.mozilla.org/zh-CN/docs/Web/API/Selection )\n2. [range]( https://developer.mozilla.org/zh-CN/docs/Web/API/Range )\n\n> Selection对象所对应的是用户所选择的 [`ranges`](https://developer.mozilla.org/zh-CN/docs/Web/API/Range) （区域），俗称拖蓝 by MDN\n\nFirefox中可以通过按住ctrl同时选中不同区域，每个区域都对应一个range对象（chrome禁用了该功能，即只能选中一个区域）。selection代表文本选区（网页中可选择的区域），所以selection包含若干个range。可以通过`selection.getRangeAt(index)`来获取选区(range)。index是要获取的range的索引（chrome中只能是0）。\n\n### 应用：获取选中文本\n\n```javascript\nconst selection = window.getSelection()\nselection.toString()\n```\n\n### 应用：取消选中\n\n```javascript\nconst selection = window.getSelection()\nselection.removeAllRanges()\n```\n\n### 应用：全选某个节点的内容\n\n```javascript\nconst range = document.createRange() // 创建range对象\nconst node = document.getElementById('dom') // 获取要全选的dom节点\nrange.selectNodeContents(node)\n\nconst selection = window.getSelection()\nselection.removeAllRanges() // 清空其它选中内容\nselection.addRange(range) // 添加选中区域\n```\n\n### 应用：截取位置选中\n\n```javascript\nconst range = document.createRange()\nconst node = document.getElementById('dom') // 获取要截取的dom节点\n\n/* \n * * 如果起始节点类型是 Text， Comment, or CDATASection之一, 那么 startOffset指的是从起始节点算起字符的偏移量。 \n * * 对于其他 Node 类型节点， startOffset 是指从起始结点开始算起子节点的偏移量。\n */\nconst [startOffset, endOffset] = [1, 7]\nrange.setStart(node, startOffset)\nrange.setEnd(node, endOffset)\n\nconst selection = window.getSelection()\nselection.removeAllRanges() // 清空其它选中内容\nselection.addRange(range) // 添加选中区域\n```\n\n## 复制与粘贴\n\n复制与粘贴的实现需要使用[Clipboard](https://developer.mozilla.org/zh-CN/docs/Web/API/Clipboard)，它首先会通知用户是否赋予读写剪贴板权限。\n\n系统剪贴板暴露在全局属性`navigator.clipboard`之下\n\n它有四个API，他们都是返回Promise\n\n- read() 从剪贴板读取数据（比如图片）。\n- readText() 从剪贴板读取文本\n- write() 写数据\n- writeText() 写文本\n\n> 注意：\n> `document.execCommand`已经被废弃了，不建议使用。\n> `clipboard`在**非HTTPS环境**下不可用\n","tags":["javascript"],"categories":["JavaScript"]},{"title":"JavaScript函数式编程","url":"/posts/1690d21b.html","content":"\n## 函数式编程要素\n\n- 声明式\n- 纯函数\n- 不可变性\n\n### 声明式\n\n**声明式**是将程序的描述与求值分离开来的。它关注于如何用各种表达式来描述程序逻辑。与其相对的是**命令式**。\n\n```javascript\n// demo：求数组的每个元素（数值类型）的平方\nconst arr = [1, 2, 3, 4, 5]\n\n// 命令式\nfor (let i = 0; i < arr.length; i++) {\n  arr[i] = Math.pow(arr[i], 2);\n}\n\n// 声明式\nconst square = num => Math.pow(num, 2)\narr.map(square)\n\n```\n\n### 纯函数\n\n纯函数要求：\n\n- 对于同一组输入必然有相同的输出。\n- 不依赖于外部环境也不改变外部环境。\n\n```javascript\n\n// 具有副作用的函数\nlet count1 = 0;\nfunction increment1() {\n  return ++count1 // 引用了全局变量\n}\n\n// 纯函数\nfunction increment2(count) {\n  return count + 1\n}\n\n```\n\n实际上，纯函数是很难得的。我们要做的就是尽可能地把具有副作用地部分抽离出来，让逻辑结构更加清晰。\n\n### 不可变数据\n\n处理数据时不要修改原数据，尽可能得基于原数据来构造新数据。\n\n```javascript\n\n// demo: 数组排序\n\nconst arr = [4, 6, 2, 3, 8, 5];\n\n// mutable\nfunction sort1() {\n  return arr.sort()\n}\n\n// immutable\nfunction sort1() {\n  return [].concat(arr).sort()\n}\n\n```\n\n> 函数式编程鼓励将复杂的任务分成成一个个纯函数。再将这些函数进行组合。这样使得任务流更加清晰，更易于维护\n\n## 柯里(curry)化\n\n柯里化可以缩减函数参数。\n\n一个向节点插入参数的demo\n\n```javascript\nfunction insertText(dom, text) {\n  document.querySelector(dom).innerText = text\n}\n\ninsertText(\"container\", \"hello world\")\n```\n\n经过柯里化后就变成了\n\n```javascript\nfunction insertText(dom) {\n  return function (text) {\n    document.querySelector(dom).innerText = text\n  }\n}\n\nconst insertToContainer = insertText(\"container\")\ninsertToContainer(\"hello world\")\n```\n\n## 组合\n\n组合是函数式编程的一个重要概念。将一个复杂的逻辑拆分成一个个函数后，需要将这些函数组合起来执行。\n\n### 链式组合\n\n在组合纯函数时，通过链式的方式比较容易被理解，例如:\n\n```javascript\narr.filter(/** .. **/)\n   .map(/** .. **/)\n   .reduce(/** .. **/)\n   //...\n```\n\n真的打算使用链式组合法的话，推荐`lodash.js`这个工具库。\n\n```javascript\nvar users = [\n  { 'user': 'barney',  'age': 36 },\n  { 'user': 'fred',    'age': 40 },\n  { 'user': 'pebbles', 'age': 1 }\n];\n \nvar youngest = _\n  .chain(users)\n  .sortBy('age')\n  .map(function(o) {\n    return o.user + ' is ' + o.age;\n  })\n  .head()\n  .value();\n// => 'pebbles is 1'\n```\n\n### 管道组合\n\n方法链的一个缺点就是：它与方法所属的对象紧紧地耦合在一起，限制链中可以使用的方法数量，也就限制了代码的表现力。\n\n```javascript\n\nfunction first() {}\n\nfunction getName() {}\n\nfunction reverse() {}\n\nfunction sort() {}\n\nconst task = pipe(first, getName, reverse, sort) // pipe 用来组合函数\n\ntask(params)\n\n```\n\n`pipe`将函数组合起来。`task`执行后，将`params`传递给`first`。`first`函数执行完成后再将结果传递给`getName`。由此类推，将所有函数组合起来，形如一条管道。\n\n上例中，`pipe`的参数都是函数声明，如果某个函数需要提前传入一些参数可以使用**柯里化**\n\n这里推荐一下`Ramda.js`这个工具库。它与`lodash`相似但却又不相同，它内置`pipe`方法以及其它组合方法。\n\n## 管道组合处理程序流\n\n上面的例子，都没有涉及到 逻辑分支。在命令式代码中，我们很容易就会写`if/else`，而函数式编程是不建议直接使用`if/else`的。\n\n在`Ramda.js`中`pipe`是用来组合函数的，叫做**组合器**。除了`pipe`还有其它组合器\n\n### R.compose\n\n`compose`与`pipe`功能一样，只是组合的方向相反。\n`R.compose(f1, f2, f3)`, 他会先执行f3，然后执行f2，最后f1\n\n### R.tap\n\n`compose`和`pipe`组合函数时，存在参数传递。每个函数的返回值都给传给管道中的下一个函数。\n如果中间有一个函数没有返回值（比如 日志埋点）就无法构成管道。\n\n`tap`能够将一个无返回值的函数插入管道中，因为tap会将参数原样返回。\n\n```javascript\nconst debug = R.tap(debugLog);\nconst cleanInput = R.compose(normalize, debug, trim);\nconst isValidSsn = R.compose(debug, checkLengthSsn, debug, cleanInput);\n```\n\n### alternation\n\n```javascript\nconst alt = function (...fns) {\n  return function (val) {\n    let result\n    for (let fn of fns) {\n      result = fn(val);\n      if (result) break;\n    }\n    return result\n  }\n}\n```\n\n`alt(fn1, fn2, fn3, ...)`，如果fn1的返回值不是`false`、`null`和`undefined`则返回fn1的返回值。否则执行fn2的，再判断其返回值。\n所以`alt`能够提供简单的逻辑条件判断\n\n### sequence\n\n实现如下\n\n```javascript\nconst seq = function(...funcs) {\n  const funcs = Array.prototype.slice.call(arguments);\n  return function (val) {\n    funcs.forEach(function (fn) {\n      fn(val);\n    });    \n  };\n};\n```\n\n`seq(fn1, fn2, fn3, ...)`, 会顺序执行所有函数，这些函数在管道中时平行的，它们都接受管道中上一个函数的返回值作为参数。通常放在管道的末尾。\n\n### fork-join\n\n```javascript\nfunction fork (join, ...fns) {\n  return function (val) {\n    let result = []\n    fns.forEach(fn => result.push(fn(val)));\n    join(...result)\n  }\n}\n```\n\n`fork`相对于`seq`增加了一步，将所有函数的执行结果传递给`join`，再做一次处理。\n\n未完...\n\n## Functor\n\n**`functor`是实现了`map`函数并遵守一些特定规则的容器类型。**比如下面这个`Just`容器\n\n```typescript\nclass Just<T> {\n  private _value: T;\n  constructor(value: T) {\n    this._value = value\n  }\n  map(fn: (...args: any[]) => any): Wrapper {\n    return Just.of(fn(this._value))\n  }\n\tstatic of<U>(value: U) {\n    return new Monad(value);\n  }\n}\n```\n\n这个**Just容器**就是一个**Functor（函子）**\n\n- 封装了value，容器外无法修改`_value`。从而保护数据\n- 提供map函数，该函数将原始值传给参数函数，并将结果再次封装。map函数将方便链式调用\n- of是一个静态函数。用于封装数据\n\n从本质上讲，Functor 只是一个可以将函数应用到它包裹的值上，并将结果再包裹起来的**数据结构**。\n\n## Maybe\n\n`Maybe`也属于`Functor`，它在`Just`上增加了错误处理\n\n```typescript\nclass Maybe<T> {\n  private _value: T;\n  constructor(value: T) {\n    this._value = value\n  }\n  isNothing(): boolean {\n    return this._value === undefined || this._value === null\n  }\n  map(fn: (...args: any[]) => any) {\n    return this.isNothing() ? Maybe.of(null) : Maybe.of(fn(this._value))\n  }\n\tstatic of<U>(value: U) {\n    return new Monad(value);\n  }\n}\n```\n\n当出现null，undefined时，调用不会抛出异常。\n\n```typescript\nMaybe.of(null).map((a) => a + 3)\n// Maybe { _value: null }\n```\n\n## Monad\n\n使用`functor`可能会造成嵌套封装的情况\n\n```typescript\nconst num = Maybe.of(Maybe.of(3))\nnum.map(v => v + 1) // error\n```\n\n这时，map的参数函数接受的参数`v`实际上还是一个`Functor`，它并不能直接参与运算。\n\n`Monad`可以使`functor`扁平化。\n\n- 提供一个`join`函数，其意是将所有嵌套的`Functor`合并成一个。\n- identity用来获取原始值，之前所有`this._value`替换成`this.identity()`\n\n```typescript\nclass Monad<T> {\n  private _value: T;\n  constructor(value: T) {\n    this._value = value;\n  }\n  isNothing(): boolean {\n    const value = this.identity()\n    return value === undefined || value === null;\n  }\n  join() {\n    if (this._value instanceof Monad) {\n      return this.isNothing() ? Monad.of(null) : this._value.join();\n    } else return this;\n  }\n  map(fn: (...args: any[]) => any) {\n    return this.isNothing() ? Monad.of(null) : Monad.of(fn(this.identity()));\n  }\n  static of<U>(value: U) {\n    return new Monad(value);\n  }\n  identity() {\n    return this.join()._value;\n  }\n}\n\nconst num = Monad.of(Monad.of(3));\nnum.map((v) => v + 1); // Monad {_value: 4}\n\n```\n\n## Applicative\n\n上面的例子都是封装数据。如果函数也是一个`functor`，就需要提供一个`apply`方法。\n\n```typescript\nclass Applicative<T> {\n  // ...\n  apply(container: Applicative<any>) {\n    return container.map(this._value)\n  }\n  // ...\n}\nconst plus3 = v => v + 3;\nApplicative.of(plus3).apply(Applicative.of(2)) // Applicative {_value: 5}\n```\n\n<hr/>\n\n结合上面的所有例子，梳理一下code\n\n```typescript\nclass Monad<T> {\n  private _value: T;\n  constructor(value: T) {\n    this._value = value;\n  }\n  isNothing(): boolean {\n    return this._value === undefined || this._value === null;\n  }\n  join() {\n    if (this._value instanceof Monad) {\n      return this.isNothing() ? Monad.of(null) : this._value.join();\n    } else return this;\n  }\n  map(fn: (...args: any[]) => any) {\n    return this.isNothing() ? Monad.of(null) : Monad.of(fn(this.identity()));\n  }\n  apply(container: Monad<any>) {\n    console.log(this.identity())\n    return container.map(this.identity())\n  }\n  static of<U>(value: U) {\n    return new Monad(value);\n  }\n  private identity() {\n    return this.join()._value;\n  }\n}\n```\n\n","tags":["functional programing"],"categories":["读书"]},{"title":"Webpack5","url":"/posts/46109b3a.html","content":"\n`Webpack5`正式版距`V4`发布已经过去2年了。新版做了许多API和底层的改动，这会导致一些现有的`plugin`或者`loader`无法在`V5`版本运行。\n\n先贴一下[官方文档](https://webpack.docschina.org/blog/2020-10-10-webpack-5-release/)\n\n本文梳理一些webpck所做出的比较重要的改动\n\n- 功能清除\n- new URL\n- 长期缓存\n- 持久化缓存\n- tree-shaking\n- 联邦模块\n\n## 功能清除\n\n首先，所有在`V4`标记为废弃的api都被移除。升级前先检查是否使用了被废弃的API（看控制台是否有警告）\n\n`V5`取消默认`nodejs`的`polyfill`\n在`V4`中可以使用一部分`nodejs`的API（例如:`crypto`模块）。在`V5`中不会对这些API进行`polyfill`，所以需要手动`polyfill`\n\n原因：官方认为在绝大数情况下这些`polyfill`都是不必要的，而且它增大了`bundle`的体积\n\n### Crypto\n\n当使用如下代码：\n\n```typescript\nimport CryptoJS from \"crypto-js\";\nconst md5Password = CryptoJS.MD5(\"123123\");\nconsole.log(md5Password);\n```\n\nwepack5会自动报错\n\n![node-polyfill](../../images/framework/node-polyfill.jpg)\n\n根据提示操作即可。\n\n### process\n\nnodejs的`process`模块无法直接使用。\n\n使用`process`是，webpack5会报错，提示引入`process`模块的`polyfill`。\n\n如果使用`process.env.NODE_ENV`则不会报错，因为webpack在解析过程中将其值替换成对应`mode`的值\n可以使用 `DefinePlugin` 或 `EnvironmentPlugin` 在配置中定义这些变量。\n\n### 其它模块\n\npath模块需要手动`polyfill`\nurl模块可以直接使用。\n\n## new URL\n\n### 引入资源方式\n\n`webpack5`对资源模块提供了内置支持\n\n- `V4`中使用`import img from './picture.png`，需要在`module.rules`中做相应的配置\n- `V5`中可以直接使用`new URL('./picture.png', import.meta.url)`\n\n> import.meta.url 是当前文件的 file: url(类似于__filename)\n> 使用URL会向 javascript 注入一个 DataURI\n\n### Worker\n\n由上，可以这么使用worker：`new Worker(new URL(\"./worker.js\", import.meta.url))`\n\n这样就可以更好地在webpack中使用 webWorker\n\n## 长期缓存\n\n长期缓存的目的是当应用重新打包后尽可能保持文件不变，这样浏览器就可以直接使用缓存。\n\n### name id hash\n\nwebpack最终输出的文件称为`bundle`(与`chunk`一一对应)。其文件名取决于webpack的配置，例如`filename: [name].[id].[hash]`\n\n- name 为chunk的名称，name一般取文件名或者或者开发者通过魔法注释指定\n- id 为chunkId，id是webpack自动生成的（`V4`是递增的）\n- hash 有分为三种 `hash` `chunkhash` `contenthash`\n  \n> 有时候name等于id？\n> 当开发者没有指定name时，name默认取id的值\n> 例如：当使用动态import，却没用魔法注释指定chunkName(/\\* webpackChunkName: \"home\" \\*/)\n\n### chunkId 和 moduleId 不稳定\n\n在`V4`中，`chunkId`和`moduleId`默认都是递增的：`1.js -> 2.js -> 3.js -> 4.js`\n但是当删除`2.js`后，原来的`3`就变成`2`，导致无法直接使用缓存内容，这种现象也被称为`chunkId`和`moduleId`不稳定\n\n### 如何稳定\n\n`V4`中使用外部插件解决\n\n- chunkId：可安装NamedChunksPlugin插件来稳定chunkId；或者配置`optimization.chunkIds='named'`。\n- moduleId：可安装HashedModuleIdsPlugin插件覆盖默认的moduleId规则，使用模块路径生成的hash作为moduleId。\n\n`V5`中对`moduleId`和`chunkId`的生成策略进行了优化，从而无需引入任何插件（生产模式下是默认启用的）\n\n- moduleId改为根据上下文模块路径计算\n- chunkId根据chunk内容计算\n\n配置`optimization`\n\n```typescript\nexport default {\n\n  // ...\n\n  optimization: {\n    chunkIds: 'deterministic',\n    moduleIds: 'deterministic'\n  },\n\n  //...\n\n}\n```\n\n## 持久化缓存\n\n持久化缓存是指第一次**全量构建**，利用磁盘缓存\n后续构建会 读取缓存，然后进行校验。\n\n`V4`中也有类似的手段，比如`cache-loader`。`babel-loader`也有`cacheDirectory: true`。\n\n`V5`内置了磁盘持久化缓存功能\n\n```typescript\nexport default {\n  cache: {\n     // 1. 将缓存类型设置为文件系统\n    type: 'filesystem', // 默认是memory\n    // 2. 将缓存文件夹命名为 .temp_cache,\n    // 默认路径是 node_modules/.cache/webpack\n    cacheDirectory: path.resolve(__dirname, '.temp_cache')\n  },\n};\n```\n\n## Tree-Shaking优化\n\n`V5`的tree-shaking支持了更多的场景。\n\n### 嵌套tree-shaking\n\n```javascript\n// inner.js\nexport const a = 1;\nexport const b = 2;\n\n// module.js\nexport * as inner from './inner';\n// 或 import * as inner from './inner'; export { inner };\n\n// user.js\nimport * as module from './module';\nconsole.log(module.inner.a);\n```\n\n`V5` 能将b给tree-shaking掉。\n\n### 内部tree-shaking\n\n```javascript\nimport { something } from './something';\n\nfunction usingSomething() {\n  return something;\n}\n\nexport function test() {\n  return usingSomething();\n}\n```\n\n当设置`\"sideEffects\": false`时并且 `test` 导出未被使用时，不但会删除`test`也会删除`something`。\n\n### Commonjs tree-shaking\n\n`V5`现在支持`CommonJS`模块的tree-shaking\n\n## 联邦模块（Module Federation）\n\n### 概述\n\n联邦模块应该是`V5`中较为亮眼的更新。联邦模块是为了解决应用间模块共享的问题。\n\n换句话说，现在有A、B两个应用。A应用中写了一个工具库，现在B应用也想用。怎么办？\n首先把工具库抽离出来\n\n- 发布到npm。应用install来使用\n- 或者打包成UMD，通过CDN类似方式使用\n\n但是这种方式就会有版本问题，A，B应用使用的版本可能不一致。\n\n联邦模块如何做的呢？\n\n联邦模块可以让B应用直接使用A应用的工具库。\n\n### 使用\n\n场景：两个应用：`app1`和`app2`。后者需要使用前者`utils.ts`\n\napp1配置如下：\n\n```typescript\nimport { ModuleFederationPlugin } from \"webpack\"\n\nexport default {\n  // other webpack configs...\n  plugins: [\n    new ModuleFederationPlugin({\n      // name 当前应用名称，不能与其它应用冲突\n      name: \"app1\",\n      // UMD标准导出，和name保持一致即可\n      library: { type: \"var\", name: \"app_two\" },\n      // 远程应用时被其他应用引入的js文件名称\n      filename: \"remoteEntry.js\",\n      // exposes 表示导出的模块，只有在此申明的模块才可以作为远程依赖被使用\n      exposes: {\n        utils: \"./src/libs/utils.ts\"\n      },\n      // shared可以让远程加载的模块对应依赖改为使用本地项目的 React或ReactDOM。\n      shared: [\"vue\", \"vue-router\", \"vuex\"]\n    }),\n    new HtmlWebpackPlugin({\n      template: \"./public/index.html\",\n      chunks: [\"main\"]\n    })\n  ]\n};\n```\n\napp2配置如下：\n\n```typescript\nimport { ModuleFederationPlugin } from \"webpack\"\n\nexport default {\n  // other webpack configs...\n  plugins: [\n    new ModuleFederationPlugin({\n      name: \"app2\",\n      // remotes 可以将其他项目的 name 映射到当前项目中\n      remotes: {\n        app1: \"app1\",\n      },\n      shared: [\"vue\", \"vue-router\", \"vuex\"]\n    }),\n    new HtmlWebpackPlugin({\n      template: \"./public/index.html\",\n      chunks: [\"main\"]\n    })\n  ]\n};\n```\n\n在app2中引入模块\n\n```html\n<head>\n  <!-- remoteEntry.js 是 filename字段的值 -->\n  <script src=\"http://localhost:3001/remoteEntry.js\"></script>\n</head>\n```\n\n在app2中使用\n\n```typescript\nimport utils from 'app1/utils'\n```\n\n`import` 的内容是**远程应用名/暴露的模块名**，对应webpack配置里面的name和expose\n\n### 玩法\n\n#### 微前端\n\n联邦模块不仅支持导出应用的某个模块，也支持expose整个应用（expose entry）\n\n对于 主从应用（一个主应用 + 多个子/微应用）这种微前端架构\n\n微应用暴露自己，主应用管理路由并使用微应用\n\n公共模块写在主应用中并暴露出来，微应用再使用\n\n#### 公共组件服务\n\n如果团队内部有组件库或工具库。现在不用发布到npm上。可以单独部署一个 **公共组件服务**。\n\n![common_component_structure](../../images/framework/common_component_structure.jpg)","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"HTTP首部","url":"/posts/8b77beaa.html","content":"\nhttp首部分为四部分——**请求行/状态行**、**请求/响应首部字段**、**通用首部字段**、**实体首部字段**组成。\n\n梳理一下当作字典，以便日后查阅。\n\n## 首部一览\n\nHTTP/1.1 规范定义了如下 47 种首部字段。\n\n| 首部字段名      | 说明                               |\n| --------------- | ---------------------------------- |\n| `Cache-Control` | （强）缓存控制，1.0还有个`Expired` |\n| `Connection`    |                                    |\n\n## 通用首部字段\n\n通用首部字段是指，请求报文和响应报文双方都会使用的首部。\n\n### Cache-Control\n\n场景：浏览器第一次请求服务器时，服务端返回资源并再**response header**加上`Cache-Control: max-age=56700000`。浏览器接受资源并把资源和相关头信息缓存下来。当第二次请求改资源时，先从缓存中找，计算第一次请求的时间和`max-age`来判断是否过期。若没过期则取缓存内容，若过期再向服务器请求。\n\n这个字段既可以出现在请求头中也可以出现在响应头中，但参数不太一样\n\n#### 请求头参数\n\n| 指令              | 参数 | 说明                                                        |\n| ----------------- | ---- | ----------------------------------------------------------- |\n| `no-cache`        | 无   | 不使用强缓存，强制向源服务器再次验证（使用协商缓存）        |\n| `no-store`        | 无   | 不使用缓存                                                  |\n| `max-age=[ 秒]`   | 秒   | 缓存的时间                                                  |\n| `max-stale=[ 秒]` | 秒   | 可省略，可容忍的最大过期时间, 接受age+stale时间内的缓存数据 |\n| `min-fresh=[ 秒]` | 秒   | `min-fresh=60`要求（缓存）服务器返回缓存时间未过60s的资源   |\n| `no-transform`    | 无   | 缓存不能改变实体主体的媒体类型                              |\n| `only-if-cached`  | 无   | 完全使用缓存，若未命中返回`504 Gateway Timeout`             |\n| `cache-extension` | 无   | 新指令标记（token）                                         |\n\n`cache-extension` token可以扩展`Cache-Control`首部字段内的指令\n例如：`Cache-Control: private, community=\"UCI\"`\n其中`community`属于扩展指令\n\n#### 响应头参数\n\n| 指令               | 参数 | 说明                                           |\n| ------------------ | ---- | ---------------------------------------------- |\n| `public`           | 无   | 可以被任意方缓存                               |\n| `private`          | 无   | 仅可被特定用户缓存                             |\n| `no-cache`         | 无   | 可省略，使用缓存前先向服务端验证有效性（协商） |\n| `no-store`         | 无   | 不缓存请求和响应内容                           |\n| `no-transform`     | 无   | 缓存不能改变实体主体的媒体类型                 |\n| `must-revalidate`  | 无   | 可缓存但必须再向源服务器进行确认               |\n| `proxy-revalidate` | 无   | 要求中间缓存服务器对缓存的响应有效性再进行确认 |\n| `max-age=[ 秒]`    | 秒   | 缓存的时间                                     |\n| `s-maxage=[ 秒]`   | 秒   | **公共缓存服务器**响应的最大Age值              |\n| `cache-extension`  | 无   | 新指令标记（token）                            |\n\n### Connection\n\n`Connection`首部字段有两个作用\n\n1. 控制不再转发给代理的首部字段\n2. 管理持久化连接\n\n#### 控制不再转发给代理的首部字段\n\n使用方式：再请求头加上`Connection: 不再转发的首部字段名`\n当请求发送给代理服务器时，代理服务器会剔除指定首部字段，然后再转发给源服务器\n\n#### 持久化连接\n\n`HTTP/1.1`默认全部都是持久化连接，当服务端想断开连接时，在响应头中指定字段`Connection: close`\n\n`HTTP/1.0`默认是非持久化连接。若想建立持久化连接，请求双方都要在头信息中加上`Connection: Keep-Alive`\n\n### Date\n\n`Date`表示创建HTTP报文的日期和时间，格式如：`Date: Tue, 03 Jul 2012 04:40:59 GMT`\n\n### Pragma\n\n`Pragma: no-cache`与`Cache-Control: no-cache`作用相同。是为了兼容`HTTP/1.0`而存在的\n\n### Trailer\n\n响应首部。`Trailer`字段指明在报文主体后记录了哪些首部字段，允许发送方在分块发送的消息后面添加额外的元信息\n使用：`Trailer: Expires`\n\n### Transfer-Encoding\n\n指定报文主体的传输编码，HTTP/1.1 的传输编码方式仅对分块传输编码有效。\n使用：`Transfer-Encoding: chunk`\n\n### Upgrade\n\n用于检测能否升级通信协议，其参数值可以用来指定一个完全不同的通信协议。\n使用：\n\n```text\nUpgrade: TLS/1.0, HTTP/1.1\nConnection: Upgrade\n```\n\n通常配合`Connection`使用，因为`Upgrade`字段不需要转发\n\n### Via\n\n用于追踪客户端和服务端之间的请求和响应报文的传输路径\n\n![via_header](../../images/图解HTTP/via_header.png)\n\n### Warning\n\n返回与缓存相关的警告，\n例如：`Warning: 113 gw.hackr.jp:8080 \"Heuristic expiration\" Tue, 03`\n格式：`Warning: [警告码][警告的主机:端口号]“[警告内容]”([日期时间])`\n\n## 请求首部字段\n\n请求首部字段是从客户端往服务器端发送请求报文中所使用的字段，用于补充请求的附加信息、客户端信息、对响应内容相关的优先级等内容。\n\n### Accept\n\n告知服务器，客户端所期望的媒体类型或媒体类型优先顺序，用q表示权重（取0~1，默认1）\n使用：`Accept: text/html,application/xhtml+xml,application/xml;q=0.9`\n\n常见媒体类型:\n\n1. 文本文件\n   - `text/html`、`text/plain`、`text/css`\n   - `application/xhtml+xml`、`application/xml`\n2. 图片文件\n   - `image/jpeg`、`image/gif`、`image/png`\n3. 视频文件\n   - `video/mpeg`、`video/quicktime`\n4. 应用程序使用的二进制文件\n   - `application/octet-stream`、`application/zip`\n\n### Accept-Charset\n\n告知服务器，客户端所期望的字符集或字符集的优先顺序，也可以用q来表示权重\n使用：`Accept-Charset: iso-8859-5, unicode-1-1;q=0.8`\n\n### Accept-Encoding\n\n告知服务器，客户端所期望的内容编码或内容编码优先级顺序\n使用: `Accept-Encoding: gzip, deflate`\n\n常见编码方式：\n\n- gzip\n由文件压缩程序 gzip（GNU zip）生成的编码格式（RFC1952），采用 Lempel-Ziv 算法（LZ77）及 32 位循环冗余校验（Cyclic Redundancy Check，通称 CRC）。\n- compress\n由 UNIX 文件压缩程序 compress 生成的编码格式，采用 Lempel-Ziv-Welch 算法（LZW）。\n- deflate\n组合使用 zlib 格式（RFC1950）及由 deflate 压缩算法（RFC1951）生成的编码格式。\n- identity\n不执行压缩或不会变化的默认编码格式\n\n采用权重 q 值来表示相对优先级，这点与首部字段 Accept 相同。另外，也可使用星号（*）作为通配符，指定任意的编码格式。\n\n### Accept-Language\n\n告知服务器客户端所期望的自然语言集（指中文或英文等），以及自然语言集的相对优先级。\n\n使用：`Accept-Language: zh-cn,zh;q=0.7,en-us,en;q=0.3`\n\n### Authorization\n\n告知服务器客户端的认证信息。\n当客户端未携带认证信息，服务端会返回**401 Unauthorized**\n使用：`Authorization: Basic dWVub3NlbjpwYXNzd29yZA==`\n\n### Expect\n\n发送一个POST请求，请求头携带`Expect: 100-continue`，会先去询问Server是否愿意接受数据\n接收到Server返回的`100-continue`应答以后，才能把数据POST给Server\n\n### From\n\n该字段用来记录用户的电子邮件地址，使用：`From: yourname@outlook.com`\n\n### Host（重要概念）\n\n先明确**虚拟主机的概念**——一台服务器对应一个公网IP地址，一个IP又可以对应多个域名，那么如何通过不同域名访问对应服务器上不同的站点呢？答案是，将服务器划分成多个虚拟主机，在请求头上加上`Host`字段指定对应虚拟主机名称，这样就能访问到对应的站点\n\n> `nginx` 划分虚拟主机很简单，直接设置不同的`server_name`即可\n\n### If-Match\n\n形如`If-*`的字段称之为条件请求，只有判断指定条件为真时，才会执行请求。\n\n客户端发送请求，携带`If-Match: \"123456\"`。服务端为实体资源生成实体标记`ETag`，然后判断`If-Match`和`ETag`的值。若相同，则返回实体资源；若不同，则返回**412 Precondition Failed**\n\n> If-match的取值还可以时`*`，表示让服务端忽略`ETag`\n\n### If-Modified-Since\n\n这个请求头与**协商缓存**有关\n\n- 客户端第一次发送请求。服务端收到请求后，返回实体资源并加上响应头`Last-Modified`其值为该资源最后一次修改时间。客户端收到响应后缓存该资源和`Last-Modified`\n- 客户端第二次发送请求，在请求头上携带`If-Modified-Since`，其值为上一次服务端返回的`Last-Modified`值。当服务端收到请求后，检查对应实体资源最新的`Last-Modified`并与`If-Modified-Since`对比判断是否过期。若未过期，则返回**304 Not Modified**表示客户端可以使用缓存；若过期，返回新的实体资源和`Last-Modified`\n\n### If-None-Match\n\n这个字段与`If-Match`作用相反\n\n待续...\n\n## 响应首部字段\n\n响应首部字段是服务器返回给客户端的响应报文中所使用的字段\n\n### Accept-Ranges\n\n用来告知客户端能否处理范围请求\n\n- Accept-Ranges: bytes  支持\n- Accept-Ranges: none   不支持\n\n### Age\n\n告知客户端，源服务器在多久前创建了响应\n\n`Age: 600` 单位：s\n\n### ETag\n\nETag是响应资源的唯一性标识，当资源改变，ETag也会变化\n\n- 强ETag：不论实体发生多么细微的变化都会改变其值 `ETag: \"usagi-1234\"`\n- 弱ETag：只有资源发生了根本改变，产生差异时才会改变 ETag 值 `ETag: W/\"usagi-1234\"`\n\n### Location\n\n`Location: http://www.usagidesign.jp/sample.html`\n\n引导客户端去指定位置请求资源，配合 3XX: Redirection\n\n### Proxy-Authenticate\n\n`Proxy-Authenticate: Basic realm=\"Usagidesign Auth\"`\n\n没搞懂\n\n### Retry-After\n\n`Retry-After: 120`，单位s，也可以是具体时间\n\n告知客户端，在多久后再次发送请求。配合 `503 Service Unavailable`或`3xx Redirect`使用\n\n### Server\n\n告知客户端，服务器上安装的HTTP服务器应用程序的信息。\n\n- `Server: Apache/2.2.17 (Unix)`\n- `Server: Apache/2.2.6 (Unix) PHP/5.2.5`\n\n### Vary\n\n","tags":["NetWork","HTTP Header"],"categories":["NetWork"]},{"title":"HTTP梳理","url":"/posts/3b531846.html","content":"## HTTP工作模型\n\n一次HTTP请求涉及到两个角色——**客户端**和**服务端**。\n\n1. 客户端发送请求（报文）\n2. 服务端收到请求开始处理\n3. 然后把响应（报文）发送回客户端\n\n![http工作模型](../../images/图解HTTP/http工作模型.jpg)\n\n## 持久化连接和管线化\n\n### 持久化连接\n\n传输层的`TCP`协议，规定通信双方必须**先建立连接**再通信。\n\n在`HTTP`的初始版本，每进行一次HTTP通信就要断开一次TCP，多个HTTP请求不能复用一个TCP连接\n\n在`HTTP1.1`中，默认开启持久化连接，是多个HTTP请求可以复用同一个TCP连接。只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\n\n![持久化连接](../../images/图解HTTP/持久化连接.jpg)\n\n### 管线化\n\n持久连接使得多数请求以管线化（pipelining）方式发送成为可能。从前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。\n\n## 无状态和Cookie\n\n### 无状态协议\n\n`HTTP`协议自身不具备保存之前发送过的请求或响应的功能\n每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。\n\n但是无状态也会导致新的问题——用户登陆状态如何保存？\n\n于是引入了`Cookie`\n\n### Cookie\n\n`Cookie` 是通过在请求和响应报文中写入 `Cookie` 信息来控制客户端的状态。\n\n1. 客户端发送请求报文\n2. 服务端收到请求，处理。在响应报文中添加一个`Set-Cookie`的首部字段\n3. 客户端收到响应，取出`Set-Cookie`的信息\n4. 客户端以后发送的请求，在请求报文首部加上`Cookie`。这样服务端就能识别客户端了。\n\n## HTTP 报文\n\n用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的HTTP 报文叫做**请求报文**，响应端（服务器端）的叫做**响应报文**。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的**字符串文本**。\n\nHTTP报文由**报文首部（header）**和**报文主体（body）**构成，两者以**空行（CR+LF）**分隔\n\n> 报文：是 HTTP 通信中的基本单位，由 8 位组字节流（octet sequence，其中 octet 为 8 个比特）组成，通过 HTTP 通信传输。\n\n## 提升传输速率\n\n### 压缩\n\n**内容编码**保持实体信息原样压缩，内容编码后的实体由客户端接收并负责解码。\n\n常用的内容编码有以下几种。\n- gzip（GNU zip）\n- compress（UNIX 系统的标准压缩）\n- deflate（zlib）\n- identity（不进行编码）\n\n### 分块\n\n**分块传输编码**会将实体主体分成多个部分（块）。\n使用分块传输编码的实体主体会由接收的客户端负责解码，恢复到编码前的实体主体。\n\n## 多部分对象集合\n\n`HTTP`协议发送的报文主体可以包含多个类型实体。\n多部分对象集合包含的对象如下：\n\n- multipart/form-data: `Content-Type: multipart/form-data; boundary=AaB03x`\n- multipart/byteranges: `Content-Type: multipart/byteranges; boundary=THIS_STRING_SEPARATES`\n\n`Content-Type`定义资源类型\n`boundary`定义不同类型实体之间的分隔符\n\n## 范围请求\n\n指定范围发送的请求叫做**范围请求**\nbyte 范围的指定形式如下。\n- 5001~10 000 字节：`Range: bytes=5001-10000`\n- 从 5001 字节之后全部的: `Range: bytes=5001-`\n- 从一开始到 3000 字节和 5000~7000 字节的多重范围: `Range: bytes=-3000, 5000-7000`\n\n针对范围请求，响应会返回状态码为 206 Partial Content 的响应报文。另外，对于多重范围的范围请求，响应会在首部字段 Content-Type 标明 multipart/byteranges 后返回响应报文。\n\n## 内容协商\n\n内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。\n\n比如说，客户端浏览器是英文的，服务器返回的网页也会是英文的。\n\n相关首部字段如下：\n- `Accept`\n- `Accept-Charset`\n- `Accept-Encoding`\n- `Accept-Language`\n- `Content-Language`\n\n## HTTP状态码\n\n|     | 类别                           | 说明                       |\n| --- | ------------------------------ | -------------------------- |\n| 1XX | Informational(信息性状态码)    | 接收到的请求正在处理       |\n| 2XX | Success(成功状态吗)            | 请求正常处理完毕           |\n| 3XX | Redirection(重定向状态吗)      | 需要进行附加操作已完成请求 |\n| 4XX | Client Error(客户端错误状态码) | 服务器无法处理请求         |\n| 5XX | Server Error(服务器错误状态吗) | 服务器处理请求出错         |\n\n### 2XX\n\n#### 200 OK\n\n表示客户端发来的请求在服务端被正常处理了\n\n#### 204 No Content\n\n请求处理成功，但是没有资源课返回\n\n#### 206 Partial Content\n\n客户端进行了范围请求，服务器成功执行了这部分请求。\n响应报文中包含由 Content-Range 指定范围的实体内容。\n\n### 3XX\n\n#### 301 Moved Permanently\n\n表示所请求的资源已转移到了新的`URI`\n\n#### 302 Found\n\n临时重定向，该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。\n\n和 301 Moved Permanently 状态码相似，但 302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的URI 将来还有可能发生改变。\n\n#### 303 See Other\n\n该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源。\n\n303 状态码和 302 Found 状态码有着相同的功能，但 303 状态码明确表示客户端应当采用 GET 方法获取资源，这点与 302 状态码有区别。\n\n#### 304 Not Modified\n\n服务端返回304，表示资源没有改动。浏览器可以从本地缓存中读取资源。\n\n#### 307 Temporary Redirect\n\n临时重定向。该状态码与 302 Found 有着相同的含义。尽管 302 标准禁止 POST 变换成 GET，但实际使用时大家并不遵守。\n307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。\n\n### 4XX\n\n#### 400 Bad Request\n\n表示请求报文存在错误\n\n#### 401 Unauthorized\n\n没有通过HTTP认证，当浏览器初次接收到 401 响应，会弹出认证用的对话窗口。\n\n#### 403 Forbidden\n\n该状态码表明对请求资源的访问被服务器拒绝了\n\n#### 404 Not Found\n\n所请求的资源不存在。\n\n### 5XX\n\n#### 500 Internal Server Error\n\n该状态码表明服务器端在执行请求时发生了错误\n\n#### 503 Service Unavailable\n\n该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。\n如果事先得知解除以上状况需要的时间，最好写入RetryAfter 首部字段再返回给客户端。\n","tags":["NetWork","HTTP"],"categories":["NetWork"]},{"title":"Web网络基础","url":"/posts/4e5b3a92.html","content":"\n## TCP/IP\n\n`TCP/IP`是互联网相关的各类协议族的总称\n`TCP/IP`具有分层结构，分为：应用层、传输层、网络层和数据链路层\n\n### 应用层\n\n应用层决定了向用户提供应用服务时通信的活动。\n相关协议：`FTP`、`DNS`以及`HTTP`\n\n### 传输层\n\n传输层提供处于网络连接中的两台计算机之间的数据传输\n相关协议：`TCP`和`UDP`\n\n### 网络层\n\n网络层规定了数据包通过怎样的传输线路到达对方计算机\n相关协议：`IP`\n\n### 数据链路层\n\n数据链路是用来处理连接网络的**硬件部分**\n例如：`NIC(网卡)`、`光纤`等物理可见部分\n\n### 通信传输流\n\n![TCPIP分层](../../images/图解HTTP/TCPIP分层.png)\n\n发送端再每一层都会打上包含该层所属的一个首部。当接收端接收到数据时，会依次拆开首部。\n\n## 与HTTP有关的协议\n\n### IP\n\n**网际协议(Internet Protocol, IP)**位于网络层，其作用是把数据包传送给对方。具体如何规定传送呢？\n\n每个网络节点都有一个**IP地址**，每一台计算机的网卡都有一个固定的**MAC地址**。\nIP地址又可以通过`ARP协议`转换成MAC地址\n\n数据包发送过程如下：\n\n1. 网关（一般为路由器）的 IP 地址被 ARP 协议解析为 MAC 地址。根据该 MAC 地址，源主机将数据包发送到网关。\n2. 网关根据数据包中的网段 ID 寻找目标网络。如果找到，将数据包发送到目标网段；如果没找到，重复步骤（1）将数据包发送到上一级网关。\n3. 数据包经过网关被发送到正确的网段中。目标IP地址被ARP协议解析为 MAC 地址。根据该 MAC 地址，数据包被发送给目标地址的主机。\n\n### TCP\n\n**传输控制协议( Transport Control Protocol, TCP)**位于传输层，提供可靠的**字节流服务**即将大块数据分割成报文段为单位的数据包进行管理。\n\n三次握手\n\n发送端首先发送一个带`SYN`标志的数据包给对方。接收端收到后，会回传一个带有`SYN/ACK`标志的数据包以表示传达确认信息。最后，发送端再发送一个带有`ACK`标志的数据包，代表“握手”结束\n\n### DNS\n\n**域名解析服务(Domain Name System, DNS)**位于应用层，提供通过域名查找IP地址，或者逆向从IP地址查找域名的服务\n\n## HTTP协议与其它协议的关系\n\n![数据请求与协议](../../images/图解HTTP/数据请求与协议.png)\n\n## URL与URI\n\n### 区别\n\n统一资源标识符（Uniform Resource Identifier, URI）\n统一资源定位符（Uniform Resource Locator， URL）\n统一资源名称（Uniform Resource Name， URN）\n\n`URL`和`URN`都是`URI`的子集。比如说人们的身份证号码就是`URN`（能够唯一标识），一个网站`http://zxffan.github.io/`就是`URL`。它们都属于`URI`\n\n### URI格式\n\n![URI格式](../../images/图解HTTP/URI格式.png)\n\n#### 协议方案名\n\n诸如：`HTTP`、`HTTPS`\n\n#### 登录信息\n\n可选项，指定用户名和密码\n\n#### 服务器地址\n\n服务器地址可以是域名，也可以是IP地址\n\n#### 服务器端口号\n\n可选，没有取默认端口号，不同协议有不同的默认端口号。\n`HTTP`是`80`；`HTTPS`是`443`\n\n#### 带层次的文件路径\n\n指定服务器上的**文件路径**来定位特指的资源\n\n#### 查询字符串\n\n可选，使用查询字符串向指定资源传入任意参数\n\n#### 片段标识符\n\n可选，标记已获取资源的子资源","tags":["NetWork","HTTP","TCP/IP"],"categories":["NetWork"]},{"title":"CSS Review","url":"/posts/6e1418c.html","content":"\n## 浏览器渲染\n\n浏览器解析一个页面会按照以下流程：\n\n1. 根据`HTML`构建`DOM Tree`\n2. 根据`CSS`构建`CSSOM Tree`\n3. `DOM Tree`和`CSSOM Tree`合并生成`Render Tree`\n4. 布局：计算元素的大小及位置\n5. 绘制：将`Render Tree`中的每个节点转换成屏幕上的实际像素\n   \n### 如何从`HTML`到`DOM Tree`？\n\n读取HTML文档的字节(Bytes)\n将字节转换成字符(Chars)\n依据字符确定标签(Tokens)\n将标签转换成节点(Nodes)\n以节点为基准构建DOM树。\n\n### 如何从`CSS`到`CSSOM Tree`？\n\n与DOM树的构建过程类似。\n\n### 阻塞渲染\n\n在生成`Dom Tree`的过程中，`script`标签会阻塞渲染线程工作。此时，控制权交给了**JS引擎线程**， JavaScript脚本执行完成之后再交由渲染引擎继续解析。\n\n为什么要阻塞？\n`JS`是能够操作DOM的。`JS`开始工作后并不确定DOM的结构（因为会变），所以暂停渲染线程工作。\n\n### 回流和重绘\n\n#### 回流\n\n回流（重排）是指当DOM节点的**几何属性**（位置、大小等）发生改变后，渲染线程需要重新计算位置和形状的现象。\n换句话说，就是DOM节点的变化导致文档流变化。\n\n#### 重绘\n\n重绘是指当DOM节点的**外观属性**（颜色、透明度、文字等），渲染线程需要重新绘制的现象。\n换句话说，就是DOM节点的变化不会导致文档流变化。\n回流一定导致重绘，重绘不一定导致回流。\n尽可能的避免回流的发生。当需要改变元素位置时，使用`transform`代替`top bottom left right`。前者只会引发图层重绘，还会间接启动GPU加速。\n\n## 习惯：CSS属性排序书写\n\n比较好的书写顺序是按照类型排序。\n\n按照`布局` → `尺寸` → `界面` → `文字` → `交互`的方式顺序书写CSS属性\n\n### 布局属性\n\n-  显示：`display` `visibility`\n-  溢出：`overflow` `overflow-x` `overflow-y`\n-  浮动：`float` `clear`\n-  定位：`position` `left` `right` `top` `bottom` `z-index`\n-  列表：`list-style` `list-style-type` `list-style-position` `list-style-image`\n-  表格：`table-layout` `border-collapse` `border-spacing` `caption-side` `empty-cells`\n-  弹性：`flex-flow` `flex-direction` `flex-wrap` `justify-content` `align-content` `align-items` `align-self` `flex` `flex-grow` `flex-shrink` `flex-basis` `order`\n-  多列：`columns` `column-width` `column-count` `column-gap` `column-rule` `column-rule-width` `column-rule-style` `column-rule-color` `column-span` `column-fill` `column-break-before` `column-break-after` `column-break-inside`\n-  格栅：`grid-columns` `grid-rows`\n\n### 尺寸属性\n\n-  模型：`box-sizing`\n-  边距：`margin` `margin-left` `margin-right` `margin-top` `margin-bottom`\n-  填充：`padding` `padding-left` `padding-right` `padding-top` `padding-bottom`\n-  边框：`border` `border-width` `border-style` `border-color` `border-colors` `border-[direction]-<param>`\n-  圆角：`border-radius` `border-top-left-radius` `border-top-right-radius` `border-bottom-left-radius` `border-bottom-right-radius`\n-  框图：`border-image` `border-image-source` `border-image-slice` `border-image-width` `border-image-outset` `border-image-repeat`\n-  大小：`width` `min-width` `max-width` `height` `min-height` `max-height`\n\n### 界面属性\n\n-  外观：`appearance`\n-  轮廓：`outline` `outline-width` `outline-style` `outline-color` `outline-offset` `outline-radius` `outline-radius-[direction]`\n-  背景：`background` `background-color` `background-image` `background-repeat` `background-repeat-x` `background-repeat-y` `background-position` `background-position-x` `background-position-y` `background-size` `background-origin` `background-clip` `background-attachment` `bakground-composite`\n-  遮罩：`mask` `mask-mode` `mask-image` `mask-repeat` `mask-repeat-x` `mask-repeat-y` `mask-position` `mask-position-x` `mask-position-y` `mask-size` `mask-origin` `mask-clip` `mask-attachment` `mask-composite` `mask-box-image` `mask-box-image-source` `mask-box-image-width` `mask-box-image-outset` `mask-box-image-repeat` `mask-box-image-slice`\n-  滤镜：`box-shadow` `box-reflect` `filter` `mix-blend-mode` `opacity`,\n-  裁剪：`object-fit` `clip`\n-  事件：`resize` `zoom` `cursor` `pointer-events` `touch-callout` `user-modify` `user-focus` `user-input` `user-select` `user-drag`\n\n### 文字属性\n\n-  模式：`line-height` `line-clamp` `vertical-align` `direction` `unicode-bidi` `writing-mode` `ime-mode`\n-  文本：`text-overflow` `text-decoration` `text-decoration-line` `text-decoration-style` `text-decoration-color` `text-decoration-skip` `text-underline-position` `text-align` `text-align-last` `text-justify` `text-indent` `text-stroke` `text-stroke-width` `text-stroke-color` `text-shadow` `text-transform` `text-size-adjust`\n-  字体：`src` `font` `font-family` `font-style` `font-stretch` `font-weight` `font-variant` `font-size` `font-size-adjust` `color`\n-  内容：`overflow-wrap` `word-wrap` `word-break` `word-spacing` `letter-spacing` `white-space` `caret-color` `tab-size` `content` `counter-increment` `counter-reset` `quotes` `page` `page-break-before` `page-break-after` `page-break-inside`\n\n### 交互属性\n\n-  模式：`will-change` `perspective` `perspective-origin` `backface-visibility`\n-  变换：`transform` `transform-origin` `transform-style`\n-  过渡：`transition` `transition-property` `transition-duration` `transition-timing-function` `transition-delay`\n-  动画：`animation` `animation-name` `animation-duration` `animation-timing-function` `animation-delay` `animation-iteration-count` `animation-direction` `animation-play-state` `animation-fill-mode`\n\n## 盒模型\n\n老生常谈——盒模型\n\n### 盒模型\n\n标准盒模型 （`box-sizing`为`content-box`）\n怪异（IE）盒模型（`box-sizing`为`border-box`）\n\n![标准盒模型和怪异盒模型](../../images/标准盒模型和怪异盒模型.png)\n\n### 视觉格式化模型\n\n块级元素：`display`声明为`block`、`list-item`、`table`、`flex`或`grid`时\n行内元素：`display`声明为`inline`、`inline-block`、`inline-table`、`inline-flex`或`inline-grid`时\n\n### 格式化上下文\n\n| 上下文           | 缩写  | 版本 | 说明         |\n| ---------------- | ----- | ---- | ------------ |\n| 块格式化上下文   | `BFC` | 2    | 块级盒子容器 |\n| 行内格式化上下文 | `IFC` | 2    | 行内盒子容器 |\n| 弹性格式化上下文 | `FFC` | 3    | 弹性盒子容器 |\n| 格栅格式化上下文 | `GFC` | 3    | 格栅盒子容器 |\n\n`BFC`——块级格式上下文通常由一个父元素和若干子元素组成。\n同一个BFC的子元素以及相邻的父子元素会发生**margin重叠**现象，不同BFC的元素不会发生重叠。\nBFC可以自动撑开元素（包含浮动元素）\n\n## 属性优先级\n\n!important： `10000`\n内联样式、外联样式：`1000`\nID选择器：`100`\n类选择器、伪类选择器、属性选择器：`10`\n元素选择器、伪元素选择器：`1`\n通配选择器、后代选择器、兄弟选择器：`0`\n\n## 布局\n\n### 普通布局\n\n符合默认布局规则。块级元素占满一行。不够一行自动换行\n\n### 浮动布局\n\n使用`float: left | right`使元素浮动（会脱离正常文档流）。\n\n### 定位布局\n\n使用`position: relative | absolute | fixed`设置相对/绝对定位。\n`top | left | right | bottom`设置位置\n\n### 表格布局（不要使用）\n\n使用`table`特性来布局\n很小的改动就会导致`table`发生回流。\n\n### 弹性布局\n\n使用`display: flex | inline-flex`设置弹性盒子容器\n\n### 多列布局\n\n使用`column-width`和`column-count`来设置列宽和列数（兼容IE10）\n可以使用`columns: column-width column-count`简写形式\n\n`column-rule`属性规定了列与列之间的直线\n`column-rule: column-rule-width column-rule-style column-rule-color`与`border`属性类似\n\n`column-span: none | all`，`all`表示跨越所有列。\n\n### 栅格布局\n\n使用`display: grid | inline-grid`来设置栅格容器\n\n### 响应式布局\n\n使用响应式单位：`vw`、`vh`、`rem`等\n使用媒体查询\n\n```css\n@media screen and (max-width: 300px) {\n    body {\n        background-color: red;\n    }\n}\n```\n\n## 内置函数Function\n\n### 颜色函数\n\n`rgb()`：RGB颜色函数，**红绿蓝**\n`rgba()`：RGBA颜色函数，**A：透明度**\n\n`hsl()`：HSL颜色函数。\nH：色相（0-360deg），`0deg`和`360deg`为红色，`120deg`为绿色，`240deg`为蓝色。\nS：饱和度（0-100%），`0%`为灰色，`100%`为全色。\nL：亮度（0-100%），`0%`为最暗，`100%`为最亮。\n\n`hsla()`：HSLA颜色函数\n\n### 属性函数\n\n`attr`：获取节点属性，目前只能配合伪元素的`content`属性使用\n`var`：获取变量\n\n```css\n--font-color: red;\n\n.warn-tip {\n    font-color: var(--font-color);\n}\n```\n\n### 数学函数\n\n`min()`：最小值\n`max()`：最大值\n\n`clamp()`：计算区间范围\n`clamp(MIN, VAL, MAX)`，最小值、首选值、最大值。相当于`max`(MIN, `min`(VAL, MAX))\n\n`calc()`：计算。`数值`、`长度`、`角度`、`时间`和`百分比`都能作为参数\n\n`counter()/counters()`：计数器，只能用于伪元素的`content`属性。\n需要结合`counter-reset`和`counter-increment`两个属性使用\n\n- `counter-reset`：重置计数器名称与初始值，编写形式为`counter-reset:name val`\n- `counter-increment`：对指定计数器累计其计数值，编写形式为`counter-increment:name`，在使用到的地方声明就会累加\n\n```css\ncounter-reset: times 1; /* 初始化times */\n\ncounter-increment: times 1; /* time 加1 */\n\n.count::after {\n    content: counter(times);\n}\n```\n\n### 背景函数\n\n`url()`：图像路径\n`element()`（only Firfox）：可以将网站中的某部分当作图片渲染，返回一个图像。结合background等属性使用\n` image-set()`：图像集合，根据屏幕分辨率匹配合适图像\n渐变：\n\n- `linear-gradient()`：线性渐变\n- `radial-gradient()`：径向渐变\n- `conic-gradient()`：锥形渐变\n- `repeat-linear-gradient()`\n- `repeat-radial-gradient()`\n- `repeat-conic-gradient()`\n\n### 滤镜函数\n\n结合`filter`属性使用\n\n`blur(100)`：模糊，具体值默认0\n`brightness(%)`：亮度\n`contrast(%)`：对比度\n`drop-shadow(h-shadow v-shadow blur spread color)`：阴影\n`grayscale(%)`：灰度\n`hue-rotate(deg)`：色相旋转\n`invert(%)`：反转\n`opacity(%)`：透明度\n`saturate(%)`：饱和度\n`sepia(%)`：褐色\n\n### 图形函数\n\n结合`clip-path`使用，用来裁剪区域\n\n`circle(30% at 50% 50%)`：圆形裁剪，**半径 at 圆心**\n`ellipse(20px 10px at 50% 50%)`：椭圆形裁剪，**横轴 纵轴 at 圆心**\n`inset(100px 50px)`：矩形，长宽\n`path()`：按照路径裁剪\n`polygon(50% 0%, 100% 50%, 50% 100%, 0% 50%)`：按照多边形裁剪（顺时针）\n\n### 变换函数\n\n结合`transform`属性使用\n\n`rotate(deg | turn)`\n`translate(x, y)`\n`scale(x y)`\n`skew(x, y)`\n`perspective()`：设置透视试图\n\n### 缓动函数\n\n`cubic-bezier()`：贝塞尔曲线\n`steps()`：逐帧\n\n## 变量Variable\n\n`CSS`有自己的一套变量系统。兼容性如下：\n\n![css var](../../images/css var.jpg)\n\n### 认识\n\n- 声明：`--变量名`\n- 读取：`var(--变量名, 默认值)`\n- 类型\n  - 普通：只能用作`属性值`不能用作`属性名`\n  - 字符：与字符串拼接 `\"Hello, \"var(--name)`\n  - 数值：使用`calc()`与数值单位连用 `var(--width) * 10px`\n- 作用域\n  - 范围：在`当前节点块作用域`及其`子节点块作用域`下有效\n  - 优先级别：`内联样式 = 外联样式 > ID选择器 > 类选择器 = 伪类选择器 = 属性选择器 > 元素选择器 = 伪元素选择器 > 通配选择器 = 后代选择器 = 兄弟选择器`\n\n### 使用技巧\n\n#### 主题换肤\n\n```vue\n<template>\n\t<div ref=\"container\" style=\"--theme-color: white\"></div>\n\t<button @click=\"switchTheme\">换肤</button>\n</template>\t\n\n<script>\nexport default {\n    methods: {\n        switchTheme() {\n            this.$refs.container.style.setProperty(\"--theme-color\", \"red\")\n        }\n    }\n}\n</script>\n\n<style lang=\"scss\">\n    .container {\n        --bg-color: var(--theme-color);\n        background-color: var(--bg-color);\n    }\n</style>\n```\n\n可见，`css`变量可以与`JS`进行交互。`scss`的变量做不到。\n\n#### 悬浮视差\n\n```vue\n<template>\n  <div ref=\"bg\" class=\"bruce flex-ct-x\" data-title=\"悬浮视差按钮\">\n    <a\n      ref=\"btn\"\n      class=\"parallax-btn\"\n      data-name=\"妙用CSS变量，让你的CSS变得更心动\"\n      @mousemove=\"move\"\n      @mouseup=\"up\"\n      @mousedown=\"down\"\n      @mouseleave=\"leave\"\n    ></a>\n  </div>\n</template>\n\n<script>\nexport default {\n  mounted() {\n    this.bgStyle = this.$refs.bg.style;\n    this.btnRect = this.$refs.btn.getBoundingClientRect();\n  },\n  methods: {\n    down(e) {\n      this.bgStyle.setProperty(\"--tz\", \"-25px\");\n    },\n    leave(e) {\n      this.bgStyle.setProperty(\"--ty\", \"0\");\n      this.bgStyle.setProperty(\"--rx\", \"0\");\n      this.bgStyle.setProperty(\"--ry\", \"0\");\n    },\n    move(e) {\n      const dx = e.offsetX - this.btnRect.width / 2;\n      const dy = e.offsetY - this.btnRect.height / 2;\n      this.bgStyle.setProperty(\"--rx\", `${dy / -1}deg`);\n      this.bgStyle.setProperty(\"--ry\", `${dx / 10}deg`);\n    },\n    up() {\n      this.bgStyle.setProperty(\"--tz\", \"-12px\");\n    },\n  },\n};\n</script>\n\n<style lang=\"scss\" scoped>\n.bruce {\n  transform: perspective(800px);\n  transform-style: preserve-3d;\n\n  height: 100vh;\n\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n.parallax-btn {\n  position: relative;\n  width: 400px;\n  height: 50px;\n  cursor: pointer;\n  user-select: none;\n  line-height: 50px;\n  text-align: center;\n  font-size: 18px;\n  color: #fff;\n  &::before {\n    position: absolute;\n    left: 0;\n    right: 0;\n    top: 0;\n    bottom: 0;\n    border-radius: 4px;\n    background: linear-gradient(135deg, #6e8efb, #a777e3);\n    box-shadow: 0 2px 5px rgba(#000, 0.2);\n    content: \"\";\n    will-change: transform;\n    transform: translateY(var(--ty, 0)) rotateX(var(--rx, 0))\n      rotateY(var(--ry, 0)) translateZ(var(--tz, -12px));\n    transition: box-shadow 500ms ease, transform 200ms ease;\n  }\n  &::after {\n    display: inline-block;\n    position: relative;\n    font-weight: bold;\n    content: attr(data-name);\n    will-change: transform;\n    transform: translateY(var(--ty, 0)) rotateX(var(--rx, 0))\n      rotateY(var(--ry, 0));\n    transition: transform 200ms ease;\n  }\n  &:hover::before {\n    box-shadow: 0 5px 15px rgba(#000, 0.3);\n  }\n}\n</style>\n```\n\n## 选择器Selector\n\n### 基础选择器\n\n| 选择器   | 别名       | 说明             | 版本 |\n| -------- | ---------- | ---------------- | ---- |\n| `tag`    | 标签选择器 | 指定类型的`标签` | 1    |\n| `#id`    | ID选择器   | 指定身份的`标签` | 1    |\n| `.class` | 类选择器   | 指定类名的`标签` | 1    |\n| `*`      | 通配选择器 | 所有类型的`标签` | 2    |\n\n### 层次选择器\n\n| 选择器  | 别名             | 说明                 | 版本 |\n| ------- | ---------------- | -------------------- | ---- |\n| `a b`   | `后代选择器`     | 元素的`后代元素`     | 1    |\n| `a > b` | `子代选择器`     | 元素的`子代元素`     | 2    |\n| `a + b` | `相邻同胞选择器` | 元素相邻的`同胞元素` | 2    |\n| `a ~ b` | `通用同胞选择器` | 元素后面的`同胞元素` | 3    |\n\n### 集合选择器\n\n| 选择器    | 别名         | 说明             | 版本 |\n| --------- | ------------ | ---------------- | ---- |\n| `a, b`    | `并集选择器` | 多个指定的`元素` | 1    |\n| `a.class` | `交集选择器` | 指定类名的`元素` | 1    |\n\n### 条件选择器\n\n| 选择器        | 说明                                     | 版本 |\n| ------------- | ---------------------------------------- | ---- |\n| `:lang`       | 指定标记语言的`元素`，例：`p:lang(en)`   | 2    |\n| `:dir()`      | 指定编写方向的`元素`                     | 4    |\n| `:has`        | 包含指定元素的`元素`                     | 4    |\n| `:is`         | 指定条件的`元素`                         | 4    |\n| `:not`        | 非指定条件的`元素`                       | 4    |\n| `:where`      | 指定条件的`元素`                         | 4    |\n| `:scope`      | 指定`元素`作为参考点                     | 4    |\n| `:any-link`   | 所有包含`href`的`链接元素`               | 4    |\n| `:local-link` | 所有包含`href`且属于绝对地址的`链接元素` | 4    |\n\n> 上面许多选择器，目前主流浏览器都未实现\n\n### 行为选择器\n\n| 选择器        | 说明             | 版本 |\n| ------------- | ---------------- | ---- |\n| `:active`     | 鼠标激活的`元素` | 1    |\n| `:hover`      | 鼠标悬浮的`元素` | 1    |\n| `::selection` | 鼠标选中的`元素` | 3    |\n\n### 状态选择器\n\n| 选择器               | 说明                                                         | 版本 |\n| -------------------- | ------------------------------------------------------------ | ---- |\n| `:target`            | 当前锚点的`元素`                                             | 3    |\n| `:link`              | 未访问的`链接元素`                                           | 1    |\n| `:visited`           | 已访问的`链接元素`                                           | 1    |\n| `:focus`             | 输入聚焦的`表单元素`                                         | 2    |\n| `:required`          | 输入必填的`表单元素`                                         | 3    |\n| `:valid`             | 输入合法的`表单元素`                                         | 3    |\n| `:invalid`           | 输入非法的`表单元素`                                         | 3    |\n| `:in-range`          | 输入范围以内的`表单元素`                                     | 3    |\n| `:out-of-range`      | 输入范围以外的`表单元素`                                     | 3    |\n| `:checked`           | 选项选中的`表单元素`<br />搭配`appearance`，可以自定义默认的单选、复选框 | 3    |\n| `:optional`          | 选项可选的`表单元素`，没有`required`的都是                   | 3    |\n| `:enabled`           | 事件启用的`表单元素`，与`disabled`相对应                     | 3    |\n| `:disabled`          | 事件禁用的`表单元素`                                         | 3    |\n| `:read-only`         | 只读的`表单元素`，与`read-write`相对应                       | 3    |\n| `:read-write`        | 可读可写的`表单元素`                                         | 3    |\n| `:target-within`     | 内部锚点元素处于激活状态的`元素`                             | 4    |\n| `:focus-within`      | 内部表单元素处于聚焦状态的`元素`                             | 4    |\n| `:focus-visible`     | 输入聚焦的`表单元素`                                         | 4    |\n| `:blank`             | 输入为空的`表单元素`                                         | 4    |\n| `:user-invalid`      | 输入合法的`表单元素`                                         | 4    |\n| `:indeterminate`     | 选项未定的`表单元素`                                         | 4    |\n| `:placeholder-shown` | 占位显示placeholder的`表单元素`(input)                       | 4    |\n| `:current()`         | 浏览中的`元素`                                               | 4    |\n| `:past()`            | 已浏览的`元素`                                               | 4    |\n| `:future()`          | 未浏览的`元素`                                               | 4    |\n| `:playing`           | 开始播放的`媒体元素`                                         | 4    |\n| `:paused`            | 暂停播放的`媒体元素`                                         | 4    |\n\n### 结构选择器\n\n| 选择器                 | 说明                                                      | 版本 |\n| ---------------------- | --------------------------------------------------------- | ---- |\n| `:root`                | 文档的`根元素`，即`html`<br />通常在这声明全局变量        | 3    |\n| `:empty`               | 无子元素的`元素`                                          | 3    |\n| `:first-letter`        | 元素的`首字母`                                            | 1    |\n| `:first-line`          | 元素的`首行`                                              | 1    |\n| `:nth-child(n)`        | 指定元素的父元素的第n个**子元素**                         | 3    |\n| `:nth-last-child(n)`   | 指定元素的父元素的倒数第n个子元素                         | 3    |\n| `:first-child`         | 指定元素的父元素的第一个**子元素**                        | 2    |\n| `:last-child`          | 指定元素的父元素的最后一个**子元素**                      | 3    |\n| `:only-child`          | 父元素仅有该元素的`元素`                                  | 3    |\n| `:nth-of-type(n)`      | 指定元素的父元素的第n个与指定元素相同标签的**子元素**     | 3    |\n| `:nth-last-of-type(n)` | 指定元素的父元素的倒数第n个与指定元素相同标签的**子元素** | 3    |\n| `:first-of-type`       | 指定元素的父元素的第一个与指定元素相同标签的**子元素**    | 3    |\n| `:last-of-type`        | 指定元素的父元素的最后一个与指定元素相同标签的**子元素**  | 3    |\n| `:only-of-type`        | 父元素仅有该标签的`标签`                                  | 3    |\n\n### 属性选择器\n\n| 选择器        | 说明                                           | 版本 |\n| ------------- | ---------------------------------------------- | ---- |\n| `[attr]`      | 指定属性的`元素`                               | 2    |\n| `[attr=val]`  | 属性等于指定值的`元素`                         | 2    |\n| `[attr*=val]` | 属性包含指定值的`元素`                         | 3    |\n| `[attr^=val]` | 属性以指定值开头的`元素`                       | 3    |\n| `[attr$=val]` | 属性以指定值结尾的`元素`                       | 3    |\n| `[attr~=val]` | 属性包含指定值(完整单词)的`元素`(不推荐使用)   | 2    |\n| `[attr|=val]` | 属性以指定值(完整单词)开头的`元素`(不推荐使用) | 2    |\n\n### 伪元素\n\n| 选择器     | 说明                             | 版本 |\n| ---------- | -------------------------------- | ---- |\n| `::before` | 在指定元素所有子元素前插入的内容 | 2    |\n| `::after`  | 在指定元素所有子元素后插入的内容 | 2    |\n\n## 背景Background\n\n### 所有属性\n\n`background`子属性众多，其属性取值也很多。\n\nbackground-color：颜色\n\n- `transparent`：透明(`默认`)\n- `Keyword`：颜色关键字\n- `HEX`：十六进制色彩模式\n- `RGB`或`RGBA`：RGB/A色彩模式\n- `HSL`或`HSLA`：HSL/A色彩模式\n- `Color1/Color2`：覆盖颜色，背景颜色可能是`Color1`，若背景图像无效则使用`Color2`代替`Color1`\n\nbackground-image：图像\n\n- `none`：无图像(`默认`)\n- `url()`：图像路径\n\nbackground-repeat：图像平铺方式\n\n- `repeat`：图像在水平方向和垂直方向重复(`默认`)\n- `repeat-x`：图像在水平方向重复\n- `repeat-y`：图像在垂直方向重复\n- `no-repeat`：图像仅重复一次\n- `space`：图像以相同间距平铺且填充整个节点\n- `round`：图像自动缩放直到适应且填充整个节点\n\nbackground-attachment：图像依附方式\n\n- `scroll`：图像随页面滚动而移动(`默认`)\n- `fixed`：图像不会随页面滚动而移动\n\nbackground-position：图像起始位置\n\n- `Position`：位置，可用任何长度单位，第二个位置(Y轴)不声明默认是`50%`(默认`0% 0%`)\n- `Keyword`：位置关键字`left、right、top、bottom、center`，可单双使用，第二个关键字不声明默认是`center`\n\nbackground-size：图像尺寸模式\n\n- `auto`：自动设置尺寸(`默认`)\n- `cover`：图像扩展至足够大，使其完全覆盖整个区域，图像某些部分也许无法显示在区域中\n- `contain`：图像扩展至最大尺寸，使其宽度和高度完全适应整个区域\n- `Size`：尺寸，可用任何长度单位，第二个尺寸(高)不声明默认是`auto`\n\nbackground-origin：定位区域(与background-position结合使用)\n\n- `padding-box`：图像相对填充定位(`默认`)\n- `border-box`：图像相对边框定位\n- `content-box`：图像相对内容定位\n\nbackground-clip：绘制区域\n\n- `border-box`：图像被裁剪到边框与边距的交界处(`默认`)\n- `padding-box`：图像被裁剪到填充与边框的的交界处\n- `content-box`：图像被裁剪到内容与填充的交界处\n\nbackground-blend-mode：混合模式\n\n- `normal`：正常(`默认`)\n- `color-burn`：颜色加深\n- `color-dodge`：颜色减淡\n- `color`：颜色\n- `darken`：变暗\n- `difference`：差值\n- `exclusion`：排除\n- `hard-light`：强光\n- `hue`：色相\n- `lighten`：变亮\n- `luminosity`：亮度\n- `multiply`：正片叠底\n- `overlay`：叠加\n- `saturation`：饱和度\n- `screen`：滤色\n- `soft-light`：柔光\n\n>`background`属性可以连写。\n>\n>- `background: color image repeat attachment position/size`\n>- 支持多重背景：`background-image: url($bg-4), url($bg-3);`\n\n### 背景渐变\n\n`CSS`渐变分为3种：\n\n-  **线性渐变**：沿着指定方向从起点到终点逐渐改变颜色，渐变形状是一条`直线`\n-  **径向渐变**：沿着任意方向从圆心往外面逐渐改变颜色，渐变形状是一个`圆形`或`椭圆形`\n-  **锥形渐变**：沿着顺时针方向从圆心往外面逐渐改变颜色，渐变形状是一个`圆锥体`\n\n相关属性有**6个**\n\n-  **linear-gradient()**：线性渐变\n-  **radial-gradient()**：径向渐变\n-  **conic-gradient()**：锥形渐变\n-  **repeating-linear-gradient()**：重复线性渐变\n-  **repeating-radial-gradient()**：重复径向渐变\n-  **repeating-conic-gradient()**：重复锥形渐变\n\n#### 线性渐变\n\n`background-image: linear-gradient(direction, color-stop)`\n\n- `direction`：方向\n  - `Keyword`：方向关键字`to left/right/top/bottom/top left/top right/bottom left/bottom right`(默认`to bottom`)\n  - `Angle`：角度，以顺时针方向的垂直线和渐变线的夹角计算，超出N圈则计算剩余角度\n- `color-stop`：色标\n  - `Color`：颜色，可参考`background-color`取值，在指定位置产生渐变效果所使用的颜色\n  - `Position`：位置，可参考`background-position`的`Position`取值，在指定位置产生渐变效果\n\n```css\n.elem {\n    width: 400px;\n    height: 200px;\n    background-image: linear-gradient(to bottom, #f66, #66f);\n    /* 等价于 */\n    background-image: linear-gradient(to bottom, #f66 0, #66f 100%);\n    \n    /* color start end  */\n    /* background-image: linear-gradient(to bottom, #f66 0 50%, #66f 100%); */\n}\n```\n\n`css`的角度跟直角坐标系不同，正上方为0度，类似表盘\n\n![css degree](../../images/css degree.jpg)\n\n#### 径向渐变\n\n`background-image: radial-gradient(shape size at position, color-stop)`\n\n径向渐变可以用来话饼图。\n\n- Shape：形状\n  - `ellipse`：椭圆形(`默认`)\n  - `circle`：圆形\n- Size：尺寸\n  - `farthest-corner`：从圆心到离圆心最远的角为半径(`默认`)\n  - `farthest-side`：从圆心到离圆心最远的边为半径\n  - `closest-corner`：从圆心到离圆心最近的角为半径\n  - `closest-side`：从圆心到离圆心最近的边为半径\n  - `Size`：尺寸，可用任何长度单位，宽和高必须同时声明\n- Position：位置\n  - `Keyword`：位置关键字`left、right、top、bottom、center`(默认`center`)\n  - `Position`：位置，可用任何长度单位\n- color-stop：色标\n  - `Color`：颜色，可参考`background-color`取值，在指定位置产生渐变效果所使用的颜色\n  - `Position`：位置，可参考`background-position`的`Position`取值，在指定位置产生渐变效果\n\n```css\n.elem {\n    width: 400px;\n    height: 200px;\n    background-image: radial-gradient(100px 100px, #f66, #66f);\n    /* 等价于 */\n    background-image: radial-gradient(ellipse 100px 100px at center, #f66, #66f);\n}\n```\n\n#### 锥形渐变\n\n`background-image: conic-gradient(color-stop)`\n\n**color-stop**：色标\n\n- `Color`：颜色，可参考`background-color`取值，在指定位置产生渐变效果所使用的颜色\n- `Position`：位置，可参考`background-position`的`Position`取值，在指定位置产生渐变效果\n\n```css\n.elem {\n    width: 400px;\n    height: 200px;\n    background-image: conic-gradient(#f66, #66f);\n    /* 等价于 */\n    background-image: conic-gradient(#f66 0, #66f 100%);\n}\n```\n#### 实现网格图层\n```vue\n<template>\n\t<div class=\"grid-box\"></div>\n</template>\n\n<style>\n    background-image: linear-gradient(\n        to top right,\n        #eee 25%,\n        transparent 25%,\n        transparent 75%,\n        #eee 75%,\n        #eee 100%\n    ),\n      linear-gradient(\n        to top right,\n        #eee 25%,\n        transparent 25%,\n        transparent 75%,\n        #eee 75%,\n        #eee 100%\n    );\n    background-position: 0 0, 10px 10px;\n    background-size: 20px 20px;\n</style> \n```\n\n### 遮罩\n\n遮罩或者说蒙版，就是在背景上再加一层。它可以实现诸如裁剪背景的效果。\n\n`mask`子属性比`background`子属性差不多。\n\nmask-mode：模式\n\n- `match-source`：根据图像类型采用合适的遮罩模式(`默认`)\n- `alpha`：根据图像透明度采用合适的遮罩模式\n- `luminance`：根据图像亮度采用合适的遮罩模式\n\nmask-image：图像\n\n- `none`：无图像(`默认`)\n- `url()`：图像路径\n\nmask-repeat：图像平铺方式\n\n- `repeat`：图像在水平方向和垂直方向重复(`默认`)\n- `repeat-x`：图像在水平方向重复\n- `repeat-y`：图像在垂直方向重复\n- `no-repeat`：图像仅重复一次\n- `space`：图像以相同间距平铺且填充整个节点\n- `round`：图像自动缩放直到适应且填充整个节点\n\nmask-position：图像起始位置\n\n- `Position`：位置，可用任何长度单位，第二个位置(Y轴)不声明默认是`50%`(默认`0% 0%`)\n- `Keyword`：位置关键字`left、right、top、bottom、center`，可单双使用，第二个关键字不声明默认是`center`\n\nmask-size：图像尺寸模式\n\n- `auto`：自动设置尺寸(`默认`)\n- `cover`：图像扩展至足够大，使其完全覆盖整个区域，图像某些部分也许无法显示在区域中\n- `contain`：图像扩展至最大尺寸，使其宽度和高度完全适应整个区域\n- `Size`：尺寸，可用任何长度单位，第二个尺寸(高)不声明默认是`auto`\n\nmask-origin：定位区域(与mask-position结合使用)\n\n- `padding-box`：图像相对填充定位(`默认`)\n- `border-box`：图像相对边框定位\n- `content-box`：图像相对内容定位\n\nmask-clip：绘制区域\n\n- `border-box`：图像被裁剪到边框与边距的交界处(`默认`)\n- `padding-box`：图像被裁剪到填充与边框的的交界处\n- `content-box`：图像被裁剪到内容与填充的交界处\n\nmask-composite：混合模式\n\n- `source-over`：叠加，显示遮罩图像合并处\n- `subtract`：相减，不显示遮罩图像重合处\n- `intersect`：相交，显示遮罩图像重合处\n- `exclude`：排除，显示遮罩图像合并处但不显示重合处\n\n## 阴影Shadow\n\n阴影三剑客——`box-shadow`、`text-shadow`、`drop-shadow()`\n\n- 想要盒子轮廓产生阴影效果，使用`box-shadow`\n- 想要文本轮廓产生阴影效果，使用`text-shadow`\n- 想要透明图像的非透明部分轮廓产生阴影效果，使用`fliter:drop-shadow()`\n\n三个方法参数类似：\n\n```css\nbox-shadow: offset-x offset-y blur spread color position\ntext-shadow: offset-x offset-y blur color\nfilter: drop-shadow(offset-x, offset-y, blur, color)\n```\n\n- OffsetX：水平偏移，阴影的水平位置(必选)\n  - `Offset`：偏移，可用任何长度单位，允许负值，正值向右负值向左(默认`0`)\n- OffsetY：垂直偏移，阴影的垂直位置(必选)\n  - `Offset`：偏移，可用任何长度单位，允许负值，正值向下负值向上(默认`0`)\n- Blur：模糊半径，阴影的清晰程度(虚色)\n  - `Length`：长度，可用任何长度单位，值越大边缘越模糊(默认`0`)\n- Spread：扩展距离，阴影的实体尺寸(实色)\n  - `Length`：长度，可用任何长度单位，允许负值，正值扩大负值缩小(默认`0`)\n- Color：投影颜色\n  - `transparent`：透明(`默认`)\n  - `Keyword`：颜色关键字\n  - `HEX`：十六进制色彩模式\n  - `RGB`或`RGBA`：RGB/A色彩模式\n  - `HSL`或`HSLA`：HSL/A色彩模式\n- Position：投影位置\n  - `outset`：阴影显示在外部(`默认`)\n  - `inset`：阴影显示在内部\n\n## 滤镜Filter\n\n`css`的`filter`属性提供了众多的图片处理效果。\n\nblur()：模糊\n\n- `Length`：长度，可用任何长度单位，值为`0`显示原图，值越大越模糊\n\nbrightness()：亮度\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示全黑，值为`100%`显示原图 \n\ncontrast()：对比度\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示全黑，值为`100%`显示原图 \n\ndrop-shadow()：阴影\n\n- 参考上述阴影\n\ngrayscale()：灰度\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示原图，值为`100%`显示全灰 \n\nhue-rotate()：色相旋转\n\n- `Angle`：角度，值为`0`显示原图，值为`0~360deg`减弱原图色彩，值超过`360deg`则相当绕N圈再计算剩余的值\n\ninvert()：反相\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示原图，值为`100%`完全反转原图色彩 \n\nopacity()：透明度\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示透明，值为`100%`显示原图 \n\nsaturate()：饱和度\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`完全不饱和原图，值为`100%`显示原图\n\nsepia()：褐色\n\n- `Percentage`：百分比，可用`0~1`代替，值为`0`显示原图，值为`100%`显示褐色\n\n> 当节点声明不为`none`的`filter`时，若其子节点有`position: absolute/fixed`的元素。它会相对于`filter`节点进行定位\n\n## 变换Transform\n\n变换分为2D和3D变换，通过`transform-style`属性来声明\n\n- **flat**：所有变换效果在平面上呈现(`默认`)\n- **preserve-3d**：所有变换效果在空间上呈现\n\n变换效果通过`transform`属性来声明：\n\ntranslate()：位移\n- **translate(x,y)**：2D位移\n- **translate3d(x,y,z)**：3D位移\n- **translateX(x)**：X轴位移，等同于`translate(x,0)`或`translate3d(x,0,0)`\n- **translateY(y)**：Y轴位移，等同于`translate(0,y)`或`translate3d(0,y,0)`\n- **translateZ(z)**：Z轴位移，等同于`translate3d(0,0,z)`\n- 描述\n  - 单位：`Length`长度，可用任何长度单位，允许负值\n  - 默认：XYZ轴不声明默认是`0`\n  - 正值：沿X轴向右位移/沿Y轴向上位移/沿Z轴向外位移\n  - 负值：沿X轴向左位移/沿Y轴向下位移/沿Z轴向内位移\n\nscale()：缩放\n- **scale(x,y)**：2D缩放\n- **scale3d(x,y,z)**：3D缩放\n- **scaleX(x)**：X轴缩放，等同于`scale(x,1)`或`scale3d(x,1,1)`\n- **scaleY(y)**：Y轴缩放，等同于`scale(1,y)`或`scale3d(1,y,1)`\n- **scaleZ(z)**：Z轴缩放，等同于`scale3d(1,1,z)`\n- 描述\n  - 单位：`Number`数值或`Percentage`百分比，允许负值\n  - 默认：XYZ轴不声明默认是`1`或`100%`\n  - 正值：`0<(x,y,z)<1`沿X轴缩小/沿Y轴缩小/沿Z轴变厚，`(x,y,z)>1`沿X轴放大/沿Y轴放大/沿Z轴变薄\n  - 负值：`-1<(x,y,z)<0`翻转沿X轴缩小/沿Y轴缩小/沿Z轴变厚，`(x,y,z)<-1`翻转沿X轴放大/沿Y轴放大/沿Z轴变薄\n\nskew()：扭曲\n- **skew(x,y)**：2D扭曲\n- **skewX(x)**：X轴扭曲，等同于`skew(x,0)`\n- **skewY(y)**：Y轴扭曲，等同于`skew(0,y)`\n- 描述\n  - 单位：`Angle`角度或`Turn`周\n  - 默认：XY轴不声明默认是`0`\n  - 正值：沿X轴向左扭曲/沿Y轴向下扭曲\n  - 负值：沿X轴向右扭曲/沿Y轴向上扭曲\n\nrotate()：旋转\n-  **rotate()**：2D旋转\n-  **rotate3d(x,y,z,a)**：3D旋转，`[x,y,z]`是一个向量，数值都是`0~1`\n-  **rotateX(a)**：X轴旋转，等同于`rotate(1,0,0,a)`，正值时沿X轴向上逆时针旋转，负值时沿X轴向下顺时针旋转\n-  **rotateY(a)**：3D Y轴旋转，等同于`rotate(0,1,0,a)`，正值时沿Y轴向右逆时针旋转，负值时沿Y轴向左顺时针旋转\n-  **rotateZ(a)**：3D Z轴旋转，等同于`rotate(0,0,1,a)`，正值时沿Z轴顺时针旋转，负值时沿Z轴逆时针旋转\n- 描述\n  - 单位：`Angle`角度或`Turn`周\n  - 正值：2D旋转时顺时针旋转\n  - 负值：2D旋转时逆时针旋转\n\nmatrix()：矩阵(太过复杂，可放弃)\n-  **matrix(a,b,c,d,e,f)**：2D矩阵(位移、缩放、扭曲、旋转的综合函数)\n-  **matrix(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p)**：3D矩阵(位移、缩放、扭曲、旋转的综合函数)\n\nperspective()：视距\n- `Length`：长度，可用任何长度单位\n  - 值越小，用户与空间Z轴距离越近，视觉效果越强\n  - 值越大，用户与空间Z轴距离越远，视觉效果越弱\n\n使用Transform默认会使浏览器开启GPU加速，因此性能更好\n\n## 过渡Transition\n\n### 属性\n\ntransition-property：属性\n\n- `all`：全部属性过渡(`默认`)\n- `none`：无属性过渡\n- `String`：某个属性过渡\n\ntransition-duration：时间\n- `Time`：秒或毫秒(默认`0`)\n\ntransition-timing-function：缓动函数\n- `ease`：逐渐变慢，等同于`cubic-bezier(.25,.1,.25,1)`(`默认`)\n- `linear`：匀速，等同于`cubic-bezier(0,0,1,1)`\n- `ease-in`：加速，等同于`cubic-bezier(.42,0,1,1)`\n- `ease-out`：减速，等同于`cubic-bezier(0,0,.58,1)`\n- `ease-in-out`：先加速后减速，等同于`cubic-bezier(.42,0,.58,1)`\n- `cubic-bezier`：贝塞尔曲线，`(x1,y1,x2,y2)`四个值特定于曲线上的点`P1`和`P2`，所有值需在`[0,1]`区域内\n\ntransition-delay：时延\n\n- `Time`：秒或毫秒(默认`0`)\n\n由于`duration`和`delay`的取值都是时间，所以可能会发生混淆。\n\n- `duration`和`delay`作用于所有节点，包括自身的`::before`和`::after`\n- `transition`中出现两个时间值时，第一个解析为`duration`，第二个解析为`delay`\n- `transition`中出现一个时间值时，解析为`duration`\n\n### 贝塞尔曲线\n\n通过`cubic-bezier()`来设置一个贝塞尔曲线值。`transform-timing-function`的值都是预设好的贝塞尔曲线值。\n\n[CubicBezier](https://cubic-bezier.com/)上可以查看具体效果\n\n![transform-timing-function](../../images/transform-timing-function.jpg)\n\n## 动画Animation\n\n### 属性\n\n`animation`可声明的两种动画：\n\n-  **关键帧动画**：\n  - 在时间轴的关键帧上绘制关键状态并使之有效过渡组成动画\n  - 通过`@keyframe`声明\n-  **逐帧动画**：\n  - 在时间轴的每一帧上绘制不同内容并使之连续播放组成动画\n  - 准备一张`逐帧长图`，在`steps()`里声明逐帧长图及其展示方式\n\nanimation-name：名称\n\n- `none`：无动画(`默认`)\n- `String`：动画名称\n\nanimation-duration：时间\n\n- `Time`：秒或毫秒(默认`0`)\n\nanimation-timing-function：缓动函数\n\n- `ease`：逐渐变慢，等同于`cubic-bezier(.25,.1,.25,1)`(`默认`)\n- `linear`：匀速，等同于`cubic-bezier(0,0,1,1)`\n- `ease-in`：加速，等同于`cubic-bezier(.42,0,1,1)`\n- `ease-out`：减速，等同于`cubic-bezier(0,0,.58,1)`\n- `ease-in-out`：先加速后减速，等同于`cubic-bezier(.42,0,.58,1)`\n- `cubic-bezier`：贝塞尔曲线，`(x1,y1,x2,y2)`四个值特定于曲线上的点`P1`和`P2`，所有值需在`[0,1]`区域内\n- `steps([,[start|end]]?)`：把动画平均划分成`n等分`，直到平均走完该动画\n- `step-start`：等同于`steps(1,start)`，把动画分成一步，动画执行时以左侧端点`0%`为开始\n- `step-end`：等同于`steps(1,end)`，把动画分成一步，动画执行时以右侧端点`100%`为开始\n\nanimation-delay：时延\n\n- `Time`：秒或毫秒(默认`0`)\n\nanimation-iteration-count：播放次数\n\n- `Number`：数值(默认`1`)\n- `infinite`：无限次\n\nanimation-direction：轮流反向播放(播放次数为一次则该属性无效果)\n\n- `normal`：正常播放(`默认`)\n- `alternate`：轮流反向播放，奇数次数正常播放，偶数次数反向播放\n\nanimation-play-state：播放状态\n\n- `running`：正在播放(`默认`)\n- `paused`：暂停播放\n\nanimation-fill-mode：播放前后其效果是否可见\n\n- `none`：不改变默认行为(`默认`)\n- `backwards`：在时延所指定时间内或在动画开始前应用开始属性(`在第一个关键帧中定义`)\n- `forwards`：在动画结束后保持最后一个属性(`在最后一个关键帧中定义`)\n- `both`：向前和向后填充模式都被应用\n\n### 案例\n\n#### 打字机\n\n```vue\n<template>\n\t<div class=\"auto-typing\">Do You Want To Know More About CSS Development Skill</div>\n</template>\n\n<script>\nexport default {}\n</script>\n\n<style>\n@mixin typing($count: 0, $duration: 0, $delay: 0) {\n    overflow: hidden;\n    border-right: 1px solid transparent;\n    width: #{$count + 1}ch;\n    font-family: Consolas, Monaco, monospace;\n    white-space: nowrap;\n    animation: typing #{$duration}s steps($count + 1) #{$delay}s infinite backwards,\n        caret 500ms steps(1) #{$delay}s infinite forwards;\n}\n.auto-typing {\n    font-weight: bold;\n    font-size: 30px;\n    color: #09f;\n    @include typing(52, 5);\n}\n@keyframes caret {\n    50% {\n        border-right-color: currentColor;\n    }\n}\n@keyframes typing {\n    from {\n        width: 0;\n    }\n}\n</style>\n```\n","tags":["css"],"categories":["CSS"]},{"title":"认识RPC","url":"/posts/91c0fa71.html","content":"\n## RPC初识\n\n`RPC（Remote Procedure Call）`即**远程过程调用**。与`Ajax`类似。主要用于不同端之间的通信。\n\n和`Ajax`的异同之处：\n\n1. 都是计算机之间网络通信的方式\n   1. `Ajax`是浏览器与服务端之间的通信方式\n   2. `RPC`是服务端之间的通信方式\n2. 都需要双方约定一个数据格式\n   1. `Ajax`约定格式为`json`\n   2. `RPC`通常使用**二进制**\n3. 寻址方式\n   1. `Ajax`使用`DNS`进行寻址\n   2. `RPC`也需要寻址，可能根据ID或者一个`VIP(虚拟IP)`。使用`DNS`成本太高。\n4. 应用层协议\n   1. `Ajax`使用`HTTP`作为应用层协议\n   2. `RPC`通常使用二进制协议（基于TCP或UDP），传输二进制数据，这样体积小，编解码速度快（计算机本身就只能识别二进制）。\n\n## 二进制编解码\n\n`RPC`通信传输的数据是**二进制数据**，而不是`JSON`数据。\n\n在`Nodejs`中，内置了`Buffer`模块，它可以用来操作二进制数据\n\n### Buffer\n\n#### 创建Buffer\n\n```javascript\n// 1. 使用Buffer.from\n// 创建一个8字节 buffer二进制数据\n// 每个字符占 1个字节\nconst buffer1 = Buffer.from('helloRPC'); \n\n// 2. Buffer.from 的参数可以为数组\n// 每个数组元素 占1个字节\nconst buffer2 = Buffer.from([1,2,3,4]);\n\n// 3. 使用Buffer.alloc\n// 创建一个20 字节的Buffer\nconst buffer3 = Buffer.alloc(20);\n```\n\n#### 读写Buffer\n\n`Buffer`内提供了众多读写`Buffer`方法，详情见[nodejs文档-Buffer](https://nodejs.org/api/buffer.html)\n\n```javascript\n// 1. 读\n\n// 从offset开始，读一个带符号8位的整型\nbuffer.readInt8(0) // 参数为offset，默认为0\n\n// 从offset开始，读一个32位的float\n// BE代表大端模式，LE代表小端模式\nbuffer.readFloatBE(0)\n\n// 2. 写\n// 第一个参数是需要写入的值\n// 第二个参数是 offset\nbuffer2.writeInt8(12, 1)\nbuffer3.writeInt16BE(255, 2)\n```\n\n> 大端模式（big-endian, BE）和小端模式（little-endian, LE）\n>\n> 两者主要指存放字节的顺序不同，BE将高位放在低地址，LE将高位放在高地址\n>\n> 16位二进制: 0000 0010 1110 1100\n>\n> 使用 writeInt16BE(128, 0), 在偏移量位0的位置写入128(2进制是 1000 0000)。写入后\n>\n> 16位二进制：**1000 0000** 1110 1100（加黑为写入的）\n>\n> 如果使用writeInt16LE(128, 0)，在偏移量0的位置写入128(2进制是 1000 0000)。写入后\n>\n> 16位二进制：**0000 1000** 1110 1100（加黑为写入的）\n>\n> 可见两者写入顺序不同\n\n#### 小结\n\n在进行`RPC`通信时，需要创建Buffer对象，然后读写数据。\n\n可是这种方式太复杂，远没有`json`方便。后者只需要通过`JSON.stringify`和`JSON.parse`进行序列化和反序列化即可。\n\n`Google`提供了一个[protocol buffers](https://github.com/protocolbuffers/protobuf)二进制编解码库，可以和使用`json`一样方便\n\n### Protocol Buffers\n\n[Protocol Buffers](https://github.com/protocolbuffers/protobuf)是一个二进制编码库。本身提供了众多语言的实现，官方文档也介绍其是一个语言无关的库\n\n所以可以在nodjs上使用它编码数据，在其它环境下（比如JAVA、Python）来使用它解码数据。\n\n先安装`npm install protocol-buffers`\n\n第一步需要编写`proto`文件，例如`test.proto`来约束二进制文件的格式。\n\n```proto\nmessage Column {\n\trequired int32 id = 1;\n\trequired string name = 2;\n\trequired float price = 3\n}\n```\n\n然后就可以导入使用\n\n```javascript\nconst protobuf =  require('protocol-buffers');\nconst fs = require('fs')\n\n// 创建schema\nconst schema = protobuf(fs.redFileSync(__dirname + '/test.proto', 'utf-8'));\n\n// 编码\nconst buf = schema.Column.encode({id:1, name: 'ff', price: 99.9});\n\n// 解码\nconst data = schema.Column.decode(buf)\n```\n\n## 搭建多路复用的RPC通道\n\n### 实现半双工通信\n\n#### 原理\n\n通过使用`ndoejs`内置的`net`模块来搭建通信的双端。\n\n`nodejs`内置的`http`模块也是基于`net`模块的。只是`http`模块用的是`http`协议。`rpc`并不用`http`协议。\n\n半双工通信即同一时间只能有一个方向的数据传输。\n\n![单双工](../../images/单双工.png)\n\n#### 编码\n\n数据mock\n\n```javascript\n// mock.js\nconst data = {\n  121391: \"第一课：北京故事\",\n  121392: \"第二课：背影-朱自清\",\n  121393: \"第三课：最后一课\",\n  121394: \"第四课：春\",\n  121395: \"第五课：济南的冬天\",\n};\n\nexports.getDataById = function (id) {\n  return data[id];\n};\n\nexports.mockId = function () {\n  const index = Math.ceil(Math.random() * 4);\n  return Object.keys(data)[index];\n};\n\n```\n\n服务端\n\n监听数据，收到数据后，延时1s将结果返回。\n\n```javascript\n// server\nconst net = require(\"net\");\nconst { getDataById } = require(\"./mock.js\");\n\nconst server = net.createServer((socket) => {\n  socket.on(\"data\", (buffer) => {\n    // 解析buffer，获取id\n    const id = buffer.readInt32BE();\n\n    // 1秒后 返回数据\n    setTimeout(() => {\n      const data = getDataById(id);\n      socket.write(Buffer.from(data));\n    }, 1000);\n  });\n});\n\nserver.listen(4000);\n\n```\n\n客户端\n\n先发送数据，当收到服务端处理结果后，输出结果并再次发送数据。\n\n```javascript\n// client\nconst net = require(\"net\");\nconst { mockId } = require(\"./mock.js\");\n\nconst socket = new net.Socket({});\n\nsocket.connect({\n  host: \"127.0.0.1\",\n  port: 4000,\n});\n\nfunction sendData() {\n  const id = mockId();\n  const buffer = Buffer.alloc(4);\n  buffer.writeInt32BE(id);\n  socket.write(buffer);\n}\n\nsocket.on(\"data\", (buffer) => {\n  console.log(buffer.toString());\n  sendData();\n});\n\nsendData();\n\n```\n\n### 实现全双工通信\n\n#### 原理\n\n全双工通信即同一时刻，通信链路上可以有多个方向的数据传输。相比单双工通信会带来两个问题。\n\n![全双工](../../images/全双工.png)\n\n问题一：客户端同一时间发送两个数据包。服务端接收到的顺序与发送顺序不一致。因此服务端不知道数据包对应是哪次发送的。\n\n解决：数据包增加一个**首部**，首部存放一个**标识ID**。从而识别数据包。\n\n\n\n问题二：当客户端连续发送n的数据包，TCP底层会进行优化，将这些（二进制）数据包合并成一个，导致服务端以为只收到一个数据包。\n\n解决：在数据包首部，再增加一个**body长度标识**，指明这个二进制数据的长度。收到数据后进行按照**长度标识**拆包。\n\n由此，新的数据包结构如下：\n\n![全双工数据报文](../../images/全双工数据报文.png)\n\n#### 编码\n\n`mock.js`内容不变\n\n增加`handler.js`用于处理接受的数据和发送数据\n\n```javascript\nmodule.exports = function (socket) {\n  let oldBuffer = null;\n  let sequence = 0;\n\n  function handleBuffer(buffer) {\n    const dataArray = [];\n    if (oldBuffer) buffer = Buffer.concat([oldBuffer, buffer]);\n\n    let completeLength = 0;\n    while ((completeLength = checkComplete(buffer))) {\n      // package为一个数据包\n      const package = buffer.slice(0, completeLength);\n      // 处理剩余的数据包\n      buffer = buffer.slice(completeLength);\n\n      const header = package.slice(0, 6);\n      const body = package.slice(6);\n      const parsedData = {\n        sequence: header.readInt16BE(),\n        data: body.toString(),\n      };\n      dataArray.push(parsedData);\n    }\n\n    oldBuffer = buffer;\n\n    return dataArray;\n\n    // 检查buffer完整性\n    // 根据首部的范围标识来判断\n    function checkComplete(buffer) {\n      if (buffer.length < 6) {\n        return 0;\n      }\n      const bodyLength = buffer.readInt32BE(2);\n      const packageLength = 6 + bodyLength;\n      return buffer.length < packageLength ? 0 : packageLength;\n    }\n  }\n\n  function sendBuffer(data, seq) {\n    // 写入body\n    const body = Buffer.from(data);\n\n    // 写入首部\n    const header = Buffer.alloc(6);\n    header.writeInt16BE(seq || sequence++);\n    header.writeInt32BE(body.length, 2);\n\n    // 拼接header和body\n    const buffer = Buffer.concat([header, body]);\n\n    socket.write(buffer);\n  }\n\n  return {\n    handleBuffer,\n    sendBuffer,\n  };\n};\n\n```\n\n服务端`server.js`\n\n```javascript\n// server\nconst net = require(\"net\");\nconst { getDataById } = require(\"./mock.js\");\nconst createHandler = require(\"./handler.js\");\n\nconst server = net.createServer((socket) => {\n  const handler = createHandler(socket);\n  socket.on(\"data\", (buffer) => {\n    // 解析buffer，获取id\n    const dataArray = handler.handleBuffer(buffer);\n    dataArray.forEach((data) => {\n      console.log(\n        `服务端收到数据：\\n\\tsequence:${data.sequence}\\n\\tdata:${data.data}`\n      );\n      // 1秒后 返回数据\n      setTimeout(() => {\n        const responseData = getDataById(data.data);\n        handler.sendBuffer(responseData);\n      }, 1000);\n    });\n  });\n});\n\nserver.listen(4000);\n\n```\n\n客户端`client.js`\n\n```javascript\n// client\nconst net = require(\"net\");\nconst { mockId } = require(\"./mock.js\");\nconst createHandler = require(\"./handler.js\");\n\nconst socket = new net.Socket({});\n\nsocket.connect({\n  host: \"127.0.0.1\",\n  port: 4000,\n});\n\nconst handler = createHandler(socket);\n\nsocket.on(\"data\", (buffer) => {\n  const dataArray = handler.handleBuffer(buffer);\n\n  dataArray.forEach((data) => {\n    console.log(\n      `客户端收到数据：\\n\\tsequence:${data.sequence}\\n\\tdata:${data.data}`\n    );\n  });\n});\n\n// 连续发送10个数据包\nfor (let i = 0; i < 10; i++) {\n  const id = mockId();\n  handler.sendBuffer(id);\n}\n\n```\n\n> 例子过于简单，所以直接使用`Buffer`\n>\n> 实际使用推荐通过`protocol buffers`处理二进制数据","tags":["网络","Nodejs"],"categories":["Server"]},{"title":"数组去重","url":"/posts/d5def5e2.html","content":"\n数组去重涉及到的场景还是比较多的，面试中也有很大频率被问到。\n\n从数据结果角度来说：数组属于线性表。适合做查询，不适合增删。\n\n去重的实现方案有很多，总的来说可分为**原地去重**和**非原地去重**两种\n\n> *原地算法*中的*原地*是指*算法*所需的辅助空间是常量，及空间复杂度O(1)\n\n## 非原地算法\n\n非原地算法可能比较符合**不可变数据`Immutable Data`**数据的思想。也是比较推荐的风格。\n\n### 用Set\n\n数据量不大的，用set即可。\n\n```typescript\nfunction unique(nums: number[]): number[] {\n  return Array.from(new Set(nums));\n}\n```\n\n### 循环\n\n循环也是比较简单的\n\n```typescript\nfunction unique(nums: number[]): number[] {\n  let result: number[] = [];\n    \n  // 循环\n  nums.forEach((item) => {\n    // 没有就加入\n    if (result.indexOf(item) === -1) {\n      result.push(item);\n    }\n  });\n  return result;\n}\n```\n\n### 使用高阶函数\n\n数组提供了一些高阶函数，`filter`、`reduce`等，可以用来实现去重。\n\n使用`reduce`：原理和循环一样，就是用到了`reduce`这个api\n\n```typescript\nfunction unique(nums: number[]): number[] {\n  return nums.reduce<number[]>((total, current) => {\n    if (total.indexOf(current) === -1) total.push(current);\n    return total;\n  }, []);\n}\n```\n\n使用`filter`：\n\n```typescript\nfunction unique(nums: number[]): number[] {\n  return nums.filter((item, index) => nums.indexOf(item) === index);\n}\n```\n\n### 其他情况：数组元素是个对象\n\n这样的话，待比较的值就不是数组元素，而是数组元素（对象）的某个key：\n\n题目：**按照对象的id去重**。\n\n1. 基于循环的例子：\n\n```typescript\ninterface IElement {\n  id: number;\n  name: string;\n}\n\nfunction unique(nums: IElement[]): IElement[] {\n  let result: IElement[] = [];\n\n  // 循环\n  nums.forEach((item) => {\n    // 没有就加入\n    if (result.every((r) => r.id !== item.id)) { // ********这里不一样********\n      result.push(item);\n    }\n  });\n  return result;\n}\n\nconst arr = [\n  { id: 1, name: \"aa\" },\n  { id: 1, name: \"bb\" },\n  { id: 2, name: \"cc\" },\n  { id: 3, name: \"dd\" },\n];\n\nconsole.log(unique(arr))\n// [ { id: 1, name: 'aa' }, { id: 2, name: 'cc' }, { id: 3, name: 'dd' } ]\n```\n\n只是判断的方式变了，这里使用到了数组的`every`方法。\n\n高阶函数`reduce`也同理，就是判断是否相同的方式变了。\n\n`filter`的话也一样，这里使用到了`findIndex`方法\n\n```typescript\nfunction unique(nums: IElement[]): IElement[] {\n  return nums.filter((item, index) => {\n      \n    // *******这里判断变了********\n    const firstIndex = nums.findIndex((n) => n.id === item.id);\n    return firstIndex === index;\n  });\n}\n```\n\n以上方法本质上都一样，都是创建一个新的数组，并未对原数组做任何修改。\n\n## 原地算法\n\n原地算法不需要额外的存储空间，直接修改原数组即可。\n\n按两种情况分析：**有序数组**和**无序数组**\n\n### 有序数组\n\n把原数组分成两个部分，一部分是结果数组（无重复的），另一部分是待遍历数组\n\n初始状态下：\n\n![数组去重-双指针](../../images/algorithm/数组去重-双指针.jpg)\n\n数组是有序的，每次遍历都判断一下`j`和`i`对应的值是否相等，如果不相等就将`j`对应的值插入结果数组中，反之则不做操作继续遍历。\n\n最后再修改一下数组的长度。这种方法也叫做**双指针法**\n\n```typescript\nfunction unique(nums: number[]): void {\n  let i = 0;\n\n  // 遍历数组\n  for (let j = 1; j < nums.length; j++) {\n    // 有序\n    if (nums[i] !== nums[j]) {\n      nums[++i] = nums[j];\n    }\n  }\n    \n  // 修改数组长度\n  nums.length = i + 1;\n}\n\nconst arr = [1, 2, 2, 3, 4, 4, 5, 6, 6, 7];\n\nunique(arr);\nconsole.log(arr);\n```\n\n### 无序数组\n\n无序数组去重，\n\n1. 第一种思想：先排序，再用上面的方法\n2. 遍历+删除\n\n```typescript\nfunction unique(nums: number[]): void {\n  for (let i = 0; i < nums.length; i++) {\n    const target = nums[i];\n    \n    if (nums.indexOf(target) !== i) {\n      // 说明原数组 有不止一个当前元素\n      // 那就 删除当前元素（多余的）\n      nums.splice(i, 1);\n      i--; // 调整索引\n    }\n  }\n}\n```\n\n上面用到了`splice`这个方法，它也是基于**原地算法**。所以整个`unique`函数也是*原地*的。\n\n### 其它情况：数组元素是个对象\n\n改一下比较对象就可以了。\n\n基于无序数组的例子：\n\n```typescript\ninterface IElement {\n  id: number;\n  name: string;\n}\n\nfunction unique(nums: IElement[]): void {\n  for (let i = 0; i < nums.length; i++) {\n    const target = nums[i];\n    \n    // ***********改一下判断规则***********\n    const firstIndex = nums.findIndex((n) => n.id === target.id);\n    if (firstIndex !== i) {\n      nums.splice(i, 1);\n      i--;\n    }\n  }\n}\n\nconst arr = [\n  { id: 1, name: \"aa\" },\n  { id: 1, name: \"bb\" },\n  { id: 2, name: \"cc\" },\n  { id: 3, name: \"dd\" },\n];\n\nunique(arr);\nconsole.log(arr);\n```\n\n","tags":["JavaScript","TypeScript","Algorithm"],"categories":["Algorithm"]},{"title":"Rust学习笔记-Ownership","url":"/posts/2c967516.html","content":"\n本系列文章是笔者学习`Rust`时所做的笔记，供日后翻阅复习。\n\n## Ownership?\n\n`ownership`（所有权）是一套用来高效管理内存的方案。\n\n内存管理主要分为两种：\n\n1. `GC(garbage collection)`：如`java`、`javascript`，它们都有垃圾回收机制，会不停地检查是否存在不会被使用到的内存，然后释放它\n2. 手动方式：如`C语言`，需要开发者手动分配和释放内存。\n\n`Rust`则是在编译时就能知道何时需要释放内存，而无需等到运行时，所以不会影响到程序的运行速度。\n\n### 栈内存和堆内存\n\n栈内存：\n\n1. 按照获取值的顺序存储数据，按照相反的顺序删除值\n2. 栈内存存储的数据都是定长的\n\n堆内存：\n\n1. 无组织的\n2. 存储数据时，内存分配器会找到一块足够存放的内存来存放，并将其标记为已使用，然后返回一个指针。指针是定长的并且存放在栈内存中\n3. 访问堆内存比访问栈内存更耗时。栈内存是相邻的，而访问堆内存需要在内存中跳跃\n\n### Ownership规则\n\n1. `Rust`中的每一个值都有且仅有一个`owner`变量\n2. `owner`离开其作用域时，该值会被删除\n\n```rust\nfn main() {\n  // 此处：s无法访问\n  let s = \"hello\";\n  // 此处：s可以访问\n} // 此处：离开作用域，s无法访问\n```\n\n`s`是字符串字面量的`owner`，离开其作用域就无法访问\n\n### 字符串与`Ownership`\n\n以字符串类型来说明`Ownership`。其它（存储在堆内存的）类型同理\n\n声明一个字符串类型，可以使用字面量或者`String`\n\n```rust\nfn main() {\n  let mut s = String::from(\"hello\")\n  \n  s.push_str(\", rust!\");\n  \n  println!(\"{}\", s);\n}\n```\n\n区别：字符串字面量不可修改，`String`是可以被修改的\n\n#### 内存和分配\n\n对于字符串字面量，在编译时就已知其长度（并且不能改变）\n\n而`String`类型，为了保持其可变性，需要满足两点：\n\n1. 在运行时请求内存分配：使用`String::from`就会在运行时来请求内存分配\n2. 当String使用完后，需要将内存返还给内存分配器（内存回收）：`Rust`是当变量离开其作用域时就会自动调用`drop`函数，来回收其内存。\n\n#### Move\n\n```rust\nfn main() {\n  let s1 = String::from(\"hello\");\n  let s2 = s1;\n  // 此处：s2有效，s1无效\n}\n```\n\n说明：\n\n1. `String`是存储在堆内存中的，`s2 = s1`只会复制栈内存的数据（含指针）而不会再拷贝一份堆内存数据\n2. `s2 = s1`叫做`s1`的`ownership`移动(move)到了`s2`，则`s1`会无效即无法再访问。这么做的原因是防止变量离开作用域后对同一块堆内存回收两次。\n\n#### Clone\n\n如果需要对堆内存进行深拷贝，就需要调用公共方法`clone`\n\n```rust\nfn main() {\n  let s1 = String::from(\"hello\");\n  let s2 = s1.clone();\n  // s1 s2都有效\n}\n```\n\n#### Copy\n\n前面所说的规则适用于堆内存的数据，而对于栈内存数据则不一样\n\n```rust\nfn main() {\n  let x = 5;\n  let y = x;\n  // x y 都有效\n}\n```\n\n这是因为`i32`类型具有`copy`特性\n\n具有`copy`特性的有：\n\n1. 所有整型\n2. 布尔类型\n3. 浮点类型\n4. 字符类型`char`\n5. 元组类型，前提：元组的成员都是具有`copy`特性的\n\n### 函数与`Ownership`\n\n#### 传参\n\n函数传参的场景涉及到了`ownership`的`move`\n\n```rust\nfn main() {\n  let s = String::from(\"hello\");\n  takes_ownership(s);\n  // s 无效，String发生move\n  \n  let x = 10;\n  makes_copy(x);\n  // x 依旧有效，x具有copy特性\n} // x离开作用域 出栈；s离开作用域，由于已经无效了不会进行回收\n\nfn takes_ownership(some_string: String) {\n  println!(\"{}\", some_string);\n} // some_string离开作用域，进行回收\n\nfn makes_copy(some_integer: i32) {\n  println!(\"{}\", some_integer);\n} // some_integer离开作用域 出栈\n```\n\n> 内存回收(drop)针对堆内存，栈内存是出栈(pop off)\n\n#### 返回值和作用域\n\n函数的返回值也会转移`ownership`\n\n```rust\nfn main() {\n  let s1 = gives_ownership();         // gives_ownership将返回值move给s1\n\n  let s2 = String::from(\"hello\");\n\n  let s3 = takes_and_gives_back(s2);  // s2 发生move\n                                        // takes_and_gives_back将返回值move给s3\n} \n// s3离开作用域，发生drop\n// s2离开作用域，但已经move了\n// s1离开作用域，发生drop\n\nfn gives_ownership() -> String {            \n  let some_string = String::from(\"hello\"); \n\n  some_string // some_string move给调用函数\n} // some_string，已经move了\n\nfn takes_and_gives_back(a_string: String) -> String { \n\n    a_string  // a_string move给调用函数\n} // a_string 离开作用域，发生drop\n```\n\n由于`ownership`存在`move`，所以只有当函数将数据返回，我们才能再次使用。`Rust`支持多返回值，所以不会干扰其它返回值数据。\n\n```rust\nfn main() {\n    let s1 = String::from(\"hello\");\n\n    let (s2, len) = calculate_length(s1);\n\n    println!(\"The length of '{}' is {}.\", s2, len);\n}\n\nfn calculate_length(s: String) -> (String, usize) { // 返回类型是一个元组\n    let length = s.len();\n\n    (s, length) // 多返回值\n}\n```\n\n## References\n\n### Immutable References\n\n在函数传参的场景下，由于`ownership`的存在，一旦`ownership`发生`move`。就无法在函数体之后的部分访问到该变量。\n\n这是`Rust`故意设计的，但`Rust`又提供了另一种函数传参方式而不会发生`move`——`引用(References)`\n\n```rust\nfn main() {\n    let s1 = String::from(\"hello\");\n\n    let len = calculate_length(&s1); // 加个 &号表示 创建一个Reference 指向s1\n\t\t\n  \t// s1 依旧有效\n}\n// len 离开作用域，出栈\n// s1 离开作用域 drop\n\nfn calculate_length(s: &String) -> usize { // 接受参数也是一个 Reference\n    s.len()\n}\n// s离开作用域，它是Reference 不会drop\n```\n\n`Reference`不会获得原数据的`ownership`\n\n上例中，我们称`calculate_length`函数`租借(borrowing)`s1\n\n但是，`calculate_length`内部不能修改 s1，否则编译器会报错\n\n### Mutable References\n\n如果需要修改`Reference`，就可以使用`&mut s`的形式声明一个`Mutable References`。\n\n```rust\nfn main() {\n    let mut s = String::from(\"hello\");\n\n    change(&mut s);\n}\n\nfn change(some_string: &mut String) {\n    some_string.push_str(\", world\");\n}\n```\n\n但也是又限制的\n\n1. 同一作用域下，同一数据块只能有一个`Mutable References`，这是为了防止`Data races`\n2. 在使用`Immutable Reference`的同时，不能使用`Mutable References`\n\n### Dangling References\n\n悬挂引用（空指针），看个例子\n\n```rust\nfn main() {\n    let reference_to_nothing = dangle();\n}\n\nfn dangle() -> &String {\n    let s = String::from(\"hello\");\n\n    &s\n} // s离开作用域 drop\n// 函数返回 s的Reference，但s已经被drop。这个reference就是Dangling References\n```\n\nRust是不允许这种情况发生的，所以这样写会报错。\n\n## Slice\n\n### 字符串切片\n\n切片(`slice`)同样也不会发生`ownership`转移\n\n```rust\nfn main() {\n  let s = String::from(\"hello world!\");\n  \n  let s1 = &s[0..3];\n  let s2 = &s[3..12];\n  \n  println!(\"{}-{}\", s1, s2); // hel-lo world!\n}\n```\n\n`&s[0..3]`会创建s中索引[0, 2]的`Reference`。\n\n有几种可以省略值的写法：\n\n1. `[0..2]`和`[..2]`是等价的\n\n2. `[2..len]`和`[2..]`等价，`len`为总长度\n3. `[0..len]`和`[..]`等价\n\n从数据结构角度看，`String Slice`会存储起始位置和长度：\n\n![rust-string-slice-structure](../../images/rust-string-slice-structure.png)\n\n写一个查找字符串首个单词\n\n```rust\nfn main() {\n  let s = String::from(\"hello world!\");\n  \n  let word = first_word(&s); // &s[..]也可以\n  println!(\"{}\", word); // hello\n}\n\nfn first_word(s: &str) -> &str {\n  let bytes = s.as_bytes();\n  \n  for (i, &item) in bytes.iter().enumerate() {\n    if item == b' ' {\n      return &s[..i];\n    }\n  }\n  \n  &s[..]\n}\n```\n\n字符串切片的类型是`&str`，`&str`类型能够兼容`&String`和`&str`\n\n### 字符串字面量\n\n字符串字面量本身就是`slice`\n\n```rust\nlet s = \"Hello, World!\"\n```\n\n`s`的类型就是`&str`即一个字符串切片。`&str`是一个`Immutable Reference`，所以字符串字面量不可变","tags":["Rust","语言学习"],"categories":["Rust"]},{"title":"搞懂EventLoop","url":"/posts/d0699962.html","content":"\n## JavaScript&单线程\n\n### 进程与线程\n\n进程是cpu分配资源的最小单位；线程是cpu调度的最小单位。一个进程可以包含多个线程。\n\ncpu给进程分配资源，进程再创建线程去工作。实际干活的是线程。同一进程下的线程共享该进程的资源。\n\n通常，进程之间是**并行执行**；线程之间是**并发执行**\n\n### 浏览器的多进程模型\n\n以开源的`Chromium`浏览器为例，当打开浏览器就会创建一个主进程，每打开一个`tab`就会再创建一个子进程。这个子进程管理每个页面。而在这个子进程中又有若干线程，例如：UI线程、JS引擎线程、浏览器事件线程 、http请求线程、EventLoop轮询处理线程等。\n\n### JavaScript单线程\n\n上面提到的`JS引擎线程`就是运行`JavaScript`代码的那个线程。所以说JavaScript是单线程的，其实更加准确地说，应该是`JavaScript`的`runtime`是单线程的。\n\nWhy?\n\n这是由`JavaScript`的用途决定的。`JS`最初是被设计成浏览器脚本语言\n\n如果设计成多线程的话，多个线程同时访问或修改dom的话，就乱套了，这时必须引入**锁**了，这对脚本语言来说没有必要。\n\n### Web Worker\n\n`H5`的`Web Worker`标准可以让主线程创建子线程，但它并未违背`JavaScript`设计初衷，应为它对子线程有很多限制：\n\n1. 子线程完全由主线程控制\n2. 子线程不能操作DOM\n\n更多`Web Worker`信息，请查看[阮一峰网络日志](http://www.ruanyifeng.com/blog/2018/07/web-worker.html)\n\n## 同步任务和异步任务\n\n### 单线程的问题\n\n已经明确了`javascript`是一门单线程的语言。\n\n但是单线程会面临一个问题：\n\n我们的代码时一行一行地执行，当前面的没有执行完，后面地就需要等待。\n\n如果程序中间有个请求接口代码块，那么当接口没有返回内容，后面地代码就需要一直等待。这时整个线程是卡死的。\n\n这显然不行，`JavaScript`引入了**同步任务**和**异步任务**的概念来解决这个问题。\n\n### EventLoop\n\n![同步任务和异步任务](../../images/JavaScript/同步任务和异步任务.webp)\n\n同步任务就是需要立即执行的任务，它没执行完后面的需要等待\n\n异步任务就是不需要立即执行的任务，比如ajax接口请求、`setTimeout`等。如果是异步任务就会在`Event Table`中注册，当指定的事件完成之后（例如接口返回响应了），就将其回调函数放到`Event Queue`中\n\n当主线程内的同步任务全部执行完毕后，会去读`Event Queue`中的函数，放入主线程执行。\n\n上述过程会一直重复执行，而这个过程被称为`Event Loop`。\n\n## 宏任务和微任务\n\n同步任务和异步任务是广义上的划分。而宏任务(`macro task`)和微任务(`micro task`)是更为精细的划分\n\n### 划分\n\n宏任务：\n\n| #                       | 浏览器 | Node |\n| :---------------------- | :----: | :--: |\n| `main script`           |   ✅    |  ✅   |\n| `I/O`                   |   ✅    |  ✅   |\n| `setTimeout`            |   ✅    |  ✅   |\n| `setInterval`           |   ✅    |  ✅   |\n| `setImmediate`          |   ❌    |  ✅   |\n| `requestAnimationFrame` |   ✅    |  ❌   |\n\n微任务：\n\n| #                            | 浏览器 | Node |\n| :--------------------------- | :----: | :--: |\n| `process.nextTick`           |   ❌    |  ✅   |\n| `MutationObserver`           |   ✅    |  ❌   |\n| `Promise.then catch finally` |   ✅    |  ✅   |\n\n微任务是属于宏任务的，换句话说，一个宏任务可以包含多个微任务\n\n### 执行流程\n\n以浏览器为例，由两个任务队列，**宏任务队列**存放宏任务；**微任务队列**存放微任务\n\n`main script`也就是`script`标签里的代码是第一个宏任务。存放至宏任务队列\n\n当第一次Event Loop时，检查两个队列，首先检查微任务队列（微任务的优先级比宏任务高）发现没有任务；再去检查宏任务队列，发现有任务`main script`取出执行。\n\n`main script`里有可能又有宏任务和微任务，再分别放入相应队列。\n\n### 几个API\n\n#### setImmediate\n\n这个API是`nodejs`独有的，表示在一次`Event Loop`执行完毕后调用\n\n#### process.nextTick\n\n这个API也是`nodejs`独有的，他会将注册的回调函数插入当前微任务队列的队首。\n\n```javascript\nprocess.nextTick(() => console.log(1));\nPromise.resolve().then(() => console.log(2));\nprocess.nextTick(() => console.log(3));\nPromise.resolve().then(() => console.log(4));\nconsole.log(5);\n\n// output: 5 1 3 2 4\n```\n\n#### Promise\n\n`promise`是`es2015`新增的API。提供了强大的异步特性。\n\n`promise`的`executor`是一个同步函数会立即执行，`then`中的回调会被注册为微任务\n\n```javascript\nnew Promise((resolve, reject) => {\n    console.log(1);\n    resolve();\n}).then(() => {\n    console.log(3)\n})\nconsole.log(2)\n\n// output: 1 2 3\n```\n\n#### async/await\n\n`async/await`仅仅影响的是函数内的执行，而不会影响到函数体外的执行顺序。\n\n```javascript\nasync function async1() {\n    console.log(\"async1 start\");\n    await  async2();\n    console.log(\"async1 end\");\n}\n\nasync  function async2() {\n    console.log('async2');\n}\n\nconsole.log(\"script start\");\n\nsetTimeout(function () {\n    console.log(\"settimeout\");\n},0);\n\nasync1();\n\n// output: \n// script start\n// async1 start\n// async2\n// async1 end\n// settimeout\n```\n\n`await async2()`相当于执行一个`Promise`，`console.log('async2');`属于`executor`；`awaait`后面的内容相当于`then`，会被放入微任务队列。\n\n## 综合试题\n\n在网上找到这么一道综合题：\n\n```javascript\nasync function async1() {\n    console.log(\"async1 start\");\n    await  async2();\n    console.log(\"async1 end\"); // async1 end\n}\nasync  function async2() {\n    console.log('async2');\n}\nconsole.log(\"script start\");\n\nsetTimeout(function () { // setTimeout1\n    console.log(\"settimeout\");\n});\nasync1()\nnew Promise(function (resolve) {\n    console.log(\"promise1\");\n    resolve();\n}).then(function () {  // promise then\n    console.log(\"promise2\");\n});\nsetImmediate(()=>{ // setImmediate\n    console.log(\"setImmediate\")\n})\nprocess.nextTick(()=>{ // nextTick\n    console.log(\"process\")\n})\nconsole.log('script end'); \n```\n\n分析：\n\n1. 输出`script start`，setTimeout1放入宏任务队列\n   1. 宏任务队列：[setTimeout1]\n   2. 微任务队列：[]\n2. 执行async1，输出`async1 start`，执行async2，输出`async2`;将`async1 end`放入微任务队列\n   1. 宏任务队列：[setTimeout1]\n   2. 微任务队列：[async1 end]\n3. 执行Promise的`executor`，输出`promise1`；将`promise then`放入微任务队列\n   1. 宏任务队列：[setTimeout1]\n   2. 微任务队列：[async1 end, promise then]\n4. 遇到setImmediate，将`setImmediate`放入宏任务队列\n   1. 宏任务队列：[setTimeout1， setImmediate]\n   2. 微任务队列：[async1 end, promise then]\n5. 遇到process.nextTick，将`nextTick`放入微任务队列队首\n   1. 宏任务队列：[setImmediate, setTimeout1]\n   2. 微任务队列：[nextTick ,async1 end, promise then]\n6. 输出`script end`\n7. 先依次取出微任务队列的任务执行，输出：`process`、`async1 end`、`promise2`\n8. 然后依次取出所有宏任务执行，输出：`settimeout`、`setImmediate`\n\n## 异步是怎么实现的\n\n根据上文可以了解到。在浏览器中，通过线程切换来实现异步。\n\n`nodejs`也是类似。它依赖于`libuv`模块。`libuv`通过线程池来实现异步操作\n\n","tags":["javascript","nodejs","browser"],"categories":["JavaScript"]},{"title":"Webpack-问题梳理","url":"/posts/378e5729.html","content":"\n## Webpack与其它构建工具有何不同？\n\n### 与Gulp和Grunt\n\n1. `Gulp`和`Grunt`打包的思路是： **遍历源文件**→**匹配规则**→**打包** （打包的文件指定的），`webpack`是按照模块的**依赖关系**进行打包\n2. webpack解决了模块化的问题，而`Gulp`和`Grunt`没有  \n\n### 与rollup\n\n1. rollup最先提出`tree shaking`，webpack也已经支持\n2. rollup不支持`code split`和`dynamic import`\n3. 经验法则：库使用`rollup`构建，应用使用`webpack`构建\n\n## Webpack 的有几种使用方法？\n\n### 通过`webpack-cli`和`npm script`，\n\n```json\n{\n    \"script\": {\n        \"dev\": \"webpack --mode development ./src/es/index.js --module-bind js=babel-loader\",\n        \"build\": \"webpack --mode production ./src/es/index.js --module-bind js=babel-loader\" \n    }\n}\n```\n\n### 编程式调用\n\n```javascript\nconst { webpack } = require('webpack')\n\nconst config = getWebpackConfig() // 生成配置文件\nconst compiler = webpack(config)\ncompiler.run()\n```\n\n## Webpack配置文件有几种写法\n\nwebpack不仅支持`javascript`还支持`Typescript`、`CoffeeScript`\n\n### 函数\n\n```javascript\nmodule.exports = (env, argv) => {\n    return { // 必须返回一个对象\n        entry: {\n            main: './src/index.js'\n        },\n        mode: env.production ? 'production' : 'development',\n        plugins: []\n    }\n}\n```\n\n`env`和`argv`两个参数对应这`webpack-cli`选项\n\n> 适用场景： 需要通过一个配置文件来区分生产环境（production）和开发环境（development），\n\n### Promise\n\n```javascript\nmodule.exports = () => {\n    return new Primise((resolve, reject) => {\n        // 处理操作\n        setTimeout(() => {\n            resolve({\n                entry: './src/index.js',\n            })\n        })\n    })\n}\n```\n\n> 适用场景：需要异步加载一些 Webpack 配置需要做的变量\n\n### 数组\n\n```javascript\nmodule.exports = [{\n\toutput: {\n      filename: './dist-amd.js',\n      libraryTarget: 'amd'\n    },\n    entry: './app.js',\n    mode: 'production',\n  }, {\n    output: {\n      filename: './dist-commonjs.js',\n      libraryTarget: 'commonjs'\n    },\n    entry: './app.js',\n    mode: 'production',\n  }]\n```\n\n数组中的每个元素为一个配置对象，所有的配置对象都会构建。\n\n> 适用场景：打包库，既想打包成`AMD` 又想 打包成 `CommonJS`\n\n### 单个配置对象\n\n最常用\n\n## 如何指定库打包出来的规范？\n\n`output.library`可以指定库打包出来的名称，支持占位符如`[name]`\n\n`output.libraryTarget`可以指定库打包出来的规范，取值范围为：`var`、`assign`、`this`、`window`、`global`、`commonjs`、`commonjs2`、`commonjs-module`、`amd`、`umd`、`umd2`、`jsonp`，默认是`var`\n\n### Webpack能够构建出哪些程序？\n\n`target`：可以指定构建目标，取值有以下几种：\n\n1. `web`： 默认，编译为类浏览器环境里可用；\n2. `node`：编译为类 Node.js 环境可用（使用 Node.js require 加载 chunk）；\n3. ` async-node`：编译为类 Node.js 环境可用（使用 fs 和 vm 异步加载分块）； \n4. `electron-main`：编译为 Electron 主进程； \n5. `electron-renderer`：编译为 Electron 渲染进程； \n6. `node-webkit`：编译为 `Webkit `可用，并且使用 jsonp 去加载分块。支持 Node.js 内置模块和 nw.gui 导入（实验\n   特性）；\n7.  `webworker`：编译成一个 `WebWorker`。\n\n##  Webpack有几种hash？有什么区别？\n\n1. `[hash]`：是整个项目 整个项目的 hash 值，其根据每次编译内容计算得到，每次编译之后都会生成新的 hash，即修改任 何文件都会导致所有文件的 hash 发生改变；在一个项目中虽然入口不同，但是 hash 是相同的；hash 无法实现 前端静态资源在浏览器上长缓存，这时候应该使用 `chunkhash`；\n2. ` [chunkhash]`：根据不同的入口文件（entry）进行依赖文件解析，构建对应的 chunk，生成相应的 hash；只要组成 entry 的模块文件没有变化，则对应的 hash 也是不变的，所以一般项目优化时，会将公共库代码拆分到一 起，因为公共库代码变动较少的，使用 chunkhash 可以发挥最长缓存的作用； \n3. `[contenthash]`：使用 `chunkhash `存在一个问题，当在一个 JS 文件中引入了 CSS 文件，编译后它们的 hash 是 相同的。而且，只要 JS 文件内容发生改变，与其关联的 CSS 文件 hash 也会改变，针对这种情况，可以把 CSS 从 JS 中使用`mini-css-extract-plugin` 或 `extract-text-webpack-plugin`抽离出来并使用 `contenthash`。\n\n## Webpack支持几种SourceMap？\n\n`devtool`：用来配置`sourceMap`，取值如下\n\n| devtool                        | 构建速度 | 重新构建速度 | 生产环境 | 品质(quality)          |\n| :----------------------------- | :------- | :----------- | :------- | :--------------------- |\n| 留空，none                     | +++      | +++          | yes      | 打包后的代码           |\n| eval                           | +++      | +++          | no       | 生成后的代码           |\n| cheap-eval-source-map          | +        | ++           | no       | 转换过的代码（仅限行） |\n| cheap-module-eval-source-map   | o        | ++           | no       | 原始源代码（仅限行）   |\n| eval-source-map                | –        | +            | no       | 原始源代码             |\n| cheap-source-map               | +        | o            | no       | 转换过的代码（仅限行） |\n| cheap-module-source-map        | o        | -            | no       | 原始源代码（仅限行）   |\n| inline-cheap-source-map        | +        | o            | no       | 转换过的代码（仅限行） |\n| inline-cheap-module-source-map | o        | -            | no       | 原始源代码（仅限行）   |\n| source-map                     | –        | –            | yes      | 原始源代码             |\n| inline-source-map              | –        | –            | no       | 原始源代码             |\n| hidden-source-map              | –        | –            | yes      | 原始源代码             |\n| nosources-source-map           | –        | –            | yes      | 无源代码内容           |\n\n|参数\t|参数解释|\n|--|--|\n|eval| 打包后的模块都使用 `eval()` 执行，行映射可能不准；不产生独立的 map 文件 |\n|cheap|\tmap 映射只显示行不显示列，忽略源自 loader 的 source map|\n|inline|\t映射文件以 base64 格式编码，加在 bundle 文件最后，不产生独立的 map 文件|\n|module|\t增加对 loader source map 和第三方模块的映射|\n\n> 一般在实际项目中，推荐生产环境不使用或者使用`source-map` （如果有 Sentry 这类错误跟踪系这类错误跟踪系统），开发环境使用 `cheap-module-eval-source-map`\n\n## 解释一下`bundle`、`chunk`和`module`\n\n`module`: 开发中每一个文件都可以看做 module，模块不局限于 js，也包含 css、图片等 \n\n`chunk`: 代码块，一个 chunk 可以由多个模块组成\n\n`bundle`: 最终打包完成的文件，一般就是和 chunk 一一对应的关系，bundle 就是对 chunk 进行压缩打包等处理后的产出 \n\n##  Webpack中loader如何使用？以及loader的执行顺序\n\n### 如何使用\n\n1. 在配置文件中配置\n2. 内联配置方式`const html = require('html-loader!./loader.html');` 或者`import html from 'html-loader!./loader.html';`\n\n### 执行顺序\n\n从右到左，从下到上\n\n## Webpack如何实现按需加载？什么是魔法注释？\n\nwebpack中通过`import`函数实现按需加载，也被称为动态导入(`dynamic import`)，\n\n1. 该函数返回`Promise`\n2. 导入的文件被打包到单独的文件中，具体得看`splitChunk`配置\n\n魔法注释：\n\n`webpackInclude`：如果是 import 的一个目录，则可以指定需要引入的文件特性，例如只加载 json 文件：`/\\.json$/`\n\n`webpackExclude`：如果是 import 的一个目录，则可以指定需要过滤的文件，例如 `/\\.noimport\\.json$/`； \n\n`webpackChunkName`：这是 chunk 文件的名称，例如 lazy-name； \n\n`webpackPrefetch`: 是否预取模块，及其优先级，可选值true、或者整数优先级别，0 相当于 true，webpack 4.6+支持；\n\n` webpackPreload` 是否预加载模块，及其优先级，可选值true、或者整数优先级别，0 相当于 true，webpack 4.6+支持； \n\n`webpackMode`: 可选值lazy/lazy-once/eager/weak。\n\n```javascript\nimport(/* webpackChunkName: \"image\", webpackInclude: /\\.(png|jpg|gif)/ */ './assets/img'); \n```\n\n## Babel的最佳实践\n\n`@babel/preset-env`搭配`useBuiltIns: \"usage\"`实现真正的按需加载。需要转换的地方会自动转换\n\n```javascript\n// babel.config.js\nmodule.exports = function(api) {\n  api.cache(true)\n\n  const presets = [\n    [\n      '@babel/preset-env',\n      {\n        modules: false,\n        corejs: 3, // 指定corejs 的版本\n        useBuiltIns: 'usage',\n      },\n    ],\n  ]\n  const plugins = []\n\n  return {\n    presets,\n    plugins,\n  }\n}\n```\n\n> `moudles`指定将`ES module `转换成其它模块规范，可能取值有 `\"amd\" | \"umd\" | \"systemjs\" | \"commonjs\" | \"cjs\" | \"auto\" | false`；false表示不去转换\n>\n> 强烈建议`false`，否则会影响`Webpack`进行优化（`Tree Shaking`必须基于`ES moudle`）\n\n## Babel原理\n\nBabel的语法转换过程主要经历三个步骤：\n\n1. 解析（Parse）：对JavaScrpt代码解析**词法语法分析**，最终生成一个`AST`。用的是`@babel/parser`\n2. 转换（Transform）：对`AST`进行遍历，在这过程中可以进行添加、删除和修改等操作。用的是`@babel/traverse`\n3. 生成（Generate）：转换后得到一棵新树，然后将树转换成代码，用的是`@babel/generator`\n\n![Babel处理过程](../../images/Babel处理过程.png)\n\n## 如何编写一个Babel插件\n\nBabel在转换阶段会遍历`AST`，那么Babel插件就是在这个过程中编写`visitor`\n\n```javascript\n// babel plugin demo\nexport default function({ types: t }) {\n    return {\n      visitor: {\n          Identifier(path, state) {},\n          FunctionDeclaration(path, state) {},\n          BinaryExpression(path, state) {},\n      }\n    };\n};\n```\n\n `type` 字段表示遍历时每个节点的类型（如： `\"FunctionDeclaration\"`，`\"Identifier\"`，或 `\"BinaryExpression\"`）\n\n遍历过程中每当在树中遇见一个 `Identifier` 的时候会调用 `Identifier()` 方法。\n\n`Identifier(path, state) {}`代表进入节点时触发\n\n```javascript\nexport default function({ types: t }) {\n\treturn {\n      visitor: {\n          Identifier: {\n              enter(path, state) {},\n              exit(path, state) {}, // 退出时触发\n          },\n      }\n    };\n};\n```\n\n> 关于Babel插件详细写法，请查阅[文档](https://github.com/jamiebuilds/babel-handbook/blob/master/translations/zh-Hans/plugin-handbook.md)\n>\n> 编写Babel插件需要熟悉`AST`结构，可以借助[AST Exploer](https://astexplorer.net/)来学习AST\n\n## Babel如何针对不同浏览器做适配\n\n`Browserslist`用来指定适配的浏览器的工具，`Babel`和`Postcss`等工具都会使用`Browserlist`。\n\n在项目根目录创建`.browserslistrc`文件，写入以下内容\n\n```text\nlast 2 version\n> 1%\nnot ie <= 11\nnot dead\n```\n\n可以在[browserl.ist](https://browserl.ist/)上检查所支持的浏览器列表\n\n![Browserslist](../../images/Browserslist.png)\n\n## Webpack中如何增强CSS功能\n\n### CSS Module\n\n`css`都是全局的，也就是说一个文件的样式可能被另一个文件的`css`样式污染。以前常用解决方法就是采用`BEM`规范，但是规范总会有人不遵守。`css module`能很好解决这个问题。\n\n`css module`顾名思义，就是给让`css`模块化。主要解决问题有：\n\n1. 解决 CSS 类都是全局的，容易造成全局污染（样式冲突）\n2. JS 和 CSS 共享类名，即JS 可以直接使用 CSS 的类名作为对象值\n3. 可以方便的编写出更加健壮和扩展方便的 CSS。\n\n```jsx\n// react\nimport style from './style.css'\n\nexport function Home() {\n    return <div style={style.box}>Hello</div>\n}\n```\n\n```vue\n<!-- vue -->\n<template>\n  <p :class=\"$style.red\">\n    This should be red\n  </p>\n</template>\n\n<style module>\n.red {\n  color: red;\n}\n.bold {\n  font-weight: bold;\n}\n</style>\n```\n\n开启方法：`css-loader` 增加 `modules: true` 的选项\n\n```javascript\nmodule.exports = {\n    //...\n    module: {\n        rules: [\n            {\n                test: /\\.css$/,\n                use: [\n                    {\n                        loader: 'css-loader',\n                        options: {\n                            modules: true\n                        }\n                    }\n                ]\n            }\n        ]\n    }\n}\n```\n\n### CSS预处理器\n\n`css预处理器`就是在css本身的基础上，增强了语法。增加了循环、条件判断、运算、函数以及作用域等\n\n常见的`css预处理器`有：`sass(scss)`、`less`、`stylus`\n\n### PostCSS\n\n`Postcss`是一个类似`Babel`的工具，只不过`Postcss`处理的是css文件。\n\n`Postcss` 核心是将 CSS 解析成 AST，然 后通过各种插件做各种转换，最终生成处理后的新 CSS，跟 Babel 在功能和实现上都类似。\n\n在`Webpack`中使用需要安装`postcss-loader`\n\n配置方法：在项目根目录新建一个`postcss.config.js`文件，写入配置内容，如下\n\n```javascript\nconst postcssPresetEnv = require('postcss-preset-env')\nconst postcssImport = require('postcss-import')\n\nmodule.exports = {\n  plugins: [\n      postcssPresetEnv({ autoprefixer: { grid: true }}),\n      postcssImport()\n  ],\n}\n\n```\n\n`postcss`和`babel`一样都有自己的插件系统。\n\n1. `postcss-preset-env`是`postcss`常用的插件集合，具体特性请查阅[文档](https://preset-env.cssdb.org/)\n2. `postcss-import`是让`postcss`规则作用的`@import`的CSS文件。\n\n2. 常用的还有一个[postcss-px-to-viewport](https://github.com/evrone/postcss-px-to-viewport)插件，用来将`px`转成`vw`，在移动端上比较常用。\n\n## Webpack如何打包多页面？\n\n`Wepack`实现多页面打包需要通过`html-webpack-plugin`来实现\n\n```javascript\nconst HtmlWebpackPlugin = require('html-webpack-plugin')\n\nmodule.exports = {\n    entry: {\n        index: './src/main.js',\n        post: './src/post.js'\n    },\n    plugins: [\n        new HtmlWebpackPlugin({\n            template: './public/index.html',\n            filename: 'index.html',\n            chunks: ['index']\n        }),\n        new HtmlWebpackPlugin({\n            template: './public/post.html',\n                filename: 'post.html',\n            chunks: ['post']\n        }),\n    ]\n}\n```\n\n注意:\n\n1. 需要打包几个页面就增加几个`HtmlWebpackPlugin实例`\n2. `chunks`指定当前页面包含那些chunk\n3. 还可以使用`excludeChunks`来排除不需要的`chunk`\n4. 使用`webpack-dev-server`时，通过http://ip:port/index访问`index`页面；通过http://ip:port/index/post访问`post`页面\n\n## 解释一下`webpack-dev-server`的原理\n\n- `webpack-dev-server`是一个基于`express`的本地服务器。\n\n- 它通过`webpack-dev-middleware`中间件来为`webpack`打包生成的资源文件提供web服务。\n\n- 同时还将开启一个`websocket`连接来实现热更新。\n\n## `webpack-dev-server`的最佳实践\n\n### 热更新\n\n1. 配置`devServer.hot`为`true`；配置`devServer.inline`为true（默认）。这会在`entry`中添加相应代码\n2. 增加`webpack.HotModuleReplacementPlugin`这个`plugin`\n\n> 如果使用`webpack-cli`，直接加上`--hot`就自动实现上面两步\n\n### proxy\n\n`devServer.proxy`可以实现本地跨域问题\n\n```javascript\nmodule.exports = {\n    devServer: {\n        proxy: {\n            '/api': {\n                target: 'http://ip:port', // 所有请求路径包含/api的请求，都会被转发到这个地址\n                pathRewrite: {'^/api', ''}\n            }\n        }\n    }\n}\n```\n\n### 自定义中间件\n\n在 `webpack-dev-server` 中有两个时机可以插入自己实现的中间件，分别是 `devServer.before` 和 `devServer.after `，即` webpack-dev-server `加载所有内部中间件之前和之后两个时机。通常用来实现`mockServer`\n\n```javascript\nmodule.exports = {\n    devServer: {\n        before(app, server) {\n            app.get('/api/get-use-info', (req, res) => {\n                res.json({name: 'zxffan', gender: 'male'})\n            })\n        }\n    }\n}\n```\n\n### Gzip\n\n将`devServer.compress`设置成`true`\n\n### 常用API\n\n- `devServer.historyApiFallback`：配置如果找不到页面就默认显示的页面；\n- `devServer.compress`：启用 gzip 压缩；\n- `devServer.hotOnly`：启用热更新，并且构建失败的时候不会刷新网页；\n- `devServer.inline`：模式切换，默认为内联模式，使用`false`切换到 iframe 模式；\n- `devServer.open`：启动后，是否自动使用浏览器打开首页；\n- `devServer.openPage`：启动后，自动使用浏览器打开指定的页面；\n- `devServer.overlay`：是否允许使用全屏覆盖的方式显示编译错误，默认不允许；\n- `devServer.port`：监听端口号，默认 8080；\n- `devServer.host`：指定 host，使用`0.0.0.0`可以让局域网内可访问；\n- `devServer.contentBase`：告诉服务器从哪里提供内容，只有在你想要提供静态文件时才需要；\n- `devServer.publicPath`：设置内存中的打包文件的虚拟路径映射，区别于`output.publicPath`；\n- `devServer.staticOptions`：为 `Expressjs` 的 `express.static`配置参数，[参考文档]( http://expressjs.com/en/4x/api.html#express.static)\n- `devServer.clientLogLevel`：在 inline 模式下用于控制在浏览器中打印的 log 级别，如`error`, `warning`, `info` or `none`；\n- `devServer.quiet`：静默模式，设置为`true`则不在控制台输出 log；\n- `devServer.noInfo`：不输出启动 log；\n- `devServer.lazy`: 不监听文件变化，而是当请求来的时候再重新编译；\n- `devServer.watchOptions`：watch 相关配置，可以用于控制间隔多少秒检测文件的变化；\n- `devServer.headers`：自定义请求头，例如自定义 userAgent 等；\n- `devServer.https`：https 需要的证书签名等配置。\n\n## Webpack优化——如何减小打包后的文件体积\n\n打包后的文件主要分为三类——`js`、`css`和`其它静态资源文件（图片等）`\n\n### 如何减小JS文件体积\n\n1. 压缩代码：使用[terser-webpack-plugin](https://www.npmjs.com/package/terser-webpack-plugin)对`es moudule`的代码进行压缩\n2. `tree shaking`，代码需要遵循`es module`\n3. 合理设置`splitChunk`拆分逻辑\n4. 第三方库按需引入\n5. 使用`scope hoisting`\n\n> webpack的`mode`设置为`production`时，webpack就会自动做一些通用的优化配置\n\n配置如下\n\n```javascript\nconst TerserWebpackPluin = require('terser-webpack-plugin')\n\nmodule.exports = {\n    // ...\n    \n    mode: 'production',\n    \n    optimization: {\n        concatenateModules: true, // 开启 scope hoisting(mode为production会自动开启)\n        minimize: true,\n        minimizer: [\n            new TerserWebpackPluin({\n                test: /\\.js(\\?.*)?$/i,\n                include: /src/,\n                //exclude\n                cache: true, // 开启缓存\n                parallel: true, // 默认true 开启多线程\n                terserOptions: {\n                    compress: {\n                        unused: true, // 删除无用的代码 \n                        drop_debugger: true, // 删掉 debugger \n                        drop_console: true, // 移除 console \n                        dead_code: true, // 移除无用的代码\n                    }\n                }\n            })\n        ]\n    }\n}\n```\n\n### 如何减小CSS文件体积\n\n1. 压缩代码：使用`cssnao`(`postcss` 插件)来进行代码压缩，其实`css-loader`已经集成了`cssnano`\n2. 抽离CSS：通过`mini-css-extract-plugin`将CSS内容抽离到CSS文件中\n\n配置内容如下\n\n```javascript\nconst MiniCssExtractPlugin = require('mini-css-extract-plugin')\n\nmodule.exports = {\n    // ...\n    \n    module: {\n        rules: [\n            {\n                test: /\\.css$/,\n                use: [\n                    'style-loader',\n                    MiniCssExtractPlugin.loader,\n                    {\n                        loader: 'css-loader',\n                        options: {\n                           \tminimize: {/* CSSNano Options */}\n                        }\n                    }\n                ]\n            }\n        ]\n    },\n    plugins: [\n        new MiniCssExtractPlugin({\n            filename: '[name].css',\n        })\n    ]\n}\n```\n\n### 如何处理图片等静态资源\n\n1. `url-loader`可以将小图片转成`Data URL`内联到JS中，从而减少请求数量\n2. 对于`svg`，使用`svg-url-loader`\n\n```javascript\nmodule.exports = {\n    module: {\n        rules: [\n            {\n                test: /\\.(png|jpg|jpeg)$/,\n                use: [\n                    {\n                        loader: 'url-loader',\n                        options: {\n                            limit: 100, //单位kb，小于这个大小的会被转成Data URL\n                        }\n                    }\n                ]\n            }\n        ]\n    }\n}\n```\n\n\n\n## Webpack优化——如何利用缓存\n\n主要思路就是，将项目中不太容易变化的代码（比如第三方库vue、react）单独抽离出来，利用`CDN`或配置浏览器缓存以减少对其的请求。\n\n### 如何拆分出来（`Code Splitting`）\n\n1. 配置多个entry\n2. 使用`dynamic import`和`split chunk`来拆分代码\n3. 使用`external`不打包这些一些第三方库，然后通过`cdn`引入\n\n特别说一下`split chunk`，以下时默认配置\n\n```javascript\nmodule.exports = {\n    // ...\n    optimization: {\n        splitChunks: {\n            chunks: 'async', // 三选一： \"initial\" | \"all\" | \"async\" (默认)\n            minSize: 30000, // 最小尺寸，30K，development 下是10k，越大那么单个文件越大，chunk 数就会变少（针对于提取公共 chunk 的时候，不管再大也不会把动态加载的模块合并到初始化模块中）当这个值很大的时候就不会做公共部分的抽取了\n            maxSize: 0, // 文件的最大尺寸，0为不限制，优先级：maxInitialRequest/maxAsyncRequests < maxSize < minSize\n            minChunks: 1, // 默认1，被提取的一个模块至少需要在几个 chunk 中被引用，这个值越大，抽取出来的文件就越小\n            maxAsyncRequests: 5, // 在做一次按需加载的时候最多有多少个异步请求，为 1 的时候就不会抽取公共 chunk 了\n            maxInitialRequests: 3, // 针对一个 entry 做初始化模块分隔的时候的最大文件数，优先级高于 cacheGroup，所以为 1 的时候就不会抽取 initial common 了\n            automaticNameDelimiter: '~', // 打包文件名分隔符\n            name: true, // 拆分出来文件的名字，默认为 true，表示自动生成文件名，如果设置为固定的字符串那么所有的 chunk 都会被合并成一个\n            cacheGroups: {\n                vendors: {\n                    test: /[\\\\/]node_modules[\\\\/]/, // 正则规则，如果符合就提取 chunk，\n                    test(module, chunks) { // 还可以是函数\n                        return module.type === 'javascrtipt/auto'\n                    },\n                    priority: -10 // 缓存组优先级，当一个模块可能属于多个 chunkGroup，这里是优先级\n                },\n                default: {\n                    minChunks: 2,\n                    priority: -20, // 权重，如果有一个模块满足了多个缓存组的条件就会去按照权重划分，谁的权重高就 优先按照谁的规则处理。\n                    reuseExistingChunk: true // 如果该chunk包含的modules都已经另一个被分割的chunk中存在，那么直接引用已存在的chunk，不会再重新产生一个\n                }\n            }\n        }\n    }\n};\n```\n\n`chunks`有三个值`initial`、`all`和`async`(默认)\n\n1. `chunks`为`async`：只有`dynamic import`才会被拆分出去\n2. `chunks`为`initial`：`dynamic import`肯定会被拆分出去，符合`cacheGroup`规则并且体积大于`minSize`也会被拆分出去（无论是否`dynamic import`）;但是非动态导入和动态导入的公共部分没有拆分在一起，而在单独拆分成不同的chunk\n3. `chunks`为`all`（推荐）：非动态导入和动态导入的公共部分会拆分在一起（符合cacheGroup规则）\n\n`cacheGroup`(缓存组)配置了拆分逻辑。\n\n### 如何设置缓存\n\n`CDN`没什么好说的，直接再HTML中引入即可。\n\n对于浏览器缓存，当浏览器请求这些资源时，服务端设置`Cache-Control`响应头，比如`Cache-Control: max-age=31536000`，表示当前资源缓存一年（31536000=360024365）。只要一年内该资源不发生变化就会一直从缓存中读取。\n\n## Webpack优化——如何加快打包速度\n\n1. 配置路径别名——`resolve.alias`，以减少目录查找次数\n2. 增加默认文件后缀名——`resolve.extensions`\n3. 排除不需要解析的模块\n   1. `module.noParse`，例如`noParse: /node_modules\\/jquery.js/`。忽略对部分没采用模块化的文件递归解析处理，例如：jQuery、 ChartJS，它们体积庞大又没有采用模块化标准，让 Webpack 去解析这些文件耗时又没有意义\n   2. `module.rules`中配置合适的`include`和`exclude`。\n4. 利用多线程：`thread-loader`和`happypack`(已经不维护了)\n5. `webpack`的`DllPlugin`和`DllReferencePlugin`，将一些不会变化的内容抽离出来，并且避免二次打包。\n6. 缓存`Cache`：很多`loader`都提供了缓存机制\n   1. `babel-loader`：设置`cacheDirectory:true`将会开启缓存\n7. 换用高性能的loader或插件\n   1. sass：使用`fast-sass-loader`代替`sass-loader`\n\n重点说一下`DllPlugin`和`DllReferencePlugin`：\n\n`DllPlugin`可以将第三方库单独打包到一个`bundle`中，还会生成一个`manifest.json`文件\n\n`DllReferencPlugin`读取这个`manifest.json`文件，在打包过程中就不会将之前抽离内容打包进来\n\n\n\n```javascript\n// webpack.config.dll.js\nconst { DllPlugin } = require('webpack')\n\nmodule.exports = {\n    // ...\n    mode: 'production',\n    entry: {\n        vendor: ['vue', 'vue-router', 'vuex'] // 将这些第三方库抽离出来\n    },\n    \n    output: {\n        filename: 'dll/[name][chunkhash].js',\n        library: '[name][chunkhash]',\n        path: './dist'\n    },\n    \n    plugins: [\n        new DllPlugin({\n            path: 'dll/manifest.json', // 设置manifest.json的路径\n            name: '[name]_[chunkhash]',\n            context: __dirname\n        })\n    ]\n}\n```\n\n使用`webpack.config.dll.js`打包一次，将`vue`、`vuex`和`vue-router`打包出来。生成`vender[hash].js`和`manifest.json`\n\n然后配置`webpack.config.js`\n\n```javascript\nconst { DllReferencePlugin } = require('webpack')\nconst manifest = require('./dll/manifest.json')\n\nmodule.exports = {\n    entry: {\n        main: './src/index.js'\n    },\n    output: {\n        filename: '[name][chunkhash].js'\n    },\n    plugin: [\n        new DllReferencePlugin({\n            context: __dirname\n            manifest // 配置manifest\n        })\n    ]\n}\n```\n\n打包最后生成的`main.js`中不会包含`vendor`里的内容。\n\n> webpack5提出了`federal module`（联邦模块）；也可以提取公共模块\n\n## 解释一下Webpack中`Tree-shaking`原理？\n\n基于`ES module`做静态分析，在编译阶段就能分析出其模块依赖关系（无需等到运行时）。然后利用`uglifyjs`或`terser-webpack-plugin`来删除多余内容\n\n`tree shaking`的注意点：\n\n1. 必须使用`es module`规范\n2. 不支持对`class`的`tree shaking`\n3. 减少副作用，具有副作用的代码不会被消除\n\n> 纯函数：对于相同的输入就有相同的输出，不依赖外部环境，也不改变外部环境。\n>\n> 非纯函数被称为具有副作用的函数\n>\n> 1. 确保代码中没有副作用\n> 2. 在`package.json`中配置`sideEffects: [\"./src/side_effect.js\"]`(指定具有副作用的内容)或者`sideEffects:false`（完全没有副作用），这样webpack就会跳过副作用的代码\n\n## Checklist\n\n### 配置文件管理\n\n`npm script`配置脚本命令，例如`node ./scripts/dev.js`\n\n使用编程式API，而不采用`webpack-cli`（个人习惯）\n\n拆分配置文件：开发环境，生产环境等\n\n`scripts`目录下有一个`config`目录用来存放各个环境的配置文件\n\n### 合理的拆分\n\n合理设置`splitchunks`、`DDLPlugin`或`Federal Module`，太细不利于缓存，太粗又会影响加载速度。，\n\n拆分原则：\n\n1. 变更频率小的部分拆分出来（例如第三方库）\n2. 公共部分拆分出来\n3. 按照路由拆分\n\n### Hash\n\n1. JavaScript 文件使用：`[chunkhash]`；\n2. CSS 文件使用：`[contenthash]`；\n3. 其他静态资源用：`[hash]`，例如图片、字体等，在`url-loader`中配置`[hash]`\n\n### code规范\n\n1. 必须使用`ES Module`，方面`Tree-Shaking`，注意副作用代码\n2. 合理使用`webpack magic comments`\n3. 选择符合`es module`规范的第三方库，例如`lodash-es`\n\n## 如何调试Webpack\n\n在`vscode`中打下断点，然后按`F5`，选择`nodejs`（`webpack`是基于node的库）。就可以进行调试\n\n如果需要自定义`debug`，创建`launch.json`文件进一步自定义。","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"Rust学习笔记-变量&类型&functions&注释&控制流","url":"/posts/452059e7.html","content":"\n本系列文章是笔者学习`Rust`时所做的笔记，供日后翻阅复习。\n\n## 变量和可变性\n\n在`Rust`中定义一个变量很简单：`let x = 100`，但这个`x`时`immutable`（不可变的）\n\n```rust\nfn main() {\n\tlet x = 100;\n\tx = 200; // error\n}\n```\n\n在`Rust`中定义一个可变变量也很简单：`let mut x = 100`，其中的`mut`代表`mutable`\n\n### 常量\n\n在`Rust`中使用`const`来定义一个常量：`const MAX_POINT: u32 = 150_000`\n\n常量即**不变化的量的**，那么**常量**和**`immutable`变量**有什么区别呢？\n\n1. 常量必须显示注明类型。\n2. 常量可以在任何作用域下（包括全局作用域）声明，`let`以及其它代码内容必须在`fucntion`下声明\n3. 常量的值必须是一个常量表达式，不能是函数或其它必须再运行时才能计算出结果的值。\n4. 常量通常定义在全局作用域下，用来避免硬编码问题。\n\n> `Rust`中常量的命名规范：全部大写，用下划线连接\n>\n> `Rust`中的数值：`100_000`代表`100,000`即`100000`\n\n### Shadowing\n\n在`Rust`中允许在同一个作用域下，一个变量被声明两次\n\n```rust\nfn main() {\n    let sentence = \"I heart you!\";\n    let sentence = sentence.len();\n    println!(sentence); // sentence is 12\n}\n```\n\n`sentence`第一次声明为一个`string`；第二次声明变成`number`。可以理解为第一个`sentence`被第二个`sentence`给`shadowed`(隐藏)了。后面访问到的都是第二个。\n\n`Shadowing`最大的好处就是：**第二次声明时可以修改变量类型，可以用于类型转换的场景**\n\n## 数据类型\n\n`Rust`是一门静态类型语言。在编译时`Rust`就必须知道所有数据的类型。\n\n`Rust`中的数据类型分类两种：**标量类型(Scalar Types)**和**复合类型(Compound Types)**\n\n### 标量类型\n\n标量类型有：整型、浮点型、布尔型、字符型\n\n#### 整型\n\n`let x: u32 = 100`，就是定义一个无符号的32位整型\n\n`let x: i32 = 100`，是定义一个带符号的32位整型\n\n| 大小    | 带符号（Signed） | 无符号（Unsigned） |\n| ------- | ---------------- | ------------------ |\n| 8-bit   | `i8`             | `u8`               |\n| 16-bit  | `i16`            | `u16`              |\n| 32-bit  | `i32`            | `u32`              |\n| 64-bit  | `i64`            | `u64`              |\n| 128-bit | `i128`           | `u128`             |\n| arch    | `isize`          | `usize`            |\n\n表示范围：以`16-bit`为例\n\n1. `i16`：带符号，最高位符号位，还剩15位，所以能表示 \n\n$$\n[-2^{15}, 2^{15}-1]\n$$\n\n2. `u16`：不带符号即为非负数，所以能表示\n\n$$\n[0, 2^{16}-1]\n$$\n\n`isize`和`usize`取决于操作系统，如果是64位系统就取64；如果是32位系统就取32。\n\n在`Rust`中可以以多种形式书写整型字面量：\n\n| Number literals  | Example       |\n| ---------------- | ------------- |\n| Decimal          | `98_222`      |\n| Hex              | `0xff`        |\n| Octal            | `0o77`        |\n| Binary           | `0b1111_0000` |\n| Byte (`u8` only) | `b'A'`        |\n\n除了Byte字面量都可以使用**类型后缀（type suffix）**：`let num = 120u32`和`let num:u32 = 120`是一样的\n\n除了Byte字面量都可以使用**`_`视觉分隔符**：`100_000`代表`100,000`即`100000`\n\n> 如果不指定数值类型，Rust默认`i32`\n\n整型溢出：`u8`只能表示`[0,255]`范围的值，当取`256`就会发生溢出\n\n1. `debug`模式下，`Rust`会进行溢出检测，当溢出发生，程序发生`panic`\n2. `release`模式下，`Rust`不会进行检测，`256`会变成`0`;`257`变成`1`。\n\n#### 浮点类型\n\n浮点类型只有两种：`f32`和`f64`(默认)，前者表示**单精度浮点类型**，后者表示**双精度浮点类型**。例如\n\n```rust\nfn main() {\n    let x = 2.1; // f64\n    let x: f32 = 3.1; // f32\n}\n```\n\n与绝大数语言一样，`Rust`的浮点类型也遵循`IEEE-754`标准，所以也存在`0.1 + 0.2`的问题。\n\n#### 布尔类型\n\n布尔类型有两种：`true`和`false`\n\n布尔类型占1个字节\n\n使用`bool`来声明布尔类型，例如\n\n```rust\nfn main() {\n    let isCheck = true;\n    \n    let hasExist: bool = false;\n}\n```\n\n#### 字符类型\n\n`Rust`的字符类型占4个字节，所以能表示很多字符，比如单个中文、日文甚至`emoji`字符\n\n使用**单引号**定义**字符字面量**；使用**双引号**定义字**符串字面量**，例如\n\n```rust\nfn main() {\n    let word = '♥';\n    \n    let sentence = \"I ♥ you!\";\n}\n```\n\n### 复合类型\n\n复合类型有两种：元组和数组\n\n#### 元组\n\n```rust\nfn main() {\n    // 定义元组\n    let tup: (i32, f64, u8) = (500, 6.4, 1);\n    \n    // 也可以省略类型\n    let tup = (500, 6.4, 1);\n\t\n    // 元组可以解构\n    let (x, y, z) = tup;\n    \n    // 使用 元组.index 的方式访问\n    let first = tup.0;\n    let second = tup.1;\n}\n```\n\n#### 数组\n\n```rust\nfn main() {\n    // 定义数组\n    let arr: [i32, i32, i32] = [1, 2, 3];\n    let arr: [i32, 3] = [1, 2, 3];\n    \n    // 数组元素都一样\n    let arr = [1, 1, 1, 1, 1];\n    let arr = [1; 5];\n    \n    // 通过index访问元素\n    let x = arr[0]；\n}\n```\n\n元组与数组的异同点：\n\n相同点：\n\n1. 都是定长的，长度不能变化。如果需要不定长，使用`vector`\n2. 都是数据集合\n\n不同点\n\n1. 数组中每个元素的类型必须相同，而元组可以不一样\n2. 使用方式不一样\n\n## Functions\n\n函数是`Rust`中最为普遍的存在。每个程序都有一个`main`函数作为程序的入口函数。可以通过`fn`关键字来定义函数。\n\n```rust\nfn main() {\n    print_hello(); // 调用函数\n    \n    let result = plus_two(2);\n    println!(\"The result is {}\", result);\n}\n\nfn print_hello() {\n    println!(\"hello\");\n}\n\nfn plus_two(a: i32) -> i32 { // -> 注明函数返回值类型\n    a + 2 // 不加分号表示是表达式，函数体的最后一行如果是表达式默认为函数返回值\n}\n\n```\n\n注意：\n\n1. 函数参数必须注明类型\n2. 有返回值必须注明返回值类型，没有返回值默认返回空元组即`()`\n\n### 语句与表达式(Statements and Expression)\n\n语句(Statements)：执行某种行为，不会有返回值\n\n表达式(Expression)：进行计算并将结果返回\n\n```rust\nfn main() {\n    let x = 123; // 语句，不会返回123\n    \n    let y = { // {} 代表表达式\n        let x = 124; // 语句\n        x + 1 // 表达式\n    }; // y = 125\n}\n```\n\n### 函数返回值\n\n使用`->`来注明函数返回值类型；\n\n返回可以使用`return`关键字；通常，函数会隐含地将最后一个表达式作为函数的返回值。\n\n## 注释\n\n单行注释：`//`\n\n文档注释： `///`：文档注释支持`markdown`语法，用来注释某个函数。当使用`cargo doc`命令时会自动生成`HTMl文件`\n\n## 控制流\n\n与绝大数语言一样，`Rust`也提供了条件判断（if）和循环（loop）来实现程序流的控制。\n\n### if表达式\n\n```rust\nfn main() {\n    let number = 3;\n    if number < 2 {\n        println!(\"less than 2\");\n    } else if number == 2 {\n        println!(\"equal to 2\");\n    } else {\n        println!(\"greater than 2\");\n    }\n}\n```\n\n注意：if 后必须借一个 返回`bool`类型的表达式，不想`JavaScript`会自动做类型转换。\n\n### let语句和if\n\n```rust\nfn main() {\n    let condition = 3 > 2;\n    let number = if condition { 10 } else { 20 }; // 10\n}\n```\n\n花括号`{}`中是一个表达式，最终就返回这个表达式的值\n\n条件分支表达式的值的类型必须一致，上例都是默认的`i32`\n\n### 循环Loops\n\n`Rust`中提供了多种循环方式，有`loop`、`while`以及`for`\n\n#### loop\n\n```rust\nfn main() {\n    let mut times = 1;\n    loop {\n        println!(\"loop times: {}\", times);\n        times += 1;\n        if times > 10 {\n            break;\n        }\n    }\n}\n```\n\n`loop`只有遇到`break`语句才会推出循环\n\n#### loop返回值\n\n在`break`后添加一个表达式，会将表达式的值返回\n\n```rust\nfn main() {\n    let mut counter = 0;\n\t\n    // result 接受值\n    let result = loop {\n        counter += 1;\n\n        if counter == 10 {\n            break counter * 2; // 返回值\n        }\n    };\n\n    println!(\"The result is {}\", result); // 20\n}\n```\n\n#### While\n\n当循环取决于一个条件表达式时可以使用`while`\n\n```rust\nfn main() {\n    let mut num = 0;\n    while num < 5 {\n        println!(\"num is {}\", num);\n        \n        num += 1;\n    }\n}\n```\n\n#### for\n\n当遍历某个集合时可以使用`for`\n\n```rust\nfn main() {\n    let arr = [1, 2, 3, 4];\n    for ele in arr.iter() {\n        println!(\"current is {}\", ele);\n    }\n}\n```\n\n当已知范围时可以使用`for`\n\n```rust\nfn main() {\n    for num in (1..10).rev() {\n        println!(\"{}!\", num);\n    }\n}\n```\n\n`(1..10)`表示一个范围`[1, 9]`\n\n`rev()`表示`reverse`\n\n## 练习\n\n### 转换摄氏度和华氏度\n\n```rust\nfn main() {\n    let temp_f = to_fahrenheit(37.0);\n    let temp_c = to_celsius(98.6);\n\n    println!(\"{}c equal to {}f\", temp_c, temp_f);\n}\n\n// 转换成华氏度\nfn to_fahrenheit(temp: f32) -> f32 {\n    32.0 + temp * 1.8\n}\n\n// 转换成摄氏度\nfn to_celsius(temp: f32) -> f32 {\n    (temp - 32.0) / 1.8\n}\n```\n\n### 生成第n个斐波那契数\n\n```rust\nfn main() {\n    let tenth = get_nth_fibonacci(10);\n    println!(\"The tenth is {}\", tenth);\n}\n\nfn get_nth_fibonacci(n: u32) -> u32 {\n    let result = if n == 1 {\n        0\n    } else if n == 2 {\n        1\n    } else {\n        get_nth_fibonacci(n - 1) + get_nth_fibonacci(n - 2)\n    };\n    result\n}\n```\n\n","tags":["Rust","语言学习"],"categories":["Rust"]},{"title":"Rust学习笔记-环境搭建","url":"/posts/85fd164e.html","content":"\n本系列文章是笔者学习`Rust`时所做的笔记，供日后翻阅复习。\n\n## 安装\n\n`rustup`以用来进行`Rust`版本管理的命令行工具。\n\n### MacOS && Linux\n\n```shell\n$ curl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh\n```\n\n该命令是用来下载一个脚本然后开始安装`rustup`工具\n\n### Windows\n\n前往[Rust官网](https://www.rust-lang.org/tools/install)下载`exe`安装包\n\n安装过程会提示需要`C++ build tools`。比较简单的办法是安装[`virtual studio`](https://visualstudio.microsoft.com/zh-hans/downloads/)。工作负载中选择`C++桌面开发`。\n\n### rustup常用命令\n\n| 命令        | 命令                                                  | 备注                                           |\n| ----------- | ----------------------------------------------------- | ---------------------------------------------- |\n| `show`      | `rustup show`                                         | 显示已安装的工具                               |\n| `update`    | `rustup update`<br />`rustup  self  update`           | 更新`rust`工具以及`rustup`<br />只更新`rustup` |\n| `check`     | `rustup check`                                        | 检查`rust`工具是否有新版本                     |\n| `default`   | `rustup default stable`<br />`rustup default nightly` | 切换版本                                       |\n| `install`   | `rustup install nightly`                              | 安装`rust`工具                                 |\n| `uninstall` | `rustup uninstall`<br />`rustup self uninstall`       | 删除`rust`工具<br />删除`rust`工具和`rustup`   |\n| `doc`       | `rustup doc`                                          | 查看文档（可以离线使用）                       |\n\n## Hello World\n\n创建`main.rs`，编写代码\n\n```rust\nfn main() {\n    println!(\"Hello, World\")\n}\n```\n\n执行代码：\n\n1. 编译：执行`rustc main.rs`，会生成可执行文件\n2. 执行：`./main` or `./main.exe`(win)\n3. 结果：命令行显示`Hello,World`\n\n## Cargo\n\n`cargo`是`Rust`的项目管理器，提供了一键创建、运行以及build`Rust`项目的命令：\n\n1. `cargo new my_project`: 创建项目\n\n2. `cargo build`: build操作，在`/target/debug/`目录下创建可执行文件\n\n3. `cargo run`: build然后run\n\n4. `cargo check`：检查code是否能够通过编译，不会创建创建可执行文件\n\n5. `cargo build --release`: build操作，会额外做优化以加快程序运行速度，在发布release版本时使用\n\n","tags":["Rust","语言学习"],"categories":["Rust"]},{"title":"Web Animation API","url":"/posts/af0be6b0.html","content":"\n## Web Animation API\n\n以前，在web页面增加动画效果都是通过css来完成的。比如`transition`或者`animation`。有了Web Animation API就可以通过`javascript`来设置以及控制动画。\n\n### CSS实现动画\n\n通过css实现一个简单的动画，让box旋转移动，代码如下：\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Document</title>\n    <style>\n      .box {\n        width: 100px;\n        height: 100px;\n        background-color: red;\n        animation: move 2s ease-in-out;\n        position: fixed;\n      }\n      @keyframes move {\n        from {\n          transform: rotate(0);\n          left: 0;\n          top: 0;\n        }\n        to {\n          transform: rotate(1turn);\n          left: 80%;\n          top: 80%;\n        }\n      }\n    </style>\n  </head>\n  <body>\n    <div class=\"box\"></div>\n  </body>\n</html>\n\n```\n\n### Javascript实现动画\n\n将上面例子改成JavaScript，代码如下\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Document</title>\n    <style>\n      .box {\n        width: 100px;\n        height: 100px;\n        background-color: red;\n        position: fixed;\n      }\n    </style>\n  </head>\n  <body>\n    <div class=\"box\"></div>\n\n    <script>\n      // 获取dom\n      const ele = document.querySelector(\".box\");\n\t  \n      // 设置keyframes\n      const keyframes = [\n        {\n          transform: \"rotate(0)\",\n          left: 0,\n          top: 0,\n        },\n        {\n          transform: \"rotate(1turn)\",\n          left: \"80%\",\n          top: \"80%\",\n        },\n      ];\n      \n      // 设置动画，animate函数返回一个Animation对象\n      const animation = ele.animate(keyframes, {\n        easing: \"ease-in-out\",\n        duration: 2000, // millisecond\n      });\n      \n      // 可以监听时间\n      animation.addEventListener(\"cancel\", () => {\n        console.log(\"cancel\");\n      });\n      animation.addEventListener(\"finish\", () => {\n        console.log(\"finish\");\n      });\n      animation.addEventListener(\"remove\", () => {\n        console.log(\"remove\");\n      });\n      \n      // 取消\n      // animation.cancel()\n        \n      // 播放\n      // animation.play()\n    </script>\n  </body>\n</html>\n\n```\n\n使用方法很简单。直接调用`animate`方法即可。\n\n### 对比\n\nweb animation api比传统的css animation方案优秀不少，能够提供更好的用户体验。\n\n1. 前者更加灵活，javascript灵活度大于css\n2. 前者能够控制动画，诸如：暂停、播放等\n3. 前者能够监听动画的生命周期事件，例如：finish、cancel\n4. 前者兼容性不足，ie以及一些移动端不支持。但是有[polyfill](https://github.com/web-animations/web-animations-js)啊！\n\n## Animation API介绍\n\n调用`animate`方法后会返回一个`Animation`对象。通过这个对象能够实现控制动画以及监听动画的生命周期事件。\n\n### 事件\n\n| event    | type     | comment                                        |\n| -------- | -------- | ---------------------------------------------- |\n| oncancel | function | animation.cancel()调用后触发                   |\n| onfinish | function | 动画播放结束后或者animation.finish()调用后触发 |\n\n### 属性\n\n| name        | type                                                      | comment                                                      |\n| ----------- | --------------------------------------------------------- | ------------------------------------------------------------ |\n| currentTime | number                                                    | 动画执行的当前时间（ms）                                     |\n| playState   | 'idle' \\| 'pending' \\| 'runing' \\| 'paused' \\| 'finished' | 一个用来标识播放状态的枚举值<br />idle:　动画当前的时间是无法解析的，并且队列里没有处于等待执行的任务。<br />pending:　动画将一直等到某些等待中的任务完成方会执行。<br />running：动画处于正在运行状态。<br />paused：动画中止，并且[`Animation.currentTime`](https://developer.mozilla.org/zh-CN/docs/Web/API/Animation/currentTime)该项属性不会更新。<br />finished:动画已经达到某一临界点，并且[`Animation.currentTime`](https://developer.mozilla.org/zh-CN/docs/Web/API/Animation/currentTime)该项属性不会更新。 |\n\n### 方法\n\n| name    | type       | comment                                                      |\n| ------- | ---------- | ------------------------------------------------------------ |\n| cancel  | () => void | 清除此动画的所有[`keyframeEffects`](https://developer.mozilla.org/zh-CN/docs/Web/API/KeyframeEffect)，并中止播放。 |\n| finish  | () => void | 立即完成，效果同中止播放（触发事件不一样）。                 |\n| pause   | () => void | 暂停播放动画                                                 |\n| play    | () => void | 开始或恢复播放动画，或者如果之前完成，则重新开始动画。       |\n| reverse | () => void | 反转播放动画，直到播放到动画开始时停止。 如果动画完成或未播放，它将从头到尾播放。 |\n\n更详细的API介绍请参考[MDN](https://developer.mozilla.org/en-US/docs/Web/API/Animation)\n\n","tags":["javascript","animation"],"categories":["JavaScript"]},{"title":"Electron-安全","url":"/posts/b81ed83c.html","content":"\n## XSS进化到RCE\n\nWeb的XSS攻击能做到脚本注入，而Electron具有原生能力可以调用nodejs的模块。这就导致进化成了RCE攻击(Remote code excute)\n\n```html\n<img onerror=\"require('fs');fs.readFile('./data.json')\"/>\n```\n\n解决：\n\n1. 基本的XSS防范措施\n2. 管理node权限\n   1. 主进程任何时候都允许\n   2. 渲染进程加载本地资源是允许\n   3. 渲染进程加载远程资源时不允许，但可以在preload中使用\n3. 限制链接跳转\n   1. https可信域允许\n   2. 应用本地协议允许\n   3. file协议不允许\n\n## cookie克隆攻击\n\n将cookie文件拷贝到其它机器，可以直接使用\n\n原因：Electron cookie没有想Chrome那样加密\n\n解决：\n\n生成设备指纹，将cookie与设备指纹绑定\n\n## 源码安全\n\nElectron打包可以设置asar，但是asar是可以解密的。\n\n`npm i asar -g`、`asar e app.asar unpack`、`cd unpack`\n\n解决：\n\n1. UI与逻辑分离：UI层使用Electron，逻辑层使用C++或Rust。通过`N-API`、`Neon`连接nodejs\n2. WebAssembly\n3. 代码混淆，使用构建工具进行代码混淆\n4. asar：防止小白\n5. [asar Hack](https://www.v2ex.com/t/493344)\n\n## 安全事项\n\napp层\n\n- 做好Web安全\n- [官方 安全Checklist](https://www.electronjs.org/docs/tutorial/security)，[文档]( https://www.electronjs.org/docs/tutorial/security#checklist-securityrecommendations)\n- 代码混淆\n\nnpm\n\n- nsp/snyk，检测npm包的安全性\n- 关注npm官博[安全文章](https://blog.npmjs.org/tagged/security)\n- nodejs安全小组 [Node.js Security WG](https://github.com/nodejs/security-wg)\n\nelectron\n\n- 升级Electron至最新\n- 有问题反馈security@electronjs.org\n- 尝试研究electron构建，具备项目应急能力\n\n","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"Electron-测试","url":"/posts/bc68d7e0.html","content":"\n## 测试金字塔\n\n![测试金字塔](../../images/测试金字塔.png)\n\n前端软件测试可以分为三步\n\n### 单元测试（`Unit Test`）\n\n单元测试是用来对一个模块、一个函数、一个组件或者一个类来进行正确性检验的测试工作。\n\n单元测试应该是最多的，而且快。\n\n单元测试颗粒更细，更加具体。测试失败要返回错误原因\n\n### 快照测试（`snapshot Test`）\n\n快照测试就是运行测试的时候，把结果保存一份，之后再来对比，比对不上测试就不通过。\n\n### 端到端测试（`E2E Test`）\n\n端到端测试时模拟用户的整个交互过程。比如：点击按钮 => 显示表单 => 填写数据 => 点击提交按钮 => 验证数据发送。 \n\n## Electron 测试\n\n### 处理Electron驱动\n\n可以使用官方提供的`spectron`；也可以[自定义驱动](https://www.electronjs.org/docs/tutorial/automated-testing-with-a-custom-driver)\n\n### 选择测试框架+工具\n\n1. ava\n2. mocha+chai\n3. jest\n4. ...\n\n### 管理测试用例\n\n通常在项目建立一个`test`目录，专门存放测试用例。\n\n按模块、功能分好类\n\n### 创建测试脚本\n\n在`package.json`加入`test`命令，编写自定义脚本，test命令去执行这个脚本。\n\n脚本主要用来执行测试用例\n\n## 自动化测试流程\n\n### 测试准备\n\n数据mock、准备上下文。\n\n### 测试用例描述\n\n用来说明这个测试用例是用来做什么的\n\n### 行为\n\n要做什么事\n\n### 断言\n\n得到什么结果\n\n### 测试后处理\n\n清理mock的数据，清理上下文\n\n## Electron测试编码\n\n```javascript\nconst Application = require('spectron').Application\nconst electronPath = require('electron')\nconst path = require('path')\n\n// jest 测试工具\ndescribe('Application lanuch', () => {\n    let app\n\tbeforeEach(() => {\n        app = new Application({\n            path: electronPath\n            args: [path.join(__dirname, '../')]\n        })\n    \treturn app.start()\n\t});\n    afterEach(() => {\n        if(app && app.isRunning()) return app.stop()\n    });\n\n\ttest('Check if the window is visible', () => {\n        expect(app.browserWindow.isVisible()).toBeTruthy()\n    });\n\n\ttest('Get the window\\'s title', () => {\n        expect(app.client.getTitle()).toBe('My App')\n    })\n})\n\n```\n\n","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"Electron-集成原生能力","url":"/posts/72ce1ec4.html","content":"\n## NAPI\n\nN-API是nodejs的一部分，独立于v8 runtime，用来在nodejs中集成C++：同一ABI（Application Binary Interface）、无需重新编译\n\n- 本身是基于C的API\n- C++封装 node-addon-api\n\n### 环境配置\n\n`yarn global add windows-build-tools` : 管理员身份安装\n\n`yarn global add node-gyp`:  gyp即generate your project\n\n### 初始化项目\n\n1. 初始化：\n   1. `npm init -y`\n   2. `yarn add bindings node-addon-api -D`\n   3. `package.json`增加`\"gyp\":true`\n2. 目录结构\n```\n|- project\n|\t|- lib # c++文件\n|   |- fingerprint.cc\n|   |- binding.gyp\n|   |- index.js\n|   |- package.json\n```\n\n### binding.gyp\n\n`bindings`用来加载原生模块(.node文件)。不同平台不同版本rebuild出来的目录结构可能不一样。通过`bindings`来抹平差异。\n\n编写`binding.gyp`\n\n```json\n{\n\t\"targets\": [\n      {\n        \"target_name\": \"fingerprint\",  // 应用名称\n        \"cflags!\": [\"-fno-exceptions\"],\n        \"cflags_cc!\": [\"-fno-exceptions\"],\n        \"sources\": [\"fingerprint.cc\"],  // 需要编译的文件\n        \"include_dirs\": [ // 编译时需要引入的头文件\n          \"<!@(node -p \\\"require('node-addon-api').include\\\")\"\n        ],\n        \"defines\": [\"NAPI_DISABLE_CPP_EXCEPTIONS\"]\n    }\n  ]\n}\n```\n\n### C++实现\n\n```c++\n// fingerprint.cc\n#include <napi.h>\n#include <iostream>\n#include <string>\n#include <stdlib.h>\n\nstd::string getFingerprint()\n{\n    srand(100);\n    std::string result = std::to_string(rand());\n    return result;\n}\n\n// 定义一个method，该方法返回一个设备指纹（随机数mock）\nNapi::String Method(const Napi::CallbackInfo &info)\n{\n    Napi::Env env = info.Env();\n    std::string fingerprint = getFingerprint();\n    return Napi::String::New(env, fingerprint);\n}\n\n// 初始化\n// 相当于 module.exports = Method\nNapi::Object Init(Napi::Env env, Napi::Object exports)\n{\n    exports.Set(Napi::String::New(env, \"getFingerprint\"),\n                Napi::Function::New(env, Method));\n    return exports;\n}\n\n// 暴露模块\n// 模块名 fingerprint，Init进行初始化\nNODE_API_MODULE(fingerprint, Init)\n```\n\n### 构建\n\n使用`node-gyp rebuild`进行构建，在根目录中会生成`build`目录。\n\n然后编写index.js，来导出模块\n\n```javascript\nconst fingerprint = require(\"bindings\")(\"fingerprint\");\n\nmodule.exports = fingerprint;\n```\n\n### 使用\n\n通常做法是，将写好的node addon发布到npm上。在其它项目中就可以通过`npm`或者`yarn`安装，然后就`require`使用\n\n```javascript\nconst fp = require(\"fingerprint\"); // fingerprint是npm包名\n\nconsole.log(fp.getFingerprint());\n```\n\n## 集成DLL（动态链接库） \n\n`node-ffi-napi`，黑盒调用\n\n```javascript\nconst FFI = require('ffi-napi')\n\nconst user32 = new FFI.libraray('user32', {\n    'finDWindowA': ['int32', ['string', 'string']],\n    'ShowWindow': ['int32', ['int32', 'int32']],\n})\n\nfunction showWechat() {\n    let res = user32.FindWindowA('weChatMainWinForPC', null)\n    let show = user32.showWindow(res, 5)\n}\n\nmodule.exports = showWechat\n```\n\n常见错误：\n\nDynamic Linking Error: Win32 error 126\n\n- dll 路径没写对、arch 没选对、dll 引用有问题\n\nDynamic Linking Error: Win32 error 127\n\n- 传参有问题、dll 没有这个函数\n\n## AppleScript\n\nmac上，还可以通过`AppleScript`使用获得原生能力\n\n[AppleScript语法文档](https://developer.apple.com/library/archive/documentation/AppleScript/Conceptual/AppleScriptLangGuide/introduction/ASLR_intro.html)\n\n[node-applescript](https://github.com/TooTallNate/node-applescript)\n\n```javascript\nconst applescript = require('applescript')\nconst script = 'tell application \"WeChat\" to activate end'\napplescript.execString(script, (err, res) => {\n    if(err) {\n        console.log(err)\n        return\n    }\n    console.log(res)\n})\n```\n\n## 集成RUST\n\n通过[Neon](https://neon-bindings.com/docs/intro)来将RUST程序集成到`nodejs`中。","tags":["javascript","Electron","桌面端软件","C++","Rust"],"categories":["Electron"]},{"title":"Electron-体验优化","url":"/posts/60bc3abb.html","content":"\nElectron内置了`Chromium`浏览器。在原生体验上，一直被诟病。在开发Electron程序时，要格外关注体验优化。\n\n## 性能优化\n\n### 核心模块优先加载\n\n不再在入口文件把所有内容都加载进来，只需要加载程序的核心功能，其它部分按需加载\n\n```javascript\nfunction compute(a, b) {\n    const calculator = require('./calculator')\n    return calculator.complex(a, b)\n}\n\n// 执行核心内容\n// ...\n\n// 执行非核心内容\ncompute(0x12f2, 0xff21)\n```\n\n在`Typescript`通过`dynamic import`实现\n\n```typescript\nasync function compute(a, b) {\n    const calculator = await import('./calculator')\n    return calculator.complex(a, b)\n}\n\n// 执行核心内容\n// ...\n\n// 执行非核心内容\ncompute(0x12f2, 0xff21)\n```\n\n### Web性能优化\n\n毕竟本质上还是Web，所以Web性能的优化技巧都可以应用得到`Electron`。如果使用`SPA`，要格外注意打包优化。\n\n### 窗口预热 与 窗口池、窗口常驻\n\n- 窗口预热：提前创建窗口，加载必要的资源（不显示），等需要时直接显示即可。这样的做法是以空间换时间。\n- 窗口池：不要频繁创建和销毁窗口，当需要加载新页面时从当前的窗口池中选择窗口\n- 窗口常驻：对于业务无关的、通用的窗口，也可以采用**常驻模式**，例如通知，图片查看器。这些窗口一旦创建就不会释放，打开效果会更好。\n\n### 网络资源缓存\n\nPWA\n\n### 主进程保持轻量\n\n`Electron`程序中，主进程和渲染进程有着`Sync IPC`（同步IPC）操作。如果主进程中有密集计算，会导致渲染进程UI阻塞。\n\n可以使用多进程，参考node的[cluster模块](http://nodejs.cn/api/cluster.html)\n\n或者通过`web worker`来实现多线程，但是`web worker`只能在渲染进程中使用，所以**对于密集计算，可以单独开个渲染进程(开启一个不显示的窗口)来处理**。\n\n还有：**不要使用remote模块！不要使用remote模块！不要使用remote模块！**，`remote模块`本质上也是使用同步IPC，所以也会很容易造成阻塞\n\n### 预加载\n\n#### Electron\n\nelectron中，在创建`BrowserWindow`时可以指定`preload`字段来预加载一段脚本\n\n#### Browser\n\n使用`requestIdleCallback`，让浏览器空闲时执行一些优先级较低的任务。\n\n当浏览器空闲时，会调用`requestIdleCallback`注册的回调函数，但是有可能浏览器一直很繁忙没有空闲，这是需要指定`timeout`，超过这个时间强制执行\n\n```javascript\nvar handle = window.requestIdleCallback(callback[, options])\n```\n\n**callback**：回调，即空闲时需要执行的任务，该回调函数接收一个`IdleDeadline`对象作为入参。其中`IdleDeadline`对象包含：\n\n- `didTimeout`，布尔值，表示任务是否超时，结合 `timeRemaining` 使用。\n- `timeRemaining()`，表示当前帧剩余的时间，也可理解为留给任务的时间还有多少。\n\n**options**：目前 options 只有一个参数\n\n- `timeout`。表示超过这个时间后，如果任务还没执行，则强制执行，不必等待空闲。\n\n### 原生模块\n\n`ndoejs`可以集成`C++`、`RUST`等，用来优化性能，详情见[Electron-集成原生能力](https://zxffan.github.io/posts/72ce1ec4.html)\n\n## 启动优化\n\n#### V8 snapshot\n\n[`atom`通过`v8 snapshot`优化启动时间](https://blog.atom.io/2017/04/18/improving-startup-time.html)\n\n`v8 snapshot`会将`javascript`输出成二进制文件，文件的内容是`javascript`代码在内存中的表现形式即数据堆\n\n这个二进制文件的执行速度时快于`javascript`代码的。\n\n在Electron中将一些启动时的核心代码进行`v8快照`，这样可以起到优化启动速度的目的\n\n> 说明：\n>\n> 1. `v8 snapshot`中的代码是处于一个裸露的v8上下文中，也就是说只能使用`plain javascript`而无法调用`Electron`和`nodejs`的API，Atom团队的[electron-link](https://github.com/atom/electron-link)可以在一定程度上**规避**这个问题\n> 2. 生成`v8 snapshot`可以通过[electron-mksnapshot](https://github.com/electron/mksnapshot)来实现\n\n#### V8 code cache\n\n`nodjes v12`对内部模块做了`code cache`，对启动速度提升很明显。\n\n## 白屏问题\n\n### 为什么会有白屏\n\n![Electron生命周期](../../images/Electron生命周期.png)\n\n在`show`（窗口显示）到`ready-to-show`（页面加载完毕）之间还需要经历以下过程\n\n1. preload解析，创建`BrowserWindow`设置的\n2. 解析HTML结构\n3. 加载外部脚本（`script`）以及样式表文件（`link`）\n4. 解析并执行脚本\n5. `Dom Tree`构建完毕\n6. 资源文件（图片、音视频）加载\n7. 页面加载完成\n\n只有完成这些过程，窗口才能显示内容。所以这段时间窗口会一直白屏。如果使用`vue`或`react`这种`SPA`框架，也会出现首屏加载过慢的情况。\n\n### 解决方法一——不显示窗口\n\n创建`BrowserWindow`时，设置`show:false`即不显示窗口\n\n等到`ready-to-show`事件触发时才显示\n\n```javascript\nconst win = new BrowserWindow({\n    widht: 600,\n    height: 300,\n    show: false\n})\n\nwin.on('ready-to-show', () => {\n    win.show()\n})\n```\n\n### 解决方法二——骨架屏\n\n最简单的方法就是直接给窗口显示个底色\n\n```javascript\nconst win = new BrowserWindow({\n    widht: 600,\n    height: 300,\n    show: false,\n    background: '#2e2c29'\n})\n```\n\n比较好的方法就是专门设计一套骨架屏。利用`BroswerView`来显示骨架屏。\n\n当窗口创建时，创建`BrowserView`来加载骨架屏页面，将`BrowserView`设置到`BrowserWindow`上并遮罩住，当骨架屏页准备好后时显示骨架屏。当渲染进程发送来一个`stop-loading`消息时，移除`BrowserView`\n\n```javascript\nconst mainWindow = new BrowserWindow({\n    width: 800,\n    height: 600,\n    webPreferences: {\n      preload: path.join(__dirname, \"preload.js\"),\n    },\n    show: false, // 默认不显示窗口\n});\n\nlet view = new BrowserView();\nmainWindow.setBrowserView(view);\nview.setBounds({ x: 0, y: 0, width: 800, height: 600 }); // 遮挡住窗口\nview.webContents.loadFile(\"loading.html\"); // 加载骨架屏页面\n\n// 当骨架屏加载完成后显示窗口\nview.webContents.on(\"dom-ready\", () => {\n    console.log(\"show\");\n    mainWindow.show();\n});\n\n// 当渲染进程发来stop-loading消息时，移除骨架屏，显示真正页面\nipcMain.on(\"stop-loading\", () => {\n    console.log(\"stop\");\n    mainWindow.removeBrowserView(view);\n});\n```\n\n## 性能检测\n\nChrome DevTools Performance\n\n## 支持快捷键\n\n[系统快捷键](http://www.electronjs.org/docs/api/global-shortcut)\n\n```javascript\nconst { app, globalShortcut } = require('electron')\n\napp.on('ready', () => {\n  // 注册一个 'CommandOrControl+X' 的全局快捷键\n  const ret = globalShortcut.register('CommandOrControl+X', () => {\n    console.log('CommandOrControl+X is pressed')\n  })\n\n  if (!ret) {\n    console.log('registration failed')\n  }\n\n  // 检查快捷键是否注册成功\n  console.log(globalShortcut.isRegistered('CommandOrControl+X'))\n})\n\napp.on('will-quit', () => {\n  // 注销快捷键\n  globalShortcut.unregister('CommandOrControl+X')\n\n  // 注销所有快捷键\n  globalShortcut.unregisterAll()\n})\n```\n\n## 本地化（i18n）\n\nElectron程序在`ready`事件后，可以通过`app.getLocale()`来获得`local值`(如`zh-CN`)，[详细列表](http://www.electronjs.org/docs/api/locales)\n\n通过[i18nnext](https://github.com/i18next/i18next)来实现国际化\n\n[Electron使用i18nnext](https://phrase.com/blog/posts/building-an-electron-app-with-internationalization-i18n/#Switching_Locale_from_the_Menu)\n\n## 开机自启\n\n通过`app.setLoginItemSettings`来设置开机自启\n\n```javascript\napp.setLoginItemSettings({\n  openAtLogin: true, // Boolean 在登录时启动应用 默认false\n  openAsHidden: true, // Boolean (可选) mac 表示以隐藏的方式启动应用。~~~~\n  // path: '', String (可选) Windows - 在登录时启动的可执行文件。默认为 process.execPath.\n  // args: [] String Windows - 要传递给可执行文件的命令行参数。默认为空数组。注意用引号将路径换行。\n})\n```\n\n","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"Electron-项目打包","url":"/posts/acb10ea6.html","content":"\n## 打包分为几步？\n\n1. 下载二进制文件 ：\n\n2. 添加业务代码：构建好的前端资源添加到resources app，electron壳子与业务代码结合\n\n3. 修改文件信息：修改 应用名称，设置图标等\n\n4. 制作镜像：压缩文件，制作镜像（dmg-builder、nsis）\n\n## 打包工具\n\n|              | electron-builder                             | electron-forge                               |\n| ------------ | -------------------------------------------- | -------------------------------------------- |\n| 签名         | ***                                          | ***                                          |\n| 安装包类型   | ***                                          | ***                                          |\n| 原生模块编译 | ***                                          | ***                                          |\n| 定制化       | ***                                          | *                                            |\n| 上手成本     | **                                           | *                                            |\n| boilerplate  | x                                            | ***                                          |\n| 跨平台构建   | Linux、windows                               | x                                            |\n| 社区活跃度   | ***                                          | **                                           |\n| 场景         | 打包和发布的完成解决方案，基本适用于所有场景 | 创建到发布的一体化解决方案，适合从0到1的项目 |\n\n推荐使用`electron-builder`\n\n## 打包准备\n\n1. 证书\n   1. mac: 开发者证书\n   2. window：赛门铁克(Symantec)、WoSign\n2. 对于系统的机器（mac打macos的包，windows打win的包，linux打linux的包）\n3. 软件所需图片\n   1. mac： \n      1. 软件图标、icns格式，通过 [image2icon](http://www.img2icnsapp.com/) 或者 [iconutil](https://www.npmjs.com/package/iconutil) 生成\n      2. dmg 背景图\n      3. 安装包图标\n   2. Windows\n      1. ico\n      2. installerIcon-安装图标\n      3. unInstallerIcon-卸载图标\n\n## 使用electron-builder来打包\n\n### 安装相关依赖\n\n- `npm i -g --production window-build-tool`（用管理员权限安装，window必备）\n- 项目目录下执行`npm i electron-builder -S`\n- 在`package.json`中，添加`\"postinstall\": \"electron-builder install-app-deps\"`。每当使用`npm install`或者`yarn add`时，会自动安装匹配当前electron版本的依赖。\n\n### 配置方式\n\n在`package.json`中加入build属性\n\n使用`electron-builder.yml`\n\n通过编程时API\n\n### 配置项\n\n在`package.json`文件中添加如下\n\n```json\n\"build\"： {\n    \"appId\": \"com.xxx.xxx\",\n    \"productName\": \"应用名称\",\n    \"directories\": {  // 目录配置\n        \"app\": \"dist\", // 打包的代码目录\n        \"buildResources\": \"resource\", // 构建包的资源目录\n        \"output\": \"release\" // 存放产包的目录\n    },\n    \"asar\": true, // asar加密，保护源代码\n    \"copyright\": \"Copyright xxxx\",\n    \n    \"mac\": {\n       \"target\": [\"dmg\", \"zip\"],  // 包格式，zip用于自动更新\n\t\t\"icon\": \"resources/icon.icns\" // logo地址\n    },\n    \"dmg\": {\n        \"background\": \"resources/background.png\", // 背景图\n        \"window\": { \"width\": 540,  \"height\": 380}, // 安装窗口大小\n        \"contents\": [ // dmg内容坐标\n          {\"x\": 410, \"y\": 190,  \"type\": \"link\", \"path\": \"/Applications\"},\n          {\"x\": 130,\"y\": 190,\"type\": \"ﬁle\"}\n        ],\n        \"iconSize\": 128, // logo大小\n   },\n   \"win\": {\n       \"icon\": \"resources/icon.ico\", // logo地址\n       \"target\": [ \"nsis\", \"squirrel\"] // nsis包，squirrel是一件安装包\n   },\n   \"nsis\": {\n       \"oneClick\": false,  // 一键安装\n       \"language\": \"2052\", // 2052代表中文\n       \"perMachine\": true, // 是否为机器上所有用户安装\n       \"allowToChangeInstallationDirectory\": true // 允许改变安装目录\n   },\n   \"squirrelWindows\": {\n       \"loadingGif\": \"resources/loading.gif\", // 安装动态图\n       \"iconUrl\": \"https://xxxxx.com/icon.ico\" // 必须是远程的\n   }\n}\n```\n\n> nsis时windows下的包安装器，可以做到很细致的定制。\n>\n> 如果使用squirrel来打包，需要安装`electron-builder-squirrel-windows`\n\n在`scripts`中加上`\"pack\": \"electron-builder\"`\n\n如果使用编程时API，则新建一个js或ts文件\n\n```javascript\n// js\nconst { build } = require(\"electron-builder\");\n\nbuild({\n    config: {\n        appId: \"com.xxx.xxx\",\n        productName: \"应用名称\",\n        // ...以下省略\n    }\n})\n\n// build函数返回一个promise\n// 可以 借助 electron-builder的类型声明文件来查看它有哪些方法和参数类型\n```\n\n然后用node执行这个js文件。如果是ts文件，可以使用ts-node，或者先用tsc编译再用node执行。\n\n`electron-builder`更详细的配置请查阅[官网](https://www.electron.build/configuration/configuration)\n\n## 总结\n\n1. 发布产品注意版本号的升级\n   1. `npm version patch`：自动升级patch\n   2. `npm version minor`：自动升级minor，path会清0\n   3. `npm version major`：自动升级major，minor和patch会清0\n\n2. 证书\n   1. windows下没有证书，可能会被杀软误杀\n   2. mac下没有证书，无法实现自动更新\n   3. windows下打包可以通过修改nsis来自定义安装逻辑\n   4. 开源软件可以基于 Travis, AppVeyor 持续集成","tags":["javascript","Electron","桌面端"],"categories":["Electron"]},{"title":"Electron-质量监控","url":"/posts/34a04fbb.html","content":"\n##  Electron质量保证\n\n|          | 开发                                                         | 测试                                                   | 上线                 | 监控                                     |\n| -------- | ------------------------------------------------------------ | ------------------------------------------------------ | -------------------- | ---------------------------------------- |\n| 渲染进程 | 代码静态检查：eslint<br />强类型语言：typescript<br />Code review | 单元测试<br />性能测试<br />UI自动化测试<br />冒烟测试 | 灰度发布<br />回滚   | 性能监控<br />异常监控<br />用户行为监控 |\n| 主进程   | 同上                                                         | Electron测试(Spectron)                                 | 功能开关<br />热修复 | **崩溃监控**                             |\n\n## 崩溃监控模型\n\n![electron错误收集](../../images/electron错误收集模型.png)\n\nElectron内置`crashReporter`模块，可以用来监控主进程和渲染检查的错误。然后将错误报告发送给服务器的`crash收集服务`\n\n崩溃报告将发送下面 `multipart/form-data` `POST` 型的数据给 `submitURL`:\n\n- `ver` String - Electron 的版本.\n- `platform` String - 例如 'win32'.\n- `process_type` String - 例如 'renderer'.\n- `guid` String - 例如 '5e1286fc-da97-479e-918b-6bfb0c3d1c72'.\n- `_version` String - `package.json` 里的版本号.\n- `_productName` String - `crashReporter` `options` 对象中的产品名字\n- `prod` String - Name of the underlying product. In this case Electron.\n- `_companyName` String - `crashReporter` `options` 对象中的公司名称\n- `upload_file_minidump` File - `minidump` 格式的崩溃报告\n- All level one properties of the `extra` object in the `crashReporter` `options` object.\n\n上述数据中的`upload_file_minidump`是个minidump格式的文件。直接时无法打开的。需要结合`electron-symbols`以及`node-minidump`，后面再说。\n\n## 实现监控\n\n### 服务端\n\n使用`koa`搭建一个crash收集服务\n\n\n```javascript\nconst Koa = require('koa')\nconst app = new Koa()\nconst Router = require('koa-router')\nconst multer = require('koa-multer') // 处理文件上传的库\nconst uploadCrash = multer({ dest: 'crash/' }) // 设置错误报告存放目录\n\nconst router = new Router()\n\nrouter.post('/crash', uploadCrash.single('upload_file_minidum'), (ctx, next) => {\n    // TODO 错误信息存储到DB\n    ctx.request.file // minidump文件\n})\n\napp.use(router.routes())\n    .use(router.allowedMethods())\n\napp.listen(33855)\n```\n\n### ELectron端\n\n配置`crashReporter`\n\n```javascript\n// crash.js\nconst { crashReporter } = require('electron')\n\nfunction init() {\n    crashReporter.start({\n        crashReporter.start({\n        \tproductName: '',\n        \tcompanyName: '',\n        \tsubmitURL: '服务器 处理异常接口地址'\n    \t})\n    })\n}\nmodules.exports = { init }\n\n// main.js\napp.on('will-finish-lanuching', () => {\n    require('./crash-reporter').init()\n})\n```\n\n### 解析错误日志\n\n服务端收到的是`minidump`文件。需要使用`symbols`以及`node-minidump`来解析日志\n\n先下载对应electron版本和对应os的symbols，[下载地址](https://github.com/electron/electron/releases)\n\n![symbols下载](../../images/symbols下载.png)\n\n建立一个node项目（也可以集成到crash收集服务中）。安装`node-minimap`\n\n执行`yarn add minidump`\n\n```javascript\nconst minidump = require('node-minidump')\nconst fs = require('fs')\nminidump.addSymbolPath('./symbols/electron-v10.0.0-beta.12-darwin-x64-symbols.zip') // 指定下载的symbols路径\n\n// 指定minidump文件地址\nminidump.walkStack('./e19fb34bc3rf6812', (err, res) => {\n    // res 解析结果\n    fs.writeFileSync('./res.txt', res) // 写入文件\n})\n```\n\n## 监控技巧\n\n渲染进程崩溃后提示用户重新加载\n通过 `preload`统一初始化崩溃监控\n主进程、渲染进程通过 `process.crash()`可以模拟崩溃\n\n通过`process`进行异常监控\n\n```javascript\nprocess.on('uncaughtException', () => {\n    // 上报异常\n})\n```\n\n","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"Electron-应用更新","url":"/posts/e7227c9a.html","content":"\n## 软件更新方式\n\n### 手动更新\n\n用户手动下载、安装新包。\n\n手动更新简单稳定，适合更新频率低，用户粘性高的场景，通常作为其它升级技术的`降级方案`。\n\n流程：\n\n1. 更新服务：匹配客户端版本，用户信息\n2. 检查更新器：返回包地址，更新文案\n3. 提示：新功能升级\n4. 手动操作：跳转浏览器，打开安装包覆盖\n\n### 文件覆盖\n\n程序自动替换文件以实现更新。\n\n不稳定，可能会写入失败。适合`打补丁`的场景\n\n流程：\n\n1. 更新服务：匹配客户端版本，用户信息\n2. 检查更新器：返回包地址，更新文案\n3. 提示：新功能升级\n4. 程序操作：吊起子程序，关闭应用，将补丁复制到应用目录，重新启动\n\n### 自动更新\n\n后台下载文件，重启即新版\n\n稳定，快，用户无感知。适合更新频率高的场景，以及对用户体验要求高的场景\n\n流程：更新服务 => 检查更新器 => 下载新包 => 重启应用加载新包\n\n### 应用商店\n\n通过各平台应用商店发布，例如Microsoft store和mac app store\n\n统一、稳定\n\n### 对比\n\n| 更新方式 | 手动更新                                         | 文件覆盖                             | 自动更新             | 应用商店           |\n| -------- | ------------------------------------------------ | ------------------------------------ | -------------------- | ------------------ |\n| 优点     | 简单、稳定                                       | 下载过程快                           | 稳定、快、打扰少     | 统一、稳定         |\n| 缺点     | 过程繁琐、慢、影响使用、                         | 实现复杂、稳定性差、文件写入可能失败 | 实现复杂             | 受应用商店局限     |\n| 使用场景 | 低频更新、用户粘性高、作为各种升级技术的降级方案 | 打补丁                               | 高频更新、体验要求高 | 需要上架商店的软件 |\n\n## Electron更新方式\n\n### Web化\n\n将渲染进程（业务）代码，放置远程服务器。Electron通过loadURL加载\n\n这样的话，只要更新服务器的代码就能实现系统更新。\n\n缺点：无法离线使用，Electron壳子无法更新。\n\n### 文件覆盖\n\nElectron检测服务器的release版本与本地是否一致，若有新版本提示升级。拉去服务器程序并覆盖本地，然后重启。\n\n相关实现请参考张鑫旭的[文档](https://www.zhangxinxu.com/wordpress/2017/06/how-electron-online-update-hot-fix/?replytocom=361528)\n\n### Electron-Updater\n\nElectron-Updater是由electron-builder提出的\n\n 优点\n\n1. 接入简单\n2. Windows 支持签名验证\n3. 支持进度条\n4. 基于 electron-builder 非常容易使用\n\n 缺点\n\n1. Windows 更新体验没有内置的好\n2. Windows 存在权限问题\n\n详见 https://www.electron.build/auto-update.html\n\n### 增量更新\n\n只更新需要更新的地方\n\n原理： 当前版本与最新版本做diff算法，将不同的地方打包成patch，更新就只更新patch部分。\n\n增量技术：\n\n1. bsdiff/bspatch：适用二进制文件、开源、免费、广泛使用（尤其移动端）\n2. Xdelta3：适用于二进制\n3. Courgette：谷歌提出的方案，是bsdiff的优化\n4. RTPatch：商业付费\n\n对比参考：https://www.shangyexin.com/2018/09/28/delta_algorithm/\n\n## 灰度发布\n\n灰度发布就是让一部分用户继续使用原来的产品功能，对另一部分用户逐渐开发新功能。然后针对新功能在做完善和优化。等到灰度发布完成后，所有用户都将使用新的产品功能。\n\n## Electron更新实战\n\n### 更新准备\n\n准备证书，Mac下自动更新必须要证书。打包时候配置。\n\n### 使用内置的[autoUpdater](https://www.electronjs.org/docs/api/auto-updater)模块\n\nElectron官方更新方法是基于内置的[Squirrel](https://github.com/Squirrel)框架和Electron的[autoUpdater](https://www.electronjs.org/docs/api/auto-updater)模块。\n\n#### autoUpdater模块简介\n\n```typescript\nconst { autoUpdater: updater } = require('electron')\n\n// 设置更新服务器地址\nupdater.setFeedURL({\n    url: '更新服务器地址',\n    headers: 'HTTP请求头',\n    serverType: 'default' // json or default \n})\n\n// 获取当前更新服务器地址\nupdater.getFeedURL()\n\n// 检查更新，访问更新服务器地址\n// 调用checkForUpdates之前必须设置setFeedURL\nupdater.checkForUpdates()\n\n// 此方法hui关闭所有应用窗口，然后自动调用app.quit()\n// 这个方法通常在 update-downloaded 事件触发后调用\nupdater.quitAndInstall()\n\n\n// 开始检查更新时触发\nupdater.on('check-for-update', () => {\n    // TODO...\n})\n\n// 检查更新后，发现有新版本后触发该事件\n// 该事件触发后，会自动下载最新版本\nupdater.on('update-avaliable', () => {\n    // TODO...\n})\n\n// 检查更新后，没有发现新版本（返回204）后触发该事件\nupdater.on('update-not-avaliable', () => {\n    // TODO...\n})\n\n// 最新版下载完成后触发该事件\n// 在 Windows 上只有 releaseName 是有效的。\nupdater.on('update-downloaded', (e, releaseNotes, releaseName, releaseDate, updateURL) => {\n    // TODO...\n    // 显示提示框，询问用户是否自动更新\n})\n\n// 用户调用quitAndInstall 后触发\nupdater.on('before-quit-for-update', () => {\n    // TODO...\n})\n\n// 更新发生错误时，触发\nupdater.on('error', (error) => {\n    // TODO...\n})\n```\n\n#### 更新流程\n\n##### mac更新\n\nElectron客户端请求服务器，服务器去检查是否有最新版本。如果有，服务端需要返回**相应数据**，没有就返回`204`状态码\n\nmac下服务端需要返回这样的`json`结构\n\n```json\n{\n\t\"url\": \"https://mycompany.example.com/myapp/releases/myrelease\", // url为包下载地址\n\t\"name\": \"My Release Name\",\n\t\"notes\": \"Theses are some release notes innit\",\n\t\"pub_date\": \"2013-09-18T12:29:53+01:00\" \n}\n```\n\n然后Electron客户端就会自动请求`url`地址去下载\n\n##### windows更新\n\nElectron客户端请求服务器，服务器去检查是否有最新版本。如果有，服务端需要返回**相应数据**，没有就返回`204`状态码\n\nwindow下需要返回RELEASES文件内容（使用Squirrel打包生成的），如`BBC6F98A5CD32C675AAB6737A5F67176248B900C appName-1.0.1-full.nupkg 62177782`\n\n客户端收到数据发现有最新版本，又会请求`feedURL/*.nupkg`地址。所以服务端要响应相应的请求。\n\n在Electron主进程加上`if(require('electron-squirrel-startup')) return`。作用是：如果在程序安装时、更新时以及卸载时启动程序，就直接返回（或者`app.quit()`）。即不启用程序（否则会报错）\n\nwindow更新注意： \n\n1. 安装包不能使用 NSIS，需要使用 Squirrel\n2. 更新需要 Squirrel 配套的 nupkg 包\n\n#### 服务端\n\n安装模块：`yarn add koa koa-router koa-static-server compare-versions`\n\n```javascript\nconst Koa = require('koa')\nconst app = new Koa()\nconst Router - require('koa-router')\nconst serve = require('koa-static-server')\nconst compareVersions = require('compare-versions')\n\n// 获取最新版本通常会去查询数据库，这里就直接mock了\nfunction getNewVersion(version) {\n    if(!version) return null\n    let maxVersion = {\n        name: '1.0.1',\n        pub_date: '2020-02-01T12:26:53+1:00',\n        notes: '新增功能AAA',\n        url: 'http://128.0.0.1:33855/public/xxxx-1.0.1-mac.zip'\n    }\n    if(compareVersions.compare(maxVersion.name, version, '>')) return maxVersion\n    return null\n}\n\n// for mac\nrouter.get('/darwin', (ctx, next) => {\n    // 处理Mac更新，?version=1.0&uid=123\n    let {version} = ctx.query\n    let newVersion = getNewVersion(version)\n    if(newVersion) {\n        ctx.body = newVersion\n    } else {\n        ctx.status = 204 // 204代表没有数据\n    }\n})\n\n// for win\nrouter.get('/win32', (ctx, next) => {\n    let {version} = ctx.query\n    let newVersion = getNewVersion(version)\n    if(newVersion) {\n        ctx.body = 'BBC6F23A34BC123BA123C900 xxxx-1.0.1-full.nupkg 62177782'\n    } else {\n        ctx.status = 204 // 204代表没有数据\n    }\n})\n\n// 重定向去下载\nrouter.get('/win32/*.nupkg', (ctx, next) => {\n    ctx.redirect(`/public/${ctx.params[0].nupkg}`)\n})\n\napp.use(server(rootDir: 'public', rootPath: '/public'))\n\napp.use(router.routes())\n\napp.listen(3385)\n```\n\n#### Electron端\n\n```javascript\n// update.js\n\nconst { autoUpdater, app, dialog } = require('electron')\n\nif(process.platform === 'darwin') {\n    autoUpdater.setFeedURL(`http://127.0.0.1:33855/darwin?version=${app.getVersion()}`)\n} else {\n    autoUpdater.setFeedURL(`http://127.0.0.1:33855/win32?version=${app.getVersion()}`)\n}\n\n// 定时轮调 or 服务端推送\nautoUpdater.checkForUpdater()\n\nautoUpdater.on('update-avaliable', () => {\n    console.log('update-avaliable')\n})\n\nautoUpdater.on('update-downloaded', (e, notes, version) => {\n    app.whenReady().then(() => {\n         // 提示用户更新\n        let clickId = dialog.showMessageBoxSync({\n            type: 'info',\n            title: '升级提示',\n            message: '存在最新版，是否立即升级',\n            buttons: ['马上升级', '取消'],\n            cancelId: 1, // 手动重启 为 cancel\n        })\n\n        if(clickId === 0) {\n            autoUpdater.quiteAndInstall()\n        }\n    }) \n})\n\nautoUpdater.on('error', err => {\n    console.log('error:', error)\n})\n\n// main.js\nconst isDev = require('electron-is-dev')\nif(require('electron-squirrel-startup')) app.quit()\n\napp.on(\"will-finish-launching\", () => {\n    !isDev && require('./update.js')\n})\n```\n\n### 使用Electron-Updater\n\n`electron-updater`是基于`electron-builder`的更新方案。\n\n#### electron-updater模块简介\n\n```javascript\nconst { autoUpdater: updater } = require('electron')\n\n// 设置更新服务器地址\n// options可以是一个url字符串 表示 安装包helatest.yml所在服务器地址\n// 也可以是个对象\nupdater.setFeedURL(options) \n\n// 获取当前更新服务器地址\nupdater.getFeedURL()\n\n// 检查更新，访问更新服务器地址\n// 调用checkForUpdates之前必须设置setFeedURL\n// 若有更新不会自动下载\nupdater.checkForUpdates()\n\n// 检查更新，若有更新自会自动下载并通知\nupdater.checkForUpdatesAndNotify()\n\n// 手动下载\n// 返回promise\nupdater.downloadUpdate()\n\n// 此方法hui关闭所有应用窗口，然后自动调用app.quit()\n// 这个方法通常在 update-downloaded 事件触发后调用\nupdater.quitAndInstall()\n\n// 更新通道\n// alpha beta lts等\n// 默认 latest\nupdater.channel = 'latest'\n\n// checkForUpdates或 checkForUpdatesAndNotify调用后触发\nupdater.on('checking-for-update', () => {\n    // TODO...\n})\n\n// 检查后，有最新版本时，触发\nupdater.on('update-available', (info) => {\n    // TODO...\n})\n\n// 检查后，没有最新版本时，触发\nupdater.on('update-not-available', () => {\n    // TODO...\n})\n\n// 下载过程中 轮调 触发\nupdater.on('download-progress', (progress, bytesPerSecond, percent, total, transferred) => {\n    // TODO...\n})\n\n// 下载完成后触发\nupdater.on('update-downloaded', (info) => {\n    // TODO...\n})\n\n// 更新发生错误时，触发\nupdater.on('error', (error) => {\n    // TODO...\n})\n\n```\n\n`electro-updater`的`autoUpdater`和electro内置的`autoUpdater`模块很相似，但前者比后者要强大不少，前者可以显示更新进度。\n\n#### 更新流程\n\n![electron-upadter更新流程](../../images/electron-updater更新流程.webp)\n\n几点补充：\n\n1. 在electron-builder打包配置中，一定要配置`public`字段，配置好后才能生成`latest.yml`文档。\n\n```json\n\"publish\": [\n    {\n        \"provider\": \"generic\",\n        \"url\": \"http://127.0.0.1:8000/\"  // 放置安装包和latest.yml的服务器地址\n    }\n],\n```\n\n2. 将打包后的`latest.yml`以及安装包。放置到服务器上，可以使用`nginx`来搭建文件服务器。Electron检查更新就是检查这个`latest.yml`文件\n\n#### Electron端\n\n```javascript\n// update.js\nconst { autoUpdater: updater } = require('electron-updater')\n\nupdater.setFeedURL('http://127.0.0.1:8000')\n\nupdater.checkForUpdatesAndNotify()\n\nupdater.on('update-available', () => {\n    // TODO 可以在这提醒用户更新\n})\n\nupdater.on('download-progress', (progress, bytesPerSecond, percent, total, transferred) => {\n    // TODO 显示进度条\n})\n\nupdater.on('update-downloaded', () => {\n    updater.quitAndInstall()\n})\n\nupdater.on('error', error => {\n    // TODO handle error\n})\n\n// main.js\napp.on(\"will-finish-launching\", () => {\n    require('./update.js')\n})\n```\n\n#### Nginx文件服务器\n\n```nginx\nautoindex on;# 显示目录\nautoindex_exact_size on;# 显示文件大小\nautoindex_localtime on;# 显示文件时间\n\nserver {\n    listen       8000 default_server;\n    listen       [::]:8000 default_server;\n    server_name  _;\n    root         /www/update/demo;  # 文件路径\n\n    location / {\n    }\n\n    error_page 404 /404.html;\n    location = /40x.html {\n    }\n\n    error_page 500 502 503 504 /50x.html;\n    location = /50x.html {\n    }\n}\n```\n\n","tags":["javascript","Electron","桌面端软件"],"categories":["Electron"]},{"title":"浏览器中的音视频","url":"/posts/4dbf3745.html","content":"\n## 浏览器如何采集摄像头和麦克风\n\n浏览器可以通过`navigator`上的`mediaDevices`属性来获取音视频流数据。`navigator.mediaDevices`返回一个[MediaDevices](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaDevices)对象\n\n![mediaDevice兼容性](../../images/mediaDevice兼容性.png)\n\n```javascript\nconst constraints = {\n    audio: true,\n    video: true,\n}\nnavigator.mediaDevices.getUserMedia(constraints).then(stream => {\n    videoElement.srcObject = stream\n    videoElement.onloadedmetadata = () => {\n        videoElement.play()\n    }\n})\n```\n\n通过`getUserMedia`可以获取摄像头视频以及麦克风的音频，它接受一个[MediaStreamConstraints](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaStreamConstraints)对象作为参数。并返回一个[MediaStream](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaStream)对象\n\n```javascript\nconst MediaStreamConstraints = {\n  video: {\n    frameRate: {min: 20}, // 帧率最小20\n    width: {min: 640, ideal: 1280}, // with最小640 理想1280\n    height: {min: 360, ideal: 720}, // 同理\n    aspectRatio: 16/9 // 宽高比 16 ：9\n  },\n  audio: {\n    echoCancellation: true, // 回音消除\n    noiseSuppression: true, // 降噪\n    autoGainControl: true // 自动增益\n  }\n};\n```\n\n具体参数见下表：\n\n![MediaStreamConstraints](../../images/media/MediaStreamConstraint.png)\n\n## 浏览器如何采集桌面\n\n`navigator.mediaDevices`还有一个`getDisplayMedia`方法，用来采集桌面（包括音视频）。用法和参数与`getUserMedia`一致\n\n```javascript\nconst constraints = {\n    audio: true,\n    video: true,\n}\nnavigator.mediaDevices.getDisplayMedia(constraints).then(stream => {\n    videoElement.srcObject = stream\n    videoElement.onloadedmetadata = () => {\n        videoElement.play()\n    }\n})\n```\n\n## 获取音视频设备列表\n\n```javascript\nnavigator.mediaDevices.enumerateDevices()\n```\n\n返回一个promise，结果是一个数组，包含一个个[MediaDeviceInfo](https://developer.mozilla.org/en-US/docs/Web/API/MediaDeviceInfo)对象：\n\n- deviceId：硬件表示，一个session内不会改变。可能会变\n- groupId：组标识。如果属于同一个物理设备，groupid一样。比如同一台显示其的内置相机和麦克风\n- kind：`videoinput` `audioinput. ` `audiooutput`\n- label：设备描述，例如`\"External USB Webcam\"`\n\n## 如何录制流\n\n录制音视频流需要通过[MediaRecorder](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaRecorder)对象\n\n下例是录制麦克风\n\n```javascript\nlet recorder\nnavigator.mediaDevices.getUserMedia(constraints).then(stream => {\n    const mimeType = 'video/mp4'\n    if (MediaRecorder.isTypeSupported(mimeType)) { // 判断是否支持该类型\n        recorder = new MediaRecorder(stream, {\n            audioBitsPerSecond : 128000, // 音频的比特率 128kbps\n            videoBitsPerSecond : 2500000, // 视频的比特率 2.5Mbps\n            mimeType\n        })\n        // 当recorder.stop() 调用后， 触发该事件\n        recorder.ondataavailable = e => {\n            // e.data  blob对象\n            // ...\n        }\n        \n        recorder.start()\n    }\n})\n```\n\n## 如何解析音频\n\n有时候会遇到音频可视化的需求，比如播放器可能会显示音频的波形。这时就需要借助[AudoContext](https://developer.mozilla.org/zh-CN/docs/Web/API/AudioContext)对象来实现。\n\n直接上代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>audio analyser</title>\n  </head>\n  <body>\n    <canvas id=\"canvas\"></canvas>\n    <script>\n      navigator.mediaDevices\n        .getUserMedia({\n          audio: true,\n        })\n        .then((stream) => { // 获取麦克风的音频流\n            const audioCtx = new AudioContext(); \n            const source = audioCtx.createMediaStreamSource(stream);\n            // 创建 音频分析器\n            const analyser = audioCtx.createAnalyser();\n\t\t\t\t\n            analyser.fftSize = 2048;\n            const bufferLength = analyser.frequencyBinCount;\n          \t// 音频数据会放在 dataArray中\n            const dataArray = new Uint8Array(bufferLength);\n\t\t\t\n            source.connect(analyser);\n            analyser.connect(audioCtx.destination);\n\n            function draw() {\n                const canvas = document.querySelector(\"#canvas\");\n                const ctx = canvas.getContext(\"2d\");\n\n                const WIDTH = canvas.width;\n                const HEIGHT = canvas.height;\n\t\t\t\t\n                // 取出音频数据，放到dataArray中\n                analyser.getByteTimeDomainData(dataArray); \n\t\t\t\t\n                // ** 绘制波形 start\n                ctx.fillStyle = \"rgb(200, 200, 200)\";\n                ctx.fillRect(0, 0, WIDTH, HEIGHT);\n\n                ctx.lineWidth = 1;\n                ctx.strokeStyle = \"rgb(0, 0, 0)\";\n\n                var sliceWidth = (WIDTH * 1.0) / bufferLength;\n                var x = 0;\n\n                ctx.beginPath();\n                for (var i = 0; i < bufferLength; i++) {\n                    let v = dataArray[i] / 128.0,\n                        y = (v * HEIGHT) / 2;\n\n                    if (i === 0) ctx.moveTo(x, y);\n                    else ctx.lineTo(x, y);\n\n                    x += sliceWidth;\n                }\n\n                ctx.lineTo(canvas.width, canvas.height / 2);\n                ctx.stroke();\n                // ** 绘制波形 end\n\n                requestAnimationFrame(draw); // 绘制下一帧\n            }\n\n            draw();\n        })\n        .catch((err) => {\n            console.log(err);\n        });\n    </script>\n  </body>\n</html>\n\n```\n\n","tags":["javascript","网络","WebRTC","audio","video"],"categories":["Media"]},{"title":"WebRTC Introduction","url":"/posts/c51bfcb4.html","content":"\n\n## webRTC简介\n\n### 什么是webRTC？\n\n网络实时通信（Web Real Time Communication），用来实现浏览器之间的实时通信。通常用来传输音视频流，实现视频聊天、直播等功能。\n\n### 兼容性\n\n![pic](../../images/webrtc兼容性.png)\n\nie？ie就不应该有这种需求！！\n\n## webRTC中涉及到的概念\n\n1. sdp：sdp描述了各端的能力（例如支持的音视频解放、传输协议等信息）。建立webRTC连接时，两端会交换对方的sdp。这样就知道对方的信息。\n   1. offer：通常先发送sdp一方的sdp被称为offer\n   2. answer：另一方收到offer后发送的sdp被称为answer\n2. ice candidate：包含了 WebRTC 与远端通信时使用的协议、IP 地址和端口等数据。当双端交换完sdp数据后，就会收集candidate信息。同样双端也要交换candidate数据\n3. NAT： 网络地址转换。由于ipv4地址不够用，我们的个人pc在本地使用的是内网ip（例如:192.168.1.2）。当访问公网上的资源是，请求经过路由器时，会将内网地址转换成公网地址，再发给目的服务器\n4. p2p：点对点（peer to peer）。指连接双端直接通信，不需要经过中间服务器。webRTC就能实现p2p，只有当p2p失败才会采用服务器中继\n\n\n## 建立连接\n\n### 连接流程\n\n![连接流程](../../images/rtc连接时序图.png)\n\n### 编码\n\n```typescript\n// A 端\n\nfunction sendToB() {\n    // ...发送给B\n}\nfunction onMsgFromB(callback) {\n    // 获得来自B的数据\n}\n\nfunction getStreamFromA() {\n    // 获取A的音视频流\n}\n\n// 1. 先建立rtc连接\nconst pc = new RTCpeerConnection()\n// 2. 添加音视频流\nconst stream = getStreamFromA()\nfor (const track of stream.getTracks()) {\n    pc.addTrack(track);\n}\n\n// 3. 创建offer\npc.createOffer().then(offer => {\n    // 4.设置本地\n    pc.setLocalDescription(offer)\n    // 5. 将offer发送给B\n    sendToB({type: 'offer', data: offer})\n})\n\nonMsgFromB(({type, data}) => {\n    if(type === 'answer') {\n        // 12.设置远程answer\n        pc.setRemoteDescription(data)\n    }\n})\n\npc.ontrack = (e) => {\n    const stream = e.streams[0]\n    video.srcObject = stream // 播放流\n}\n\n\n// B端\nfunction sendToA() {\n    // ...发送给A\n}\nfunction onMsgFromA(callback) {\n    // 获得来自A的数据\n}\nfunction getStreamFromA() {\n    // 获取B的音视频流\n}\n// 6. 先建立rtc连接\nconst pc = new RTCpeerConnection()\n\n// 7. 添加音视频流\nconst stream = getStreamFromA()\nfor (const track of stream.getTracks()) {\n    pc.addTrack(track);\n}\n\nonMsgFromB(({type, data}) => {\n    if(type === 'offer') {\n        // 8. 设置offer\n        pc.setRemoteDescription(data)\n        // 9.创建answer\n        pc.createAnswer().then(answer => {\n            // 10.设置本地\n            pc.setLocalDescription(answer)\n            // 11. 将answer发送给A\n            sendToB({type: 'answer', data: answer})\n        })\n    }\n})\n\npc.ontrack = (e) => {\n    const stream = e.streams[0]\n    video.srcObject = stream // 播放流\n}\n```\n\n> 添加流用的是addTrack没有使用addStream（即将废弃）。addtrack 和 ontrack 是最新的API。\n>\n> 视频流的获取，请参考另一篇文章[浏览器中的音视频](https://zxffan.github.io/posts/4dbf3745.html)\n\n## candidate\n\n双端交换sdp后，并未真正建立连接。然后还需要收集双方的candidate（不止一个哦）并交换。然后浏览器会按照candidate列表逐一测试连通性，直到有一条candidate连接，webRTC连接才算真正的建立。\n\n### 连接流程\n\n![ice candidate](../../images/ice_candidate.png)\n\nSTUN和TURN下面会展开，暂且理解为部署在服务器上的服务，用来获取数据生成candidate的。\n\n### 编码\n\n```typescript\n// 基于上面修改\n// 1. 请求， RTCpeerConnection会自己做\n\n// A 端\n// 2. 服务器（STUN/TURN）返回candidate\npc.onicecandidate = (iceEvent) => {\n    // 3. 发送iceEvent(或者直接发送candidate也可以)给B端\n    sendToB({type: 'candidate', data: iceEvent})\n}\nonMsgFromB(({type, data}) => {\n    \n    // ...\n    \n    if(type === 'candidate') {\n        pc.addIceCandidate(data.candidate)\n    }\n})\n\n// B 端\n\n// 5. 服务器（STUN/TURN）返回candidate\npc.onicecandidate = (iceEvent) => {\n    // 6. 发送iceEventf给A端\n    sendToA({type: 'candidate', data: iceEvent})\n}\nonMsgFromB(({type, data}) => {\n  \n    // ...\n    \n    if(type === 'candidate') {\n        // 4. 设置A端发来的的candidate\n        pc.addIceCandidate(data.candidate)\n    }\n})\n```\n\n## STUN/TURN\n\nSTUN和TURN是两个服务，RTCPeerConnection会自动请求这两个服务来获取candidate。\n\n```typescript\n// 基于上面的代码\n\n// A端 & B端\n\n// 建立RTCpeerConnection时，配置服务地址\nconst pc = new RTCpeerConnection({\n  iceServers: [\n    { urls: \"stun:47.94.xxx.xx:3478\" },\n    { urls: \"turn:47.94.xxx.xx:3478\", username: \"usrname\", credential: \"password\" },\n  ],\n})\n\n\n```\n\n### STUN\n\n两个处于不同网段的客户端需要点对点通信必须知道对方的公网ip，并且在双方的NAT映射表中必须有一条映射记录。STUN服务用来获取公网地址。处于不同网段的两台客户端，需要访问STUN服务来获取其公网地址。\n\n### TURN\n\n当点对点通信失败后，将会采用中继的方式。也就是数据走服务器转发。TURN就是用来实现中继的。\n\n### 部署STUN/TURN\n\n`conturn`应该是比较知名的STUN/TURN服务器。\n\n如何部署请自行查阅资料，或参考官方[git repo](https://github.com/coturn/coturn)\n\n### candidate列表\n\n以下测试，A端（192.168.1.134）和B端（192.168.1.134）都是我本机。\n\nwebRTC的candidate分为三类\n\n- host 类型，即本机内网的 IP 和端口\n- srflx 类型, 即本机 NAT 映射后的外网的 IP 和端口\n- relay 类型，即中继服务器的 IP 和端口\n\n![candidate-list](../../images/candidate-list.png)\n\n1. webRTC会先测试host类型的candidate。这种类型时最容易收集的。就算没有配置STUN/TURN也能收集到。如果测通了就没必要往下测试了。\n2. srflx类型的candidate包含公网ip信息。它是从stun服务器获取的。\n3. 当前两种都没连通，就会测试relay类型的candidate，也就是通过turn服务进行中继。\n\n## 信令服务\n\n前面写了这么一段代码\n\n```typescript\n// A端\nfunction sendToB() {\n    // ...发送给B\n}\nfunction onMsgFromB(callback) {\n    // 获得来自B的数据\n}\n\n// B端同理\n```\n\n埋了一个伏笔，sendToB如何实现。答案就是信令服务\n\n### 概念\n\n信令服务就是在通信的双端之间搭建的一个用于建立webRTC连接的服务，用于转发sdp、candidate等。\n\n信令服务可以是一个webSocket服务，用来进行A、B端之间的媒体协商。\n\n> 媒体协商就是指交换sdp和candidate的过程\n\n### 流程\n\n![信令服务](../../images/信令服务.png)\n\n### 编码\n\n```typescript\nconst WebSocket = require(\"ws\");\nconst wss = new WebSocket.Server({ port: 3001 });\nconst code2Ws = new Map();\n\nwss.on(\"connection\", (ws, request) => {\n  ws.isAlive = true;\n  let code;\n  ws.sendData = (event, data) => {\n    ws.send(JSON.stringify({ event, data }));\n  };\n\n  ws.sendError = (msg) => ws.sendData(\"error\", msg);\n\n  ws.on(\"message\", (message) => {\n    try {\n      const parsedMsg = JSON.parse(message);\n      const { event, data } = parsedMsg;\n\n      switch (event) {\n        case \"login\":\n          //  为客户端生成唯一标识，也可以由客户端发送标识（如mac地址）\n          code = data.code || Math.floor(Math.random() * (9999999 - 1000000)) + 100000 + \"\";\n          code2Ws.set(code, ws); // 记录\n          ws.sendData(\"login\", { code }); // 范围标识\n          break;\n        case \"communicate\":\n          const remote = data.remote; // 需要通信的客户端标识\n          if (code2Ws.has(remote)) { // 存在就建立两端之间的映射关系\n            ws.sendData(\"communicate\", { success: true }); // 通知A端\n            ws.sendRemote = code2Ws.get(remote).sendData;\n            code2Ws.get(remote).sendRemote = ws.sendData;\n            ws.sendRemote(\"communicate\", { remote: code }); // 通知B端\n          } else {\n            ws.sendData(\"communicate\", { success: false }); // 没有，则通知A，失败\n          }\n          break;\n        case \"forward\":\n          ws.sendRemote && ws.sendRemote(data); // 转发消息\n          break;\n      }\n    } catch (e) {\n      ws.sendError(\"message invalid\");\n      return;\n    }\n  });\n  \n  // 连接关闭 就删除当前客户端的标识\n  ws.on(\"close\", () => {\n    code2Ws.delete(code);\n  });\n});\n\n// 定时检测连接\nconst interval = setInterval(function ping() {\n  wss.clients.forEach(function each(ws) {\n    if (ws.isAlive === false) return ws.terminate();\n\n    ws.isAlive = false;\n  });\n}, 5 * 60 * 1000);\n\nwss.on(\"close\", function close() {\n  clearInterval(interval);\n});\n\n```\n\n## 数据通道（RTCDataChannel）\n\n媒体协商一旦完成就可以关闭与信令服务的连接即关闭webSocket连接。之后的数据传输可以通过`数据通道`来传输。\n\n### 概念\n\n建立webRTC连接的两端能够开辟一个数据通道，用来传输非音视频流数据，比如文字聊天、文件传输、远程桌面、游戏控制、P2P 加速等。\n\n###  双向通信\n\nRTCDataChannel可以实现双向通信，有两种模式\n\n- `In-band`(默认)：假设通信双方中的一方调用 createDataChannel 创建 RTCDataChannel 对象时，将 options 参数中的 negotiated 字段设置为 false，则通信的另一方就可以通过它的 RTCPeerConnection 对象的 ondatachannel 事件来得到与对方通信的 RTCDataChannel 对象了，这种方式就是 In-band 协商方式。\n- `out-of-band`：这种方式不再是一端调用 createDataChannel，另一端监听 ondatachannel 事件，从而实现双方的数据通信；而是两端都调用 createDataChannel 方法创建 RTCDataChannel 对象，再通过 ID 绑定来实现双方的数据通信。\n\n### 实现\n\n#### In-band\n\n```typescript\n// A端\nconst pc = new RTCPeerConnection();\nconst dc = pc.createDataChannel(\"my channel\", { negotiated: true });\n\ndc.onmessage = function (event) {\n    console.log(\"received: \" + event.data);\n};\n\ndc.onopen = function () {\n    console.log(\"datachannel open\");\n  ds.send(\"hello!\")\n};\n\ndc.onclose = function () {\n    console.log(\"datachannel close\");\n};\n\n// B端\npc.ondatachannel = (e) => {\n    const dc = e.channel // 获取\n    dc.onmessage = (e) => {\n        console.log(e.data)\n    };\n};\n```\n\n#### out-of-band\n\n```typescript\n// A 端\nconst pc = new RTCPeerConnection();\nconst dc = pc.createDataChannel(\"my channel\", { negotiated: true, id: 0 });\n\ndc.onmessage = function (event) {\n    console.log(\"received: \" + event.data);\n};\n\ndc.onopen = function () {\n    console.log(\"datachannel open\");\n};\n\ndc.onclose = function () {\n    console.log(\"datachannel close\");\n};\n\n// B 端\nconst pc = new RTCPeerConnection({ negotiated: true, id: 0 });\nconst dc = pc.createDataChannel(\"my channel\");\n\ndc.onmessage = function (event) {\n    console.log(\"received: \" + event.data);\n};\n\ndc.onopen = function () {\n    console.log(\"datachannel open\");\n};\n\ndc.onclose = function () {\n    console.log(\"datachannel close\");\n};\n```\n\n>注意：RTCDataChannel对象需要在媒体协商前创建。\n\n## WebRTC背后的原理\n\n### UDP\n\n`WebRTC`使用的是`UDP`协议。这是为了保证实时性。TCP有超时重传机制，这回导致很高的传输延迟。\n\n### 编码帧\n\n通过编码器（如 H264/H265、VP8/VP9）压缩后的帧称为编码帧。这里我们以 H264 为例，经过 H264 编码的帧包括以下三种类型。\n\n- I 帧：关键帧。压缩率低，可以单独解码成一幅完整的图像。\n- P 帧：参考帧。压缩率较高，解码时依赖于前面已解码的数据。\n- B 帧：前后参考帧。压缩率最高，解码时不光依赖前面已经解码的帧，而且还依赖它后面的 P 帧。换句话说就是，B 帧后面的 P 帧要优先于它进行解码，然后才能将 B 帧解码。\n\n> 解码过后的帧叫做**非编码帧**\n\n### RTP\n\n一般情况下，在实时互动直播系统传输音视频数据流时，我们并不直接将音视频数据流交给 UDP 传输，而是先给音视频数据加个 `RTP 头`，然后再交给 UDP 进行传输。\n\n这是因为一个I帧数据量是很大的。一个UDP报文是无法全部传输完的。所以发送是需要拆分并要加上首部，在接收的时候再组装\n\n### RTCP\n\nUDP是不可靠传输，所以在使用 RTP 包传输数据时，难免会发生丢包、乱序、抖动等问题。\n\nRTCP协议则负责流媒体的传输质量保证，提供流量控制和拥塞控制等服务。在RTP会话期间，各参与者周期性彼此发送RTCP报文。报文中包含各参与者数据发送和接收等统计信息，参与者可以据此动态控制流媒体传输质量\n\n### RTCDataChannel\n\n `RTCDataChannel`使用的是`SCTP`协议（底层也是基于`UDP`），它基于UDP实现了流量控制和拥塞控制等功能。而且它可以配置UDP报文传输的**有序性**和**可靠性**\n\n```javascript\nvar dc = pc.createDataChannel(\"dc\", { \n  ordered: false, // 是否有序\n  maxPacketLifeTime: 3000,// 重传消息失败的最长时间。也就是说超过这个时间后，即使消息重传失败了也不再进行重传了。\n  maxRetransmits: 10, // 重传消息失败的最大次数\n  \n}); //创建 RTCDataChannel对象\n```\n\n## 通信数据\n\n1. 通过浏览器（chrome），可以查看通信质量信息`chrome://webrtc-internals`\n2. 调用`RTCPeerConnection`对象的`getStats`方法获取数据\n\n```javascript\n//获得速个连接的统计信息\n//在一个连接中有很多 report\npc.getStats().then(reports => { \n  //遍历每个 report \n  reports.forEach(report => { //将每个 report 的详细信息打印出来 \n    console.log(report); \n  });\n}).catch( err=>{ console.error(err); }););\n```\n\n3. 只获取与发送/接受相关的数据\n\n   ```javascript\n   var pc = new RTCPeerConnection(null);\n   \n   //从 PC 上获得 sender 对象\n   var sender = pc.getSenders()[0];\n   \n   //调用sender的 getStats 方法    \n   sender.getStats()\n     .then(reports => { //得到相关的报告\n     \treports.forEach(report =>{ //遍历每个报告\n         if(report.type === 'outbound-rtp'){ //如果是rtp输出流\n           // ....\n         }\n     });\n   \n   ```\n\n### 质量指标\n\n1. packetsSent/packetsRecived：发送/接受包的数量，计算丢包率\n2. \n\n","tags":["javascript","网络","WebRTC"],"categories":["Media"]},{"title":"正则表达式","url":"/posts/2f57a694.html","content":"\n## REGEXP对象\n\n两种实例化RegExp对象\n\n1. 字面量\n2. 构造函数\n\n```javascript\n// 字面量\nvar reg = /\\bis\\b/  // \\b表示单词边界\n\n'He is a boy. This is a dog. Where is she?'.replace(reg, 'IS') // 只会替换一处\n// He IS a boy. This is a dog. Where is she\n\nreg = /\\bis\\b/g // g 代表 global\n'He is a boy. This is a dog. Where is she?'.replace(reg, 'IS') // 指挥替换一处\n// He IS a boy. This IS a dog. Where IS she\n\n\n\n// 构造函数\nvar  reg = new RegExp('\\\\bis\\\\b', 'g')\n'He is a boy. This is a dog. Where is she?'.replace(reg, 'IS') // 指挥替换一处\n// He IS a boy. This IS a dog. Where IS she\n```\n\n## 修饰符\n\n1. g：global 全文搜索\n2. i：忽略大小写\n3. m：多行搜索\n\n## 元字符\n\n正则表达式有两种基本字符类型组成\n\n1. 愿意文本字符 abc\n2. 元字符（含有特殊含义的非字母字符）\n\n## 字符类\n\n元字符[]来构建一个类，来匹配一类字符\n\n[abc]来匹配a或b或c\n\n^可以创建反向类，\\[^abc]表示不是a或b或c的字符\n\n## 范围类\n\n[a-z]表示a到z的任意字符（包含a和z）\n\n[a-zA-z]\n\n[0-9]\n\n[0-9-]匹配0到9和横线-\n\n## 预定义类\n\n| 字符 | 等价类          | 含义                             |\n| ---- | --------------- | -------------------------------- |\n| .    | [^\\r\\n]         | 除了回车符和换行符之外的所有字符 |\n| \\d   | [0-9]           | 数字字符                         |\n| \\D   | [^0-9]          | 非数字字符                       |\n| \\s   | [\\t\\n\\x0B\\f\\r]  | 空白符                           |\n| \\S   | [^\\t\\n\\x0B\\f\\r] | 非空白符                         |\n| \\w   | [a-zA-Z_0-9]    | 单词字符（数字、字母下划线）     |\n| \\W   | [^a-zA-Z_0-9]   | 非单词字符                       |\n\n## 边界\n\n| 字符 | 含义       |\n| ---- | ---------- |\n| ^    | 以xxx开始  |\n| $    | 以xxx结束  |\n| \\b   | 单词边界   |\n| \\B   | 非单词边界 |\n\n## 量词\n\n| 字符  | 含义                     |\n| ----- | ------------------------ |\n| ？    | 出现零次或一次           |\n| +     | 出现一次或多次           |\n| *     | 出现零次或多次（任意次） |\n| {n}   | 出现n次                  |\n| {n,m} | 出现n到m次               |\n| {n,}  | 至少出现n次              |\n\n## 贪婪模式和非贪婪模式\n\n```javascript\n'12345678'.replace(/\\d{3,6}/g, 'X') // 会尽量多地匹配-贪婪模式\n// X78\n\n// 在量词后面加上?-非贪婪模式\n'12345678'.replace(/\\d{3,6}?/g, 'X') // 非贪婪模式\n// XX78\n```\n\n## 分组\n\n使用()实现分组的功能\n\n```javascript\n'a1b2c3d4'.replace(/[a-z]\\d{3}/g, 'X')\n// a1b2c3d4\n\n'a1b2c3d4'.replace(/([a-z]\\d){3}/g, 'X')\n// Xd4\n```\n\n## 或\n\n使用|可以实现或的效果\n\n## 反向引用\n\n2015-12-25 => 12-25-2015\n\n```js\n'2015-12-25'.replace(/(\\d{4})-(\\d{2})-(\\d{2})/g, '$2-$3-$1')\n// 12-25-2015\n```\n\n## 忽略分组\n\n使用?:来忽略分组\n\n(?:Byron).(ok)\n\n$1指的是 ok\n\n## 断言\n\n正则表达式从文本头部向尾部开始解析，文本尾部方向，成为“正向”\n\n正向断言就是在正则表达式匹配到规则的时候，向前检查是否符合断言\n\nJavaScript不支持反向断言\n\nES2018（ES9）新增反向断言\n\n符合和不符合特定断言成为肯定/正向匹配和否定/反向匹配\n\n| 名称         | 正则           | 含义 |\n| ------------ | -------------- | ---- |\n| 正向断言     | exp(?=assert)  |      |\n| 否定正向断言 | exp(?!assert)  |      |\n| 反向断言     | exp(?<=assert) |      |\n| 否定反向断言 | exp(?<!assert) |      |\n|              |                |      |\n\n```javascript\n'a2*34v8'.replace(/\\w(?=\\d)/g, 'X')\n// X2*34X8\n\n'a2*34vv'.replace(/\\w(?!\\d)/g, 'X')\n// aX*3XXX\n\nvar match = /(?<=\\D)\\d+/.exec('$123.89')\nconsole.log( match[0] ); // 123\n\nvar match = /(?<!\\D)\\d+/.exec('$123.89')\nconsole.log( match[0] ); // 23\n\n```\n\n## 对象属性\n\nglobal: 是否全文搜索，默认false\n\nignore case：是否大小写敏感，默认false\n\nmultiline：多行搜索，默认false\n\nlastIndex：是当前白表达式匹配内容最后一个字符的下一个位置\n\nsource：正则表达式的文本字符串\n\n## 正则表达式的方法\n\n### test方法\n\n检测字符串中是否有匹配正则的内容，若有返回true，没有返回false\n\n```javascript\nvar reg1 = /\\w/\nvar reg2 = /\\w/g\n\nreg1.test('a') // true\nreg2.test('$') // false\n\nwhile(reg2.test('ab')) {\n    console.log(reg2.lastIndex)\n}\n// 1\n// 2\n```\n\n**坑**\n\n使用test时，正则表达式不要使用g（全局匹配），如下\n\n```javascript\nvar reg = /\\w/g\nundefined\nreg.test(\"wom\")\n// true\nreg.test(\"wom\")\n// true\nreg.test(\"wom\")\n// true\nreg.test(\"wom\")\n// false\nreg.test(\"wom\")\n// true\n```\n\n第四次匹配变成了false，这是因为每次匹配都会改变reg的lastIndex属性。下次匹配在从lastIndex位置开始匹配。第四次匹配前lastIndex为3，从index为3的位置开启匹配所以匹配不到，这次匹配完后lastIndex又改成0所以下次又能匹配到。\n\n### exec方法\n\n未匹配到返回null，匹配到返回一个结果数组\n\n返回的数组\n\n1. 第一个元素是与正则表达式相匹配的文本\n2. 第二个元素是与RegExpObject的第一个子表达式相匹配的文本（如果有的话），子表达式就是分组，也就是指分组匹配的文本\n3. 第三个元素是与RegExp对象的第二个子表达式相匹配的文本（如果有的话），依此类推\n\n```javascript\nvar reg1 = /\\d(\\w)(\\w)\\d/\nvar reg2 = /\\d(\\w)(\\w)\\d/g\n\nvar ts = \"ab1cd2fg3hi4jk5mop\"\n\n// 非全局匹配-不存在lastIndex\nvar ret = reg1.exec(ts)\nconsole.log(ret)\n/* 输出\n [\"1cd2\", \"c\", \"d\", index: 2, input: \"ab1cd2fg3hi4jk5mop\", groups: undefined]\n*/\n\n\n\n// 全局匹配-需要循环，每次匹配修改lastIndex的值\nvar ret\nwhile(ret = reg2.exec(ts)) {\n  console.log(ret)\n}\n/*\n[\"1cd2\", \"c\", \"d\", index: 2, input: \"ab1cd2fg3hi4jk5mop\", groups: undefined]\n\n[\"3hi4\", \"h\", \"i\", index: 8, input: \"ab1cd2fg3hi4jk5mop\", groups: undefined]\n*/\n```\n\n## 字符串对象的方法\n\n### search方法\n\nsearch()用于检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串\n\n方法返回第一个匹配结果index，查不到返回-1\n\n### match方法\n\nmatch()方法将检索字符串，以找到一个或多个与regexp匹配的文本\n\nregexp是否具有标志g对结果影响很大，\n\n1. 如果regexp没有标志位g，那么match（）方法就只能在字符串中执行一次匹配如果没有找到任何匹配的文本，将返回null \n\n```javascript\nvar reg1 = /\\d(\\w)(\\w)\\d/\nvar reg2 = /\\d(\\w)(\\w)\\d/g\n\nvar ts = \"ab1cd2fg3hi4jk5mop\"\n\nts.match(reg1)\n//[\"1cd2\", \"c\", \"d\", index: 2, input: \"ab1cd2fg3hi4jk5mop\", groups: undefined]\n```\n\n2. 否则它将返回一个数组，其中存放了与它找到的匹配文本有关的信息\n\n```javascript\nts.match(reg2)\n// [\"1cd2\", \"3hi4\"]\n```\n\n### split方法\n\n```js\n'a1b2c3d4'.split(/\\d/)\n// ['a', 'b', 'c', 'd']\n```\n\n### replace方法\n\n```js\n'a1b'.replace('1', 2) // a2b\n\n'a1b1c1'.replace('1', '2') // a2b1c1\n'a1b1c1'.replace(/1/g, '2') // a2b2c2\n\n'a1b2c3d4'.replace(/\\d/g, function(match, index, origin) {\n  console.log(match,index,origin);\n  return +match + 1\n})\n/*\n1 1 a1b2c3d4\n2 3 a1b2c3d4\n3 5 a1b2c3d4\n4 7 a1b2c3d4\n\"a2b3c4d5\"\n*/\n```\n\n## 手撕题\n\n### 数字千分位表示\n\n```javascript\nvar a = \"139553123.123123123\"\n// 由两部分组成\n// 前半部分 否定反向断言：排除有. 从而让小数部分不加逗号\n// 后半部分 正向断言：3个一组 以.或者边界结尾\na.replace(/(?<=\\b(?<!\\.)\\d*)\\B(?=(\\d{3})+(\\b|\\.))/g, \",\") // \"139,553,123.123123123\"\n```\n\n### 处理日期格式\n\n```javascript\n\"yyyy日MM月dd天 hh:mm:ss\".split(/(?<=[^yMdhms])|(?=[^yMdhms])/g)\n// [\"yyyy\", \"日\", \"MM\", \"月\", \"dd\", \"天\", \" \", \"hh\", \":\", \"mm\", \":\", \"ss\"]\n```\n\n","tags":["javascript","regExp"],"categories":["JavaScript"]},{"title":"HTTPS工作流程","url":"/posts/ef0f9b3a.html","content":"## HTTP与HTTPS\n\nHTTP(超文本传输协议)，有着一个致命的缺陷，那就是内容是**明文传输**的，没有经过任何加密，而这些明文数据会经过**WiFi、路由器、运营商、机房**等多个物理设备节点，如果在这中间任意一个节点被监听，传输的内容就会完全暴露，，这一攻击手法叫做MITM（Man In The Middle）**中间人**攻击。\n\n常见的如运行商劫持，推送广告\n\n![劫持](../../images/network/运营商劫持.webp)\n\n## HTTPS工作流程\n\n![https](../../images/network/HTTP-process.webp)\n\n1. 客户端发送HTTPS请求（默认端口443）\n2. 服务端有一套`CA数字证书`，证书含有一个`公钥public`。服务端接收到请求，会将这个证书发送给客户端。服务端还有一个`私钥private`，私钥是一直保存再服务端不公开的。\n3. 客户端收到证书，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续。\n4. 客户端先生成一段`随机key`，再利用证书中的`公钥public`加密这段`随机key`，并将这个`随机key密文`发送给服务端。\n5. 服务端收到这个`随机key密文`文后，通过`私钥private`来解密，获取客户端真正的`随机key`\n6. 服务端使用`随机key`来加密需要传输的HTTP数据，并发送给客户端\n7. 客户端再用`随机key`来解密服务端传输过来的密文，获取真正的数据\n8. 后续HTTPS请求使用之前交换好的`随机Key`进行对称加解密。\n\n>  由于随机key明文没有再网络上传输，所以\"中间人\"并不知道用于加密和解密的随机key，因此是安全的\n\n## 对称加密和非对称加密\n\nHTTPS的工作流程其实就是 非对称加密+对称加密。\n\n- 非对称加密：公钥加密，私钥解密\n\n- 对称加密：随机key加密解密\n\n**非对称加解密耗时要远大于对称加解密**，对性能有很大损耗\n\n## CA颁发机构\n\n上述的HTTPS工作流程中的CA证书验证十分重要。如果没有它，会发生以下情况：\n\n![劫持](../../images/network/https劫持.webp)\n\n1. 服务端发送公钥A1给客户端，中间人把服务端的公钥替换为自己的公钥B1\n2. 客户端通过公钥B1加密生成K密文，并发送给服务端\n3. 中间人通过自己的私钥B2解密K密文得到K，再用公钥A1加密，发送给服务端\n4. 客户端与服务端通信的K，已被中间人获取，所以不再安全\n\n出现这一问题的核心原因是**客户端无法确认收到的公钥是不是真的是服务端发来的**。为了解决这个问题，互联网引入了一个公信机构，这就是CA。\n\n1. CA机构拥有自己的一对公钥和私钥\n2. CA机构在颁发证书时对证书明文信息进行哈希\n3. 将哈希值用`私钥`进行**加签**，得到数字签名\n\n明文数据和数字签名组成证书，传递给客户端。\n\n1. 客户端得到证书，分解成明文部分Text和数字签名Sig1\n2. 用CA机构的公钥进行**解签**，得到Sig2（由于CA机构是一种公信身份，因此在系统或浏览器中会内置CA机构的证书和公钥信息）\n3. 用证书里声明的哈希算法对明文Text部分进行哈希得到T\n4. 当自己计算得到的哈希值T与**解签**后的Sig2**相等**，表示证书可信，**没有被篡改**","tags":["NetWork","HTTP"],"categories":["NetWork"]},{"title":"手写webpack的plugin","url":"/posts/b6d2303e.html","content":"## 概述\n\n> 一句话：本质上来说， plugin 就是通过监听 compiler 的某些 hook 特定时机，然后处理 stats。\n\n首先我们来看下 Webpack 插件需要包含的几个条件： \n\n- Webapck 的插件必须要是一个类； \n- 该类必须包含一个 apply 的函数，该函数接收 compiler 对象参数； \n- 该类可以使用 Webpack 的 compiler 和 Compilation 对象的钩子； \n- 也可以自定义自己的钩子系统。\n\n```javascript\nclass MyPlugin {\n  constructor(options) {\n    // 自定义配置\n    this.options = options\n  }\n\tapply(compiler) {\n    compiler.hooks.done.tap('MyPlugin', () => {})\n    \n    compiler.hooks.emit.tapPromise('MyPlugin', compilation => {\n      // 返回一个 Promise，在我们的异步任务完成时 resolve……\n      return new Promise((resolve, reject) => {\n        setTimeout(function() {\n          console.log('异步工作完成……');\n          \tresolve();\n          }, 1000);\n        });\n      });\n\t}\n}\n\nmodule.exports = MyPlugin\n```\n\n## 官方DEMO——FileListPlugin\n\n```js\nclass FileListPlugin {\n    apply(compiler) {\n        // emit 是异步 hook，使用 tapAsync 触及它，还可以使用 tapPromise/tap(同步)\n        compiler.hooks.emit.tapAsync('FileListPlugin', (compilation, callback) => {\n            // 在生成文件中，创建一个头部字符串：\n            var filelist = 'In this build:\\n\\n';\n\n            // 遍历所有编译过的资源文件，\n            // 对于每个文件名称，都添加一行内容。\n            for (var filename in compilation.assets) {\n                filelist += '- ' + filename + '\\n';\n            }\n\n            // 将这个列表作为一个新的文件资源，插入到 webpack 构建中：\n            compilation.assets['filelist.md'] = {\n                source: function() {\n                    return filelist;\n                },\n                size: function() {\n                    return filelist.length;\n                }\n            };\n\n            callback();\n        });\n    }\n}\n```\n\n## 自定义 Plugin——prefetch-webpack-plugin\n\n### 实现目标\n\n假如我们有个 `lazy.js` 模块需要 Prefetch，那么可以直接使用如下配置\n\n```javascript\n// 下面是魔法注释 （magic comments）\nimport(/* webpackPrefetch: true */ './lazy');\n```\n\n有了这个注释，在获取 chunk 对象的时候，就可以拿到它的这个标注，从而根据这个注释给页面增加`<link rel=\"prefetch\">`标签。\n\n> Tips： \n>\n> - `/* webpackPrefetch: true */` ：把主加载流程加载完毕，在空闲时在加载其它，等再点击其他时，只需 要从缓存中读取即可，性能更好，推荐使用；能够提高代码利用率，把一些交互后才能用到的代码写到异 步组件里，通过懒加载的形式，去把这块的代码逻辑加载进来，性能提升，页面访问速度更快；*\n> - `/* webpackPreload: true */` : 和主加载流程一起并行加载。\n\n### 原理和实现步骤\n\n1. 首先我们应该利用`compiler.compilation`这个钩子，得到`Compilation`对象；\n2. 然后在`Compilation`对象中监听 html-webpack-plugin 的钩子，拿到 HTML 对象，这里需要区分 html-webpack-plugin 的版本：\n   1. 在`3.x`版本，html-webpack-plugin 的钩子是直接挂在 Compilation 对象上的，我们使用的是`compilation.hooks.htmlWebpackPluginAfterHtmlProcessing`；\n   2. 在`4.x`版本（截稿最新版本是 4.0-beta.3）中，html-webpack-plugin 自己使用`Tapable`实现了自定义钩子，需要使用`HtmlWebpackPlugin.getHooks(compilation)`的方式获取自定义的钩子。\n3. 然后我们从`Compilation`对象中读取当前 HTML 页面的所有`chunks`，筛选异步加载的 chunk 模块，这里有两种情况：\n   1. 生成多个 HTML 页面，那么 html-webpack-plugin 插件会设置`chunks`选项，我们需要从 `Compilation.chunks`来选取 HTML 页面真正用到的 chunks，然后在从 chunks 中过滤出 Prefetch chunk；\n   2. 如果是单页应用，那么不存在`chunks`选项，这时候默认`chunks='all'`，我们需要从全部 `Compilation.chunks` 中过滤出 Prefetch chunk。\n4. 最后结合 Webpack 配置的`publicPath`得到异步 chunk 的实际线上地址，然后修改 html-webpack-plugin 钩子得到的 HTML 对象，给 HTML 的``添加``内容。\n\n","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"手写webpack的loader","url":"/posts/e0efe5dc.html","content":"## 概述\n\nwebpack的loader本质上就是一个函数\n\n```javascript\nmodule.exports = function(content, sourcemap) {\n  // 处理 content 操作...\n  \n  this.callback(null, content) // 或者 return content\n}\n```\n\n> this 是 webpack 调用 loader 时候传入的自定义的特殊上下文，所以不应该使用箭头函数！\n\nthis.callback 可以传入四个参数（其中后两个参数可以省略），分别是： \n\n- error ：当 loader 出错时向外抛出一个 Error 对象，成功则传入 null ；\n- content ：经过 loader 编译后需要导出的内容，类型可以是为 String 或者 Buffer ； \n- sourceMap ：为方便调试生成的编译后内容的 source map； \n- ast : 本次编译生成的 AST 静态语法树，之后执行的 loader 可以直接使用这个 AST，可以省去重复生成 AST 的 过程。\n\n## loader 异步处理数据\n\n第一种方式是是使用 `async/await` 异步函数写法\n\n```javascript\nmodule.exports = async function(content) {\n  function timeout(delay) {\n    return new Promise((resolve, reject) => {\n      setTimeout(() => {\n      \t// 模拟一些异步操作处理 content\n        resolve(content);\n        }, delay);\n      });\n    }\n    const data = await timeout(1000);\n    return data;\n};\n\n```\n\n第二种方式是使用 `this.async` 方法获取一个异步的 callback ，然后返回它。\n\n```javascript\nmodule.exports = function(content) {\n  function timeout(delay) {\n    return new Promise((resolve, reject) => {\n      setTimeout(() => {\n        // 模拟异步操作\n        resolve(content)\n      }, delay)\n    })\n  }\n  const callback = this.async()\n  timeout(1000).then(data => {\n    callback(null, data)\n  })\n}\n```\n\n> this.async 获取的 callback，参数也是跟 this.callback 的参数一致，即 error，content，sourcemap 和 ast。\n\n## 处理二进制数据\n\n像 file-loader 这样的 Loader，实际处理的内容是二进制数据，那么就需要通过设置 `moudle.exports.raw = true;` 来告诉 Webpack 给 loader 传入二进制格式的数据。\n\n```javascript\nmodule.exports = function(source) {\n  if (source instanceof Buffer) {\n    // 一系列的操作\n    return source // 本身也可以返回二进制数据提供给下一个loader\n  }\n}\nmodule.exports.raw = true // 不设置，就会拿到字符串\n```\n\n## loader 的 pitch\n\nloader 的执行分为两个阶段，pitch阶段loader从左到右链式调用。而Normal阶段是从右到左的链式调用。\n\n![loader_pitch](../images/framework/loader-pitch.webp)\n\n在一些场景下，loader 并不依赖上一个 loader 的结果，而只关心原输入内容。这时候，要 拿到一开始的文件原内容，就需要使用 `module.exports.pitch = function();`\n\n```javascript\nmodule.exports.pitch = function(remainingRequest, precedingRequest, data) {\n  if (somothingFlag()) {\n  \treturn 'module.exports = require(' + JSON.stringify('-!' + remaining) + ');'\n  }\n  data.value = 1\n}\n```\n\npitch函数的data，在执行阶段也会暴露在 `this.data` 之下，并且可以用于在循环时，捕获和共享前面的信息。\n\n## loader 结果缓存\n\nWebpack 增量编译机制会观察每次编译时的变更文件，在默认情况下，Webpack 会对 loader 的执行结果进行缓 存，这样能够大幅度提升构建速度，不过我们也可以手动关闭它：\n\n```javascript\nmodule.exports = function(content) {\n  this.cacheable(false)\n  return content\n}\n```\n\n## loader 工具库\n\n### loader-utils\n\nloader-utils 提供了各种跟 loader 选项（options）相关的工具函数\n\n```javascript\nconst { getOptions，stringifyRequest, parseQuery } = require('loader-utils');\n\nmodule.exports = function(content) {\n  // getOptions 用于在loader里获取传入的options，返回的是对象值。\n  const options = getOptions(this);\n  \n  // stringifyRequest转换路径，避免require()或impot时使用的绝对路径\n  stringifyRequest(this, './test.js'); // Result => \"\\\"./test.js\\\"\"\n  \n  // parseQuery获取query参数的\n  parseQuery('?name=kev&age=14') // Result => {name: 'kev', age: '14'}\n}\n```\n\n### schema-utils\n\nschema-utils 是 loader 和 plugin 的参数认证器，检测传入的参数是否符合预期\n\n```javascript\nconst validateOptions = require('schema-utils');\n// 下面是一个schema描述\nconst schema = {\n  type: 'object',\n  properties: {\n    name: {\n    \ttype: 'string'\n  \t},\n    test: {\n      anyOf: [{type: 'array'}, {type: 'string'}, {instanceof: 'RegExp'}]\n    },\n    transform: {\n      instanceof: 'Function'\n    },\n    sourceMap: {\n      type: 'boolean'\n    }\n  },\n  additionalProperties: false\n};\n\nmodule.exports = function(source) {\n  // 验证参数的类型是否正确。\n  validateOptions(schema, options, 'loader name');\n};\n```\n\n## loader 上下文\n\nloader 中 this 相关的其它方法和属性 \n\n- this.context : 当前处理转换的文件所在的目录； \n- this.resource : 当前处理转换的文件完整请求路径，包括 querystring； this.resourcePath : 当前处理转换的文件的路径； \n- this.resourceQuery : 当前处理文件的 querystring； \n- this.target : Webpack 配置的 target； \n- this.loadMoudle : 处理文件时，需要依赖其它文件的处理结果时，可以使用 this.loadMoudle(request: strin g, callback: function(err, source, sourceMap, module)) 去获取到依赖文件的处理结果； \n- this.resolve : 获取指定文件的完整路径；\n- this.addDependency : 为当前处理文件添加依赖文件，以便依赖文件发生变化时重新调用 Loader 转换该文件， this.addDependency(file: string) ； \n- this.addContextDependency : 为当前处理文件添加依赖文件目录，以便依赖文件目录里文件发生变化时重新调 用 Loader 转换该文件， this.addContextDependency(dir: string) ； \n- this.clearDependencies : 清除当前正在处理文件的所有依赖； \n- this.emitFile : 输出一个文件，使用的方法为 this.emitFile(name: string, content: Buffer | string, so urceMap: {...}) ； \n- this.emitError ：发送一个错误信息。\n\n## markdown-loader\n\n```javascript\nconst showdown = require('showdown') // 第三方工具，把md转成html\nconst { getOptions } = require('loader-utils')\n\nmodule.exports = function(content) {\n  // 获取options\n  const options = getOptions(this)\n\n  // 获取cache\n  this.cacheable()\n\n  // 初始化showdown转换器\n  const converter = new showdown.Converter(options)\n\n  // 处理content\n  content = converter.makeHtml(content)\n\n  // 返回结果\n  this.callback(null, content)\n}\n\n```","tags":["javascript","webpack","架构"],"categories":["工程化"]},{"title":"Webpack原理","url":"/posts/e2b02a9e.html","content":"## Webpack工作流程\n\n### 类比\n\nWebpack 可以看做是一个工厂车间， `plugin` 和 `loader` 是车间中的两类机器，工厂有一个车间主任和一个生 产车间。车间主任叫 `Compiler` ，负责指挥生产车间机器 `Compilation` 进行生产劳动， `Compilation` 会首先将 进来的原材料（ `entry` ）使用一种叫做 `loader` 的机器进行加工，生产出来的产品就是 `Chunk` ； `Chunk` 生产出 来之后，会被组装成 `Bundle` ，然后通过一类 `plugin` 的机器继续加工，得到最后的 `Bundle` ，然后运输到对应 的仓库（`output`）。这个工厂的生产线就是 `Tapable`，厂子运作的整个流程都是生产线控制的，车间中有好几 条生产线，每个生产线有很多的操作步骤（ `hook` ），一步操作完毕，会进入到下一步操作，直到生产线全流 程完成，再将产出传给下一个产品线处理。整个车间生产线也组成了一条最大的生产线。\n\n### 工作流程\n\n#### 三个阶段\n\n- 准备阶段：主要任务是创建 Compiler 和 Compilation 对象；\n- 编译阶段：这个阶段任务是完成 modules 解析，并且生成 chunks；\n  - module 解析：包含了三个主要步骤，创建实例、loaders 应用和依赖收集；\n  - chunks 生成，主要步骤是找到每个 chunk 所需要包含的 modules 。 \n- 产出阶段：这个阶段的主要任务是根据 chunks 生成最终文件，主要有三个步骤：模板 Hash 更新，模板渲染 chunk，生成文件。\n\n#### 细化\n\n1. 初始化参数：包括从配置文件和 shell 中读取和合并参数，然后得出最终参数；**shell 中的参数要优于配置文件的**\n2. 使用上一步得到的参数**实例化一个 Compiler 类**，注册所有的插件，给对应的 Webpack 构建生命周期绑定 Hook\n3. 开始编译：执行 Compiler 类的 run 方法开始执行编译\n4. compiler.run 方法调用 compiler.compile ，在 compile 内**实例化一个 Compilation 类**， Compilation 是做构 建打包的事情，主要事情包括： \n   1. 查找入口：根据 entry 配置，找出全部的入口文件\n   2. 编译模块：根据文件类型和 loader 配置，使用对应 loader 对文件进行转换处理\n   3. 解析文件的 AST 语法树\n   4. 找出文件依赖关系\n   5. 递归编译依赖的模块\n5. 递归完后得到每个文件的最终结果，根据 entry 配置生成代码块 chunk\n6. 输出所有 chunk 到对应的 output 路径\n\n![webpack工作流程](../../images/framework/webpack-proceed.png)\n\n## Tapable\n\n### 概述\n\n`Tapable`是webpack的核心模块。其原理和nodejs的`EventEmitter` 类似，但是功能更强大，包括多种类型，通过**事件的注册和监听**，触发 Webpack 生命周期中的函数方法。tapable 都是放到对象的 hooks 上，所以我们叫它们 钩子。\n\n```javascript\n// webpack 4.29.6\n// lib/compiler\nclass Compiler extends Tapable {\n  constructor(context) {\n    super();\n    this.hooks = {\n      shouldEmit: new SyncBailHook(['compilation']),\n      done: new AsyncSeriesHook(['stats']),\n      additionalPass: new AsyncSeriesHook([]),\n      beforeRun: new AsyncSeriesHook(['compiler']),\n      run: new AsyncSeriesHook(['compiler']),\n      emit: new AsyncSeriesHook(['compilation']),\n      afterEmit: new AsyncSeriesHook(['compilation']),\n      thisCompilation: new SyncHook(['compilation', 'params']),\n      compilation: new SyncHook(['compilation', 'params']),\n      normalModuleFactory: new SyncHook(['normalModuleFactory']),\n      contextModuleFactory: new SyncHook(['contextModulefactory']),\n      beforeCompile: new AsyncSeriesHook(['params']),\n      compile: new SyncHook(['params']),\n      make: new AsyncParallelHook(['compilation']),\n      afterCompile: new AsyncSeriesHook(['compilation']),\n      watchRun: new AsyncSeriesHook(['compiler']),\n      failed: new SyncHook(['error']),\n      invalid: new SyncHook(['filename', 'changeTime']),\n      watchClose: new SyncHook([]),\n      environment: new SyncHook([]),\n      afterEnvironment: new SyncHook([]),\n      afterPlugins: new SyncHook(['compiler']),\n      entryOption: new SyncBailHook(['context', 'entry'])\n    };\n  }\n}\n\n```\n\n### Tapable中Hook类型\n\nHook 类型可以分为同步（ Sync ）和异步（ Async ），异步又分为并行和串行：\n\n![tapable_hook](../../images/framework/tapable_hook.png)\n\n根据使用方式来分，又可以分为 Basic 、 Waterfall 、 Bail 和 Loop 四类，每类 Hook 都有自己的使用要点：\n\n| 类型      | 使用要点                                                                                  | hook                                                               |\n| --------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------ |\n| Basic     | 基础类型，不关心监听函数的返回值，不根据返回值做事情                                      | `SyncHook` 、 `AsyncParallelHook` 和 `AsyncSeriesHook`             |\n| Bail      | 保险式，只要监听函数中有返回值（不为 undefined ），则跳过之后的监听函数（类比Array.find） | `SyncBailHook `、 `AsyncSeriesBailHook` 、 `AsyncParallelBailHook` |\n| Waterfall | 瀑布式，上一步的返回值(非undefined)继续交给下一步处理和使用（类比Array.reduce）           | `SyncWaterfallHook` 和 `AsyncSeriesWaterfallHook`                  |\n| Loop      | 循环类型，如果该监听函数返回 true 则这个监听函数会反复执行，如果返回 undefined 则退出循环 | `SyncLoopHook`                                                     |\n\n### Tapable原理解析\n\nTapable执行分为四步\n\n1. 使用 tap* 对事件进行注册绑定。根据类型不同，提供三种绑定的方式： `tap` 、 `tapPromise` 、 `tapAsync` ，其中 `tapPromise` 、 `tapAsync` 为异步类 Hook 的绑定方法\n2. 使用 call* 对事件进行触发，根据类型不同，也提供了三种触发的方式： `call` 、 `promise` 、 `callAsync` \n3. 生成对应类型的代码片段（要执行的代码实际是拼字符串拼出来的）\n4. 生成第三步生成的代码片段。\n\n### 总结 \n\nTapable 是 Webpack 的核心模块，Webpack 的所有工作流程都是通过 Tapable 来实现的。Tapable 本质上是提供 了多种类型的事件绑定机制，根据不同的流程特点可以选择不同类型的 Hook 来使用。Tapable 的核心实现在绑定 事件阶段跟我们平时的自定义 JavaScript事件绑定（例如EventEmitter）没有太大区别，但是在事件触发执行的时 候，会临时生成可以执行的函数代码片段。通过这种实现方式，Tapable 实现了强大的事件流程控制能力，也增加 了如 waterfall / parallel 系列方法，实现了异步/并行等事件流的控制能力。\n\n## Compiler 和 Compilation\n\ncompiler和compilation都继承Tapable，不同点是Compiler是每 个 Webpack 的配置，对应一个Compiler对象，记录着整个 Webpack 的生命周期；在构建的过程中，每次构建都 会产生一次Compilation，Compilation则是构建周期的产物。\n\n### Compiler\n\n每次执行webpack构建的时候，webpack内部都会实例化一个`Compiler`对象，然后调用它的`run`方法开始一次完整的编译过程。\n\n```javascript\nconst webpack = require('webpack')\nconst webpackConfig = require('./webpack.config.js')\n\n// 只传入config\nconst compiler = webapck(webpackConfig)\n\n// 执行\ncompiler.run()\n\n// 上面两句等价于\nwebpack(webpackConfig, callback)\n```\n\n> 使用`webpack-dev-server`API方式时，只需要将compiler对象给dev server即可，不需要手动执行`compiler.run()`；如果需要手动实例化`Compiler`对象，可以通过`const Compiler = webpack.Compiler`来获取它的类。\n\n### Compiler钩子\n\n| 钩子名               | Tapable 类型      | 触发时机                                                         | 传入 callback 的参数               |\n| :------------------- | :---------------- | :--------------------------------------------------------------- | :--------------------------------- |\n| entryOption          | SyncBailHook      | 在 webpack 中的 entry 配置处理过之后                             | `context`，`entry`                 |\n| afterPlugins         | SyncHook          | 初始化完内置插件之后                                             | `compiler`                         |\n| afterResolvers       | SyncHook          | resolver 完成之后（后面解释resolver是什么）                      | `compiler`                         |\n| environment          | SyncHook          | 准备编译环境，webpack plugins配置初始化完成之后                  | `compiler`                         |\n| afterEnvironment     | SyncHook          | 编译环境准备好之后                                               | `compiler`                         |\n| beforeRun            | AsyncSeriesHook   | 开始正式编译之前                                                 | `compiler`                         |\n| run                  | AsyncSeriesHook   | 开始编译之后，读取 records 之前；监听模式触发`watch-run`         | `compiler`                         |\n| watchRun             | AsyncSeriesHook   | 监听模式下，一个新的编译触发之后                                 | `compiler`                         |\n| normalModuleFactory  | SyncHook          | NormalModuleFactory 创建之后                                     | `normalModuleFactory`实例          |\n| contextModuleFactory | SyncHook          | ContextModuleFactory 创建之后                                    | `contextModuleFactory`实例         |\n| beforeCompile        | AsyncSeriesHook   | compilation 实例化需要的参数创建完毕之后                         | `compilationParams`                |\n| compile              | SyncHook          | 一次 compilation 编译创建之前                                    | `compilationParams`                |\n| thisCompilation      | SyncHook          | 触发 compilation 事件之前执行                                    | `compilation`，`compilationParams` |\n| compilation          | SyncHook          | compilation创建成功之后                                          | `compilation`，`compilationParams` |\n| make                 | AsyncParallelHook | 完成编译之前                                                     | `compilation`                      |\n| afterCompile         | AsyncSeriesHook   | 完成编译和封存（seal）编译产出之后                               | `compilation`                      |\n| shouldEmit           | SyncBailHook      | 发布构建后资源之前触发，回调必须返回`true`/`false`，`true`则继续 | `compilation`                      |\n| emit                 | AsyncSeriesHook   | 生成资源到 output 目录之前                                       | `compilation`                      |\n| afterEmit            | AsyncSeriesHook   | 生成资源到 output 目录之后                                       | `compilation`                      |\n| done                 | AsyncSeriesHook   | compilation完成之后                                              | `stats`                            |\n| failed               | SyncHook          | compilation失败                                                  | `error`                            |\n| invalid              | SyncHook          | 监听模式下，编译无效时                                           | `fileName`，`changeTime`           |\n| watchClose           | SyncHook          | 监听模式停止                                                     | 无                                 |\n\n> Tips：整个`Compiler`完整地展现了 Webpack 的构建流程：\n>\n> - 准备阶段：run之前做的事情都属于准备阶段，这阶段的calback入参以compiler为主； \n> - 编译阶段：这阶段以compilation的钩子为主，calback入参以compilation为主； \n> - 产出阶段：这阶段从compilation开始，最后回到Compiler钩子上，calback传入参数是跟结果相关的数据，包括stats、error\n\n钩子的调用需要使用`tap`、`tapPromise`或`tapAsync`\n\n```javascript\ncompiler.hooks.someHook.tap('MyPlugin', params => {    /* ... */ });\n```\n\n注解1: Resolver\n\nCompiler 的 Resolver 是指来自于enhanced-resolve模块，它主要功能是一个提供异步require.resolve()，即从哪里去查找文件的路径，可以通过Webpack的resolve和resolveLoader来配置。Compiler类有三种类型的内置 Resolver：\n\n- Normal：通过绝对路径或相对路径，解析一个模块； \n- Context：通过给定的上下文（context）解析一个模块； \n- Loader：解析一个 webpack loader。\n\n注解2： ：`thisCompilation`和`compilation`\n\n这里为什么会有 thisCompilation和compilation 两个钩子呢？其实是跟子编译（child compiler）有关， Compiler 实例通过 createChildCompiler 方法可以创建子编译实例 childCompiler。创建childCompiler时，childCompiler会复制 compiler 实例的任务点监听器。compilation的钩子会被复制，而 的钩子会被复制，而 thisCompilation 钩子则 钩子则不会被复制。\n\n### Compilation\n\n在 Compilation 阶段，模块会被加载(loaded)、封存(sealed)、优化(optimized)、分块(chunked)、哈希(hashed)和重新创建(restored)，Compilation 对象包含了当前的模块资源、编译生成资源、变化的文件等。当 Webpack 以监听（watch）模式运行时，每当检测到一个文件变化，一次新的 Compilation 将被创建。Compilation 对象也提供了很多事件回调供插件做扩展，通过 Compilation 也能读取到 Compiler 对象。\n\n#### Compilation钩子\n\ncompilation先从单个 module 开始处理，查找依赖关系， 最后完成单个module 处理，完成全部modules 之后，开始 chunks 阶段处理，最后在根据优化配置，按需生成 assets。\n\n带★是比较重要的\n\n| 钩子名                    | Tapable 类型      | 触发时机                                                                  | 传入 callback 的参数                             |\n| :------------------------ | :---------------- | :------------------------------------------------------------------------ | :----------------------------------------------- |\n| buildModule               | SyncHook          | 在模块构建开始之前触发                                                    | `module`                                         |\n| rebuildModule             | SyncHook          | 在重新构建一个模块之前触发                                                | `module`                                         |\n| failedModule              | SyncHook          | 模块构建失败时执行                                                        | `module`，`error`                                |\n| succeedModule             | SyncHook          | 模块构建成功时执行                                                        | `module`                                         |\n| finishModules             | SyncHook          | 所有模块都完成构建                                                        | `module`                                         |\n| finishRebuildingModule    | SyncHook          | 一个模块完成重新构建                                                      | `module`                                         |\n| seal                      | SyncHook          | ★编译（compilation）停止接收新模块时触发                                  | `module`                                         |\n| unseal                    | SyncHook          | 编译（compilation）开始接收新模块时触发                                   | `module`                                         |\n| optimizeDependencies      | SyncBailHook      | 依赖优化开始时触发                                                        | `modules`                                        |\n| afterOptimizeDependencies | SyncHook          | 依赖优化结束时触发                                                        | `modules`                                        |\n| optimize                  | SyncHook          | ★优化阶段开始时触发                                                       | `modules`                                        |\n| optimizeModules           | SyncBailHook      | ★模块的优化                                                               | `modules`                                        |\n| afterOptimizeModules      | SyncHook          | 模块优化结束时触发                                                        | `modules`                                        |\n| optimizeChunks            | SyncBailHook      | ★优化 chunks                                                              | `chunks`                                         |\n| afterOptimizeChunks       | SyncHook          | chunk 优化完成之后触发                                                    | `chunks`                                         |\n| optimizeTree              | AsyncSeriesHook   | 异步优化依赖树                                                            | `chunks`，`modules`                              |\n| afterOptimizeTree         | SyncHook          | 异步优化依赖树完成时                                                      | `chunks`，`modules`                              |\n| optimizeChunkModules      | SyncBailHook      | 优化单个chunk中的 modules 开始                                            | `chunks`                                         |\n| afterOptimizeChunkModules | SyncHook          | 优化单个chunk中的 modules 结束                                            | `chunks`                                         |\n| shouldRecord              | SyncHook          |                                                                           | `chunks`                                         |\n| reviveModules             | SyncHook          | 从 records 中恢复模块信息                                                 | `modules`，`records`                             |\n| optimizeModuleOrder       | SyncHook          | 将模块从最重要的到最不重要的进行排序                                      | `chunks`                                         |\n| beforeModuleIds           | SyncHook          | 处理 modulesId 之前                                                       | `modules`                                        |\n| moduleIds                 | SyncHook          | 处理 modulesId                                                            | `modules`                                        |\n| optimizeModuleIds         | SyncHook          | 优化 modulesId                                                            | `chunks`                                         |\n| afterOptimizeModuleIds    | SyncHook          | 优化 modulesId之后                                                        | `chunks`                                         |\n| reviveChunks              | SyncHook          | 从 records 中恢复 chunk 信息                                              | `modules`，`records`                             |\n| optimizeChunkOrder        | SyncHook          | 将 chunk 从最重要的到最不重要的进行排序                                   | `chunks`                                         |\n| beforeOptimizeChunkIds    | SyncHook          | chunk id 优化之前触发                                                     | `chunks`                                         |\n| optimizeChunkIds          | SyncHook          | chunk id 优化开始触发                                                     | `chunks`                                         |\n| afterOptimizeChunkIds     | SyncHook          | chunk id 优化结束触发                                                     | `chunks`                                         |\n| recordModules             | SyncHook          | 将模块信息存储到 records                                                  | `modules`，`records`                             |\n| recordChunks              | SyncHook          | 将 chunk 信息存储到 records                                               | `chunks`，`records`                              |\n| beforeHash                | SyncHook          | 在编译被哈希（hashed）之前                                                | -                                                |\n| afterHash                 | SyncHook          | 在编译被哈希（hashed）之后                                                | -                                                |\n| record                    | SyncHook          | 将 compilation 相关信息存储到 records 中                                  | `compilation`，`records`                         |\n| beforeChunkAssets         | SyncHook          | 在创建 chunk 资源（asset）之前                                            | `chunks`                                         |\n| additionalChunkAssets     | SyncHook          | 为 chunk 创建附加资源（asset）                                            | `chunks`                                         |\n| additionalAssets          | AsyncSeriesHook   | ★为编译（compilation）创建附加资源（asset）                               | -                                                |\n| optimizeChunkAssets       | AsyncSeriesHook   | ★优化所有 chunk 资源（asset）                                             | `chunks`                                         |\n| afterOptimizeChunkAssets  | SyncHook          | chunk 资源（asset）已经被优化                                             | `chunks`                                         |\n| optimizeAssets            | AsyncSeriesHook   | ★优化存储在 compilation.assets 中的所有资源（asset）                      | `assets`                                         |\n| afterOptimizeAssets       | SyncHook          | 优化compilation.assets 中的所有资源（asset）之后                          | `assets`                                         |\n| moduleAsset               | SyncHook          | 一个模块中的一个资源被添加到编译中                                        | `module`，`filename`                             |\n| chunkAsset                | SyncHook          | 一个 chunk 中的一个资源被添加到编译中                                     | `chunk`，`filename`                              |\n| assetPath                 | SyncWaterfallHook | asset 路径确认之后                                                        | `filename`，`data`                               |\n| childCompiler             | SyncHook          | 子编译（compiler）触发                                                    | `childCompiler`，`compilerName`，`compilerIndex` |\n| normalModuleLoader        | SyncHook          | ★普通模块 loader，真正（一个接一个地）加载模块图（graph）中所有模块的函数 | `loaderContext`，`module`                        |\n\n#### Stats\n\n在webpack的回调函数——`webpack(cofnig, (err, stats) => {})`中会得到stats对象，这个对象实际来自于`Compilation.getStats()`，返回的是主要含有`modules`、`chunks`和`assets`三个属性值的对象。\n\n- modules： 记录了所有解析后的模块\n- chunks：记录了所有chunk\n- assets：记录了所有要生成的文件\n\nStats对象本质是来自于`lib/Stats.js`的类的实例。常用的方法：\n\n- stats.hasWarnings()\n- stats.hasErrors()\n- stats.toJson()\n- stats.toString()\n\n#### Stats对象数据结构\n\n在webpack的回调中获取stats，然后再调用`toJson`方法获取stats的数据接口\n\n```javascript\nwebpack(config, (err, stats) => {\n    console.log(stats.toJson())\n})\n```\n\nStats对象可以通过`webpack-cli`打包成一个json文件：`webpack --profile --json > compilation-stats.json`\n\n数据结构如下：\n\n```json\n{\n    \"version\": \"4.29.6\", // 用来编译的 webpack 的版本\n    \"hash\": \"11593e3b3ac85436984a\", // 编译使用的 hash\n    \"time\": 2469, // 编译耗时 (ms)\n    \"filteredModules\": 0, // 当 `exclude`传入`toJson` 函数时，统计被无视的模块的数量\n    \"outputPath\": \"/\", // path to webpack 输出目录的 path 路径\n    \"assetsByChunkName\": {\n        // 用作映射的 chunk 的名称\n        \"main\": \"web.js?h=11593e3b3ac85436984a\",\n        \"named-chunk\": \"named-chunk.web.js\",\n        \"other-chunk\": [\"other-chunk.js\", \"other-chunk.css\"]\n    },\n    \"assets\": [\n        // asset 对象 (asset objects) 的数组\n    ],\n    \"chunks\": [\n        // chunk 对象 (chunk objects) 的数组\n    ],\n    \"modules\": [\n        // 模块对象 (module objects) 的数组\n    ],\n    \"errors\": [\n        // 错误字符串 (error string) 的数组\n    ],\n    \"warnings\": [\n        // 警告字符串 (warning string) 的数组\n    ]\n}\n```\n\n> stats.toJson可以指定要不要输出对应的数据。例如不想输出 modules 和 chunks，可以使用stats. toJson({modules: false, chunks: false})\n\n#### module\n\n在每个 module 中，我们可以得到它的所有信息，这些信息可以分为四大类：\n\n1. 基本信息：包括最基本的内容、大小、id；\n2. 依赖关系：`module.reasons`对象描述了这个模块被加入依赖图表的理由，包含了引入的方式、引入的 module 信息及其对应代码在第几行第几列等，可以通过这个计算出 module 之间的依赖关系图表（graph）；\n3. chunks 和 assets 关系：`module.chunks`和`module.assets`包含到 chunks 和 assets 中的对应 id 等；\n4. 被 webpack 处理的后的信息：包含`module.failed`、`module.errors`、`module.warnings`等。\n\n```json\n{\n    \"assets\": [\n        // asset对象 (asset objects)的数组\n    ],\n    \"built\": true, // 表示这个模块会参与 Loaders , 解析, 并被编译\n    \"cacheable\": true, // 表示这个模块是否会被缓存\n    \"chunks\": [\n        // 包含这个模块的 chunks 的 id\n    ],\n    \"errors\": 0, // 处理这个模块发现的错误的数量\n    \"failed\": false, // 编译是否失败\n    \"id\": 0, // 这个模块的ID (类似于 `module.id`)\n    \"identifier\": \"(webpack)\\\\test\\\\browsertest\\\\lib\\\\index.web.js\", // webpack内部使用的唯一的标识\n    \"name\": \"./lib/index.web.js\", // 实际文件的地址\n    \"optional\": false, // 每一个对这个模块的请求都会包裹在 `try... catch` 内 (与ESM无关)\n    \"prefetched\": false, // 表示这个模块是否会被 prefetched\n    \"profile\": {\n        // 有关 `--profile` flag 的这个模块特有的编译数据 (ms)\n        \"building\": 73, // 载入和解析\n        \"dependencies\": 242, // 编译依赖\n        \"factory\": 11 // 解决依赖\n    },\n    \"reasons\": [\n        // 见下文描述\n    ],\n    \"size\": 3593, // 预估模块的大小 (byte)\n    \"source\": \"// Should not break it...\\r\\nif(typeof...\", // 字符串化的输入\n    \"warnings\": 0 // 处理模块时警告的数量\n}\n```\n\n其中`module.reasons`数据结构如下：\n\n```json\n{\n    \"loc\": \"33:24-93\", // 导致这个被加入依赖图标的代码行数\n    \"module\": \"./lib/index.web.js\", // 所基于模块的相对地址 context\n    \"moduleId\": 0, // 模块的 ID\n    \"moduleIdentifier\": \"(webpack)\\\\test\\\\browsertest\\\\lib\\\\index.web.js\", // 模块的地址\n    \"moduleName\": \"./lib/index.web.js\", // 可读性更好的模块名称 (用于 \"更好的打印 (pretty-printing)\")\n    \"type\": \"require.context\", // 使用的请求的种类 (type of request)\n}\n```\n\n#### chunk\n\n在每个 chunk 中，信息也可以分为四大类：\n\n1. 基本信息：包括最基本的内容、大小、id；\n2. 来源：`chunk.origins`对象描述了这个模块被加入的理由，包含了引入的方式、引入的 module 信息及其对应代码在第几行第几列等，可以通过这个计算出 module 之间的依赖关系图表（graph）；\n3. 引用关系：`chunk.parents`和`chunk.children`被引用和引用的 ids；\n4. 包含和被包含：`chunk.files`和`chunk.modules`包含到 assets 和自己包含 modules 中信息等。\n\n```json\n{\n    \"entry\": true, // 表示这个 chunk 是否包含 webpack 的运行时\n    \"files\": [\n        // 一个包含这个 chunk 的文件名的数组\n    ],\n    \"filteredModules\": 0, // 见上文的 结构\n    \"id\": 0, // 这个 chunk 的id\n    \"initial\": true, // 表示这个 chunk 是开始就要加载还是 懒加载(lazy-loading)\n    \"modules\": [\n        // 模块对象 (module objects)的数组\n        \"web.js?h=11593e3b3ac85436984a\"\n    ],\n    \"names\": [\n        // 包含在这个 chunk 内的 chunk 的名字的数组\n    ],\n    \"origins\": [\n        // 下文详述\n    ],\n    \"parents\": [], // 父 chunk 的 ids\n    // 生成 assets 的原因\n    \"reason\": \"split chunk (cache group: asyncVendors) (name: async)\",\n    \"hash\": \"170746935298270ad813\",\n    // 自己引用谁\n    \"children\": [],\n    // 引用的顺序\n    \"childrenByOrder\": {},\n    \"modules\": [],\n    \"rendered\": true, // 表示这个 chunk 是否会参与进编译\n    \"size\": 188057 // chunk 的大小(byte)\n}\n```\n\n`chunk.origins`对应的格式如下：\n\n```json\n{\n    \"loc\": \"\", // 具体是哪行生成了这个chunk\n    \"module\": \"(webpack)\\\\test\\\\browsertest\\\\lib\\\\index.web.js\", // 模块的位置\n    \"moduleId\": 0, // 模块的ID\n    \"moduleIdentifier\": \"(webpack)\\\\test\\\\browsertest\\\\lib\\\\index.web.js\", // 模块的地址\n    \"moduleName\": \"./lib/index.web.js\", // 模块的相对地址\n    \"name\": \"main\", // chunk的名称\n    \"reasons\": [\n        // 模块对象中`reason`的数组\n    ]\n}\n```\n\n#### asset\n\n`asset`相对简单一些，内容如下：\n\n```json\n{\n    \"chunkNames\": [], // 这个 asset 包含的 chunk\n    \"chunks\": [10, 6], // 这个 asset 包含的 chunk 的 id\n    \"emitted\": true, // 表示这个 asset 是否会让它输出到 output 目录\n    \"name\": \"10.web.js\", // 输出的文件名\n    \"size\": 1058 // 文件的大小\n}\n```","tags":["javascript","webpack","架构"],"categories":["工程化"]}]